1
00:00:00,000 --> 00:00:04,600
started. Can you hear me? Testing?

2
00:00:04,600 --> 00:00:06,600
They're supposed to be in their place.

3
00:00:06,600 --> 00:00:09,200
I think this needs... Alright, there we go. Thanks.

4
00:00:09,200 --> 00:00:12,800
Okay, we're gonna call this meeting to order.

5
00:00:12,800 --> 00:00:18,300
I'm Rob Penzer. I'm the Associate Director of the Helix Center and welcome to

6
00:00:18,300 --> 00:00:22,400
the last roundtable for this academic year.

7
00:00:22,400 --> 00:00:26,700
I wanted to make some announcements about upcoming programs for the following year.

8
00:00:26,700 --> 00:00:33,700
Future topics include women and science, climate change and global paralysis,

9
00:00:33,700 --> 00:00:41,700
nationalism and fanaticism, limitation, infinity, complexity and emergence,

10
00:00:41,700 --> 00:00:49,700
immortality, the sublime meditation, mystery and the unknown, free will,

11
00:00:49,700 --> 00:00:58,700
genes, computers and medicine, epigenetics, memory, consciousness, understanding genius.

12
00:00:58,700 --> 00:01:06,700
I want to make special note of an event on Saturday October 12th and Sunday October 13th,

13
00:01:06,700 --> 00:01:11,700
the Helix Center in conjunction with the Algama Foundation of Switzerland will be hosting

14
00:01:11,700 --> 00:01:15,700
an international gathering of scholars drawn from the arts and sciences to explore the

15
00:01:15,700 --> 00:01:20,700
significance of the work of A.B. Warburg for art, neuroscience and psychoanalysis.

16
00:01:20,700 --> 00:01:25,700
We will re-examine his work through the compound lenses of current knowledge of dynamic memory,

17
00:01:25,700 --> 00:01:29,700
the Freudian unconscious and historical scholarship with a focus on four areas,

18
00:01:29,700 --> 00:01:35,700
neurostatics, memory and unconscious, psychosis and creativity,

19
00:01:35,700 --> 00:01:39,700
Bizvanger and Warburg and classical and Renaissance art.

20
00:01:39,700 --> 00:01:43,700
Participants include historian Christopher Johnson, author of memory,

21
00:01:43,700 --> 00:01:48,700
metaphor and A.B. Warburg's Atlas of Images, historian and psycho analyst Peter Lohanburg,

22
00:01:48,700 --> 00:01:54,700
art historians David Friedberg and Thomas de Costa Kauffman, philosopher and art historian

23
00:01:54,700 --> 00:02:01,700
Georges Dider-Bermain, philosopher Andrea Pinotti, Warburg Institute historian Francois Quiviget,

24
00:02:01,700 --> 00:02:07,700
neuroscientist Christina Alberini, Anjan Chatterjee and Vittorio Gellese,

25
00:02:07,700 --> 00:02:10,700
who's name you may know from the discovery of her neurons,

26
00:02:10,700 --> 00:02:16,700
Pierre Magistretti, the Algama Foundation co-founder, novelist and essayist Siri Housved,

27
00:02:16,700 --> 00:02:21,700
and psycho-analysts Francois Answar May and Edna Sassyan.

28
00:02:21,700 --> 00:02:25,700
So now I'd like to introduce today's round table participants.

29
00:02:25,700 --> 00:02:32,700
Stephanie Brown is associate professor of preventive medicine at SUNY Stony Brook

30
00:02:32,700 --> 00:02:37,700
and an adjunct assistant professor at the Institute for Social Research at the University of Michigan.

31
00:02:37,700 --> 00:02:42,700
Dr. Brown's current research focuses on the neuro-affective mechanisms underlying altruistic

32
00:02:42,700 --> 00:02:47,700
and pro-social behavior. She examines the role that other focused motivational states play

33
00:02:47,700 --> 00:02:53,700
in stress regulation, the implications of helping induce stress regulation for physical health

34
00:02:53,700 --> 00:02:58,700
and longevity, and the contribution of other focused motivational states and behaviors

35
00:02:58,700 --> 00:03:03,700
to the darker side of human experience, including depression, suicidality and PTSD.

36
00:03:03,700 --> 00:03:07,700
These lines of research are designed to shed light into the mechanisms underlying a caregiving

37
00:03:07,700 --> 00:03:12,700
motivational system, including its evolutionary origins and its implications for compassionate

38
00:03:12,700 --> 00:03:19,700
care, medicine, economic behavior, ethnic and international conflict, and other political attitudes and behaviors.

39
00:03:19,700 --> 00:03:25,700
Lisa Cataldo is associate professor of pastoral care and counseling at the Fordham University

40
00:03:25,700 --> 00:03:29,700
Graduate School of Religion and Religious Education, where she directs the clinical program

41
00:03:29,700 --> 00:03:35,700
and teaches courses in clinical practice, professional ethics, psychology and religion, and trauma.

42
00:03:35,700 --> 00:03:39,700
She's a licensed psychoanalyst and is a supervisor and faculty member at the National Institute

43
00:03:39,700 --> 00:03:43,700
for the Psychotherapies and the Stephen A. Mitchell Center for Relational Studies.

44
00:03:43,700 --> 00:03:48,700
As a psychoanalyst and student of many of the world's religions, Dr. Cataldo's research

45
00:03:48,700 --> 00:03:52,700
explores the intersection of psychoanalytic psychology and religion spirituality,

46
00:03:52,700 --> 00:03:58,700
including issues of intersubjectivity, multiplicity and identity as they relate to religious or spiritual life.

47
00:03:58,700 --> 00:04:02,700
Most recently, her work has focused on the effects of early trauma and dissociation

48
00:04:02,700 --> 00:04:05,700
on the development of God images and the life of faith.

49
00:04:05,700 --> 00:04:09,700
Her writing and research are focused on practice with the aim of helping clinicians understand

50
00:04:09,700 --> 00:04:14,700
the religious or spiritual lives of patients and the ways to approach these issues in a therapeutic setting.

51
00:04:14,700 --> 00:04:20,700
Alan Leslie is professor of psychology and cognitive science at Rutgers University,

52
00:04:20,700 --> 00:04:25,700
where he directs the cognitive development laboratory, a fellow of the Association for Psychological Science

53
00:04:25,700 --> 00:04:28,700
and the American Academy of Arts and Sciences.

54
00:04:28,700 --> 00:04:31,700
Professor Leslie investigates the developmental neurocognitive mechanisms

55
00:04:31,700 --> 00:04:36,700
and domains specialized learning involved in abstract ideation emerging early in life,

56
00:04:36,700 --> 00:04:42,700
such as cause and effect, enduring object, one, two, three, social agent, believing,

57
00:04:42,700 --> 00:04:45,700
pretending, desiring, purpose and moral transgression.

58
00:04:45,700 --> 00:04:49,700
One of the principal authors of the research that discovered the theory of mind,

59
00:04:49,700 --> 00:04:54,700
impairment and autism, he also continues to study children with autistic spectrum disorders.

60
00:04:54,700 --> 00:04:59,700
Win Schwartz, a clinical psychologist and research psychoanalyst on the core faculty

61
00:04:59,700 --> 00:05:04,700
of the Massachusetts School of Professional Psychology, and on the faculties of Harvard Medical School

62
00:05:04,700 --> 00:05:06,700
and the Harvard Extension School.

63
00:05:06,700 --> 00:05:09,700
He is a co-editor of Advances in Descriptive Psychology.

64
00:05:09,700 --> 00:05:14,700
He has been a professor at Wellesley College and has taught at the Boston Psychoanalytic Society and Institute

65
00:05:14,700 --> 00:05:16,700
and the Massachusetts Institute of Psychoanalysis.

66
00:05:16,700 --> 00:05:21,700
His empirical research is focused on dreaming, memory and problem representation,

67
00:05:21,700 --> 00:05:24,700
non-hypnosis and episodic memory.

68
00:05:24,700 --> 00:05:29,700
As a student of descriptive psychology, Dr. Schwartz has been especially interested in theory-free,

69
00:05:29,700 --> 00:05:33,700
pre-empirical formulations of action and responsibility, the concept of hypnosis,

70
00:05:33,700 --> 00:05:38,700
the status dynamics of psychotherapy and supervision, and the parameters of empathic action.

71
00:05:38,700 --> 00:05:41,700
Currently, he is exploring liberation, improvisation and play,

72
00:05:41,700 --> 00:05:45,700
and the behavioral logic of social progress and reaction.

73
00:05:45,700 --> 00:05:50,700
He maintains a psychotherapy and supervision practice in Boston where he works with individuals and couples.

74
00:05:50,700 --> 00:05:59,700
So, somebody should begin.

75
00:05:59,700 --> 00:06:05,700
Okay, well, we're supposed to talk about empathy and altruism, I gather.

76
00:06:05,700 --> 00:06:08,700
So, let me just make this as a preliminary statement.

77
00:06:08,700 --> 00:06:15,700
Just a reminder that to be a person in a world of persons, as all of us are,

78
00:06:15,700 --> 00:06:21,700
means you already know, practically speaking, all you need to know about empathy and altruism

79
00:06:21,700 --> 00:06:27,700
in an ordinary sense, because you have to know about that in order to practice your life as a member

80
00:06:27,700 --> 00:06:30,700
in good standing of the community.

81
00:06:30,700 --> 00:06:35,700
What I'm going to suggest is that empathy is an ordinary feature of social practice,

82
00:06:35,700 --> 00:06:42,700
is an essential feature of how we know how to respond and coordinate our behaviors with others,

83
00:06:42,700 --> 00:06:47,700
and that we only become especially interested in it when it goes wrong,

84
00:06:47,700 --> 00:06:52,700
when we think we understand somebody and we discover that we have misunderstood them,

85
00:06:52,700 --> 00:06:57,700
or when we think we're being helpful and we discover that we've in fact not been helpful.

86
00:06:57,700 --> 00:06:58,700
That's one dilemma.

87
00:06:58,700 --> 00:07:03,700
The other dilemma is that our subject matter, psychology and its related disciplines,

88
00:07:03,700 --> 00:07:09,700
often get in the way and confuse us, I think, as to what the hell the subject matter is about.

89
00:07:09,700 --> 00:07:14,700
I think there is going to be, I think, some useful discussion about,

90
00:07:14,700 --> 00:07:21,700
to what extent we're talking about empathy as our shared understanding of each other's actions

91
00:07:21,700 --> 00:07:26,700
and the way in which we understand these actions in a way that we can appreciate being understood,

92
00:07:26,700 --> 00:07:33,700
and some other set of phenomena that may be secondary to that, may support that,

93
00:07:33,700 --> 00:07:36,700
or maybe something else instead.

94
00:07:36,700 --> 00:07:40,700
So, I think it's a fascinating subject, but like everything else in our subject matter,

95
00:07:40,700 --> 00:07:45,700
we have a hell of a time figuring out whether we're talking about the same thing or something else.

96
00:07:45,700 --> 00:07:50,700
So I think some of what we may end up wanting to play with is to get on the same page.

97
00:07:50,700 --> 00:07:56,700
I'll respond to that because in thinking about this, I think the biggest question is,

98
00:07:56,700 --> 00:08:02,700
are we all talking about the same thing when we're using words like empathy, compassion, and altruism?

99
00:08:02,700 --> 00:08:07,700
Because to me, they're quite distinct, and I come from a psychoanalytic background,

100
00:08:07,700 --> 00:08:12,700
not a research science background, so I'm really looking forward to hearing what you have to say.

101
00:08:12,700 --> 00:08:19,700
When I think about empathy, to me, empathy is a morally neutral term.

102
00:08:19,700 --> 00:08:24,700
So it's not necessarily a good thing. It's just a thing that we can do.

103
00:08:24,700 --> 00:08:32,700
So we can tune in to resonate with, understand somehow the interior experience of another person

104
00:08:32,700 --> 00:08:38,700
to a certain degree, never 100%, can never totally understand what I'm feeling.

105
00:08:38,700 --> 00:08:46,700
I could never totally understand what you're feeling, but we can get it to some extent, and that's a human capacity.

106
00:08:46,700 --> 00:08:51,700
So for me, that capacity for empathy can be used for good or ill.

107
00:08:51,700 --> 00:08:55,700
So some of the greatest empaths of all time are cult leaders.

108
00:08:55,700 --> 00:09:04,700
So I thought about this a lot, because to me, no one was more empathic than Jim Jones, or someone like that.

109
00:09:04,700 --> 00:09:12,700
Why? Because a real empath can understand what motivates another person and what their needs are,

110
00:09:12,700 --> 00:09:21,700
and then how you fulfill them may be in a negative way, maybe by tapping into their wounds and sort of addressing them.

111
00:09:21,700 --> 00:09:26,700
So to me, empathy itself is not a moral good. It's a capacity.

112
00:09:26,700 --> 00:09:34,700
Compassion would be, then, for me, the extension of empathy, that's the moral action or the moral good.

113
00:09:34,700 --> 00:09:39,700
And altruism is the action that comes out of compassion.

114
00:09:39,700 --> 00:09:48,700
So I would love to hear what other people think about that, because I think we often talk in our psychological world about empathy being kind of the goal.

115
00:09:48,700 --> 00:09:55,700
But to me, empathy is the beginning. It's not really the goal. What are you going to do with your empathy and how is your empathy formed,

116
00:09:55,700 --> 00:09:57,700
and for what purpose are you using it?

117
00:09:57,700 --> 00:09:59,700
That seems like a reasonable starting point.

118
00:09:59,700 --> 00:10:09,700
So I want to just add that your distinction between empathy and compassion is empathy being sort of value neutral, compassion being the good.

119
00:10:09,700 --> 00:10:22,700
I would argue we can't necessarily say altruism then is an outcome of compassion, because flying planes into buildings can be thought of as an altruistic behavior on behalf of the cause of the country.

120
00:10:22,700 --> 00:10:31,700
No, it can't. That's just bullshit. It's not an altruistic behavior. It's not an altruistic behavior.

121
00:10:31,700 --> 00:10:42,700
There's a certain way in which a certain kind of relativistic use of terms can undermine any fundamental meaning of those terms.

122
00:10:42,700 --> 00:10:49,700
There may be a community in which vis-a-vis that community, I have done something that enhanced my status in that community,

123
00:10:49,700 --> 00:10:52,700
or maybe even enhanced that community.

124
00:10:52,700 --> 00:11:02,700
But when you get to the level of talking about a destruction of the other in a fashion that has nothing whatsoever to do with an eye-to-bout relationship,

125
00:11:02,700 --> 00:11:12,700
a destruction of a mass destruction of the other based on a theology, based on a policy based on an ideology, it distorts the meaning.

126
00:11:12,700 --> 00:11:21,700
It fundamentally distorts any ordinary notion of the meaning to talk about that as either empathic or altruistic. It may serve a goal.

127
00:11:21,700 --> 00:11:26,700
It may serve a political goal. It may serve an economic goal. It may serve a religious goal.

128
00:11:26,700 --> 00:11:30,700
But as soon as that enters this discourse, we end up talking about something else.

129
00:11:30,700 --> 00:11:40,700
So let me get this straight. You're the one that wants us to define our terms ahead of time and not presume that we mean the same thing by the word.

130
00:11:40,700 --> 00:11:48,700
So when I use the term altruism, I submit to you that I might be using that term differently, and if I were to describe to you my definition,

131
00:11:48,700 --> 00:11:53,700
you might agree that something like the 9-11 event would be an example.

132
00:11:53,700 --> 00:11:57,700
I stand corrected. How are we going to get on the same page about that?

133
00:11:57,700 --> 00:12:01,700
Perhaps I could define what I mean by altruism.

134
00:12:01,700 --> 00:12:12,700
I take an evolutionary definition, a biological definition, and I use the word altruism to describe any behavior.

135
00:12:12,700 --> 00:12:21,700
So it's a behavior as opposed to an intention that leads to a benefit to the recipient at a cost to the self.

136
00:12:21,700 --> 00:12:32,700
And so, from an evolutionary perspective, would translate into beneficial reproductive consequences. But we can take a step back and talk about intention.

137
00:12:32,700 --> 00:12:43,700
But when I use the word altruism, I'm mostly referring to suppression of some sort of self-interest in a way that would promote allocating valuable resources to another entity or individual.

138
00:12:43,700 --> 00:12:53,700
Well, if you use the biological concept of fitness, though here, even you starting with your example, the biological fitness of the guys in the plains were sort of wiped out.

139
00:12:53,700 --> 00:12:56,700
That's not exactly what I disagree with that completely.

140
00:12:56,700 --> 00:12:58,700
You can take a next three or four generations out.

141
00:12:58,700 --> 00:13:05,700
No, I mean the definition of inclusive fitness, this isn't just we're not just talking about your own survival.

142
00:13:05,700 --> 00:13:15,700
So some uncle and cousin and Saudi is going to reproduce better because of that.

143
00:13:15,700 --> 00:13:16,700
Where it's 3,400 people got taken out of the gene pool here.

144
00:13:16,700 --> 00:13:29,700
Evolution works on the successful transmission of genes into the next generation, whether or not those genes are shared within yourself between you and your children or within a larger group.

145
00:13:29,700 --> 00:13:39,700
Or there are relationships that potentially connect people who are unrelated but who nevertheless are looking out for people who do share your genes.

146
00:13:39,700 --> 00:13:49,700
So we have a very, from a classical Darwinian sense, fitness is actually something much broader than the individual survival.

147
00:13:49,700 --> 00:13:51,700
No, I understand that. But that's what I'm raising the question.

148
00:13:51,700 --> 00:13:55,700
In this particular example, why would you apply altruism there?

149
00:13:55,700 --> 00:14:05,700
Because you're raising an empirical question whether the fitness, whether there's going to be a differential reproductive success increase based on some set of acts.

150
00:14:05,700 --> 00:14:08,700
That involves self-sacrifice.

151
00:14:08,700 --> 00:14:21,700
All that can happen, all that we have to hypothesize or postulate is that whatever neural hardwearing that we have that causes us to sacrifice to raise children, for example,

152
00:14:21,700 --> 00:14:31,700
helpless infants to reproductive age, whatever neural architecture is designed for that purpose, that parenting purpose somehow gets triggered in other instances.

153
00:14:31,700 --> 00:14:33,700
That's all that we have to hypothesize.

154
00:14:33,700 --> 00:14:38,700
And is there any evidence that this kind of event had an impact in that form? That's right, I'm saying it's an empirical question.

155
00:14:38,700 --> 00:14:50,700
No, what I'm saying is that the empirical, we don't actually have to demonstrate that there was an impact of that event on anybody's individual reproductive success on their inclusive fitness,

156
00:14:50,700 --> 00:15:05,700
on the inclusive fitness of others. There may be monetary exchanges that went on. There may be solidification of the Al Qaeda in group that benefited,

157
00:15:05,700 --> 00:15:10,700
you know, particular nieces and nephews of the leadership. I don't know, I'm just guessing.

158
00:15:10,700 --> 00:15:13,700
But there may be things like that, but that's really not the point.

159
00:15:13,700 --> 00:15:28,700
The point isn't whether the resources did benefit in that instance. All I'm saying is that we could use the term altruism to describe what happened because individuals who commit crimes,

160
00:15:28,700 --> 00:15:36,700
crimes or who are soldiers during wartime, who sacrifice themselves on behalf of a group or a cause or a country,

161
00:15:36,700 --> 00:15:44,700
that that basic tendency, that basic human tendency derives from this sort of willingness to risk one's life to benefit others.

162
00:15:44,700 --> 00:15:52,700
So can I, I'm going to ask you a question because this is interesting to me. I'm not an evolutionary person. I find it really interesting.

163
00:15:52,700 --> 00:15:58,700
So what I'm hearing is that from this point of view, altruism is also is morally neutral.

164
00:15:58,700 --> 00:16:11,700
Altruism is not a moral good. You're saying it's just the willingness to sacrifice oneself for a cause, whether that cause is good or evil, right, in the minds of the larger social group.

165
00:16:11,700 --> 00:16:27,700
That's my docket. Okay. So part of the issue, even part of why this argument's broken out so fast is not simply because we have different definitions of terms and so forth.

166
00:16:27,700 --> 00:16:44,700
But we think about these problems from very different angles. So if you're thinking about empathy or altruism at a personal level, the kind of level that we consciously experience,

167
00:16:44,700 --> 00:17:00,700
it's a great puzzle by anybody who would sacrifice the life for some greater cause that they perceive. Your particular approach is from an evolutionary point of view.

168
00:17:00,700 --> 00:17:14,700
So they have this sort of point of view centered on a gene that doesn't have any experiences or consciousness or anything of that sort and doesn't really entertain ideas. It's just, it's actually just a chemical.

169
00:17:14,700 --> 00:17:31,700
But it's a self reproducing chemical and it tries to spread simply because of that's its nature, it's an entire physical process.

170
00:17:31,700 --> 00:17:44,700
And so it's a very different angle, which is as a question in cognitive science and it's sort of quite interesting because it relates to the personal level.

171
00:17:44,700 --> 00:18:02,700
And it also relates to the evolutionary level. And the cognitive science approach is something that's been growing over the last 34 years and now becoming very much part of neuroscience.

172
00:18:02,700 --> 00:18:19,700
And it's the approach to trying to understand the brain in terms of how it creates the mind. So it's sort of trying to bridge between these two very different levels, the biological and the personal.

173
00:18:19,700 --> 00:18:32,700
I don't think ever quite makes it to the personal level. So there's still a gap that remains. But that's the general framework that my work sit situates in.

174
00:18:32,700 --> 00:18:49,700
And within that, my approach is to be interested in the very beginnings of the development of the brain and its functioning in babies and preschool kids.

175
00:18:49,700 --> 00:19:02,700
And we study these questions experimentally. And the field has been going perhaps for about 20, 30 years, a little bit longer.

176
00:19:02,700 --> 00:19:10,700
And it's been making extraordinary progress over that time. So I end up knowing a little bit more about empathy.

177
00:19:10,700 --> 00:19:28,700
And I thought resonate to Lisa's opening remarks that empathy can be thought of as in a way that's not, it isn't valence, that's not as good or bad.

178
00:19:28,700 --> 00:19:35,700
Whereas perhaps something like altruism might be similarly an action.

179
00:19:35,700 --> 00:19:53,700
And I appreciate the problem that Stanford has brought up because altruism for evolutionary theory poses a puzzle that seems to run contrary to evolutionary theory, the notion of the selfish gene that simply acts to promote itself,

180
00:19:53,700 --> 00:20:09,700
but it's a very complex frequency in a population. And then it's hard to see why a behavior would seem to run against the interests of the individual.

181
00:20:09,700 --> 00:20:29,700
And cases are well testified in both other species and in our own. And so it's makes an interesting problem to understand. I think part of the answer to it can be given at the level which I study questions like this.

182
00:20:29,700 --> 00:20:51,700
But there are in fact, the attempt is to show that in fact there are benefits from altruism that occur. And one of the examples that comes from my field is drawn from game theory.

183
00:20:51,700 --> 00:21:01,700
It's a very simple game. There are two people in the game. And the one of the people in the game is appointed as the dictator.

184
00:21:01,700 --> 00:21:12,700
And they're giving say $10. And here's the game. The game is that the dictator can decide how much of the $10.

185
00:21:12,700 --> 00:21:27,700
Here she's going to give to this other person. Whatever amount that dictator decides the other person gets, including if the decision is to give them zero.

186
00:21:27,700 --> 00:21:47,700
And the remainder of the dictator actually gets to leave, gets to leave the lab with however much of that $10 they give to themselves. And it's comes from game themes, the branch of mathematics.

187
00:21:47,700 --> 00:22:03,700
And the mathematicians assume that the rational behavior in that game would be that the dictator keep the $10 and gives the other person nothing at all.

188
00:22:03,700 --> 00:22:08,700
After all, they've never seen this other person before. They never will see them again once they leave.

189
00:22:08,700 --> 00:22:21,700
So the natural thing to do, the sort of rational, defined in a certain kind of way, the way to win this game is to give your fellow nothing at all.

190
00:22:21,700 --> 00:22:36,700
Now that's not in fact what people do. In fact, people keep only about 70% of the $10. And they give away 30% and the mathematicians throw up their hands and say human beings behave

191
00:22:36,700 --> 00:22:42,700
in an irrational way. But it depends whether it's rational or not.

192
00:22:42,700 --> 00:22:48,700
This is how you define the game. Human beings refuse to play the mathematicians game.

193
00:22:48,700 --> 00:22:51,700
But they just play this altruistic game.

194
00:22:51,700 --> 00:23:02,700
I think this way is useful to start with what people actually do and what the nature of a live life looks like.

195
00:23:02,700 --> 00:23:15,700
We start, and this makes remarks in preface to a question about how brain mind or brain behavior research might proceed, sometimes proceed, often doesn't.

196
00:23:15,700 --> 00:23:24,700
And that is, let's say for example that we take for granted because we see it, we practice it, we live it, that we more or less understand each other.

197
00:23:24,700 --> 00:23:32,700
And that we get it right often enough so that we can hold hands and walk across the street that we can know what hurt each other's feelings.

198
00:23:32,700 --> 00:23:36,700
I can actually feel bad because if I don't put in the tacking remarks of yours, which I apologize for.

199
00:23:36,700 --> 00:23:38,700
And I can reciprocally feel bad.

200
00:23:38,700 --> 00:23:42,700
It felt sort of unbecoming and I feel pretty awkward about it right now.

201
00:23:42,700 --> 00:23:46,700
But all of this is part of shared social practices, shared understandings.

202
00:23:46,700 --> 00:23:54,700
We know how to understand when there's empathic behavior, when there's lapses of empathic behavior.

203
00:23:54,700 --> 00:24:05,700
We also know as a matter of course that at times we take care of other people without at least at the forefront concerns for ourselves.

204
00:24:05,700 --> 00:24:13,700
And I'm not thinking about whether it's going to help me get laid or whether it's going to help pass on my genes or my cousins' genes or other members of my tribes' genes.

205
00:24:13,700 --> 00:24:16,700
It may very well have that consequence in the long run.

206
00:24:16,700 --> 00:24:18,700
But those aren't what's on my mind.

207
00:24:18,700 --> 00:24:21,700
What's on my mind is that I want to make my kids life better.

208
00:24:21,700 --> 00:24:23,700
I want to make my neighbors life better.

209
00:24:23,700 --> 00:24:27,700
I want to feel satisfied.

210
00:24:27,700 --> 00:24:29,700
There's lots of things that I want to do.

211
00:24:29,700 --> 00:24:31,700
I want to behave fairly.

212
00:24:31,700 --> 00:24:36,700
My perspectives, my rational perspectives aren't simply a hedonic or prudent.

213
00:24:36,700 --> 00:24:38,700
They're also ethical and aesthetic.

214
00:24:38,700 --> 00:24:53,700
I also have some built-in sense of being a person in the world of people, being a member of our community, of some notion of justice and fairness, of some notion of what fits together in ordinary practices, of what feels good, and what is in my self-interest.

215
00:24:53,700 --> 00:25:00,700
And all of those are intrinsic considerations that mark an ordinary person's behavior.

216
00:25:00,700 --> 00:25:09,700
Now, if we start with the fact that people already do this, then I think the problem for brain research isn't so much.

217
00:25:09,700 --> 00:25:14,700
It becomes, in fact, well, how can a brain support doing that?

218
00:25:14,700 --> 00:25:17,700
And I think often we get it somewhat ass backwards.

219
00:25:17,700 --> 00:25:29,700
We start with some mechanistic notion, some deterministic notion, some theology, some a priori commitment to a particular view of science or what knowledge or rationality is.

220
00:25:29,700 --> 00:25:33,700
And then from there, we can't get to the ordinary things that we do.

221
00:25:33,700 --> 00:25:36,700
And so we end up saying, well, I guess that's not really what's happening here.

222
00:25:36,700 --> 00:25:38,700
Something else must be happening here.

223
00:25:38,700 --> 00:25:43,700
And so what I'm describing and sort of advocating is what I guess is generally called a top-down approach.

224
00:25:43,700 --> 00:25:53,700
That we begin with a full understanding of what people actually do with an adequate literary dramatic description of the way lives actually unfold.

225
00:25:53,700 --> 00:25:59,700
And then it's our job as scientists, insofar as we want to do normal science, is to account for that.

226
00:25:59,700 --> 00:26:16,700
And I think what happens is that if in our production of a scientific argument, if we can't get from our science to what we already know we know how to do, then I think the question generally should be, well, there's probably something wrong with the science and not with something we already know how to do.

227
00:26:16,700 --> 00:26:23,700
And part of my concern here is that we already, you know, we have some shared meanings about altruism.

228
00:26:23,700 --> 00:26:34,700
There was a level of detail where we start to become, I think, we begin to differ in terms of its motivation, whether it's motivation is a cellular motivation, whatever that would be,

229
00:26:34,700 --> 00:26:41,700
whether it's motivation is self-satisfaction or ethics or self-interest or what have you.

230
00:26:41,700 --> 00:26:49,700
But what we mean is I'm doing something for somebody else in which it counts more that I'm doing it for them than what rewards I get.

231
00:26:49,700 --> 00:26:53,700
They're up to the boundary condition of self-sacrifice.

232
00:26:53,700 --> 00:26:59,700
When we talk about empathy, we're talking about some vision in which I understand your intentionality.

233
00:26:59,700 --> 00:27:08,700
I understand what you're trying to do, what the significances are of your actions, which is to say, I know something about what you want, what you're recognizing, what you know how to do,

234
00:27:08,700 --> 00:27:13,700
and what significance it has for you, those being some parameters of an empathic act.

235
00:27:13,700 --> 00:27:22,700
And I know how to represent my understanding of you in a way you can tolerate being understood, in which my understanding of you isn't exploited, doesn't strip you naked, doesn't violate you.

236
00:27:22,700 --> 00:27:37,700
It may manipulate you in the very ways in which a person who's feeling understood often wants to get closer to the person they're feeling understood by or further away if they don't want to be understood.

237
00:27:37,700 --> 00:27:45,700
But that involves some ordinary sense of an appreciation of the ongoing intentionality, the ongoing significance in mental states of the other person.

238
00:27:45,700 --> 00:27:48,700
However we do it, however we do it.

239
00:27:48,700 --> 00:28:01,700
But what you are saying is you already have the answers to the question of empathy and altruism, and the way you just described it, you gave the answers rather than the other position, which is, let's see if we can understand these things better.

240
00:28:01,700 --> 00:28:17,700
That we use everyday language, what you just described everyday feeling, but what if that's nothing to do exactly with what's really happening on a scientific basis that would allow us then to distinguish between various things that we put under one heading.

241
00:28:17,700 --> 00:28:20,700
I think it's a reasonable maxim that people take at that thing.

242
00:28:20,700 --> 00:28:28,700
So if you were to ask the question instead of giving the answers, how would you ask the questions about empathy and altruism?

243
00:28:28,700 --> 00:28:31,700
Well, would you think the issues lie?

244
00:28:31,700 --> 00:28:32,700
Here's the question.

245
00:28:32,700 --> 00:28:39,700
And the question comes, the way Wittgenstein began on surgery, he says, if you grant that there's one hand in front of me, all the rest follows.

246
00:28:39,700 --> 00:28:43,700
If you say there's not one hand in front of me, I can ask you to look closer.

247
00:28:43,700 --> 00:28:52,700
Or parallel to that, what are your reasons for not assuming or seeing things are as they seem?

248
00:28:52,700 --> 00:29:03,700
People take it that things are as they seem until or unless they have reasons to think otherwise. The scientific enterprise generally doesn't do a whole lot for us in amplifying the way things already seem.

249
00:29:03,700 --> 00:29:05,700
It sometimes will show us something hard.

250
00:29:05,700 --> 00:29:09,700
The earth's in flat until it was found that it wasn't flat.

251
00:29:09,700 --> 00:29:13,700
So your position would say, look, the earth is flat. Why should we worry about it?

252
00:29:13,700 --> 00:29:19,700
No need to go further. I feel it's flat, I see it's flat, I see there's the horizon, that's it.

253
00:29:19,700 --> 00:29:30,700
Well, actually, that's not my position, but it bears a family resemblance, which is at some point I can't get away with the idea that the world is flat.

254
00:29:30,700 --> 00:29:36,700
At some point, and that's why the person takes it as they seem until or unless they have reason enough to think otherwise.

255
00:29:36,700 --> 00:29:47,700
If you're living in the plains of Missouri and it's seven or eight hundred years ago, the world's pretty flat and you get away with it.

256
00:29:47,700 --> 00:29:57,700
If you're a mariner and you want to move all the way from here to India, at some point you're going to discover that there's something wrong with that algorithm or that method of understanding.

257
00:29:57,700 --> 00:30:01,700
So the question is, where does the question come from?

258
00:30:01,700 --> 00:30:15,700
I mean, Freud, for example, and Darwin and a number of others turned things upside down by pointing out that there were all sorts of other factors that made things that looked one way actually have to some extent other sets of meanings.

259
00:30:15,700 --> 00:30:19,700
But that's different than saying none of us or any of us.

260
00:30:19,700 --> 00:30:29,700
It's one thing to say that all behavior is motivated sexually or aggressively, which of course is a distortion of Freud.

261
00:30:29,700 --> 00:30:41,700
But it's another thing to say that these behaviors that you were claiming had nothing whatsoever to do with sex, in fact what kind of sexual and aggressive, by then building a case demonstrating through evidence.

262
00:30:41,700 --> 00:30:47,700
The scientific project requires building evidence for showing that things are not the way they seem.

263
00:30:47,700 --> 00:30:58,700
And so that's actually the only point that I'm trying to make in terms of this, which is that there wasn't providing an answer to empathy anymore that I provided to answer the question of how do I know how to get from here to the other side of the room.

264
00:30:58,700 --> 00:31:00,700
I just get up and walk, I do it.

265
00:31:00,700 --> 00:31:04,700
The question becomes, what happens if I can't do it successfully?

266
00:31:04,700 --> 00:31:10,700
Or if in fact, I think I'm walking across the room, but in fact I'm doing something else.

267
00:31:10,700 --> 00:31:20,700
So I just want to clarify the sort of defense of science, but also point out that you're making an excellent point from that really meshes with my understanding.

268
00:31:20,700 --> 00:31:26,700
First of all, science I think is maybe more precise to say it's about explanation.

269
00:31:26,700 --> 00:31:31,700
So we're using it to discover things that we don't understand.

270
00:31:31,700 --> 00:31:48,700
So which I would agree creates a bias, but in this case, I wonder, I struggled to figure out why science reduces everything to self-interest, which it does.

271
00:31:48,700 --> 00:32:00,700
Across the social and behavioral sciences, if you want to study something like relationships, you're going to find no field devoted to genuine concern for the well-being of another person.

272
00:32:00,700 --> 00:32:02,700
So that's what we're talking about in a relationship.

273
00:32:02,700 --> 00:32:06,700
Everything gets reduced to the benefits that individuals ultimately get in a relationship.

274
00:32:06,700 --> 00:32:07,700
That's just an example.

275
00:32:07,700 --> 00:32:27,700
So whether we're talking about what you raised with the mathematicians assuming that, or the economists assuming that people are going to keep as much money for themselves as they can, or the psychologists who decide that everything is about reinforcement and reward seeking and punishment avoiding and psychological

276
00:32:27,700 --> 00:32:30,700
hedonism, that's the question I have.

277
00:32:30,700 --> 00:32:48,700
Why is it that science seems to be, I've always argued it's because it's been progressing as an intuitive field and not actually doing the hard work to try to think about what are the implications of having social creatures that need to take care of one another to survive.

278
00:32:48,700 --> 00:32:53,700
I'm saying they're going with their intuition that everything feels selfish, but I have no idea.

279
00:32:53,700 --> 00:32:58,700
Why do you think science is assuming that selfish selflessness is an existent?

280
00:32:58,700 --> 00:32:59,700
It's an interesting question.

281
00:32:59,700 --> 00:33:06,700
When Wittgenstein ended the investigations with in psychology we have experimental method and conceptual confusion.

282
00:33:06,700 --> 00:33:13,700
Part of what I think was being noted and it's been something that's been struggled with in a variety of areas in psychology.

283
00:33:13,700 --> 00:33:22,700
The particular area that I'm mostly interested in, which is called descriptive psychology, has been an attempt to sort of start over by beginning to start with a particular area that I'm mostly interested in.

284
00:33:22,700 --> 00:33:34,700
Beginning with a general concept of person as a person being an individual with a history that involves deliberate action that occurs in a kind of dramaturgical fashion that you can see it tells a story.

285
00:33:34,700 --> 00:33:40,700
Their life is lived in the nature of a story of a set of episodes that have meaning.

286
00:33:40,700 --> 00:33:43,700
Then you come to the question, well what are the sources of meaning?

287
00:33:43,700 --> 00:33:45,700
What's intrinsic?

288
00:33:45,700 --> 00:34:06,700
Certainly self-interest is intrinsic, just as pleasure is intrinsic, but the concept of person, especially when we begin to look at the idea that a person is able to deliberate, to make choices, brings immediately certain other logical categories as things that are inherent in the practices of persons.

289
00:34:06,700 --> 00:34:20,700
Those involve the full range of aesthetics and ethics, the notions of justice or fairness, the notions of truth, rigor, objectivity, beauty, all of which are intrinsic, all of which are reasons to do something.

290
00:34:20,700 --> 00:34:25,700
Now there's been historical attempts to reduce all of these to one of the other categories.

291
00:34:25,700 --> 00:34:28,700
It's all really hedonics, or it's all really prudence.

292
00:34:28,700 --> 00:34:36,700
What those end up doing is distorting the fundamental meanings of ethics and aesthetics, for example.

293
00:34:36,700 --> 00:34:43,700
When you point out that in a general reading of psychology, what you see are these very narrowed visions.

294
00:34:43,700 --> 00:34:54,700
I think that's correct, and I think that's part of what has made our subject matter in some ways so unfortunately limited, but it's not intrinsically limited that way.

295
00:34:54,700 --> 00:34:57,700
Historically it happens to be limited that way.

296
00:34:57,700 --> 00:35:04,700
I think the key thing here is that this applies to both of your remarks.

297
00:35:04,700 --> 00:35:06,700
It is historical.

298
00:35:06,700 --> 00:35:25,700
Historically it has been the case that psychology and its various self-styled scientific forms has been committed to very simple kinds of ideas like

299
00:35:25,700 --> 00:35:33,700
symbolic, motivation, self-interest, only associations.

300
00:35:33,700 --> 00:35:37,700
Just very, very simple.

301
00:35:37,700 --> 00:35:42,700
Start to the mind.

302
00:35:42,700 --> 00:35:48,700
I think that's historically true, but I think that picture is actually kind of changing, that people are in fact.

303
00:35:48,700 --> 00:36:06,700
People like me are now in fact studying human nature without these assumptions that should reduce to something, you know, a handful of very simple, intrinsic properties.

304
00:36:06,700 --> 00:36:19,700
I think in fact there's a vast range of very sophisticated and very abstract properties that are intrinsic to the human mind from the outset.

305
00:36:19,700 --> 00:36:24,700
I think in fact to understand that is really to understand something about human nature.

306
00:36:24,700 --> 00:36:39,700
Part of the problem of being a psychologist of any sort is it's very hard to get away from the idea that you already understand your own mind and the mind of others.

307
00:36:39,700 --> 00:36:47,700
Science really only starts when a person recognizes that they don't know something.

308
00:36:47,700 --> 00:37:11,700
I mean that's actually the actual practicing scientist that's their life is trying to identify things that are not already known, that are not already understood to try to identify where the terror in cognita is where the dark places are and to go into those places

309
00:37:11,700 --> 00:37:25,700
and find a way of going into those places and casting light. Instead of being like the drunk man who's looking for his keys under the lampposts, you know, and he's asked about what he's doing, he's looking for his keys and say, well did you lose them here, is that why you're

310
00:37:25,700 --> 00:37:52,700
searching there there, well at least I can see here. If that's your approach to doing science you won't really ever achieve very much. So part of the problem is just to get a distance from your own mind, a distance from your own experience and try to get away from this idea that you actually know anything at all about how your mind works.

311
00:37:52,700 --> 00:38:11,700
In fact I think it's this feeling that you know how your mind works is largely an illusion, the brain, that's sort of a trick that the brain plays on the mind, it kind of gives the mind the feeling that it understands what the brain's doing, but in fact you don't really know anything about what the brain's doing

312
00:38:11,700 --> 00:38:28,700
anymore, you know what your stomach's doing when it digests food, I don't know, I don't think about it again, stomach knows what to do with it, that's pretty much the way the brain works. So asking questions about the brain is one way that you can get this scientific

313
00:38:28,700 --> 00:38:52,700
distance and another way to get this distance is to ask well what about a baby, because there's all these things that I know of, that I know about, I don't really know how I came to know most of these things, so for example I know something close to probably about 80 to a

314
00:38:52,700 --> 00:39:09,700
hundred thousand words in English, and I can't, I mean perhaps I can remember learning one or two of those words, but the vast majority of them I have no idea when or how I learned them, but I just did.

315
00:39:09,700 --> 00:39:23,700
So that's sort of, there are things that you think really hard, there are things about your brain, there are things that you know and experience now, you don't really understand where it came from, it just is so.

316
00:39:23,700 --> 00:39:47,700
But it's true that psychology, at the turn of last century, the big issue that a psychologist had was to try to be taken seriously by other scientists, and there was a sort of an inferiority feeling there, and so one way to get around that was to find something that you could reduce

317
00:39:47,700 --> 00:40:16,700
anything too, because that seemed to be the way that science worked although that's a kind of superficial understanding, but I think that's part of the background of why these kind of simple ideas were adopted, but on the other hand it's also partly not a bad way to approach things, start with some very simple ideas and push them, as long as you always remain open minded and don't dogmatically refuse to ever open your mind to any other questions,

318
00:40:16,700 --> 00:40:22,700
for example that this simple set of ideas may not actually be working.

319
00:40:22,700 --> 00:40:45,700
Well, the thing about science is that it does actually change, it does actually make progress over time, it seems to be one of the few areas that you can say that about, and I think that certain parts of psychology and brain science are beginning to be able to do that.

320
00:40:45,700 --> 00:40:52,700
So science is beginning to make progress although I don't want to exaggerate, just really how far I've got.

321
00:40:52,700 --> 00:41:12,700
One of the things that, so I realized, you guys are talking about empathy, it's just really what I would call theory of mind, the theory of mind that we have, and it's not really a theory I think, it's not really a theory about mind, but it is this intense

322
00:41:12,700 --> 00:41:21,700
theory of mind that we're weaning interest in the inner lives of other people that we have, and that seems to be a basic thing about human nature.

323
00:41:21,700 --> 00:41:41,700
And in this historical way, people that started to study thinking in children made the assumption that this ability, which would generally be called perspective taking, so thinking somebody else's point of view on

324
00:41:41,700 --> 00:42:03,700
a situation, that that was something that, oh, there was something very high level that you couldn't do until you were at least seven years old, and it was as a result of learning lots of language and having, which the seven year olds already have,

325
00:42:03,700 --> 00:42:20,700
being, it's culture rated to quite an advance degree, perhaps going to formal education, going to school, it was really going to be, it was bound to be, had to be a very late achievement, even in its most rudimentary forms.

326
00:42:20,700 --> 00:42:49,700
And I noticed that on the website, there's a reference to theory of mind, and it says that this is now known to emerge at about three years of age, and I thought, well, that's quite good, because people usually say it's about four and a half years of age, so it's quite good that this website has revised that, pushed it down about to three years of age, and I guess I'm here today to tell you that we've pushed that back still further.

327
00:42:49,700 --> 00:43:14,700
And now it looks like it emerges in the first year of life, probably in the second half of the first year of life, although it may be that I have to come back in two years time, and tell you that it's there in the first half of the first year, but anyway, that's already remarkably early, and it's very, very striking, this seems to be something that human babies

328
00:43:14,700 --> 00:43:20,700
do not let me remind you that this is to have no language whatsoever.

329
00:43:20,700 --> 00:43:39,700
In fact, they're just beginning to try to crack into language, they have no language whatsoever, they have virtually no, in culturation, I mean, you really have to push the boat out to say that they've been influenced by culture by that time.

330
00:43:39,700 --> 00:43:41,400
This really does begin to look,

331
00:43:41,400 --> 00:43:45,900
and I said it's an intrinsic property of the human brain.

332
00:43:45,900 --> 00:43:47,880
And I think if you find something that the human brain's

333
00:43:47,880 --> 00:43:50,640
doing very, very early on in life,

334
00:43:50,640 --> 00:43:52,440
which is probably a pretty good clue,

335
00:43:52,440 --> 00:43:54,240
that as far as the brain's concerned,

336
00:43:54,240 --> 00:43:56,120
this is something pretty basic.

337
00:43:56,120 --> 00:43:59,600
So I want to just jump in here.

338
00:43:59,600 --> 00:44:02,080
It seems like I'm not a scientist,

339
00:44:02,080 --> 00:44:04,680
so I'm a relational psychoanalyst.

340
00:44:04,680 --> 00:44:07,320
So a relational psychoanalytic point of view,

341
00:44:07,320 --> 00:44:10,440
that first, those first months of life,

342
00:44:10,440 --> 00:44:12,400
and that creation of the theory of mind,

343
00:44:12,400 --> 00:44:16,360
where the baby can sense that the other has a mind

344
00:44:16,360 --> 00:44:18,960
that's different and interacting,

345
00:44:18,960 --> 00:44:21,120
would seem to make a lot of sense, right?

346
00:44:21,120 --> 00:44:26,200
That that's a relational phenomenon that is intrinsic,

347
00:44:26,200 --> 00:44:27,760
but can only develop to the extent

348
00:44:27,760 --> 00:44:31,080
there's actually a person there interacting with the infant.

349
00:44:31,080 --> 00:44:34,880
The infant wouldn't develop that mind

350
00:44:34,880 --> 00:44:37,880
or that ability to empathize or connect

351
00:44:37,880 --> 00:44:39,920
with another person without a relationship.

352
00:44:39,920 --> 00:44:41,800
It's without a person there.

353
00:44:41,800 --> 00:44:42,920
They'd die, right?

354
00:44:42,920 --> 00:44:45,720
There has to be an interaction, right?

355
00:44:45,720 --> 00:44:49,040
So the relational aspect of that, to me,

356
00:44:49,040 --> 00:44:50,440
is really foundational.

357
00:44:50,440 --> 00:44:54,280
And I kind of want to shift our conversation a little bit,

358
00:44:54,280 --> 00:44:56,680
maybe just because I don't feel a lot to contribute

359
00:44:56,680 --> 00:44:58,080
to the discussion of science.

360
00:44:58,080 --> 00:45:04,280
But I think about, you know, I'm probably

361
00:45:04,280 --> 00:45:07,040
going to bring up a word that may blow up the whole situation

362
00:45:07,040 --> 00:45:08,880
because the word is religion.

363
00:45:08,880 --> 00:45:12,400
And so I'm a psychoanalyst and a psychologist of religion.

364
00:45:12,400 --> 00:45:16,400
Very particularly interested in people's psychology

365
00:45:16,400 --> 00:45:19,600
and their lives, their spiritual lives, or lives of faith,

366
00:45:19,600 --> 00:45:23,000
their lives of belief, whatever form that might take,

367
00:45:23,000 --> 00:45:26,760
including science, can be your religion that can count too.

368
00:45:26,760 --> 00:45:31,000
So thinking about some of the questions

369
00:45:31,000 --> 00:45:36,000
that we're posted on the blur about today.

370
00:45:36,000 --> 00:45:38,240
One that was included in there was,

371
00:45:38,240 --> 00:45:42,480
can people actually be altruistic in any kind of pure sense?

372
00:45:42,480 --> 00:45:47,680
Or is all acts of selflessness actually performed

373
00:45:47,680 --> 00:45:51,160
in some way in a self-interested way,

374
00:45:51,160 --> 00:45:52,360
even if it's unconscious?

375
00:45:52,360 --> 00:45:55,520
Even if there's an unconscious self-interest.

376
00:45:55,520 --> 00:45:57,920
And I wanted to talk about that a little bit

377
00:45:57,920 --> 00:46:03,280
because I think that we do see people, including ourselves,

378
00:46:03,280 --> 00:46:08,440
every day, acting in altruistic fashion in small ways

379
00:46:08,440 --> 00:46:10,840
and sometimes in big ways.

380
00:46:10,840 --> 00:46:13,400
And I just, I mentioned to the rubroity

381
00:46:13,400 --> 00:46:16,120
that I just saw Desmond Tutu last week in London

382
00:46:16,120 --> 00:46:21,280
received the Templeton Prize, humanitarian prize.

383
00:46:21,280 --> 00:46:23,200
This is basically a prize for altruism.

384
00:46:23,200 --> 00:46:24,040
That's what you get.

385
00:46:24,040 --> 00:46:26,160
And it's $2 million.

386
00:46:26,160 --> 00:46:26,660
Right?

387
00:46:26,660 --> 00:46:30,720
So Mother Teresa has won this prize.

388
00:46:30,720 --> 00:46:32,880
Nelson Mandela has won the prize.

389
00:46:32,880 --> 00:46:34,120
He wasn't planning that all along.

390
00:46:34,120 --> 00:46:34,720
He did these acts together.

391
00:46:34,720 --> 00:46:39,880
Apparently, he did not have the Dalai Lama won it last year.

392
00:46:39,880 --> 00:46:40,360
He was telling it.

393
00:46:40,360 --> 00:46:41,960
So I don't think the Dalai Lama was, you know,

394
00:46:41,960 --> 00:46:44,360
scheming his whole life to do all these good things

395
00:46:44,360 --> 00:46:46,440
so that he could get $2 million from Jack Temple.

396
00:46:46,440 --> 00:46:47,360
No, no, no, no.

397
00:46:47,360 --> 00:46:48,520
Right.

398
00:46:48,520 --> 00:46:54,960
So I think about people like that on a sort of larger scale.

399
00:46:54,960 --> 00:46:58,960
The people who, when I was a child, I wished I could be like.

400
00:46:58,960 --> 00:46:59,800
Right?

401
00:46:59,800 --> 00:47:03,000
Why would you wish you could be like a person like that?

402
00:47:03,000 --> 00:47:09,040
Who sacrifices their life, essentially, for other people?

403
00:47:09,040 --> 00:47:11,120
For the good of other people and not their own good,

404
00:47:11,120 --> 00:47:13,960
not to make $2 million from Jack Temple.

405
00:47:13,960 --> 00:47:15,560
Let me ask you a question about the way

406
00:47:15,560 --> 00:47:18,320
you're formulating this.

407
00:47:18,320 --> 00:47:20,440
And I think in some ways, one of the questions

408
00:47:20,440 --> 00:47:22,840
is whether or not the behavior is done intrinsically

409
00:47:22,840 --> 00:47:24,760
or instrumentally.

410
00:47:24,760 --> 00:47:27,680
If I'm going to do something good because I know when I'm

411
00:47:27,680 --> 00:47:31,200
finished, I'm going to get paid, like when I work

412
00:47:31,200 --> 00:47:32,960
in my private practice.

413
00:47:32,960 --> 00:47:34,520
You know, there's acts there that I think

414
00:47:34,520 --> 00:47:36,160
are intrinsically merit, but I'm also

415
00:47:36,160 --> 00:47:37,480
telling you're in my living.

416
00:47:37,480 --> 00:47:40,040
And that's part and parcel of the act.

417
00:47:40,040 --> 00:47:43,120
I'm not doing it just for the good of the other.

418
00:47:43,120 --> 00:47:44,480
So there's something both instrumental

419
00:47:44,480 --> 00:47:46,840
and I believe something intrinsic.

420
00:47:46,840 --> 00:47:48,360
But can there be, and I think that's

421
00:47:48,360 --> 00:47:50,080
in some ways the distinction.

422
00:47:50,080 --> 00:47:53,440
If I'm doing something that is intrinsic,

423
00:47:53,440 --> 00:47:55,640
I'm doing it for its own reason.

424
00:47:55,640 --> 00:47:58,560
If it's instrumental, I'm doing it because it's inherently

425
00:47:58,560 --> 00:48:00,440
tied to another goal.

426
00:48:00,440 --> 00:48:01,400
Now that's the first part.

427
00:48:01,400 --> 00:48:04,040
So this is what my question is.

428
00:48:04,040 --> 00:48:06,120
It seems to me that on logical grounds,

429
00:48:06,120 --> 00:48:08,280
if you have two reasons for doing something,

430
00:48:08,280 --> 00:48:11,160
you have more reason than if you only had one of those reasons.

431
00:48:11,160 --> 00:48:13,360
But that doesn't mean that either of those reasons

432
00:48:13,360 --> 00:48:16,720
are intrinsically tied to the other.

433
00:48:16,720 --> 00:48:22,320
That I can do something for the good of the other,

434
00:48:22,320 --> 00:48:28,440
for reasons that are ethical as an intrinsic reason.

435
00:48:28,440 --> 00:48:31,120
And I added some sacrifice to myself.

436
00:48:31,120 --> 00:48:35,040
And in doing so, feel satisfied.

437
00:48:35,040 --> 00:48:39,560
Now, is the feeling of satisfaction,

438
00:48:39,560 --> 00:48:41,960
does that make it instrumental?

439
00:48:41,960 --> 00:48:44,000
To the extent that you begin to argue that,

440
00:48:44,000 --> 00:48:46,440
then the concept of an intrinsic meaning

441
00:48:46,440 --> 00:48:50,840
loses any kind of quality.

442
00:48:50,840 --> 00:48:54,280
So one notion is, given that when we do good,

443
00:48:54,280 --> 00:48:56,400
we often feel satisfied in contrast

444
00:48:56,400 --> 00:48:59,840
to feeling nothing or feeling miserable.

445
00:48:59,840 --> 00:49:01,600
I suppose if we do good and we feel miserable,

446
00:49:01,600 --> 00:49:05,040
we actually describe that motivationally as masochistic,

447
00:49:05,040 --> 00:49:08,080
and we've got a whole other set of ways of explaining it.

448
00:49:08,080 --> 00:49:11,880
But if I do something for good, and doing something for good

449
00:49:11,880 --> 00:49:16,080
also accomplishes other means, that also are intrinsic.

450
00:49:16,080 --> 00:49:18,360
And so that's in some ways part of my confusion

451
00:49:18,360 --> 00:49:22,120
about this notion that somehow it needs to be unalloyed.

452
00:49:22,120 --> 00:49:25,360
It seems to me that it has to be intrinsic, not instrumental.

453
00:49:25,360 --> 00:49:28,080
But one can be doing a number of intrinsic things

454
00:49:28,080 --> 00:49:30,560
side by side without that destroying

455
00:49:30,560 --> 00:49:33,440
the merit of any one of them, unless, of course, it does.

456
00:49:33,440 --> 00:49:34,400
I agree.

457
00:49:34,400 --> 00:49:37,960
And I was thinking this week, discussing this

458
00:49:37,960 --> 00:49:43,480
with my partner, saying, he's a filmmaker, documentarian.

459
00:49:43,480 --> 00:49:45,760
He makes movies about people doing good things.

460
00:49:45,760 --> 00:49:47,640
That's basically what he does.

461
00:49:47,640 --> 00:49:51,760
So we, about altruistic people doing good things.

462
00:49:51,760 --> 00:49:53,080
And so we were talking about this.

463
00:49:53,080 --> 00:49:56,360
And I thought about this sort of unalloyed notion

464
00:49:56,360 --> 00:49:59,840
of altruism that somehow there's no good to the person.

465
00:49:59,840 --> 00:50:02,880
Otherwise, it's not altruistic in the pure sense.

466
00:50:02,880 --> 00:50:04,320
I don't, I agree with you.

467
00:50:04,320 --> 00:50:07,160
I don't think that's a necessary condition,

468
00:50:07,160 --> 00:50:11,160
because even if it's just feeling that you did the right thing,

469
00:50:11,160 --> 00:50:14,040
and that's a satisfying sense, it

470
00:50:14,040 --> 00:50:19,960
doesn't diminish the power or the ethical power

471
00:50:19,960 --> 00:50:21,360
of an altruistic act.

472
00:50:21,360 --> 00:50:25,240
But I was trying to think in my own,

473
00:50:25,240 --> 00:50:27,640
the stories I know about, do I know

474
00:50:27,640 --> 00:50:31,600
of a person who really ever did something that seems to me

475
00:50:31,600 --> 00:50:36,920
completely against their own interest for the benefit of others?

476
00:50:36,920 --> 00:50:41,080
And the only story that I could come up with that felt

477
00:50:41,080 --> 00:50:44,640
as close to that as I can imagine is Dietrich Bonhoeffer.

478
00:50:44,640 --> 00:50:47,680
So I don't know if all of you know who Dietrich Bonhoeffer was.

479
00:50:47,680 --> 00:50:50,760
But he was a Protestant minister and theologian,

480
00:50:50,760 --> 00:50:55,520
a German who wrote about doing good things for other people

481
00:50:55,520 --> 00:50:56,400
among other things.

482
00:50:56,400 --> 00:50:58,880
He had a wonderful book called The Cost of Discipleship.

483
00:50:58,880 --> 00:51:01,760
So how do you live a good life without cost to yourself?

484
00:51:01,760 --> 00:51:03,840
You can't.

485
00:51:03,840 --> 00:51:06,720
You have to give up something of yourself.

486
00:51:06,720 --> 00:51:09,520
But he came to the United States and could

487
00:51:09,520 --> 00:51:12,520
have stayed here for the rest of the war and spared his own life.

488
00:51:12,520 --> 00:51:16,120
He was not popular with the Nazis, as you can imagine,

489
00:51:16,120 --> 00:51:18,040
and decided not to do that.

490
00:51:18,040 --> 00:51:20,400
So he went back to Germany during the war

491
00:51:20,400 --> 00:51:23,240
and became part of the plot to assassinate Hitler.

492
00:51:23,240 --> 00:51:26,120
And he was a religious minister, right?

493
00:51:26,120 --> 00:51:26,760
Not the thing.

494
00:51:26,760 --> 00:51:29,720
You think most ministers would put at the top of their list

495
00:51:29,720 --> 00:51:33,480
that they're going to kill someone as a good act.

496
00:51:33,480 --> 00:51:39,680
And he was caught in that plot, and he was hung.

497
00:51:39,680 --> 00:51:44,840
So I thought about this from a religious person's point of view.

498
00:51:44,840 --> 00:51:48,880
And from Dietrich Bonhoeffer's own Protestant theology,

499
00:51:48,880 --> 00:51:51,840
the act of participating in the murder of another person,

500
00:51:51,840 --> 00:51:56,640
even if that person is Hitler, is immortal sin.

501
00:51:56,640 --> 00:52:00,160
He would go to hell for doing it.

502
00:52:00,160 --> 00:52:03,640
He would give up his hope of heaven

503
00:52:03,640 --> 00:52:05,320
by participating in this act.

504
00:52:05,320 --> 00:52:06,920
And his entire life was structured

505
00:52:06,920 --> 00:52:09,480
around this religious philosophy, where he would want

506
00:52:09,480 --> 00:52:12,000
to be in the presence of God after death.

507
00:52:12,000 --> 00:52:15,400
That would be the Christian view.

508
00:52:15,400 --> 00:52:18,320
And what he sacrificed was not only his physical life,

509
00:52:18,320 --> 00:52:21,240
but literally his salvation in order

510
00:52:21,240 --> 00:52:27,560
to save as many people as he possibly could.

511
00:52:27,560 --> 00:52:32,640
So I couldn't think of any possible good to him in that story.

512
00:52:32,640 --> 00:52:35,880
It's one of the most, to me, sort of purely altruistic acts

513
00:52:35,880 --> 00:52:38,800
that I can think of historically.

514
00:52:38,800 --> 00:52:40,400
I'm sure there are many, many others.

515
00:52:40,400 --> 00:52:41,880
But this is Birot's Stephanie's question

516
00:52:41,880 --> 00:52:43,440
at the very beginning, which is somebody

517
00:52:43,440 --> 00:52:47,360
who would basically kill themselves

518
00:52:47,360 --> 00:52:48,920
in the act of promoting something

519
00:52:48,920 --> 00:52:51,360
that they took to be a good.

520
00:52:51,360 --> 00:52:53,640
So would that kind of fit with what you're talking about?

521
00:52:53,640 --> 00:52:56,280
Even that because this would benefit humanity

522
00:52:56,280 --> 00:52:58,480
as a whole over the long term?

523
00:52:58,480 --> 00:52:58,960
Sure.

524
00:52:58,960 --> 00:53:01,320
I mean, it really doesn't matter.

525
00:53:01,320 --> 00:53:04,360
Whatever gets attached in your mind

526
00:53:04,360 --> 00:53:08,440
to the recipient, the beneficiary.

527
00:53:08,440 --> 00:53:14,560
I mean, I define, I look at a particular kind of sacrifice,

528
00:53:14,560 --> 00:53:16,560
or particular kind of altruism, which

529
00:53:16,560 --> 00:53:18,880
is incurring cost over a long period of time

530
00:53:18,880 --> 00:53:21,520
in the absence of reciprocity, and in some cases,

531
00:53:21,520 --> 00:53:22,560
giving up your own life.

532
00:53:22,560 --> 00:53:26,080
And so I look at very costly investment in others.

533
00:53:26,080 --> 00:53:29,800
And that's why I say value neutral,

534
00:53:29,800 --> 00:53:33,640
because we can disagree with what other people have decided,

535
00:53:33,640 --> 00:53:37,240
justifies their horrific acts.

536
00:53:37,240 --> 00:53:40,560
We can think on the one hand, killing is wrong.

537
00:53:40,560 --> 00:53:45,360
But on the other hand, that it's

538
00:53:45,360 --> 00:53:48,680
outweighed by the benefits of the recipient.

539
00:53:48,680 --> 00:53:50,520
And so we're going to incur those costs.

540
00:53:50,520 --> 00:53:52,440
And researching the brand is really

541
00:53:52,440 --> 00:53:54,720
helpful for disentangling some of these things.

542
00:53:54,720 --> 00:53:57,040
I mean, there are circuits in our brain

543
00:53:57,040 --> 00:53:59,240
that are weighing, on the one hand,

544
00:53:59,240 --> 00:54:01,120
the rules of right and wrong.

545
00:54:01,120 --> 00:54:06,440
And those are interacting with the personal relation

546
00:54:06,440 --> 00:54:10,040
aspect, which is interacting with the social good.

547
00:54:10,040 --> 00:54:13,880
And I mean, these are very complicated.

548
00:54:13,880 --> 00:54:18,120
And I agree that disentangling the pure reason and pure motive

549
00:54:18,120 --> 00:54:21,920
is, to me, I consider it a moot point in the work that I do.

550
00:54:21,920 --> 00:54:23,320
So even though I study altruism,

551
00:54:23,320 --> 00:54:25,480
I would never go into a situation and say,

552
00:54:25,480 --> 00:54:27,600
I'm going to decide whether this is altruistic or not.

553
00:54:27,600 --> 00:54:30,240
I don't think that's possible.

554
00:54:30,240 --> 00:54:32,040
These are certainly very, I mean,

555
00:54:32,040 --> 00:54:37,040
they bring up these very dramatic cases, like 9-11

556
00:54:37,040 --> 00:54:42,680
and Bonhoeffer and I mean, they are very dramatic cases.

557
00:54:42,680 --> 00:54:44,480
I just want to say the difference

558
00:54:44,480 --> 00:54:47,480
between what you said and the 9-11.

559
00:54:47,480 --> 00:54:50,040
What those people believe is that that act

560
00:54:50,040 --> 00:54:51,280
will get them to heaven.

561
00:54:51,280 --> 00:54:52,280
That's right.

562
00:54:52,280 --> 00:54:53,560
So it was clearly true.

563
00:54:53,560 --> 00:54:55,600
Unless it does, it can negotiate with God.

564
00:54:55,600 --> 00:54:57,880
Once it's up there and proved that he did the good thing

565
00:54:57,880 --> 00:54:59,160
given though he did the bad thing,

566
00:54:59,160 --> 00:55:03,840
he was actually not having any, he was doing it for no gain,

567
00:55:03,840 --> 00:55:04,760
any place.

568
00:55:04,760 --> 00:55:06,800
Well, he knew he was doing it for adults.

569
00:55:06,800 --> 00:55:08,480
He knew he would lose, right?

570
00:55:08,480 --> 00:55:10,600
He was giving up.

571
00:55:10,600 --> 00:55:12,920
But there is one thing that he wanted in life.

572
00:55:12,920 --> 00:55:13,960
And I think that's true.

573
00:55:13,960 --> 00:55:16,000
I think in the 9-11 situation, there

574
00:55:16,000 --> 00:55:19,320
was actually quite an explicit gain that they wanted to.

575
00:55:19,320 --> 00:55:20,960
But the 9-11 situation, they go back to the end,

576
00:55:20,960 --> 00:55:23,440
and does actually offer a certain insight

577
00:55:23,440 --> 00:55:26,160
into the two cases.

578
00:55:26,160 --> 00:55:29,240
Notice I jumped all over the place when you brought up 9-11.

579
00:55:29,240 --> 00:55:31,640
But I smiled when you talked about doing something

580
00:55:31,640 --> 00:55:32,960
against the Nazi.

581
00:55:32,960 --> 00:55:35,160
And I think in a way, the part of the thing

582
00:55:35,160 --> 00:55:38,400
is this notion that it's kind of like the victor gets

583
00:55:38,400 --> 00:55:42,160
to define at the final state who's the real good guy.

584
00:55:42,160 --> 00:55:45,200
And I think we're conflating good guy with altruism,

585
00:55:45,200 --> 00:55:47,400
which I want to do, and you don't want to do it

586
00:55:47,400 --> 00:55:49,480
because you want to look at it in a very specific way

587
00:55:49,480 --> 00:55:51,320
connected to the notion of fitness.

588
00:55:51,320 --> 00:55:55,160
No, I actually want to look at it in a very disconnected,

589
00:55:55,160 --> 00:55:58,160
abstract way where I can take myself out

590
00:55:58,160 --> 00:56:00,560
of what I'm observing.

591
00:56:00,560 --> 00:56:01,840
But you're making some connections

592
00:56:01,840 --> 00:56:07,680
between sacrifice and, I may have misunderstood it,

593
00:56:07,680 --> 00:56:08,880
because I thought you were predicated.

594
00:56:08,880 --> 00:56:10,080
You're arguing on an evolutionary.

595
00:56:10,080 --> 00:56:12,360
I use a biological definition because it gets me out

596
00:56:12,360 --> 00:56:13,280
of the can of worms.

597
00:56:13,280 --> 00:56:15,440
I'm trying to think about specific motivation

598
00:56:15,440 --> 00:56:16,440
in a given instance.

599
00:56:16,440 --> 00:56:17,600
Into another can of worms.

600
00:56:17,600 --> 00:56:19,640
Well, behavior.

601
00:56:19,640 --> 00:56:22,880
Are resources going outside the body,

602
00:56:22,880 --> 00:56:24,800
acting towards another individual?

603
00:56:24,800 --> 00:56:27,280
Is there a cost to the one person?

604
00:56:27,280 --> 00:56:28,160
Is it benefiting the other?

605
00:56:28,160 --> 00:56:31,400
So I choose a biological definition as a start point.

606
00:56:31,400 --> 00:56:34,880
Really, because of some of the points you're making,

607
00:56:34,880 --> 00:56:37,360
which is that how can you theorize about something

608
00:56:37,360 --> 00:56:40,160
unless you have a clear way to define it?

609
00:56:40,160 --> 00:56:42,640
And I think behavior is nice and clear.

610
00:56:42,640 --> 00:56:45,120
We can get 1,000 people together.

611
00:56:45,120 --> 00:56:47,240
They can all say, yes, this happened or no,

612
00:56:47,240 --> 00:56:48,880
but it didn't happen.

613
00:56:48,880 --> 00:56:51,680
And so it's a good starting place to say, OK, now,

614
00:56:51,680 --> 00:56:54,800
once we establish what we're interested in defining,

615
00:56:54,800 --> 00:56:56,480
what are the likely motivations behind it?

616
00:56:56,480 --> 00:56:59,320
How can we think about the brain?

617
00:56:59,320 --> 00:57:02,560
And so all I'm trying to do is say,

618
00:57:02,560 --> 00:57:07,280
I can't consider the moral or the value judgment

619
00:57:07,280 --> 00:57:09,280
of the particular behavior in question

620
00:57:09,280 --> 00:57:13,280
without bringing myself into the mix.

621
00:57:13,280 --> 00:57:13,720
That's true.

622
00:57:13,720 --> 00:57:14,720
You can't.

623
00:57:14,720 --> 00:57:16,360
You know, and I think that's one of the things

624
00:57:16,360 --> 00:57:18,120
that's interesting.

625
00:57:18,120 --> 00:57:19,920
I mean, I don't know if anybody could ever

626
00:57:19,920 --> 00:57:22,680
keep themselves 100% out of things, obviously.

627
00:57:22,680 --> 00:57:25,320
It helps to do neuroimaging and blood samples

628
00:57:25,320 --> 00:57:28,400
because you can't mess with that, isn't it?

629
00:57:28,400 --> 00:57:29,400
Right.

630
00:57:29,400 --> 00:57:30,440
It's not imperfect, no.

631
00:57:30,440 --> 00:57:32,200
But it certainly helps.

632
00:57:32,200 --> 00:57:33,920
I don't know if it helps, it's the right word.

633
00:57:33,920 --> 00:57:38,800
But changes things when you leave the question of,

634
00:57:38,800 --> 00:57:42,400
you said you look at behavior, so leaving the question of ethics

635
00:57:42,400 --> 00:57:45,520
or morality out of it and leaving the question

636
00:57:45,520 --> 00:57:48,120
of meaning out of it.

637
00:57:48,120 --> 00:57:50,200
So the problem we're describing in some ways

638
00:57:50,200 --> 00:57:54,160
is I'm taking as a given that in the history

639
00:57:54,160 --> 00:57:57,200
of the origin of the terms of altruism,

640
00:57:57,200 --> 00:57:58,960
somebody's going to check Wikipedia and figure out

641
00:57:58,960 --> 00:57:59,800
that I'm wrong now.

642
00:57:59,800 --> 00:58:03,640
But I believe that the history of the word

643
00:58:03,640 --> 00:58:08,560
has always been invested in moral or ethical language,

644
00:58:08,560 --> 00:58:13,960
that it's always had its place in that kind of discourse.

645
00:58:13,960 --> 00:58:16,400
So it's had that commitment.

646
00:58:16,400 --> 00:58:19,640
If you want to remove, and we actually

647
00:58:19,640 --> 00:58:24,000
were first sitting sat down at the table before we came in here,

648
00:58:24,000 --> 00:58:27,120
I was talking to you, I'll just make a brief digression

649
00:58:27,120 --> 00:58:29,720
into this about the problem of definition.

650
00:58:29,720 --> 00:58:32,960
And there's a lot of things that are almost

651
00:58:32,960 --> 00:58:38,600
impossible to define in a strict webster definition form.

652
00:58:38,600 --> 00:58:42,440
We're talking about emotion as one empathy as another,

653
00:58:42,440 --> 00:58:43,480
or behavior.

654
00:58:43,480 --> 00:58:45,760
Many of these things are hard to define,

655
00:58:45,760 --> 00:58:48,400
try to find what a chair is.

656
00:58:48,400 --> 00:58:51,160
Now, one way out of the problem, which we see now

657
00:58:51,160 --> 00:58:54,240
in legal studies, in which what we do in descriptive psychology

658
00:58:54,240 --> 00:58:56,480
is called a paradigm case analysis,

659
00:58:56,480 --> 00:58:58,560
where you start with a complete case, a case that

660
00:58:58,560 --> 00:59:01,320
has all of the elements that everybody can look at.

661
00:59:01,320 --> 00:59:03,320
So yeah, if it has all of those things,

662
00:59:03,320 --> 00:59:06,040
sure, we agree that that's empathy,

663
00:59:06,040 --> 00:59:07,440
that if it has all of those things,

664
00:59:07,440 --> 00:59:10,240
sure, we agree that that's altruistic,

665
00:59:10,240 --> 00:59:12,080
that if it involves self-sacrifice,

666
00:59:12,080 --> 00:59:14,640
that if it's good for the community,

667
00:59:14,640 --> 00:59:17,080
that there is no apparent self-gain,

668
00:59:17,080 --> 00:59:18,920
if it has all of those features,

669
00:59:18,920 --> 00:59:21,320
we're going to call that altruism.

670
00:59:21,320 --> 00:59:24,280
If, in the example of empathy, if it involves

671
00:59:24,280 --> 00:59:27,480
my recognizing your motivations, what you recognize,

672
00:59:27,480 --> 00:59:29,840
what you know how to do, what you can tolerate,

673
00:59:29,840 --> 00:59:32,680
what your ongoing intent is, what the significance is

674
00:59:32,680 --> 00:59:35,920
of all that to you, if that's part of what your recognition

675
00:59:35,920 --> 00:59:38,680
of the other is, and you do it in a way that they can tolerate,

676
00:59:38,680 --> 00:59:40,600
yeah, that's pretty clearly, at least,

677
00:59:40,600 --> 00:59:42,960
what the average Joe is, or the average scientist,

678
00:59:42,960 --> 00:59:45,320
also is going to say, we mean by empathy.

679
00:59:45,320 --> 00:59:47,760
We start to remove pieces of that.

680
00:59:47,760 --> 00:59:50,600
We start to remove, for example, in this particular case,

681
00:59:50,600 --> 00:59:53,960
if we take the general notion of altruism,

682
00:59:53,960 --> 00:59:58,960
as something that is a feature of the moral universe,

683
00:59:59,960 --> 01:00:03,600
and we take out this notion of ethic, or greater good,

684
01:00:03,600 --> 01:00:06,600
or whatever else we want to combine to the notion of morality,

685
01:00:06,600 --> 01:00:09,760
and instead simply define it as self-sacrifice,

686
01:00:09,760 --> 01:00:11,400
we have one of the important elements,

687
01:00:11,400 --> 01:00:13,080
the self-sacrifice element.

688
01:00:13,080 --> 01:00:15,720
Now, under those conditions, some of our judges will say,

689
01:00:15,720 --> 01:00:17,240
okay, that's still what I mean by altruism,

690
01:00:17,240 --> 01:00:19,600
we can study that, but others are going to say,

691
01:00:19,600 --> 01:00:22,560
it doesn't involve enough of the case for me to feel

692
01:00:22,560 --> 01:00:24,600
that we're talking about the full subject matter.

693
01:00:24,600 --> 01:00:27,120
And so some of the tasks in science often is to do

694
01:00:27,120 --> 01:00:29,840
what you're describing, I believe, which is to pull out

695
01:00:29,840 --> 01:00:31,160
some feature of it.

696
01:00:31,160 --> 01:00:33,000
The trouble is if we take that feature,

697
01:00:33,000 --> 01:00:35,680
and now confuse it with the paradigm case,

698
01:00:35,680 --> 01:00:38,400
or what happens is that you begin with an example,

699
01:00:38,400 --> 01:00:40,000
and somebody like me gets upset because they say,

700
01:00:40,000 --> 01:00:41,720
but you didn't include this.

701
01:00:41,720 --> 01:00:42,960
Oh, and that happens all the time.

702
01:00:42,960 --> 01:00:44,680
I mean, that's the goal in science, right?

703
01:00:44,680 --> 01:00:47,800
Is to actually take the pieces,

704
01:00:47,800 --> 01:00:49,280
bring them into the laboratory,

705
01:00:49,280 --> 01:00:52,960
control everything you can to discover cause and effect.

706
01:00:52,960 --> 01:00:55,720
And what you do is every cause and effect relationship

707
01:00:55,720 --> 01:00:57,560
and all the boundary conditions around it,

708
01:00:57,560 --> 01:00:59,280
they constitute puzzle pieces.

709
01:00:59,280 --> 01:01:00,880
Yeah, we say that's a problem.

710
01:01:00,880 --> 01:01:02,400
But let me finish.

711
01:01:02,400 --> 01:01:04,200
We have your puzzle pieces,

712
01:01:04,200 --> 01:01:07,280
and then what you do is you try to put them together.

713
01:01:07,280 --> 01:01:09,040
And when you put them together,

714
01:01:09,040 --> 01:01:13,120
therein lies the help when it comes to something like ethics

715
01:01:13,120 --> 01:01:15,520
or something like social policy.

716
01:01:15,520 --> 01:01:19,560
Because as a result of the pieces that I've put together,

717
01:01:19,560 --> 01:01:23,560
I've been able to figure out ways

718
01:01:23,560 --> 01:01:28,400
to actually trigger these kinds of motivations in others,

719
01:01:28,400 --> 01:01:30,600
which can be used, and also to understand

720
01:01:30,600 --> 01:01:33,320
which aspects of our society are inhibiting

721
01:01:33,320 --> 01:01:35,840
and interfering with these kinds of more

722
01:01:35,840 --> 01:01:37,480
prosocial motivations.

723
01:01:37,480 --> 01:01:39,640
I could tell you what's wrong,

724
01:01:39,640 --> 01:01:43,080
like I could hypothesize about what features of the media

725
01:01:43,080 --> 01:01:45,800
or what features of our technology

726
01:01:45,800 --> 01:01:50,000
are actually shutting down every single ounce of compassion

727
01:01:50,000 --> 01:01:51,080
that we might have,

728
01:01:51,080 --> 01:01:53,400
and what causes us to operate in defensive ways,

729
01:01:53,400 --> 01:01:54,240
in fearful ways.

730
01:01:54,240 --> 01:01:58,520
And so what I can do is make predictions about ways

731
01:01:58,520 --> 01:02:02,120
to harness and leverage what seems desirable

732
01:02:02,120 --> 01:02:03,240
about the human condition.

733
01:02:03,240 --> 01:02:07,160
I can do that as a result of this kind of systematic analysis

734
01:02:07,160 --> 01:02:10,240
that does include a conversation

735
01:02:10,240 --> 01:02:12,040
between observation, description,

736
01:02:12,040 --> 01:02:14,520
and also theory and explanation.

737
01:02:14,520 --> 01:02:17,280
Yeah, I think the only distinction I'd wanna add

738
01:02:17,280 --> 01:02:22,280
that is a kind of a historical philosophical point,

739
01:02:22,480 --> 01:02:25,400
which is cause and effect is an extraordinary,

740
01:02:25,400 --> 01:02:27,080
useful device.

741
01:02:27,080 --> 01:02:28,920
If this happens, this always happens.

742
01:02:28,920 --> 01:02:33,000
If you've got time one, you've got time two sequences,

743
01:02:33,000 --> 01:02:35,160
and there's a long history of that kind of technique

744
01:02:35,160 --> 01:02:36,960
and technology paying off.

745
01:02:36,960 --> 01:02:38,920
But that actually is a subclass

746
01:02:38,920 --> 01:02:41,240
of the more general mode of explanation,

747
01:02:41,240 --> 01:02:44,720
which is something gives reason to,

748
01:02:44,720 --> 01:02:47,680
something is understandable, something follows.

749
01:02:47,680 --> 01:02:50,720
In a lot of behavioral descriptions,

750
01:02:50,720 --> 01:02:53,520
I'll prefer talking about something elicits

751
01:02:53,520 --> 01:02:56,360
or something fosters rather than something causes

752
01:02:56,360 --> 01:02:57,760
for a very simple reason,

753
01:02:57,760 --> 01:03:00,000
which is that for a set of conditions

754
01:03:00,000 --> 01:03:02,600
that in retrospect, I see how it got there,

755
01:03:02,600 --> 01:03:04,800
but in looking into the future,

756
01:03:04,800 --> 01:03:06,960
it's understandable that it might follow,

757
01:03:06,960 --> 01:03:09,120
but it doesn't have to follow any particular way.

758
01:03:09,120 --> 01:03:10,880
You cannot discover cause and effect

759
01:03:10,880 --> 01:03:12,800
without the scientific method.

760
01:03:12,800 --> 01:03:15,640
That's, well, yeah, I'm not arguing with that,

761
01:03:15,640 --> 01:03:16,840
but I think there's systematic ways

762
01:03:16,840 --> 01:03:19,120
that go back to natural history studies

763
01:03:19,120 --> 01:03:21,240
that show that there are broader ways to do it.

764
01:03:21,240 --> 01:03:23,080
But cause and effect is something, yeah,

765
01:03:23,080 --> 01:03:24,680
I mean, when we do our correlational studies,

766
01:03:24,680 --> 01:03:27,080
we have to use language like associated with,

767
01:03:27,080 --> 01:03:28,720
likely to happen.

768
01:03:28,720 --> 01:03:29,800
I mean, we have to use that,

769
01:03:29,800 --> 01:03:31,000
we have to soften the language.

770
01:03:31,000 --> 01:03:32,760
The beautiful thing about an experiment

771
01:03:32,760 --> 01:03:34,440
is we don't have to soften the language.

772
01:03:34,440 --> 01:03:35,840
Now we can be wrong.

773
01:03:35,840 --> 01:03:37,960
We can discover something in our experiment

774
01:03:37,960 --> 01:03:41,320
that turns out to not be replicable,

775
01:03:41,320 --> 01:03:44,320
but then we find that out because we can't replicate it.

776
01:03:44,320 --> 01:03:46,240
So what's nice is all the puzzle pieces,

777
01:03:46,240 --> 01:03:48,040
all the cause and effect relationships

778
01:03:48,040 --> 01:03:53,040
that are solid enough to be replicated over and over again

779
01:03:53,640 --> 01:03:55,600
and you put them together in an explanation

780
01:03:55,600 --> 01:03:56,880
and then you go out and you predict

781
01:03:56,880 --> 01:03:58,800
what that explanation suggests.

782
01:03:58,800 --> 01:04:02,240
If you're right, if you find what you're looking for,

783
01:04:02,240 --> 01:04:03,840
it may as well be the truth,

784
01:04:03,840 --> 01:04:05,720
even if you can never get to the truth,

785
01:04:05,720 --> 01:04:07,600
because what you can do is you can build bridges

786
01:04:07,600 --> 01:04:09,040
around these kinds of concepts.

787
01:04:09,040 --> 01:04:11,300
And so the kind of hard,

788
01:04:12,600 --> 01:04:15,440
hard objective, you know,

789
01:04:15,440 --> 01:04:17,160
something that you can get your hands on,

790
01:04:17,160 --> 01:04:19,120
the science is the way forward.

791
01:04:19,120 --> 01:04:19,960
You know, it's interesting because, you know,

792
01:04:19,960 --> 01:04:23,000
we're sitting here in a building devoted to psychoanalysis,

793
01:04:23,000 --> 01:04:26,480
which from Freud on had to contend with,

794
01:04:26,480 --> 01:04:31,480
probably until the mid 1970s with extraordinarily difficult

795
01:04:31,800 --> 01:04:36,280
paradox, which was at least initially a theoretical,

796
01:04:36,280 --> 01:04:39,400
and I would argue theological argument

797
01:04:39,400 --> 01:04:41,640
that all understanding should be deterministic.

798
01:04:41,640 --> 01:04:44,120
Everything in some point is gonna reduce

799
01:04:44,120 --> 01:04:47,040
the cause and effect explanations.

800
01:04:47,040 --> 01:04:51,120
While developing a therapeutic methodology based on

801
01:04:51,120 --> 01:04:53,560
liberation based on an attempt to be utterly honest,

802
01:04:53,560 --> 01:04:57,280
to speak freely, to be liberated in effect

803
01:04:57,280 --> 01:04:59,680
from the unexamined, to be able to move

804
01:04:59,680 --> 01:05:04,520
from the unexamined cause to action with reason,

805
01:05:04,520 --> 01:05:08,160
to be able to move from a determined,

806
01:05:08,160 --> 01:05:12,960
unconsciously determined set of activities

807
01:05:12,960 --> 01:05:15,800
into one in which the actor can make some choices.

808
01:05:15,800 --> 01:05:18,360
And, you know, and that kind of tension, I think,

809
01:05:18,360 --> 01:05:19,680
has, you know,

810
01:05:19,680 --> 01:05:24,680
informed and infected our studies for a very, very long time.

811
01:05:25,720 --> 01:05:26,560
Which is...

812
01:05:26,560 --> 01:05:27,400
Including in science.

813
01:05:27,400 --> 01:05:29,040
I mean, you see this tension everywhere.

814
01:05:29,040 --> 01:05:32,400
I mean, we can't sit here and talk about

815
01:05:32,400 --> 01:05:35,520
what the fundamental principles of, you know,

816
01:05:35,520 --> 01:05:37,840
the relationship between emotion and motivation are

817
01:05:37,840 --> 01:05:39,840
at the level of, you know, neurotransmitters.

818
01:05:39,840 --> 01:05:41,600
I mean, there's so much we do not know,

819
01:05:41,600 --> 01:05:45,320
and it's all this back and forth between what we see

820
01:05:45,320 --> 01:05:48,600
and what we tweak and some things we can take

821
01:05:48,600 --> 01:05:50,040
to the bank, other things we can't.

822
01:05:50,040 --> 01:05:51,560
And if you want to take things to the bank,

823
01:05:51,560 --> 01:05:53,640
there's so many qualifiers, right?

824
01:05:53,640 --> 01:05:55,440
So many circumstances under which,

825
01:05:55,440 --> 01:05:57,160
well, it's not true here and it is true here.

826
01:05:57,160 --> 01:06:00,800
And it really depends on what problem you're trying to solve

827
01:06:00,800 --> 01:06:02,400
and how do you generate knowledge.

828
01:06:02,400 --> 01:06:03,600
And they're just, I'm just saying,

829
01:06:03,600 --> 01:06:05,720
science is a useful way to generate knowledge.

830
01:06:06,920 --> 01:06:11,180
We put these two things together, empathy and altruism.

831
01:06:12,480 --> 01:06:14,720
From your work on theory of mind

832
01:06:14,720 --> 01:06:18,600
and from your perspectives, are they related?

833
01:06:18,600 --> 01:06:20,360
Do they have to be put next to each other

834
01:06:20,360 --> 01:06:22,440
or they're not related at all?

835
01:06:23,960 --> 01:06:28,960
Well, my way of approaching these kinds of

836
01:06:29,560 --> 01:06:31,200
very interesting questions wouldn't be

837
01:06:31,200 --> 01:06:36,200
through dramatic examples like 9-11 or even

838
01:06:40,000 --> 01:06:41,920
the Second World War.

839
01:06:41,920 --> 01:06:45,680
That's something because those things are so complex.

840
01:06:45,680 --> 01:06:50,600
The reasoning that Bonhoeffer went through itself

841
01:06:50,600 --> 01:06:53,680
very, very complex case.

842
01:06:53,680 --> 01:06:55,920
But if you take a very simple case like,

843
01:06:57,560 --> 01:07:01,320
I begin to take out my pen and I drop my pen on the floor.

844
01:07:03,240 --> 01:07:05,720
Before I've hardly noticed that I've done that,

845
01:07:05,720 --> 01:07:08,400
you can bring it in the stretch and you pick the pen up

846
01:07:08,400 --> 01:07:09,600
and give it back to me.

847
01:07:09,600 --> 01:07:10,600
Put it in my pocket.

848
01:07:10,600 --> 01:07:13,560
Why are you putting your pocket that way?

849
01:07:13,560 --> 01:07:17,520
That's not gonna count, but if you're actually,

850
01:07:17,520 --> 01:07:20,200
if the effect of what you do is to help me,

851
01:07:20,200 --> 01:07:21,880
well, there you have an act

852
01:07:21,880 --> 01:07:24,640
and you can ask all these same questions about it.

853
01:07:24,640 --> 01:07:28,480
Is this, was this an altruistic act and so forth?

854
01:07:28,480 --> 01:07:32,960
And again, with somebody as complex as you,

855
01:07:32,960 --> 01:07:36,120
it would be hard for me to be exactly sure

856
01:07:36,120 --> 01:07:38,400
what your motivations were.

857
01:07:38,400 --> 01:07:43,400
But so that's where asking the same kinds of questions

858
01:07:43,840 --> 01:07:48,840
of babies can be so interesting because it's,

859
01:07:49,960 --> 01:07:52,880
we ask these questions of babies and small children

860
01:07:52,880 --> 01:07:56,240
over through the lens of experiments

861
01:07:56,240 --> 01:07:59,120
because we have to be able to control

862
01:07:59,120 --> 01:08:01,840
and to try to determine what cause and the fact is

863
01:08:01,840 --> 01:08:04,600
and to do things that are replicable.

864
01:08:04,600 --> 01:08:07,720
And one of the, so all the kind of claims I'm making

865
01:08:07,720 --> 01:08:10,280
about babies, they're based on experiments

866
01:08:10,280 --> 01:08:14,720
and I could, I don't want to turn this into one

867
01:08:14,720 --> 01:08:17,640
of my classrooms or anything and say exactly

868
01:08:17,640 --> 01:08:19,480
what these experiments are.

869
01:08:19,480 --> 01:08:21,440
But here's the basic situation.

870
01:08:21,440 --> 01:08:24,640
You have somebody, there's an 18 month old present

871
01:08:24,640 --> 01:08:28,560
and you have somebody who's a strange or an experimenter

872
01:08:29,560 --> 01:08:34,560
and the experimenter takes a pen out and drops it.

873
01:08:34,560 --> 01:08:39,400
It looks like it's an accident, drops it on the floor

874
01:08:39,400 --> 01:08:43,160
and pauses for a moment.

875
01:08:44,320 --> 01:08:49,320
And it's commonly the case that toddlers of 18 months of age

876
01:08:51,200 --> 01:08:54,240
will in fact, you know, struggle down from the chair

877
01:08:54,240 --> 01:08:58,040
that they're sitting on and total across to this pen

878
01:08:58,040 --> 01:09:01,320
and give it back, you know, that sort of shaking waste

879
01:09:01,320 --> 01:09:04,880
until the 18 months and give it back to the person

880
01:09:04,880 --> 01:09:06,440
who dropped it.

881
01:09:06,440 --> 01:09:10,680
And the contrasting cases where the experimenter

882
01:09:10,680 --> 01:09:13,320
does the same thing in a sense,

883
01:09:13,320 --> 01:09:17,520
but does it in such a manner that they're displaying

884
01:09:17,520 --> 01:09:21,360
their intention to throw their pen upon the floor?

885
01:09:21,360 --> 01:09:24,360
That's what this experiment and this other condition

886
01:09:24,360 --> 01:09:25,960
throws the pen on the floor.

887
01:09:25,960 --> 01:09:29,440
And under those circumstances where the experimenter

888
01:09:29,440 --> 01:09:34,000
has deliberately thrown their own pen on the floor,

889
01:09:34,000 --> 01:09:38,000
you don't see this helping behavior from 18 month olds.

890
01:09:38,000 --> 01:09:40,480
Now that's a very remarkable thing to me.

891
01:09:40,480 --> 01:09:43,960
Now, I mean, I'm sure that in a way that caregivers,

892
01:09:43,960 --> 01:09:46,680
and I know this is true, caregivers have always sort of

893
01:09:46,680 --> 01:09:49,760
known that about their babies, they've always felt that

894
01:09:49,760 --> 01:09:53,240
about their babies, that there is really a person,

895
01:09:53,240 --> 01:09:55,920
I think about the baby now on the other end,

896
01:09:55,920 --> 01:10:00,920
who is with whom you have a relationship,

897
01:10:01,800 --> 01:10:06,720
and part of that relationship is that you are reflected

898
01:10:06,720 --> 01:10:11,720
in that baby's mind, your mind, your intentions and desires

899
01:10:12,720 --> 01:10:17,720
and perspective is reflected in your baby's mind.

900
01:10:18,440 --> 01:10:22,040
And that's sort of really what we mean by having a baby

901
01:10:22,040 --> 01:10:25,240
at a very basic level, what we mean by having

902
01:10:25,240 --> 01:10:26,320
a relationship.

903
01:10:26,320 --> 01:10:29,320
And that's also the big thing that's absent

904
01:10:29,320 --> 01:10:34,320
if your child is substantially autistic,

905
01:10:36,800 --> 01:10:41,560
that you don't have that reflection of your own inner life

906
01:10:41,560 --> 01:10:45,880
in your, well, it's typically would be a son.

907
01:10:46,840 --> 01:10:50,880
And that makes the whole job of parenting extremely difficult.

908
01:10:52,320 --> 01:10:54,160
So if you take these little cases,

909
01:10:54,160 --> 01:10:58,280
these very simple cases, undramatic cases, everyday cases,

910
01:10:58,280 --> 01:11:03,160
to me these are the cases, and you use this to investigate

911
01:11:03,160 --> 01:11:06,960
very early, development, lo and behold, you find that these

912
01:11:06,960 --> 01:11:09,920
kinds of responses and judgments,

913
01:11:09,920 --> 01:11:12,800
and would I call that altruistic?

914
01:11:12,800 --> 01:11:17,440
Well, you know, I mean, what you want to call things,

915
01:11:20,440 --> 01:11:22,280
I sort of up to you, but I just say,

916
01:11:22,280 --> 01:11:24,600
look, this is what they do.

917
01:11:24,600 --> 01:11:27,160
So there's something, we need to explain this.

918
01:11:27,160 --> 01:11:29,920
What are they doing, why are they doing it?

919
01:11:29,920 --> 01:11:32,640
And you can see these nice sort of distinctions

920
01:11:32,640 --> 01:11:35,760
you can set up by giving the two contrasting cases.

921
01:11:35,760 --> 01:11:38,240
One's where I do something by accident,

922
01:11:38,240 --> 01:11:41,000
so I don't want to drop my pen on the floor, in fact.

923
01:11:41,000 --> 01:11:44,040
You know, this is something that's disrupted my life

924
01:11:44,040 --> 01:11:48,480
for a moment, and the child spontaneously wants to help

925
01:11:48,480 --> 01:11:51,600
to set you back on course, versus the case

926
01:11:51,600 --> 01:11:53,400
where you deliberately throw it on the floor,

927
01:11:53,400 --> 01:11:55,720
well, that's what the person wants.

928
01:11:55,720 --> 01:11:59,480
Has this been done with siblings to see if there's so...

929
01:11:59,480 --> 01:12:02,840
This is, this, all of this is, well, you would then have

930
01:12:02,840 --> 01:12:05,600
to get one of the siblings to do the acting of the roles,

931
01:12:05,600 --> 01:12:07,200
that's more difficult.

932
01:12:07,200 --> 01:12:12,080
So the one side of this is taken by an experimenter

933
01:12:12,080 --> 01:12:15,920
who is very trained and practiced at producing

934
01:12:15,920 --> 01:12:17,840
these different displays.

935
01:12:17,840 --> 01:12:22,240
And there's other kinds of examples that are even more

936
01:12:22,240 --> 01:12:29,240
dramatic where the task for the baby is to figure out

937
01:12:30,760 --> 01:12:34,760
what it is you want, what you're trying to do,

938
01:12:34,760 --> 01:12:36,120
what you're wanting.

939
01:12:36,120 --> 01:12:41,000
Not from any of the sign that you give in the manner

940
01:12:41,000 --> 01:12:44,920
of your behaviour, accident versus deliberate,

941
01:12:44,920 --> 01:12:49,720
but simply in terms of your perspective on the world.

942
01:12:49,720 --> 01:12:54,920
So you're trying to open this box and you can't quite manage.

943
01:12:54,920 --> 01:12:56,920
There's another box.

944
01:12:56,920 --> 01:13:02,720
A few moments ago you put an object in this first box

945
01:13:02,720 --> 01:13:04,640
and then you left the room.

946
01:13:04,640 --> 01:13:07,120
And while you were away, somebody moved that object

947
01:13:07,120 --> 01:13:09,480
from this box, put it in that box.

948
01:13:09,480 --> 01:13:12,920
You didn't see that, but you come back into the room

949
01:13:12,920 --> 01:13:15,920
and now you're trying to open the box.

950
01:13:15,920 --> 01:13:18,640
And you can't quite manage.

951
01:13:18,640 --> 01:13:22,680
In this case, what 18 months those do is they struggle

952
01:13:22,680 --> 01:13:25,920
to their feet and toggle across to the other box,

953
01:13:25,920 --> 01:13:30,080
open it, take the toy out and give it to you.

954
01:13:30,080 --> 01:13:32,600
And the other, so we needed a contrast,

955
01:13:32,600 --> 01:13:33,800
we always needed a contrast.

956
01:13:33,800 --> 01:13:38,880
So the contrast in cases, you put this object in this box

957
01:13:38,880 --> 01:13:41,880
and you start to leave the room.

958
01:13:41,880 --> 01:13:45,720
While you're leaving the room, a second person takes the,

959
01:13:45,720 --> 01:13:48,640
a second adult, takes the object out in this box,

960
01:13:48,640 --> 01:13:50,040
puts it into this box.

961
01:13:50,040 --> 01:13:52,840
But just at that moment you turn back and you look

962
01:13:52,840 --> 01:13:58,080
and you see this second adult putting the object in this box

963
01:13:58,080 --> 01:13:59,360
and then you leave.

964
01:13:59,360 --> 01:14:01,440
And then a few moments later you come back in

965
01:14:01,440 --> 01:14:05,800
and you go up to this box and try to open it again.

966
01:14:05,800 --> 01:14:08,680
Now in this case, what was the toddler do?

967
01:14:08,680 --> 01:14:11,200
Well, the toddler struggles to her feet

968
01:14:11,200 --> 01:14:15,400
and totals across to this box and opens it for you.

969
01:14:15,400 --> 01:14:16,720
Doesn't retrieve the toy.

970
01:14:16,720 --> 01:14:19,760
What stage does the child look at the situation

971
01:14:19,760 --> 01:14:20,840
and just start to laugh?

972
01:14:20,840 --> 01:14:21,840
Ah.

973
01:14:21,840 --> 01:14:25,000
Well, it's, it wasn't worrying about it.

974
01:14:25,000 --> 01:14:28,560
Is that, you know, part of what I think is beautifully

975
01:14:28,560 --> 01:14:30,240
illustrated in these kind of experiments,

976
01:14:30,240 --> 01:14:33,600
I gather it's, you hang out with experimental philosophers.

977
01:14:33,600 --> 01:14:36,600
And they tend not, they like to play with all sorts

978
01:14:36,600 --> 01:14:39,360
of general notions.

979
01:14:39,360 --> 01:14:41,800
But in experiments like this, part of what I think

980
01:14:41,800 --> 01:14:45,320
it's beautifully demonstrated is at what, you know,

981
01:14:45,320 --> 01:14:50,320
how children, how infants become people, become persons.

982
01:14:50,320 --> 01:14:55,040
And some of what you're noticing is that early on,

983
01:14:55,040 --> 01:14:57,680
what happens more often than not is that the child does

984
01:14:57,680 --> 01:14:59,920
something that appears to be pro-social.

985
01:14:59,920 --> 01:15:02,920
In some fashion, something that, you know, seems to be nice

986
01:15:02,920 --> 01:15:05,520
benefits to the other person.

987
01:15:05,520 --> 01:15:07,840
I suppose at some stage, some of these kids,

988
01:15:07,840 --> 01:15:11,000
under other circumstances, just watch the adult struggle,

989
01:15:11,000 --> 01:15:13,560
wait for the adult to leave, and then swipe depend

990
01:15:13,560 --> 01:15:16,120
from the one where it was really hidden.

991
01:15:16,120 --> 01:15:18,040
Maybe not under these conditions where they're being

992
01:15:18,040 --> 01:15:21,320
observed because of the knowledge of the consequences.

993
01:15:21,320 --> 01:15:23,680
But I think what's, what's really interesting is that

994
01:15:23,680 --> 01:15:26,760
you're observing, I mean, obviously, one of the,

995
01:15:26,760 --> 01:15:30,040
to go back to the earlier question about brains.

996
01:15:30,040 --> 01:15:33,360
Obviously, brains facilitate our becoming persons

997
01:15:33,360 --> 01:15:36,160
because if they didn't, you know, we'd become something else

998
01:15:36,160 --> 01:15:39,160
or we would misunderstand the brain.

999
01:15:39,160 --> 01:15:41,680
So in effect, what your research is showing is that

1000
01:15:41,680 --> 01:15:46,640
very, very early on, an infant begins to develop a

1001
01:15:46,640 --> 01:15:50,840
perspective that has, that is seen by an other is pro-social,

1002
01:15:50,840 --> 01:15:53,840
that recognizes what the other is trying to do, and that

1003
01:15:53,840 --> 01:15:56,000
facilitates the other getting what they're trying to do,

1004
01:15:56,000 --> 01:15:58,760
in this case, getting the pen, and that you're finding that

1005
01:15:58,760 --> 01:16:01,960
that occurs, versions that occur earlier and earlier.

1006
01:16:01,960 --> 01:16:03,960
But I'm wondering at what point the child, you also begin

1007
01:16:03,960 --> 01:16:06,280
to notice or have some evidence that the child is

1008
01:16:06,280 --> 01:16:08,760
deciding whether they want to do that or not?

1009
01:16:08,760 --> 01:16:12,960
Well, I mean, I think the way that I put this is that,

1010
01:16:12,960 --> 01:16:15,320
you know, those questions that you're asking about, say

1011
01:16:15,320 --> 01:16:19,640
yourself, they know who I would always give the pen.

1012
01:16:19,640 --> 01:16:23,080
Yeah, I mean, what would be my motivations or something

1013
01:16:23,080 --> 01:16:26,920
in this case, and how does that relate to the baby

1014
01:16:26,920 --> 01:16:29,600
becoming you?

1015
01:16:29,600 --> 01:16:33,320
Well, I would simply point out that your brain used

1016
01:16:33,320 --> 01:16:35,920
to be in an 18-month-old toddler.

1017
01:16:35,920 --> 01:16:37,200
It's the same brain.

1018
01:16:37,200 --> 01:16:42,800
It's just, you know, fast forward a few years.

1019
01:16:42,800 --> 01:16:47,240
And it's that same brain still in there.

1020
01:16:47,240 --> 01:16:51,840
It's, of course, been working for longer.

1021
01:16:51,840 --> 01:16:53,840
It's been working for longer.

1022
01:16:53,840 --> 01:17:00,240
But I think that, you know, you have the properties that you

1023
01:17:00,240 --> 01:17:04,160
have and I have those that I have and that we share

1024
01:17:04,160 --> 01:17:08,320
as human beings because those properties are built

1025
01:17:08,320 --> 01:17:13,160
into the brain and they were there already in the 18-month-old.

1026
01:17:13,160 --> 01:17:16,000
And perhaps they were there even in the 12-month-old.

1027
01:17:16,000 --> 01:17:17,200
I mean, I don't know.

1028
01:17:17,200 --> 01:17:19,040
And look at other species too.

1029
01:17:19,040 --> 01:17:22,400
Chimpanzee, they're, but they have to be cultivated.

1030
01:17:22,400 --> 01:17:25,280
They're not exactly the same in other species.

1031
01:17:25,280 --> 01:17:29,760
So, I mean, when you look at the question of whether you

1032
01:17:29,760 --> 01:17:34,320
get real, well, real whatever, you know, I can help.

1033
01:17:34,320 --> 01:17:35,560
I'll describe it.

1034
01:17:35,560 --> 01:17:38,320
Autorotic behavior in chimpanzees,

1035
01:17:38,320 --> 01:17:40,760
you get that partial cooperation.

1036
01:17:40,760 --> 01:17:44,960
So if you can set up a situation with two chimps,

1037
01:17:44,960 --> 01:17:50,240
whereby one chimp can only get their bit of banana

1038
01:17:50,240 --> 01:17:53,240
if the other one helps them to do something.

1039
01:17:53,240 --> 01:17:56,360
And this one can only get their piece of banana

1040
01:17:56,360 --> 01:17:57,560
if this one helps them.

1041
01:17:57,560 --> 01:17:59,920
So you're asked to sort of chimp stuff to learn that they

1042
01:17:59,920 --> 01:18:01,880
have to cooperate.

1043
01:18:01,880 --> 01:18:05,760
If either of them will get or going to get a piece of banana,

1044
01:18:05,760 --> 01:18:08,520
they have to cooperate with one another.

1045
01:18:08,520 --> 01:18:11,760
And now what happens is the chimpanzee start off behaving.

1046
01:18:11,760 --> 01:18:14,640
Now, of course, this means that one chimp has to help

1047
01:18:14,640 --> 01:18:15,600
the other one first.

1048
01:18:15,600 --> 01:18:19,800
I mean, at some point, this chimp will get the big piece

1049
01:18:19,800 --> 01:18:21,840
of banana first.

1050
01:18:21,840 --> 01:18:25,720
Or this one will get the first, which means that this one has

1051
01:18:25,720 --> 01:18:29,080
to help this one. This one gets its banana.

1052
01:18:29,080 --> 01:18:31,000
And now the question is, what's this one?

1053
01:18:31,000 --> 01:18:32,520
Just got their banana.

1054
01:18:32,520 --> 01:18:33,600
What do they do?

1055
01:18:33,600 --> 01:18:37,520
Do they continue to act so that this one can get their banana

1056
01:18:37,520 --> 01:18:38,320
after all?

1057
01:18:38,320 --> 01:18:40,560
And the answer is, because I said, no, no, they don't.

1058
01:18:40,560 --> 01:18:43,400
As soon as they get their own banana, they're off.

1059
01:18:43,400 --> 01:18:47,960
But if you do this with three-year-old children, human kids,

1060
01:18:47,960 --> 01:18:49,600
they do cooperate all the way.

1061
01:18:49,600 --> 01:18:51,080
So this kid gets their banana.

1062
01:18:51,080 --> 01:18:55,000
And then continues to help the confederate get their banana.

1063
01:18:55,000 --> 01:18:57,000
So some of the problem.

1064
01:18:57,000 --> 01:18:59,000
There's a difference between species.

1065
01:18:59,000 --> 01:19:00,160
But why is your question?

1066
01:19:00,160 --> 01:19:00,560
Even since.

1067
01:19:00,560 --> 01:19:01,760
Which I find intriguing.

1068
01:19:01,760 --> 01:19:03,040
What you made me think about.

1069
01:19:03,040 --> 01:19:06,160
I always go to sort of the human experience overall.

1070
01:19:06,160 --> 01:19:08,600
And he says the same brain, right?

1071
01:19:08,600 --> 01:19:11,200
So you're 18 months old or six months old.

1072
01:19:11,200 --> 01:19:13,720
And you started to develop this empathy.

1073
01:19:13,720 --> 01:19:17,560
And then you have six younger brothers and sisters,

1074
01:19:17,560 --> 01:19:18,920
in a real family.

1075
01:19:18,920 --> 01:19:21,360
Where's the point where the kids stop wanting to help?

1076
01:19:21,360 --> 01:19:22,600
Let me go to the confederate.

1077
01:19:22,600 --> 01:19:30,240
So that question about how does the empathy and the maybe

1078
01:19:30,240 --> 01:19:33,600
compassion develop over time?

1079
01:19:33,600 --> 01:19:35,880
Because it doesn't seem to me it's a static thing.

1080
01:19:35,880 --> 01:19:37,840
Because the older you get, the more choice

1081
01:19:37,840 --> 01:19:39,960
you have about whether you're doing it or not.

1082
01:19:39,960 --> 01:19:43,000
And at certain point, you may choose.

1083
01:19:43,000 --> 01:19:44,920
The child may choose.

1084
01:19:44,920 --> 01:19:45,400
No.

1085
01:19:45,400 --> 01:19:46,440
It's certainly changed.

1086
01:19:46,440 --> 01:19:50,640
But there are certain things that don't change.

1087
01:19:50,640 --> 01:19:55,120
There's lots and lots of things that do.

1088
01:19:55,120 --> 01:19:58,120
So some of the things that don't change

1089
01:19:58,120 --> 01:20:02,120
are the very, very simple things.

1090
01:20:02,120 --> 01:20:05,920
Part of what I think there is a behavioral logic that we

1091
01:20:05,920 --> 01:20:07,480
could use to unfold most of this.

1092
01:20:07,480 --> 01:20:09,840
Which is that if you've acquired any personal

1093
01:20:09,840 --> 01:20:14,440
characteristic, regardless of your species, it's dependent

1094
01:20:14,440 --> 01:20:21,400
on having a prior capacity and an intervening history.

1095
01:20:21,400 --> 01:20:22,840
However, I mean, that's how you acquire.

1096
01:20:22,840 --> 01:20:23,840
You've got a capacity.

1097
01:20:23,840 --> 01:20:27,340
And the child who is on the spectrum, who evidently

1098
01:20:27,340 --> 01:20:29,440
has a different capacity, and is going

1099
01:20:29,440 --> 01:20:31,000
to require a different set of histories

1100
01:20:31,000 --> 01:20:33,920
and intervening experiences in order to develop.

1101
01:20:33,920 --> 01:20:36,080
In the average expected environment,

1102
01:20:36,080 --> 01:20:40,040
with a good enough child and a good enough mother,

1103
01:20:40,040 --> 01:20:42,640
by a certain age, the age that you're noticing,

1104
01:20:42,640 --> 01:20:44,800
some of these children are beginning to engage in things

1105
01:20:44,800 --> 01:20:47,680
that look to be prosocial.

1106
01:20:47,680 --> 01:20:49,520
What I think is sort of an interesting question

1107
01:20:49,520 --> 01:20:53,040
is whether that activity at that stage

1108
01:20:53,040 --> 01:20:56,600
is automatic in some fashion.

1109
01:20:56,600 --> 01:20:57,560
And I'm neutral by it.

1110
01:20:57,560 --> 01:20:58,960
I don't know where it is or not.

1111
01:20:58,960 --> 01:21:00,600
Or whether it already has something

1112
01:21:00,600 --> 01:21:06,480
to do with some set of histories about how the child has

1113
01:21:06,480 --> 01:21:09,720
been smiled at, appreciated, what has been done.

1114
01:21:09,720 --> 01:21:13,120
So that the child now having those prior capacities

1115
01:21:13,120 --> 01:21:15,400
is now able to see that, oh, I'm

1116
01:21:15,400 --> 01:21:18,400
going to help you rather than not help you.

1117
01:21:18,400 --> 01:21:22,960
And so there is a notion here of, I think,

1118
01:21:22,960 --> 01:21:26,640
both, if you will, hardwiring in the sense of what

1119
01:21:26,640 --> 01:21:28,800
the hardware is, what the prior capacities are,

1120
01:21:28,800 --> 01:21:30,800
and how they change over time, and what

1121
01:21:30,800 --> 01:21:35,400
the intervening history is that enables some set of characteristics

1122
01:21:35,400 --> 01:21:38,160
to be more likely to be the case than others.

1123
01:21:38,160 --> 01:21:41,800
I'm going to answer that, and then I'll go to the audience.

1124
01:21:41,800 --> 01:21:42,800
Right.

1125
01:21:42,800 --> 01:21:48,400
Well, certainly your each individual's developmental history

1126
01:21:48,400 --> 01:21:53,880
will be very different if you are locked in a dark cupboard.

1127
01:21:53,880 --> 01:21:58,320
But there are just lots and lots of things

1128
01:21:58,320 --> 01:22:03,000
between the most extreme two possibilities.

1129
01:22:03,000 --> 01:22:05,520
One is that there is no human nature.

1130
01:22:05,520 --> 01:22:08,600
It's just all a result of your exposure.

1131
01:22:08,600 --> 01:22:12,120
And if you were brought up with chint, you would be a chimp.

1132
01:22:12,120 --> 01:22:15,440
And if a chimp was brought up with a human being,

1133
01:22:15,440 --> 01:22:16,720
it would turn it to a human being.

1134
01:22:16,720 --> 01:22:19,880
And that, people have tried to bring chimps up that way,

1135
01:22:19,880 --> 01:22:22,800
and they don't turn at the human beings.

1136
01:22:22,800 --> 01:22:26,440
But on the other hand, between that extreme

1137
01:22:26,440 --> 01:22:28,400
and the other extreme that somehow we're

1138
01:22:28,400 --> 01:22:31,440
born knowing absolutely everything that we know now,

1139
01:22:31,440 --> 01:22:32,880
that's obviously not true.

1140
01:22:32,880 --> 01:22:38,400
So the answer is somewhere between those two extremes.

1141
01:22:38,400 --> 01:22:43,840
And that's what makes all these questions so difficult to answer.

1142
01:22:43,840 --> 01:22:48,400
And there are animal models of responding to need in others.

1143
01:22:48,400 --> 01:22:51,920
And the hypothalamus plays a primary role in that.

1144
01:22:51,920 --> 01:22:57,880
And it's a cross-species from rats to sheep to birds.

1145
01:22:57,880 --> 01:23:01,840
What you find is just this hardwired response to need

1146
01:23:01,840 --> 01:23:02,840
that it looks like.

1147
01:23:02,840 --> 01:23:06,440
And it looks like the experience will make it easier or more

1148
01:23:06,440 --> 01:23:08,200
difficult to respond to need.

1149
01:23:08,200 --> 01:23:10,680
Because look, altruism is a special case.

1150
01:23:10,680 --> 01:23:12,880
You're incurring costs.

1151
01:23:12,880 --> 01:23:14,840
You could give up all of your resources

1152
01:23:14,840 --> 01:23:16,280
to another person if you were always

1153
01:23:16,280 --> 01:23:17,400
activating that motivation.

1154
01:23:17,400 --> 01:23:18,840
You'd never survive in reproduces.

1155
01:23:18,840 --> 01:23:20,600
Well, and that's why you're just a science issue

1156
01:23:20,600 --> 01:23:23,200
that you're defining to be in with becomes so important, which

1157
01:23:23,200 --> 01:23:25,280
is especially if you want to look at the notion

1158
01:23:25,280 --> 01:23:28,280
of prior capacities or embodiment issues,

1159
01:23:28,280 --> 01:23:36,200
or what within the body would facilitate or inhibit

1160
01:23:36,200 --> 01:23:40,240
the expression of what the person in the average expected

1161
01:23:40,240 --> 01:23:42,480
environment with a good enough mother,

1162
01:23:42,480 --> 01:23:44,760
with a good enough set of socializations becomes.

1163
01:23:44,760 --> 01:23:47,600
And under those conditions, most of they become like us.

1164
01:23:47,600 --> 01:23:48,840
One of the really beautiful features,

1165
01:23:48,840 --> 01:23:52,640
I think of the sort of saved psychoanalysis from the 30s,

1166
01:23:52,640 --> 01:23:55,840
40s, and the 50s was this notion of an average expected

1167
01:23:55,840 --> 01:23:58,040
environment, a good enough mother,

1168
01:23:58,040 --> 01:24:00,480
some notion of a very broad set of conditions,

1169
01:24:00,480 --> 01:24:03,040
but still a broad set of human conditions that

1170
01:24:03,040 --> 01:24:05,720
would lead to a certain kind of enculturation,

1171
01:24:05,720 --> 01:24:07,960
that if you distort those conditions too much,

1172
01:24:07,960 --> 01:24:09,280
you end up in trouble.

1173
01:24:09,280 --> 01:24:11,240
And even if you have those conditions,

1174
01:24:11,240 --> 01:24:14,280
but if the child is not a good enough child to begin with,

1175
01:24:14,280 --> 01:24:15,640
you don't get the result.

1176
01:24:15,640 --> 01:24:18,840
And in some ways, the science becomes extraordinarily

1177
01:24:18,840 --> 01:24:22,880
important, is defining how these things can go wrong.

1178
01:24:22,880 --> 01:24:26,720
I think we do know early exposure to stress completely

1179
01:24:26,720 --> 01:24:33,040
changes the receptor distributions in these areas

1180
01:24:33,040 --> 01:24:34,040
that we're talking about.

1181
01:24:34,040 --> 01:24:37,760
So moms who have to be away from their infants,

1182
01:24:37,760 --> 01:24:41,360
because they're having to work in our country, for example,

1183
01:24:41,360 --> 01:24:44,280
that's probably a problem.

1184
01:24:44,280 --> 01:24:46,800
I agree with you, human capacities, though, are.

1185
01:24:46,800 --> 01:24:49,880
I mean, these do look like very general mechanisms.

1186
01:24:49,880 --> 01:24:51,280
OK.

1187
01:24:51,280 --> 01:24:51,920
Questions.

1188
01:24:51,920 --> 01:24:56,680
Please ask questions rather than make long comments.

1189
01:24:56,680 --> 01:24:59,160
If you can line up to the microphone.

1190
01:24:59,160 --> 01:25:00,160
The microphone.

1191
01:25:00,160 --> 01:25:01,160
Sir.

1192
01:25:01,160 --> 01:25:02,160
Hi.

1193
01:25:02,160 --> 01:25:03,160
Hi.

1194
01:25:03,160 --> 01:25:04,160
Hi.

1195
01:25:04,160 --> 01:25:05,160
I have a question.

1196
01:25:05,160 --> 01:25:06,160
I just kept wanting just to play with your shirt.

1197
01:25:06,160 --> 01:25:07,160
I mean, what was that about?

1198
01:25:07,160 --> 01:25:08,160
Please, go ahead.

1199
01:25:08,160 --> 01:25:10,160
I hope they got that up.

1200
01:25:10,160 --> 01:25:11,160
No.

1201
01:25:11,160 --> 01:25:12,160
Apparently they're filming.

1202
01:25:12,160 --> 01:25:13,160
Exhibit A.

1203
01:25:13,160 --> 01:25:14,160
That's going to go better, though, yeah.

1204
01:25:14,160 --> 01:25:21,160
Can you speak into the issue of you dropping your pen on the child?

1205
01:25:21,160 --> 01:25:28,640
Pics of the pen.

1206
01:25:28,640 --> 01:25:35,440
My question is, how do you know whether this is an act of right action or right place?

1207
01:25:35,440 --> 01:25:37,680
And I'll give you an example.

1208
01:25:37,680 --> 01:25:44,920
What if that same child is in a room and something falls off his shelf?

1209
01:25:44,920 --> 01:25:50,200
And he approaches the object, picks it up, and puts it back on the shelf.

1210
01:25:50,200 --> 01:25:52,560
The pen belongs with the man.

1211
01:25:52,560 --> 01:25:54,480
The book belongs on the shelf.

1212
01:25:54,480 --> 01:25:55,920
That's a good question.

1213
01:25:55,920 --> 01:25:56,920
That's good.

1214
01:25:56,920 --> 01:25:57,920
How do you know?

1215
01:25:57,920 --> 01:25:58,920
It's cool.

1216
01:25:58,920 --> 01:26:06,760
Well, I think part of the answer is given by it's not simply where the pen belongs, because

1217
01:26:06,760 --> 01:26:17,080
presumably that's the same answer in both the cases where the person drops their pen by

1218
01:26:17,080 --> 01:26:24,120
accident they didn't mean to, and the case where they deliberately throw it on the floor.

1219
01:26:24,120 --> 01:26:29,120
I mean, it's still that person's pen belongs, but it has no sense of altruism or right.

1220
01:26:29,120 --> 01:26:30,520
Yeah, that's what you said.

1221
01:26:30,520 --> 01:26:31,520
Is it this experiment?

1222
01:26:31,520 --> 01:26:32,520
Oh, well, yeah.

1223
01:26:32,520 --> 01:26:33,520
It's really quite, yeah.

1224
01:26:33,520 --> 01:26:39,040
So it's, I mean, why do I think these are in, I say, simple cases?

1225
01:26:39,040 --> 01:26:44,840
Because you can't really imagine, I think, that an 18-month-old is reasoning this out

1226
01:26:44,840 --> 01:26:53,160
in a very complicated, fancy way, or reflecting upon this for several months laying plans and

1227
01:26:53,160 --> 01:26:54,160
plots.

1228
01:26:54,160 --> 01:27:00,880
It's just a very spontaneous reaction, but it's a sophisticated one because it takes,

1229
01:27:00,880 --> 01:27:04,280
because it takes into account my intention.

1230
01:27:04,280 --> 01:27:06,680
It takes into account what I wanted.

1231
01:27:06,680 --> 01:27:13,160
But is his intention, he's only 18 months, is his intention an automatic, it fell from

1232
01:27:13,160 --> 01:27:17,920
the man's hand, it fell from the bookshelf, just an automatic response?

1233
01:27:17,920 --> 01:27:23,560
Or is it a sense of altruism over the poor man dropped his pen?

1234
01:27:23,560 --> 01:27:29,960
And I think we have to, I mean, in my opinion, the book and the pen are equal.

1235
01:27:29,960 --> 01:27:33,800
Something is a rye, and he just naturally corrects.

1236
01:27:33,800 --> 01:27:38,920
I like studies, though, with other manipulations, like trying to help an experiment or open

1237
01:27:38,920 --> 01:27:41,480
a door that he's trying to have trouble opening.

1238
01:27:41,480 --> 01:27:42,480
Yeah, I've seen that.

1239
01:27:42,480 --> 01:27:43,480
Yeah, so I mean, nerd.

1240
01:27:43,480 --> 01:27:44,480
But what about what is the answer?

1241
01:27:44,480 --> 01:27:45,480
I think the answer is an inanimate.

1242
01:27:45,480 --> 01:27:51,480
I think, you know, you're saying, is it automatic or is there a sense of what could

1243
01:27:51,480 --> 01:27:52,880
help?

1244
01:27:52,880 --> 01:27:55,240
I think the answer is yes, in both cases.

1245
01:27:55,240 --> 01:27:57,520
It's an automatic sense of wanting to help.

1246
01:27:57,520 --> 01:27:58,720
That's an empirical question.

1247
01:27:58,720 --> 01:28:01,680
I can give you a naturalistic observation.

1248
01:28:01,680 --> 01:28:06,480
Unfortunately, it's an N of 1, but Eric Marcus, psychoanalyst, tells a really wonderful

1249
01:28:06,480 --> 01:28:15,120
poignant story about his 24-month-old son who was in the room when Eric was returning

1250
01:28:15,120 --> 01:28:19,600
from the hospital after his mother had died and his father was with him.

1251
01:28:19,600 --> 01:28:26,040
And no words were spoken, and the two-year-old looked at his father, took the binky out of

1252
01:28:26,040 --> 01:28:30,040
his mouth, and walked over to him to offer it.

1253
01:28:30,040 --> 01:28:31,040
Yeah.

1254
01:28:31,040 --> 01:28:32,040
Yeah.

1255
01:28:32,040 --> 01:28:37,040
Hi.

1256
01:28:37,040 --> 01:28:52,760
I write about evolutionary biology, and I guess I was hoping for some clear picture in

1257
01:28:52,760 --> 01:29:00,480
your minds of this distinction between human altruism and other organisms.

1258
01:29:00,480 --> 01:29:06,960
I mean, the problem we get when we talk just sort of this generally about the subject is

1259
01:29:06,960 --> 01:29:11,080
that we say, well, altruism must really include this component.

1260
01:29:11,080 --> 01:29:14,080
For example, this must include this component of selflessness.

1261
01:29:14,080 --> 01:29:20,520
It must be the organism, the human, the actor, can't benefit.

1262
01:29:20,520 --> 01:29:24,880
Well, in evolutionary biology, we call that strong altruism.

1263
01:29:24,880 --> 01:29:29,760
And frankly, we don't have an explanation for strong altruism.

1264
01:29:29,760 --> 01:29:35,920
All of the research in the last 40 years assumes either kin selection or assortment.

1265
01:29:35,920 --> 01:29:42,000
Both require the carrier class and the recipient class to be virtually identical, which means

1266
01:29:42,000 --> 01:29:45,280
that you must get some benefit.

1267
01:29:45,280 --> 01:29:51,680
So strong altruism, whereby definition, the carrier doesn't get any benefit, doesn't

1268
01:29:51,680 --> 01:29:52,680
receive it.

1269
01:29:52,680 --> 01:29:57,200
It's not a recipient or a beneficiary.

1270
01:29:57,200 --> 01:30:00,560
We simply don't have a good explanation for that per se.

1271
01:30:00,560 --> 01:30:07,440
I'm not suggesting that there won't be one or that I'm not working on one.

1272
01:30:07,440 --> 01:30:13,440
So I think what I'm wondering about is, if you want to try and maybe distinguish between

1273
01:30:13,440 --> 01:30:24,680
what you feel human altruism is from this more animalistic, I don't know what would

1274
01:30:24,680 --> 01:30:27,840
be a good word for.

1275
01:30:27,840 --> 01:30:29,320
I'm sorry?

1276
01:30:29,320 --> 01:30:31,560
Not a sapient, okay?

1277
01:30:31,560 --> 01:30:33,560
About from biologically.

1278
01:30:33,560 --> 01:30:36,560
Well, we're all biological.

1279
01:30:36,560 --> 01:30:46,440
And if you believe certain writers, groups are living systems and society is living systems.

1280
01:30:46,440 --> 01:30:51,920
Sorry, in your question, I thought we actually tried to play with the question and one of

1281
01:30:51,920 --> 01:30:54,480
the, we did it in three ways.

1282
01:30:54,480 --> 01:31:00,440
One was the difference between intrinsic versus instrumental, in which, and I'm taking as

1283
01:31:00,440 --> 01:31:03,080
a given that people can do things for intrinsic reasons.

1284
01:31:03,080 --> 01:31:05,680
I'm just doing it because it's the right thing to do.

1285
01:31:05,680 --> 01:31:09,400
Now that's one class versus instrumental, but the other class is.

1286
01:31:09,400 --> 01:31:11,400
Are you suggesting that's to think of human?

1287
01:31:11,400 --> 01:31:14,800
Yes, I think that's distinct for humans, and I'm going to be neutral about that because

1288
01:31:14,800 --> 01:31:16,160
it's hard for me to ask my dog.

1289
01:31:16,160 --> 01:31:20,000
I mean, I guess the joke goes, I'll trust my dog with my life, but not my lunch.

1290
01:31:20,000 --> 01:31:21,000
I can comment on that.

1291
01:31:21,000 --> 01:31:23,000
But we have that other case, which is that something-

1292
01:31:23,000 --> 01:31:24,000
So that was like an anecdote?

1293
01:31:24,000 --> 01:31:25,000
No, he finished.

1294
01:31:25,000 --> 01:31:26,000
Let me finish.

1295
01:31:26,000 --> 01:31:30,360
So we discussed intrinsic versus instrumental, but then we also brought up the case in which

1296
01:31:30,360 --> 01:31:41,440
there is a genetic and or other set of biologic advantages that you were speaking to.

1297
01:31:41,440 --> 01:31:46,400
And it seems to me that these are the way we've been breaking this down.

1298
01:31:46,400 --> 01:31:52,760
One way is to insist, at least in the human example, that there is a moral component.

1299
01:31:52,760 --> 01:31:56,680
Another is to remove the moral component and be neutral about that, which allows to introduce

1300
01:31:56,680 --> 01:31:57,680
these other cases.

1301
01:31:57,680 --> 01:32:03,240
But that's a self-satisfied answer because your suggested moral component only exists

1302
01:32:03,240 --> 01:32:05,240
in humans, therefore- No, I'm not saying that.

1303
01:32:05,240 --> 01:32:06,240
No, no, no.

1304
01:32:06,240 --> 01:32:07,240
It's because the moral component, it must be human uniquely.

1305
01:32:07,240 --> 01:32:08,240
No, no, I wasn't.

1306
01:32:08,240 --> 01:32:09,240
That was not what I said.

1307
01:32:09,240 --> 01:32:11,280
I'm not saying that it only exists in human.

1308
01:32:11,280 --> 01:32:15,120
I'm saying that it's only easy for me to find out about humans.

1309
01:32:15,120 --> 01:32:16,120
I can talk about it.

1310
01:32:16,120 --> 01:32:17,480
It's hard for me to talk about it with my dog.

1311
01:32:17,480 --> 01:32:22,000
I do, in fact, believe my dog does do some things only for my good, but only on a good

1312
01:32:22,000 --> 01:32:23,000
day.

1313
01:32:23,000 --> 01:32:24,000
But it says moral.

1314
01:32:24,000 --> 01:32:28,960
I mean, I think there is, you know, you talk about morality and animals.

1315
01:32:28,960 --> 01:32:30,560
But also, I mean, there may be a way.

1316
01:32:30,560 --> 01:32:35,640
I don't know what they- The bones hang behind the- when they flee a predator, the larger

1317
01:32:35,640 --> 01:32:41,400
male bones will hang behind and they will mob a predator and prevent the predator from

1318
01:32:41,400 --> 01:32:43,240
pursuing the pack.

1319
01:32:43,240 --> 01:32:45,160
Now, are they doing that for their own purposes?

1320
01:32:45,160 --> 01:32:49,280
But, see, I think part of it is the question of can you- Have they acted properly?

1321
01:32:49,280 --> 01:32:53,040
They act or reflect on the morality of what they're doing.

1322
01:32:53,040 --> 01:32:54,040
So that's part of it.

1323
01:32:54,040 --> 01:32:56,240
What does it mean to act stuff when they want to answer that?

1324
01:32:56,240 --> 01:32:58,040
I mean, does that just think the human or is-

1325
01:32:58,040 --> 01:33:02,760
So I think there are many ways that what we think of as distinctly human is not distinctly

1326
01:33:02,760 --> 01:33:04,080
human at all.

1327
01:33:04,080 --> 01:33:09,240
And when we're talking about activating this general parenting system, where, you know,

1328
01:33:09,240 --> 01:33:14,760
whatever is in place for mammals to raise their young, and that that would be cross

1329
01:33:14,760 --> 01:33:16,680
species, right?

1330
01:33:16,680 --> 01:33:20,200
And what would change with species are a couple things.

1331
01:33:20,200 --> 01:33:23,640
One is, what does it take to activate that parenting system?

1332
01:33:23,640 --> 01:33:30,240
So when you talk about, you know, brains that are much smaller, it may be a particular

1333
01:33:30,240 --> 01:33:34,040
science stimuli that activate that brain, that activate that system.

1334
01:33:34,040 --> 01:33:38,780
But when you talk about something like humans, we have these reasoning abilities and all

1335
01:33:38,780 --> 01:33:42,920
kinds of things that could potentially make us think, oh, this person over here, I don't

1336
01:33:42,920 --> 01:33:45,280
know her, but I think she might need my help.

1337
01:33:45,280 --> 01:33:47,840
Because, you know, she's looking at me in a particular way.

1338
01:33:47,840 --> 01:33:50,600
And I'm not sure if I'm going to go see what she wants.

1339
01:33:50,600 --> 01:33:53,520
So it's like we can activate it in other ways, right?

1340
01:33:53,520 --> 01:33:55,680
But the behavior itself may be very similar.

1341
01:33:55,680 --> 01:34:03,600
With one other very interesting piece about humans compared to other species is that part

1342
01:34:03,600 --> 01:34:09,040
of our brain that's more lateral is really a relatively new evolutionary development.

1343
01:34:09,040 --> 01:34:12,760
And these areas of our brain track things like morality.

1344
01:34:12,760 --> 01:34:23,760
And these, and including in that is senses of injustice and that even little kids have,

1345
01:34:23,760 --> 01:34:28,320
even though they might still act in their own self-interest, they can still be outraged

1346
01:34:28,320 --> 01:34:30,760
and they still have those feelings.

1347
01:34:30,760 --> 01:34:37,600
So the question I've wondered is if we start with these capacities to give, and now we're

1348
01:34:37,600 --> 01:34:41,080
in humans where we're giving all the time to everyone, and now everybody's starting

1349
01:34:41,080 --> 01:34:46,360
to exploit us, now you're going to really start to have to develop sophisticated mechanisms

1350
01:34:46,360 --> 01:34:49,360
to really track costs and benefits over time.

1351
01:34:49,360 --> 01:34:50,360
Who's my friend?

1352
01:34:50,360 --> 01:34:51,360
Who's not my friend?

1353
01:34:51,360 --> 01:34:53,240
Is this person trustworthy?

1354
01:34:53,240 --> 01:34:57,120
And now all of a sudden we have something that's more instrumental because we can have

1355
01:34:57,120 --> 01:35:04,200
strategic helping that enters where we can empathize for other reasons than necessarily

1356
01:35:04,200 --> 01:35:05,960
the good perhaps.

1357
01:35:05,960 --> 01:35:09,000
And we can apply these in more ways.

1358
01:35:09,000 --> 01:35:14,040
And what it does it is adds this interesting layer, I guess, on everything.

1359
01:35:14,040 --> 01:35:15,040
That's my explanation.

1360
01:35:15,040 --> 01:35:16,040
Thank you.

1361
01:35:16,040 --> 01:35:32,160
I think your stuff of this gentleman was describing a study experiment and it was about the dictator

1362
01:35:32,160 --> 01:35:38,080
who had the choice of taking all everything for himself or giving him.

1363
01:35:38,080 --> 01:35:42,480
And you start to say something about 70%.

1364
01:35:42,480 --> 01:35:43,480
And then you were interrupted.

1365
01:35:43,480 --> 01:35:51,560
I was very curious what the resolution of these I remember doing a study like that.

1366
01:35:51,560 --> 01:35:55,600
But you were interrupted and I don't know what came of that study.

1367
01:35:55,600 --> 01:35:56,600
Okay.

1368
01:35:56,600 --> 01:36:00,200
Where why was that manipulated?

1369
01:36:00,200 --> 01:36:05,440
Was that, you know.

1370
01:36:05,440 --> 01:36:12,400
It's, I mean, despite the fact that 100% of people could just pocket the whole 10 bucks

1371
01:36:12,400 --> 01:36:21,000
and leave and there'd be no comeback.

1372
01:36:21,000 --> 01:36:30,360
Despite that, what about 70% of people do is they give about 30% of the 10 bucks to the

1373
01:36:30,360 --> 01:36:31,520
other person.

1374
01:36:31,520 --> 01:36:37,240
And then they take the remaining 70% and leave.

1375
01:36:37,240 --> 01:36:41,600
And the mathematician says they're not playing the game.

1376
01:36:41,600 --> 01:36:46,360
They're irrational because they should take it all.

1377
01:36:46,360 --> 01:36:48,760
And that's really been the basis of economic theory.

1378
01:36:48,760 --> 01:36:54,480
It's been the assumption that the rational agent would take everything and leave.

1379
01:36:54,480 --> 01:36:58,240
But we don't behave like that, actually.

1380
01:36:58,240 --> 01:37:05,440
So what is there any explanation, any conclusion?

1381
01:37:05,440 --> 01:37:12,200
Is there a, you know, the possibilities that this is a kind of a calculation?

1382
01:37:12,200 --> 01:37:17,960
If I do this, then ultimately this will be rewarded.

1383
01:37:17,960 --> 01:37:25,520
Or is there an intrinsic sense again of morality as an advantage of fairness?

1384
01:37:25,520 --> 01:37:27,160
So I was curious.

1385
01:37:27,160 --> 01:37:31,080
So I think, so I'm on the side of intrinsic.

1386
01:37:31,080 --> 01:37:34,600
I think there is an intrinsic moral sense.

1387
01:37:34,600 --> 01:37:41,120
I think there's an intrinsic sense of being interested in other people's inner lives,

1388
01:37:41,120 --> 01:37:43,920
interested in the mode of nations.

1389
01:37:43,920 --> 01:37:50,440
And the way that I study intrinsic is by looking at babies and very, very young kids.

1390
01:37:50,440 --> 01:37:56,760
And if I can find, if I can find these things in babies and young kids, I'm going to take

1391
01:37:56,760 --> 01:38:03,080
a big step towards supporting my claim that these kinds of things are intrinsic.

1392
01:38:03,080 --> 01:38:06,840
Now, they're intrinsic, but they're completely routine.

1393
01:38:06,840 --> 01:38:10,720
So the 18 month old picks up my pen.

1394
01:38:10,720 --> 01:38:15,640
When I don't mean to drop it, it gives it back to me, tries to help me.

1395
01:38:15,640 --> 01:38:17,480
You say, well, is that automatic?

1396
01:38:17,480 --> 01:38:18,480
Is it praiseworthy?

1397
01:38:18,480 --> 01:38:23,200
Should, well, I don't know if you saw your grandchild doing something.

1398
01:38:23,200 --> 01:38:26,120
I bet you would praise your child.

1399
01:38:26,120 --> 01:38:32,000
And I thought, well, maybe she did that automatically or something of that sort.

1400
01:38:32,000 --> 01:38:34,000
And one shouldn't be praiseworthy.

1401
01:38:34,000 --> 01:38:37,200
But I think it was an experiment that you described.

1402
01:38:37,200 --> 01:38:39,640
They didn't ask people afterwards.

1403
01:38:39,640 --> 01:38:42,360
Why did you take the $10?

1404
01:38:42,360 --> 01:38:44,000
Why did you leave $3?

1405
01:38:44,000 --> 01:38:45,000
Why did you do this?

1406
01:38:45,000 --> 01:38:47,000
Why did you do that?

1407
01:38:47,000 --> 01:38:50,200
Yeah, so now the variations.

1408
01:38:50,200 --> 01:38:51,200
Right.

1409
01:38:51,200 --> 01:38:55,880
So if you give these kinds of experiments to adults, and then afterwards you say to them,

1410
01:38:55,880 --> 01:38:57,400
why did you do that?

1411
01:38:57,400 --> 01:38:59,920
You get all sorts of different explanations.

1412
01:38:59,920 --> 01:39:03,880
I think, basically, when you look at these explanations, they're all over the place.

1413
01:39:03,880 --> 01:39:05,600
I think people don't really know why.

1414
01:39:05,600 --> 01:39:07,720
They do these things.

1415
01:39:07,720 --> 01:39:10,560
Why did you help me?

1416
01:39:10,560 --> 01:39:16,320
You see these heroes that jumped down onto the subway and pulled somebody from the electric

1417
01:39:16,320 --> 01:39:21,360
lines, the risk of their lives, and afterwards they're interviewed on, you know, Channel

1418
01:39:21,360 --> 01:39:22,360
4 or something.

1419
01:39:22,360 --> 01:39:23,360
Why did you do that?

1420
01:39:23,360 --> 01:39:24,520
Oh, no, anybody would do it.

1421
01:39:24,520 --> 01:39:25,520
I just did it.

1422
01:39:25,520 --> 01:39:26,520
They were doing it.

1423
01:39:26,520 --> 01:39:29,320
And then they, but I'm thinking.

1424
01:39:29,320 --> 01:39:40,160
Could there be a basic tribalism that we connect, we relate to things that are similar, that

1425
01:39:40,160 --> 01:39:41,360
we relate to.

1426
01:39:41,360 --> 01:39:49,880
And that's kind of program, or hormone, oxytocin, whatever, that could that be a factor, that

1427
01:39:49,880 --> 01:39:57,880
we all have some of that connection with those lives.

1428
01:39:57,880 --> 01:40:02,520
Well, again, if you want to come.

1429
01:40:02,520 --> 01:40:03,920
I don't mind what you call it.

1430
01:40:03,920 --> 01:40:05,120
I just say, there it is.

1431
01:40:05,120 --> 01:40:11,200
I think this is part of human nature, and the human nature is in part angelic, and it's

1432
01:40:11,200 --> 01:40:14,400
also in part, you know, the devil.

1433
01:40:14,400 --> 01:40:17,680
I mean, it's both things are there, both possibilities.

1434
01:40:17,680 --> 01:40:23,640
But you know, in part in parcel with people's explanations, I mean, I think it's often

1435
01:40:23,640 --> 01:40:27,840
the case that people know what they take to be the right thing to do without being able

1436
01:40:27,840 --> 01:40:30,000
to articulate it.

1437
01:40:30,000 --> 01:40:32,200
And I think these things often show up.

1438
01:40:32,200 --> 01:40:33,560
It shows up behaviorally.

1439
01:40:33,560 --> 01:40:35,080
They know what's expected of them.

1440
01:40:35,080 --> 01:40:37,840
They know what is, you know, in character.

1441
01:40:37,840 --> 01:40:40,320
They know what the tribe requires, whatever it is.

1442
01:40:40,320 --> 01:40:41,960
It's the unconscious mind.

1443
01:40:41,960 --> 01:40:48,280
I mean, I think the unconscious mind is far more sophisticated than Freud could have imagined.

1444
01:40:48,280 --> 01:40:49,560
It's not a primitive thing.

1445
01:40:49,560 --> 01:40:52,440
It's a very sophisticated thing.

1446
01:40:52,440 --> 01:40:53,880
It reasons, it thinks.

1447
01:40:53,880 --> 01:40:56,120
It remembers, it knows.

1448
01:40:56,120 --> 01:40:57,240
It talks.

1449
01:40:57,240 --> 01:40:59,560
It does all sorts of things.

1450
01:40:59,560 --> 01:41:06,520
And you know, that's like the rest of the iceberg and our conscious selves very much sit

1451
01:41:06,520 --> 01:41:08,560
on top of this.

1452
01:41:08,560 --> 01:41:15,840
And so I think these things are real and I think they're really built into the brain.

1453
01:41:15,840 --> 01:41:18,360
And I think we always have them.

1454
01:41:18,360 --> 01:41:21,880
And it's just fundamental part of human nature.

1455
01:41:21,880 --> 01:41:25,320
So I'll take the last four questions.

1456
01:41:25,320 --> 01:41:27,880
I'm terribly upset.

1457
01:41:27,880 --> 01:41:32,120
I thought of Reverend Bonhoeff in hell.

1458
01:41:32,120 --> 01:41:34,640
And I'd like to get him out with your compassion.

1459
01:41:34,640 --> 01:41:38,000
I guess he's not there.

1460
01:41:38,000 --> 01:41:40,400
I don't think he's there.

1461
01:41:40,400 --> 01:41:42,400
That's it.

1462
01:41:42,400 --> 01:41:51,680
I tried to transpose the situation a little and wonder what the church would say if one

1463
01:41:51,680 --> 01:42:03,040
of its leaders, one of its pastors, was in a situation of seeing an armed man, perhaps

1464
01:42:03,040 --> 01:42:13,680
in a theater or a school and a minister on hand, the only way he could stop the person

1465
01:42:13,680 --> 01:42:18,400
was by life threatening action.

1466
01:42:18,400 --> 01:42:22,360
To me, killing Hitler might have saved a few more lives.

1467
01:42:22,360 --> 01:42:23,360
Sure.

1468
01:42:23,360 --> 01:42:24,920
And I mean, I think that was his thought.

1469
01:42:24,920 --> 01:42:32,360
I know in yoga, in Hindu mythology, the story, the teaching is you cannot take a life.

1470
01:42:32,360 --> 01:42:33,520
A life is sacred.

1471
01:42:33,520 --> 01:42:35,040
You cannot take a life.

1472
01:42:35,040 --> 01:42:41,520
However, even the Swami, should he be defending the life of an innocent child, could take

1473
01:42:41,520 --> 01:42:46,120
a life without having karmic repercussions.

1474
01:42:46,120 --> 01:42:51,520
So I was sort of speculate not theologically about what might have gone through Bonhoeff's

1475
01:42:51,520 --> 01:42:59,560
own mind about his moral life and his salvation and his faith.

1476
01:42:59,560 --> 01:43:05,040
He may have imagined he was giving up heaven by doing that and would have been willing

1477
01:43:05,040 --> 01:43:11,760
to give up his own salvation in order to save the people that he was trying to save.

1478
01:43:11,760 --> 01:43:15,000
I don't think he's in hell.

1479
01:43:15,000 --> 01:43:23,720
So the devil's in the unless clauses.

1480
01:43:23,720 --> 01:43:30,880
But there's always been a less clause in all theologies or some sort of less clauses that

1481
01:43:30,880 --> 01:43:31,880
allow.

1482
01:43:31,880 --> 01:43:32,880
Maybe.

1483
01:43:32,880 --> 01:43:33,880
Okay.

1484
01:43:33,880 --> 01:43:35,040
Shifting gears just a bit.

1485
01:43:35,040 --> 01:43:41,760
I'm familiar with game theory, the theoretical game theory, the dictator model.

1486
01:43:41,760 --> 01:43:42,760
Do you have you performed?

1487
01:43:42,760 --> 01:43:48,520
Do you know if anyone is performing or designing these kinds of experiments based on non-zero

1488
01:43:48,520 --> 01:43:54,120
or some game theory rather than Nashian economics or some derivative because if so and that

1489
01:43:54,120 --> 01:43:59,920
panned out that might give a mathematical framework to start addressing the myopic nature of

1490
01:43:59,920 --> 01:44:03,520
always focusing on self-interest and what you thought about that.

1491
01:44:03,520 --> 01:44:10,080
Well I think it's not, you know, this is not my field exactly but I know there's a lot

1492
01:44:10,080 --> 01:44:17,320
of work in a field that can be something that's called the behavioral economics.

1493
01:44:17,320 --> 01:44:22,880
Sometimes it's called neuro economics and so one of the things that they study in that

1494
01:44:22,880 --> 01:44:33,240
field are these game theoretic games and the basic idea behind this new movement, neuro

1495
01:44:33,240 --> 01:44:41,000
economics or whatever you want to call it is to actually try to take these economic models

1496
01:44:41,000 --> 01:44:53,040
and better represent the actual nature of human beings rather than just make these assumptions

1497
01:44:53,040 --> 01:44:56,040
that mathematicians made.

1498
01:44:56,040 --> 01:45:04,400
I have two colleagues, Joe Jeffries and Anthony Putman who sometime in the last two years in

1499
01:45:04,400 --> 01:45:16,720
the Journal of Behavioral Finance have done a series of redescriptions of these classic

1500
01:45:16,720 --> 01:45:25,000
experiments using a wider behavioral logic to make sense of why, you know, of these kinds

1501
01:45:25,000 --> 01:45:26,920
of problems.

1502
01:45:26,920 --> 01:45:31,800
So I think it's within that general realm of behavioral economics we find all the classical

1503
01:45:31,800 --> 01:45:37,520
problems of psychology still there and the kind of introduction of some broader ways

1504
01:45:37,520 --> 01:45:43,480
of conceiving what people actually do and I know that Putman and Jeffries work seems

1505
01:45:43,480 --> 01:45:46,280
to be of that sort.

1506
01:45:46,280 --> 01:45:50,720
We have a study where we did a cooperative card game.

1507
01:45:50,720 --> 01:45:55,960
It was a behavioral economics study and we measured progesterone, a calming hormone and

1508
01:45:55,960 --> 01:46:01,360
the cooperative card game was basically the subjects came in and they had to learn a

1509
01:46:01,360 --> 01:46:05,160
really sophisticated new language almost.

1510
01:46:05,160 --> 01:46:08,240
They didn't get told the rules ahead of time and they had to sort of discover it as they

1511
01:46:08,240 --> 01:46:13,120
went along and when they had an increase in progesterone when they played that game they

1512
01:46:13,120 --> 01:46:17,120
reported a greater willingness to risk their life for their partner at the end.

1513
01:46:17,120 --> 01:46:24,200
That's also interesting because in the extreme with some techniques like single neuron recording

1514
01:46:24,200 --> 01:46:29,400
on neutron diffraction and all the rest of that you might be able to track that neural

1515
01:46:29,400 --> 01:46:33,440
network formation while they're developing that new response.

1516
01:46:33,440 --> 01:46:34,440
Yeah.

1517
01:46:34,440 --> 01:46:35,440
Yeah.

1518
01:46:35,440 --> 01:46:36,440
Yeah.

1519
01:46:36,440 --> 01:46:37,440
Yeah.

1520
01:46:37,440 --> 01:46:38,440
Yeah.

1521
01:46:38,440 --> 01:46:39,440
Thank you.

1522
01:46:39,440 --> 01:46:50,920
I have a little bit of a devil's advocate although I believe in conscious altruism and

1523
01:46:50,920 --> 01:46:56,280
believe that there is some moral consciousness that does exist but I think also there may

1524
01:46:56,280 --> 01:47:02,800
be pleasure of well being some form of endorphins to do well and I think human beings are very

1525
01:47:02,800 --> 01:47:07,200
pleased sometimes when they're not paid back and they do something for someone else.

1526
01:47:07,200 --> 01:47:16,480
So there is something intrinsic just to the self that enjoys that whole behavior and I

1527
01:47:16,480 --> 01:47:21,760
just wanted to say one other thing about the falling pen or something.

1528
01:47:21,760 --> 01:47:27,760
I mean I did have a dog who did pick up things when something fell but I think they're the

1529
01:47:27,760 --> 01:47:32,760
line what's interesting in human beings is that line that eventually becomes conscious

1530
01:47:32,760 --> 01:47:38,080
as you were speaking where it no longer is instinctual is no longer on those other levels

1531
01:47:38,080 --> 01:47:40,600
but turns into a conscious act and awareness.

1532
01:47:40,600 --> 01:47:44,120
I think that's the important part where one begins really.

1533
01:47:44,120 --> 01:47:45,120
Thank you.

1534
01:47:45,120 --> 01:47:49,680
I want to bring this back a little bit to psychoanalysis.

1535
01:47:49,680 --> 01:47:52,440
I'm a psychoanalyst.

1536
01:47:52,440 --> 01:47:58,880
One thing we know is and I think this has been a fascinating, fascinating discussion

1537
01:47:58,880 --> 01:48:06,480
and it's so complicated and Freud certainly said in one of his papers that at one point

1538
01:48:06,480 --> 01:48:13,520
in the future we will find that there is a organic underlay to all of the psychological

1539
01:48:13,520 --> 01:48:17,400
theories that he postulated so I just wanted to say that.

1540
01:48:17,400 --> 01:48:22,840
I also hate people getting up and not asking questions and making points but I really want

1541
01:48:22,840 --> 01:48:28,560
to so please forgive me.

1542
01:48:28,560 --> 01:48:34,760
There is I think a brilliant psychoanalyst who talks about rights, about narcissism.

1543
01:48:34,760 --> 01:48:36,400
His name is Sheldon Ba.

1544
01:48:36,400 --> 01:48:37,400
Do you know him?

1545
01:48:37,400 --> 01:48:38,400
Yes.

1546
01:48:38,400 --> 01:48:39,400
Yes.

1547
01:48:39,400 --> 01:48:44,200
And he talks about the child who grows up in a family in which the mother, neither the

1548
01:48:44,200 --> 01:48:54,680
mother nor father has that child, separate child in the mind, in her mind and those children

1549
01:48:54,680 --> 01:49:01,840
tend to grow up with what we might call narcissistic personality disorders.

1550
01:49:01,840 --> 01:49:07,640
And if, and I've seen this in patients, it's really quite dramatic.

1551
01:49:07,640 --> 01:49:09,960
So that's one thing I want you to mention.

1552
01:49:09,960 --> 01:49:16,720
The other thing I thought of is in terms of altruism, I thought of Socrates and the apology

1553
01:49:16,720 --> 01:49:25,200
and how he really knew he was going to die but he kept his principles.

1554
01:49:25,200 --> 01:49:30,880
I thought of Schindler, well he got something out of the factory that he, but it's a good

1555
01:49:30,880 --> 01:49:35,360
example of just an ordinary man as they say, becoming extraordinary.

1556
01:49:35,360 --> 01:49:39,920
The other thing I just wanted to ask and I wanted to ask you, I had a very strong reaction

1557
01:49:39,920 --> 01:49:45,440
to what you said about, and this is political, okay?

1558
01:49:45,440 --> 01:49:55,600
I have a lot of political concerns about Fox News had a, they had people talking about

1559
01:49:55,600 --> 01:50:03,400
how one of the big problems in society is that women go to work and they are the people

1560
01:50:03,400 --> 01:50:07,960
who are taking jobs away from men, etc.

1561
01:50:07,960 --> 01:50:13,600
And I just, I assume that you didn't mean what you said about when women go to work

1562
01:50:13,600 --> 01:50:20,680
and the children behind as if they do because many women don't.

1563
01:50:20,680 --> 01:50:25,360
They have great caretakers, their husbands stay home or the grandmother is there.

1564
01:50:25,360 --> 01:50:26,360
I just wanted to-

1565
01:50:26,360 --> 01:50:28,200
That was a politically incorrect moment.

1566
01:50:28,200 --> 01:50:29,200
What I-

1567
01:50:29,200 --> 01:50:31,200
I think it's dangerous if-

1568
01:50:31,200 --> 01:50:35,320
No, no, I should have said when the primary caregiver has to go to work.

1569
01:50:35,320 --> 01:50:36,960
And that's the word I would have used.

1570
01:50:36,960 --> 01:50:43,080
Well, you began with a point that I think absolutely has to be addressed.

1571
01:50:43,080 --> 01:50:47,960
When you say that Freud makes the argument that at some point he thinks it's all going

1572
01:50:47,960 --> 01:50:48,960
to be reduced to the organ.

1573
01:50:48,960 --> 01:50:49,960
No, he doesn't say-

1574
01:50:49,960 --> 01:50:50,960
Let me finish.

1575
01:50:50,960 --> 01:50:51,960
Actually, let me finish.

1576
01:50:51,960 --> 01:50:52,960
Okay.

1577
01:50:52,960 --> 01:50:53,960
Let me finish.

1578
01:50:53,960 --> 01:50:56,440
He makes similar points about his writings.

1579
01:50:56,440 --> 01:51:00,560
But if we look to the final work, we look at the outline of psychoanalysis, the first

1580
01:51:00,560 --> 01:51:04,440
paragraph, he begins with the fact that we know sort of two things.

1581
01:51:04,440 --> 01:51:07,520
We know something about consciousness and we know something about the brain.

1582
01:51:07,520 --> 01:51:12,120
And I don't have the full paragraph in mind, but in that paragraph, in effect what he

1583
01:51:12,120 --> 01:51:17,800
says, if we knew something about the connection, it would tell us at most location, and this

1584
01:51:17,800 --> 01:51:20,760
is the key, nothing about meaning.

1585
01:51:20,760 --> 01:51:26,840
He's always conceptually separated out, meaning from mechanism.

1586
01:51:26,840 --> 01:51:31,920
And this may go back to his relationship with Breuntano in-

1587
01:51:31,920 --> 01:51:35,280
You know, when he was studying- when he was studying all his philosophy professor at

1588
01:51:35,280 --> 01:51:44,240
Vienna, who argued that all what's inherent in all organism is intentionality versus his

1589
01:51:44,240 --> 01:51:46,720
commitment to the Helmholtz program.

1590
01:51:46,720 --> 01:51:52,520
And these constantly defined attention within psychoanalysis, which he finally addressed beautifully

1591
01:51:52,520 --> 01:51:56,600
in that last- in that final volume in the first paragraph.

1592
01:51:56,600 --> 01:51:59,600
He separates it out and he sides with Breuntano.

1593
01:51:59,600 --> 01:52:01,600
Thank you.

1594
01:52:01,600 --> 01:52:03,600
Thank you to our panel.

1595
01:52:03,600 --> 01:52:30,200
Just need to sign this...

