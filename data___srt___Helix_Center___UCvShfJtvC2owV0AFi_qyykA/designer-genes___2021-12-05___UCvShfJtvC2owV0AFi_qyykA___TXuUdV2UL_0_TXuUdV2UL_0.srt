1
00:00:00,000 --> 00:00:23,000
Recording in progress

2
00:00:23,000 --> 00:00:31,000
Good afternoon.

3
00:00:31,000 --> 00:00:34,000
On behalf of

4
00:00:34,000 --> 00:00:40,000
Ed Narsassian, Director of Helix, Helix Center.

5
00:00:40,000 --> 00:00:44,000
I welcome you to the first of our season.

6
00:00:44,000 --> 00:00:50,000
The second zoom year in our COVID period.

7
00:00:50,000 --> 00:01:01,000
We have gone ahead this year and scheduled some marvelous programs that I just want to mention to you so you can mark them down.

8
00:01:01,000 --> 00:01:19,000
In February, February 26th, we'll be having one on kinetic economics, which will discuss how we are affected in an international global trade world that when goods can't move.

9
00:01:19,000 --> 00:01:32,000
March 12th, we'll have a program on psychedelics April 30th on metaphysics in May 4th on flourishing versus languishing.

10
00:01:32,000 --> 00:01:38,000
So just consider us on those dates.

11
00:01:38,000 --> 00:01:47,000
And today we're very happy to have you join us for Design of G's as in G-E-N-E-S.

12
00:01:47,000 --> 00:01:52,000
And we have a wonderful group who are going to be with us today.

13
00:01:52,000 --> 00:02:07,000
And let me introduce a few of you who are having a little bit of problem with the zoom, but some you may hear phoning in and some are present here.

14
00:02:07,000 --> 00:02:19,000
Henry Greeley is the Edelman Johnson Professor of Law at the Genetics Center for Law and Bio Sciences at Stanford.

15
00:02:19,000 --> 00:02:26,000
He specializes in ethical, legal, and social issues arising from the bio sciences.

16
00:02:26,000 --> 00:02:32,000
And you can read online all of his incredible distinguished accomplishments.

17
00:02:32,000 --> 00:02:36,000
Robert Kutzman, we are hoping we'll be able to join us.

18
00:02:36,000 --> 00:02:44,000
He's Professor of Psychiatry at the College of Physicians and Surgeons and the Joseph Mailman School of Public Health.

19
00:02:44,000 --> 00:02:52,000
And the Director of the Online and In-Person Bioethics Masters in Certificate Program at Columbia University.

20
00:02:52,000 --> 00:03:12,000
Bartlett Riblekski is a full professor at the Bioethics Program at the School of Public Health University of Montreal and senior lecture on Global Health and Social Medicine at Harvard Medical School.

21
00:03:12,000 --> 00:03:30,000
Her research covers a variety of topics such as public funding or the interview IVF, the use of surplus frozen embryos, posthumous reproduction, pre-implantation genetic diagnosis, and many other related focuses.

22
00:03:30,000 --> 00:03:47,000
And Daniel Comfort is here as Professor of History of Medicine at Johns Hopkins. His interest lies in the history of genetics, eugenics, genomics, and biomedicine, as well as bioethics.

23
00:03:47,000 --> 00:03:53,000
And you can read of his other accomplishments and publications on the website.

24
00:03:53,000 --> 00:04:06,000
So I welcome you all. We've had a little bit of zoom entanglement. And so we hope the difficulties are over and from here on and it will be very compelling.

25
00:04:06,000 --> 00:04:20,000
So Jerry Horowitz, who is the Co-Director of the Helix Center, will now moderate. Thank you, Jerry. And Jerry from Columbia University, Professor of Psychiatry.

26
00:04:20,000 --> 00:04:36,000
Thank you, Beverly. This is very exciting. Made even more exciting by the late appearance of two of our esteemed panelists. This is great. Thank, thank you to Miguel and to Alex for getting this all done just at the last moment.

27
00:04:36,000 --> 00:04:41,000
Anyway, I'm eager to let the panelists begin their conversation.

28
00:04:41,000 --> 00:04:54,000
On today's topic, I want to point out that questions can be submitted on zoom and also through YouTube that will be collected by our administrator Alex.

29
00:04:54,000 --> 00:05:06,000
And he will read them out or read out a selection of them at the end of our conversation. And so just bear in mind that they will be collated and referred to later.

30
00:05:06,000 --> 00:05:19,000
And so, you know, further ado, Hank, Greeley in advance, agreed to sort of start things off and give us a sort of an overview of this topic. And then we'll see how the conversation proceeds from there.

31
00:05:19,000 --> 00:05:20,000
Hank.

32
00:05:20,000 --> 00:05:25,000
Okay, well, thank you. Happy to be here, wherever here is in cyberspace.

33
00:05:25,000 --> 00:05:37,000
Well, it was almost exactly three years ago, three years and a week ago when I was shocked one Sunday evening by an email from a friend, the title of which was Christopher babies.

34
00:05:37,000 --> 00:05:47,000
He was reporting on the then leaked report that a Chinese Chinese scientist named who John Kue, or something close to that.

35
00:05:47,000 --> 00:06:06,000
And he did announce the birth of twin girls, whose embryos had been edited using process called CRISPR, clustered regularly in a space short palindromic repeats which is a real good reason to use the acronym and just call it CRISPR, and had been born that year.

36
00:06:06,000 --> 00:06:21,000
And this caused a huge uproar. Ultimately, I think, Dr. who expected to be hailed as a hero, ended up getting denounced as a villain and ultimately sentenced to three years in prison in China.

37
00:06:21,000 --> 00:06:41,000
But that's the, that's the most recent of many interesting things that have gone on with human reproduction at the intersection of human reproduction and genetics. We can go back 50 years or so to when we started doing prenatal genetic testing through a process called amniot synthesis.

38
00:06:41,000 --> 00:07:07,000
After the birth of Louise Roberts, the first IVF baby. We started having more possibilities, and we can go back 30 years to the birth of the first child, who was born after a procedure called preamplantation genetic diagnosis, where embryos created through IVF so outside the women's body are genetically tested.

39
00:07:07,000 --> 00:07:19,000
That child is 31 years old I had the good fortune of talking to the reproductive endocrinologist who is involved in her birth and he's so proud of the fact that she's now a scientist.

40
00:07:19,000 --> 00:07:24,000
I keep telling him it didn't have anything to do with him or his genes and he just smiles.

41
00:07:24,000 --> 00:07:39,000
And now things have gotten more complicated we have embryo selection through PGD we have fetal selection through prenatal diagnosis we have embryo selection through preamplantation genetic diagnosis, which I'm just going to call PGD.

42
00:07:39,000 --> 00:07:56,000
And starting three years ago we have embryo editing through Christopher editing of embryos with at least three cases Dr Hood did at least, Dr who's work led to the birth of at least three babies before he was stopped and ultimately imprisoned.

43
00:07:56,000 --> 00:08:13,000
These options are continuing they're growing their new possibilities like mitochondrial replacement therapy, and their new possibilities coming from the genetics world, including some new efforts to try to figure out more meaning from James, particularly a process that is quite controversial

44
00:08:13,000 --> 00:08:33,000
called probabilistic risk scores. So all of these are going on the one thing that I think is clear is that at least in places and for people with access to good health care, modern health care and money to pay for it.

45
00:08:33,000 --> 00:08:46,000
A genetics is playing an increasing role in how we're having our babies. So I think between prenatal diagnosis preamplantation genetic diagnosis and embryo editing.

46
00:08:46,000 --> 00:08:57,000
Those are the three main steps that we need to think about in conjunction with how much or how little we know about what the DNA sequences actually mean.

47
00:08:57,000 --> 00:08:59,000
And I'll stop there.

48
00:08:59,000 --> 00:09:00,000
Excellent. Thank you.

49
00:09:00,000 --> 00:09:13,000
Hank, I think you raised so many interesting and I would dare say these are all touching on our sort of ethical sense, each one of them. I wonder if we could.

50
00:09:13,000 --> 00:09:24,000
And I also just, I just want to add very quickly, I'm always, I want to try to keep you honest in this sense I've always, a load the expression you know these are complex moral issues because I find that sort of as a hand waving gesture.

51
00:09:24,000 --> 00:09:34,000
I'd like to get down more into nitty gritty of how they are morally complex. So I invite any of the rest of the panelists to start in with any one of these topics and let's see how far we can go with it.

52
00:09:34,000 --> 00:09:47,000
So, first of all, thank you again to the organizers for planning this and it's great to see my colleagues and have a chance to interact with them this afternoon on this very important topic so I'm honored to be here and thank you again.

53
00:09:47,000 --> 00:09:56,000
And Hank, thank you for laying out some of the background and the issues. I think there's a few things I should say one is just as a little bit of background.

54
00:09:56,000 --> 00:10:00,000
So we don't demonize the technology entirely.

55
00:10:00,000 --> 00:10:22,000
The ability to edit jeans I should say does offer potential benefits for living people in other words that we, there are now clinical trials being done of gene therapies, and my scientists friends who work on this are emphasized that we don't want to shut down all research using this

56
00:10:22,000 --> 00:10:36,000
CRISPR technology that Hank so eloquently presented, but it's important that that is in other words, for instance, for Alzheimer's disease for people who are already born who have Alzheimer's, they have the genes that they're going to have.

57
00:10:36,000 --> 00:10:59,000
There are the potentials to use CRISPR, these so called sort of genetic scissors to cut out bad genes, for instance, and so there's a potential to use this for disease that could benefit large numbers of people, also for improving food, improving crops, livestock, making food that's resistant to pests, for instance, so just as a background.

58
00:10:59,000 --> 00:11:20,000
I think it's important to mention that the area I think where we're all concerned of course is using these technologies to alter future human beings that is to take when sperm meets egg and forms an embryo and eventually would form two cells and four than eight and eventually become one of us.

59
00:11:20,000 --> 00:11:39,000
When it's still at the one embryo stage we can go in as Hank was saying and alter the genes, and this is what Dr. who did, and I think is Hank and my fellow panelists know the problem is it's not quite ready for prime time in addition to all the other ethical problems so

60
00:11:39,000 --> 00:11:49,000
and answer your question there was a lot of risks involved basically is number one so Dr who apparently took out more DNA than he wanted to.

61
00:11:49,000 --> 00:12:11,000
And so there are so called off target effects I may want to just take out this much DNA and end up taking that much also genes probably have multiple functions in the body. So one gene he actually wanted to disable the so called CCR five gene that would allow HIV to get into cells.

62
00:12:11,000 --> 00:12:25,000
And so if you disable that gene but by disabling that gene, the child has a higher risk of having other viruses, influenza virus West now virus getting into cells.

63
00:12:25,000 --> 00:12:36,000
And in addition, he took out too much and jeans may that one gene may do other things as well that we're not even aware of yet so there's a lot of risks involved.

64
00:12:36,000 --> 00:12:53,000
And a problem is that we may we now live in a globalized world. And so even though there have been attempts in the US and in Western Europe to come up with guidelines by the National Academy of Sciences and the Royal Academy of Science

65
00:12:53,000 --> 00:13:13,000
and the Human Society Association in Great Britain. It's not clear what kind of enforcement ability, if any, or what kind of power such guidelines put out by such international organizations will have clearly we need to try to have such

66
00:13:13,000 --> 00:13:31,000
guidelines but the UN of course doesn't do that is very important doesn't manage to prevent all the war is it go on and so the possibility of a rogue scientists like Dr. her in filling the blank of whatever country outside Western Europe you want to think of Russia.

67
00:13:31,000 --> 00:13:50,000
So, as North Korea might go ahead and use this so there are questions about international oversight and ability to sort of control what's going on and then lastly I'll just make the point that as Hank really mentioned with pre implantation genetic diagnosis.

68
00:13:50,000 --> 00:14:08,000
We in the US have a basically unregulated assisted reproductive technology industry it's a multi billion dollar industry that allows many people to have children who are in fertile, but these technologies are being used to, for instance, give people just a boy child

69
00:14:08,000 --> 00:14:21,000
if they want to boy child, or we're now being able to prevent the breast cancer mutation other mutations that we know about from being transmitted to future generations.

70
00:14:21,000 --> 00:14:38,000
But this is a technology that wealthy people can use but not poor people sir questions of justice that were beginning and we'll begin to see diseases like breast cancer increasingly become diseases of the core because wealthy people as we go into the future will be able to

71
00:14:38,000 --> 00:14:48,000
prevent such diseases from being transmitted that those genes so just to highlight some of the sort of ethical complexities involved sort of drilling down a little bit.

72
00:14:48,000 --> 00:14:54,000
So I think it's great to have this discussion because I think awareness public awareness of these issues is really crucial.

73
00:14:54,000 --> 00:15:13,000
Bardete you had something to say. Yeah, because the points I wanted to make a follow beautifully from exactly the points Robert just made, which are that regardless of which technology we're using regardless of whether we're editing embryos in vitro or selecting embryos in vitro

74
00:15:13,000 --> 00:15:25,000
or selecting against certain fetuses through prenatal testing.

75
00:15:25,000 --> 00:15:43,000
What is it that we're keeping and what is it that we're rejecting from the human gene pool, or what kinds of individuals we would like to welcome into our future society and what kind of individuals were practically avoiding having.

76
00:15:43,000 --> 00:16:01,000
So I want to offer my comments through a critique of the title of this event designer genes, because I get phone calls from journalists every week to talk about these technologies to talk about the ethical and social dimensions of these technologies.

77
00:16:01,000 --> 00:16:20,000
And what do they all want to talk about designer babies, you know, I don't like designers in any field of life. But when you take the concept of designer and attach it to the baby, I think this is dangerous because I think it gets a lot of public attention

78
00:16:20,000 --> 00:16:34,000
and a lot of our social discourse and social debate that we should have urgently into the wrong direction. What do I mean, everybody's scared of having, so here's what's going on in the media right in the public imagination.

79
00:16:34,000 --> 00:16:44,000
We're going to have super intelligent babies, we're going to have tall babies, we're going to have blue eyes and blonde hair which always take offense because, you know, me.

80
00:16:44,000 --> 00:16:48,000
Why, why nobody wants to have.

81
00:16:48,000 --> 00:17:07,000
We're scared of enhancement we're scared of sort of selecting traits of future people in areas that have nothing to do with all the good stuff Robert talked about which is avoiding disease, and preventing suffering, and preventing early death.

82
00:17:07,000 --> 00:17:18,000
We're afraid of going in the direction of sort of designing human beings, but I think it's misguided to dedicate so much attention to it because we scientifically still don't know how to do that.

83
00:17:18,000 --> 00:17:24,000
Those traits that everybody's so worried about intelligence, height, sexual orientation.

84
00:17:24,000 --> 00:17:36,000
They're controlled by many genes, they're controlled by interactions between genes, and they're controlled by the interactions between our genomes and the environment through epigenetics and other processes.

85
00:17:36,000 --> 00:17:42,000
Even if we wanted to create a beautiful basketball player, we don't know how to do that.

86
00:17:42,000 --> 00:17:55,000
At the same time we're spending so much energy discussing this instead of discussing the really urgent question, which is within the area of medical uses, what is justified.

87
00:17:55,000 --> 00:18:11,000
So all these declarations and policy statements that Robert just mentioned, tell us that if we ever move forward responsibly with CRISPR that Hank explained, we should only do it for serious genetic diseases.

88
00:18:11,000 --> 00:18:22,000
Nobody today has defined what is a serious genetic disease, and I want the public conversation to be on that, because that is a question we're facing right now.

89
00:18:22,000 --> 00:18:27,000
He gave the twins resistance to the HIV virus.

90
00:18:27,000 --> 00:18:31,000
Is that serious enough to justify putting them at risk?

91
00:18:31,000 --> 00:18:47,000
A Russian scientist now wants to edit out the gene that causes hereditary deafness. Is that serious enough? How do we understand as a society, what is a serious disease that we all agree we'd rather not see in our children.

92
00:18:47,000 --> 00:19:00,000
We haven't actually had the deep conversation on that, and that conversation is urgent, whereas those designer genes are definitely not urgent because we don't know how to do it now, and potentially we'll never know how to do it.

93
00:19:00,000 --> 00:19:02,000
So these are my two cents.

94
00:19:02,000 --> 00:19:12,000
Well, you know, you might be unhappy to understand that an alternative title for our talk today was going to be cosmetic genetics.

95
00:19:12,000 --> 00:19:24,000
Yeah, no, it's a, it was intended to be a slightly polemical title to gather in both the serious part of this problem that you're highlighting really perfectly well.

96
00:19:24,000 --> 00:19:34,000
And the fact that some of it gets appropriated for other uses.

97
00:19:34,000 --> 00:19:52,000
Sure, thank you first. Hello to everyone. It's wonderful to be here. And actually, I can follow on Vardite's really thoughtful commentary with a couple of things, bringing a little bit of a historical perspective to the conversation.

98
00:19:52,000 --> 00:20:08,000
I completely agree. The other remarks so far that CRISPR has many important medical, medical applications and it's already had some some real medical benefits. It became almost almost overnight.

99
00:20:08,000 --> 00:20:16,000
It became a standard workhorse laboratory technique, you know, just basic research. Everybody was doing it's cheap. It's easy.

100
00:20:16,000 --> 00:20:29,000
So, yeah, we need to be sure to differentiate between the, the, the really kind of work a day use of of CRISPR just in doing it.

101
00:20:29,000 --> 00:20:44,000
All kinds of biomedical laboratory research and these kinds of sci-fi scenarios and and and and huge ethical issues that are raised with things like prenatal genetic diagnosis and so forth.

102
00:20:44,000 --> 00:21:13,000
I guess I would say two things in response to Vardite. One is the, she's absolutely right, of course, that we have no idea how to, how to create an added design of smarter baby or a taller baby or even estimates now range about out of sort of 20 to 25,000 human genes.

103
00:21:13,000 --> 00:21:27,000
The current estimates I've seen are about on the order of 1000 of those genes, one in, you know, about one in 20 genes influences intelligence somehow.

104
00:21:27,000 --> 00:21:52,000
It's not clear that this separation of genes and environment is actually how biology works. And so there's a risk. One of the risks that I see looking at this in a long term historical point of view over a couple of centuries is the, is the public effects of the social

105
00:21:52,000 --> 00:22:05,000
importance of these anxieties that we're talking about. The fact that we cannot do it, but people believe that we can has that has social and ethical ramifications itself.

106
00:22:05,000 --> 00:22:14,000
Right. And so these are questions of accurate science communication of myth busting.

107
00:22:14,000 --> 00:22:24,000
And, you know, and and desensationalizing the science where we can.

108
00:22:24,000 --> 00:22:31,000
The, I guess the other thing I could say right right now in the immediate responses.

109
00:22:31,000 --> 00:22:49,000
That the, I agree that that we should be that the important aspects of, you know, if we're going to edit embryos, we should be thinking about what diseases we can address profitably.

110
00:22:49,000 --> 00:23:12,000
You know, most and, and let's face it, most of those diseases if we're talking about embryos and future human beings as as Hank started as but, you know, most of those can be effectively and easily prevented with prenatal genetic diagnosis and, and abortion.

111
00:23:12,000 --> 00:23:24,000
Right. And so, in most cases it's probably not going to be practical to go in and just, you know, oh, I love this embryo all of it. It's got all the right genes except for that one snip that I want to fix.

112
00:23:24,000 --> 00:23:29,000
It's not. It doesn't, it doesn't work like that.

113
00:23:29,000 --> 00:23:41,000
The other thing is, but the line. I think, you know, most people, many people anyway are uncomfortable with the idea of enhancement.

114
00:23:41,000 --> 00:23:57,000
And, and our fate and most people are in favor of the idea of using the techniques to prevent disease. But the problem is the line between therapy and enhancement is really blurry.

115
00:23:57,000 --> 00:24:22,000
I like to use the example of human growth hormone, right, which can be used therapeutically if someone is considered to be extremely short stature now one has to note that in some cases conditions like a counterplace

116
00:24:22,000 --> 00:24:32,000
or a counterplastic dwarfism can like like deafness may be actually a desirable trait in certain communities. So we have to keep that in mind.

117
00:24:32,000 --> 00:24:44,000
But if you are thinking of a child as, you know, sort of pathologically short, okay, you can say that's a therapeutic application of human growth hormone.

118
00:24:44,000 --> 00:25:02,000
And then what if the child is, is, you know, quite below normal in the normal range, but the very bottom. Well, you could say there, there, you know, there are social costs to that and I would like to give my baby, you know, every advantage to succeed, every chance to succeed.

119
00:25:02,000 --> 00:25:15,000
So I'd like to be, you know, normal, or tired, or taller or her. And, you know, then we're in greater area that's a, it's a different kind of therapy surely, right, not so much medical is psychological and social.

120
00:25:15,000 --> 00:25:28,000
And, you know, where exactly how much is too much growth hormone is, are you then going to say to the, to the parent whose child is, is going to be a normal height that I want to give my child every advantage.

121
00:25:28,000 --> 00:25:42,000
And, you know, like, Julian Sabliescu says the, you know, appropriate to have been, beneficence we have a responsibility to provide the children with the best genetic environments that we can.

122
00:25:42,000 --> 00:25:52,000
Where do you draw that line, how much growth hormone, where does growth hormone become go from therapeutic to enhance to enhancement.

123
00:25:52,000 --> 00:26:02,000
So these are so the fuzzy lines between some of these categories is also where some of the big ethical issues.

124
00:26:02,000 --> 00:26:16,000
Really, you know, that's really where the rubber meets the road and what we're going to have to have, I think, really serious conversations to hash these things out pretty much on a case by case basis anyone, any cases.

125
00:26:16,000 --> 00:26:22,000
So, I'd like to pick up on a couple of things from both varded and Nathaniel.

126
00:26:22,000 --> 00:26:32,000
Varded said something that I say all the time, even though I'm about to criticize it, which is we need to decide, we need to figure out we need to do this we need to do that.

127
00:26:32,000 --> 00:26:37,000
But of course we also have to ask who is the we is the we individual parents.

128
00:26:37,000 --> 00:26:47,000
And if it's individual parents is it individual parents of normal height, or is it individual parents were both parents have a cadre plasia, and our very, our little people.

129
00:26:47,000 --> 00:26:52,000
Is it individual parents with good hearing or is it individual parents who are deaf.

130
00:26:52,000 --> 00:26:57,000
And if it's non individual parents but it's society as a whole, how do we do that.

131
00:26:57,000 --> 00:27:13,000
Varded actually, I mean, I think you're absolutely right that this issue of serious disease versus non serious disease on the one hand, or big risk versus acceptable risk unacceptable versus acceptable risk, just as Nathaniel's right that the line between

132
00:27:13,000 --> 00:27:20,000
enhancement and treatment gets very blurry, by the way, on the height issue.

133
00:27:20,000 --> 00:27:36,000
And the current medical standard is two standard deviations below the mean. So basically if you're in the lowest five percent, five percentile of height, you can get treated with human growth hormone, regardless of whether we know why you're so short.

134
00:27:36,000 --> 00:27:58,000
So that's obviously not a really compelling number they picked it because five is a nice number. Right. So we do see places that have tried to do the go in a more organized way the UK has a very complex system of regulation involving something called the human fertilization and embryology authority.

135
00:27:58,000 --> 00:28:12,000
And the HFEA is nothing in this discourse can avoid acronyms, everything's acronym here. And the HFEA actually decides what diseases you can do pre implantation genetic diagnosis for and which diseases you can't.

136
00:28:12,000 --> 00:28:21,000
And if you can't, if they decide you can't what happens in many cases at least of parents with enough money, is they come to the US to get it done.

137
00:28:21,000 --> 00:28:34,000
And the US as verdict said has no regulation on what can be done it's a matter of choice between the individual IVF clinic, and the parents, the parents with money, at least.

138
00:28:34,000 --> 00:28:52,000
The verdict I think is, is rightly focusing on what both varded and Nathaniel are talking about treatment versus enhancement in the US now there is no such enforceable line and if you can find a clinic that is willing to do something that's enhancing.

139
00:28:52,000 --> 00:29:06,000
And granted there's very little we can do and almost nothing legitimate that we can do with respect to intelligence or sports ability or music ability or math ability or all those, we could probably configure out light eyes versus dark eyes and light hair versus dark

140
00:29:06,000 --> 00:29:26,000
hair, but which versions of light hair or dark hair or light eyes or dark eyes we can't figure out. And the US, all you need is parents money and a clinic that's willing to try. And that's I think something the US and a social and governmental level needs to address.

141
00:29:26,000 --> 00:29:34,000
I can pick up on a few things from there. I'm sorry. Oh God, so you got our hand up first actually. Go ahead.

142
00:29:34,000 --> 00:29:44,000
I love how this conversation is flowing so directly following up on Hanks last words, who the we is is obviously the question.

143
00:29:44,000 --> 00:29:58,000
So we decided we and my research team decided to gather one possible group of week. We gathered experts from various disciplines and also people who live with genetic conditions.

144
00:29:58,000 --> 00:30:03,000
And we asked them to discuss what series is to them.

145
00:30:03,000 --> 00:30:22,000
And we discovered something very interesting at the level of the individual conversation conversations, for example, that patients or parents are having with clinicians about prenatal testing about what justifies going through IVF in order to do in order to test embryos.

146
00:30:22,000 --> 00:30:39,000
People resist hard definitions. They want the understanding of serious to remain something very personal, very subjective, because, you know, we have different, we come to different stories to the to these decisions.

147
00:30:39,000 --> 00:30:53,000
And for example, if several women in the family died of breast cancer, having an embryo with increased risk of this disease, even though it's later in life, even though it's just a risk.

148
00:30:53,000 --> 00:31:10,000
You know, you have resistance to that because you're traumatized by what you've lived. Whereas for another person who's not familiar with the disease, oh, it's just risk. It's not necessarily that this child will have it. And in any case, it's going to be much later in life. So, you know, it's just not that threatening.

149
00:31:10,000 --> 00:31:29,000
What is serious is contextualized is cultural is personal subjective and people wanted to remain that way. They don't want the government to tell them that this does not deserve to be screened because some, you know, political body decided it's not serious enough.

150
00:31:29,000 --> 00:31:42,000
However, there's another context where we have to make decisions as a society. What will be allowed or banned? What will be offered to patients or not mentioned? What will be funded?

151
00:31:42,000 --> 00:31:56,000
Or people will have to pay out of pocket. These are decisions we make as a society. And for these decisions, we must come to an agreement, even on questions that are so complicated, that maybe at some level, they should be left to individual decision making.

152
00:31:56,000 --> 00:32:01,000
So I just want to add that layer of layer of complexity to our conversation.

153
00:32:01,000 --> 00:32:14,000
I can just add a few points, and again, great conversation. So, an answer to Vardite's earlier comments about why such attention to IQ and for which diseases.

154
00:32:14,000 --> 00:32:23,000
First of all, it was quite interesting that the National Academy of Science at the Royal Society address this issue of which diseases.

155
00:32:23,000 --> 00:32:38,000
They thought once CRISPR for embryos is safe enough, it should be used and they actually came up with several categories. So they try to define this, but I think the ways they did it themselves raised questions.

156
00:32:38,000 --> 00:32:57,000
And they said, well, if both parents, or one of the parents has both genes that are autosomal dominant as they say for serious condition like Huntington's disease. So if someone had both parents with Huntington's disease, which is a fatal disease that, for which there's a very predictive gene.

157
00:32:57,000 --> 00:33:17,000
And so, if they thought that, and for in that situation, it would be permissible. They thought that if both parents were quote homozygous for a recessive disease so both parents had sickle cell disease or both parents had cystic fibrosis, then it would be acceptable.

158
00:33:17,000 --> 00:33:37,000
And they gave another example as well, which is if both parents were homozygous for different diseases that were autosomal dominant so both parents had genes for early onset Alzheimer's. The problem is, though, that if both parents, these are extremely extremely rare conditions, but I think the reason they are putting them forward is because

159
00:33:37,000 --> 00:33:54,000
there's a certain technological imperative. So I think it's not only the media and the public that's interested in how do we enhance children like how do we increase IQ but I might I'm concerned that scientists themselves are that there are some scientists and researchers please to feel we have this technology.

160
00:33:54,000 --> 00:34:00,000
Let's use it. This is what we've done in the past we have technology and so let's go ahead and use it.

161
00:34:00,000 --> 00:34:14,000
So for instance, with those cases, if both parents have Huntington's disease, they're probably knocking on the race of kids well, which is raised another question they probably won't live to reproductive age if they have Huntington's from both their parents.

162
00:34:14,000 --> 00:34:37,000
Same if they have both parents have sickle cell again it may be hard for them to retrieve productive age. So these are very hypothetical situations but the fact that they were put forth by the National Academy of Science and the Royal Society I think shows that there's pressure to leave the door open for scientific research in this area and I think that raises ethical questions itself.

163
00:34:37,000 --> 00:34:54,000
I would just say a few of the things which is one is who the we is at least the United States, the example here I think is that we is who's going to pay for right so in this country I think the ARG the assistive reproductive technology industry as I mentioned is seen as the

164
00:34:54,000 --> 00:35:09,000
best because it's paid for mostly out of pocket. So if you can afford to, you know, pay to have the breast cancer mutation look for in your embryos and those embryos that have it screened out, you get to do it.

165
00:35:09,000 --> 00:35:13,000
And again this raises questions of justice etc.

166
00:35:13,000 --> 00:35:29,000
There are other in Western Europe, a PGD is banned in some countries or it's very limited which cases can be covered because the National Health Insurance is covering it and so they have more of a say I think in what ends up happening.

167
00:35:29,000 --> 00:35:47,000
Again, just a couple of other thoughts that throw in the conversation. I think again the the the fact that the in this country the assisted reproductive technology is monitored by the American Society for Reproductive Medicine, which is a guild of those

168
00:35:47,000 --> 00:36:02,000
researchers, they come up live an ethics committee they come up with guidelines are not always followed. One problem in the US is that we did have guidelines and regulations there's concern among many researchers that the issues would be taken over by the

169
00:36:02,000 --> 00:36:21,000
researchers, which is just right. And by pro life, so they may say for instance you can't do any PGD, or they may get involved in other ways in preventing either infertile people from accessing these treatments or from PGD being used for getting rid of diseases

170
00:36:21,000 --> 00:36:39,000
and they want to screen out the embryos, there may be legitimate uses of PGD which may then be shut down as well so we're living in a precarious political time in some ways for the political body of our country to take these issues on

171
00:36:39,000 --> 00:36:57,000
the work note on what Robert just said in the US you also have the issue of is it a federal question, or is this state by state question. And this kind of regulation typically is state by state. I imagine you could probably construct a constitutional federal statute that might be a bit of a stretch

172
00:36:57,000 --> 00:37:11,000
of interstate commerce clause. But if you think of 50 states each with their own different regulatory schemes and the likelihood that Mississippi or South Dakota would have a different scheme from New York or California.

173
00:37:11,000 --> 00:37:16,000
It gets, it's very complicated very fast.

174
00:37:16,000 --> 00:37:30,000
We already have that with the problem of gestational surrogacy. So people quote renting wounds as it said, California has a large industry New York just voted to do our governor Cuomo the late governor for the recent former governor

175
00:37:30,000 --> 00:37:45,000
of the state. I'll go recently put it in place but it varies to state by state by state in all kinds of ways that lead to complexities people having children born in other states etc. I think you certainly have a declared politically dead not legally dead.

176
00:37:45,000 --> 00:38:00,000
Sorry about that. I wonder if you would all agree, and please don't if you don't. That in many of these instances there's a bit of an arbitrary. There needs to be a certain amount of arbitrariness and where the cutoff may be.

177
00:38:00,000 --> 00:38:22,000
I think that doesn't necessarily mean certain bodies shouldn't try to create a cutoff. But that perhaps it should be something that's open to revision over time. What have you I don't know what you all think about that if that's true or not.

178
00:38:22,000 --> 00:38:35,000
I'm going to jump in. I mean, I think this falls from Nathaniel was saying that often in medicine we think of diagnostic categories is being very clear. But in fact to a certain degree we construct these notions.

179
00:38:35,000 --> 00:38:50,000
What is serious disease, even what are the boundaries of disease one is someone everyone faces some anxiety and depression at some point in their life but one is someone quote unquote clinically depressed or need treatment for anxiety etc.

180
00:38:50,000 --> 00:39:01,000
And so nature is complicated but we try to apply these rigid categories and in some ways, it may not always be possible to do so.

181
00:39:01,000 --> 00:39:17,000
And so it was raised that in the case of the babies in China that he got involved with that of course it was an attempt to prevent HIV infectivity in those children but many of the critics said well there's a triple anti retro viral therapies

182
00:39:17,000 --> 00:39:30,000
and this is not a death sentence that had been many many years ago I wonder if the response would have been different if HIV was still the sort of fatal illness it was 25 years ago.

183
00:39:30,000 --> 00:39:59,000
I think it's fascinating to see how the ethical discussion reflection and even guidelines and recommendations change over time exactly Gerald in response to what you said. We learn more about the technologies, our social perceptions of what justifies certain interventions changes, for example, because we didn't have a treatment and now we do or because we realized that something is actually more detrimental than we thought.

184
00:39:59,000 --> 00:40:10,000
And it's just an opportunity to kind of plug in another, you know, more general point which is that the bio ethical conversations that we're having.

185
00:40:10,000 --> 00:40:24,000
Sometimes the public expects us as bio ethicists to make arguments come up with a position, tell everybody what to do, you know whether it's individual patients or governments and be done with it.

186
00:40:24,000 --> 00:40:43,000
And the people with the punches and the punches again can be the evolution of science and what we know, the accumulation of data, and the evolution of social values and norms look at the end of life debates that all countries are going through over the past decades

187
00:40:43,000 --> 00:41:02,000
and change legislation as our social values change. So I think when it comes to these questions that are inherently societal. What the next generation is going to look like is of course a personal question what child am I going to raise, but it's inherently a social question of the face of future society.

188
00:41:02,000 --> 00:41:19,000
We have to also be responsive to the science and to where social values are at a given time. And when I look at just the last six years of declaration and statements on CRISPR, you see that evolution happening right before your eyes.

189
00:41:19,000 --> 00:41:37,000
In 2015, there was an international summit and the general vibe was definitely no, not ready, dangerous, stay away. Only four or five years later, the, the, you know, the last thing off the press is talking about a responsible, translational pathway.

190
00:41:37,000 --> 00:41:44,000
All of a sudden, it's kind of obvious that we're going to translate this into the clinic, but how do we do it responsibly.

191
00:41:44,000 --> 00:42:02,000
We're seeing this evolution before our eyes. And what I'm struggling with because I do a lot of media is how to explain to the public that the fact bioethics, you know, shifts and changes and devolves is not because we're unreliable or capricious or we don't know what we're talking about.

192
00:42:02,000 --> 00:42:13,000
It's because we're taking into account all these changing factors. Of course, during COVID it was the big challenge one day, public health tells you mask the next day it tells you.

193
00:42:13,000 --> 00:42:25,000
We saw recommendations change, and we saw the bio ethical debate change, because we learned more about the virus. And it's the same in this arena we learn more about genetics.

194
00:42:25,000 --> 00:42:41,000
The public becomes better informed and educated the conversation changes, the bioethics evolves, and it's not easy to explain the sort of the backstory of how our conversations leading to all these international guidelines and statements.

195
00:42:41,000 --> 00:42:55,000
And what these are happening and what they're informed by. It's a very complex process but I think it's critically important that the public understands why we're sometimes shifting our positions towards more permissive or less permissive.

196
00:42:55,000 --> 00:43:12,000
Two things from what word it just said, and one has to do with the role of bioethicist some people look to bioethics for advice some people hate bioethicists because they view them as acting like black robed judges who say, this is good no you go to hell.

197
00:43:12,000 --> 00:43:31,000
In fact, I think you get three bioethicists talking about any issue and you end up with five different positions. So the we in bioethics is not unified we as well, but with respect to gene human germline genome editing, which is the fancy term for what who did.

198
00:43:31,000 --> 00:43:49,000
So it's editing human genes in a way that can be passed on to future generations. That's why it's different from just using gene therapy on me to fix a disease I've got, unless it gets into my sperm, and at this point, two 30 year old kids

199
00:43:49,000 --> 00:44:00,000
would go and a vasectomy even then it wouldn't matter for me, but unless it gets into somebody's sperm or eggs it's not going to affect it's not going to change the genes of the next generation.

200
00:44:00,000 --> 00:44:11,000
So it's the germline the eggs and sperm that make it that have raised this issue. I was part of some of those groups in 2015.

201
00:44:11,000 --> 00:44:27,000
Agreed then that this was not ready for prime time because it was not proven safe and effective. And that we haven't really talked about of all the ethical issues I think the least controversial and the most important is it's

202
00:44:27,000 --> 00:44:42,000
not just people to do something that's unreasonably unsafe, or to sell people something that's unreasonably ineffective safety and efficacy. We think of as FDA and not really ethical but they're, they're powerful powerful ethical issues.

203
00:44:42,000 --> 00:44:58,000
In 2015, everybody agreed that this wasn't safe and effective hadn't been shown safe and effective. Some people said, if it is shown safe and effective there may be some times in which it could be used. And that's where Roberts point about the particular diseases that this commission

204
00:44:58,000 --> 00:45:15,000
picked out. They were picking those out because those were things that pre-implantation genetic diagnosis couldn't fix, but maybe this could. So some people say if it's safe and effective, there are some ethical uses other people say even if it's safe and effective we should never use

205
00:45:15,000 --> 00:45:32,000
it because the germline is a line we shouldn't cross messing with our future generations is something we shouldn't do. That distinction remains, but it's become a little more exacerbated. I think the latest commission and the idea that we're moving to how to do it responsibly.

206
00:45:32,000 --> 00:45:47,000
Those are the people who say if it's proven safe and effective but it hasn't yet been proven safe and effective. Here's some ways it could be used. There's still the whole, there's a large set of people in bioethics and otherwise they say it should never be used at all for any reason.

207
00:45:47,000 --> 00:46:06,000
So, the, I think the, the discussion has evolved, but what was a more obscure and more nascent division six years ago is becoming a little clearer now between those who say never and those who say, well maybe under some circumstances.

208
00:46:06,000 --> 00:46:21,000
But right now everybody, almost everybody says it's not proven safe and effective. It's not ready for primetime you shouldn't try to make babies in something that's this manner that is this risky.

209
00:46:21,000 --> 00:46:38,000
I would just say, I'm sorry Robert I think Nathaniel had a point you wanted to make. Oh, I was just going to say that the points and Hank just made our super important I'm really glad you erased them so so clearly and articulately.

210
00:46:38,000 --> 00:46:58,000
I would say that it's important to remember that safety and advocacy aren't the only two ethical issues that are involved here. And I think sometimes in discussing these issues with people, numbers of the scientific community, the ethical

211
00:46:58,000 --> 00:47:12,000
discussions sort of end there once it's safe and effective then you know, then it's out of our hands you guys deal with it. And there are, there are other important ethical questions to keep in mind while we're thinking about safety and advocacy as well.

212
00:47:12,000 --> 00:47:29,000
For example consensus, you know what what is there, you know how do we decide that if there's a social consensus that this kind of thing should be allowed the FDA ultimately is supposed to go supposed to go along with by the will of the people.

213
00:47:29,000 --> 00:47:51,000
We have to we're going to have to record reconcile this right. And that raises the question that actually comes back to some of the verdicts comments on the last comments, which is where we've been raising a number of issues around the issue of informed consent, right.

214
00:47:51,000 --> 00:48:10,000
And we haven't, I don't think we've used that phrase yet but we've all been talking about it. And what counts as informed when we're talking about technologies that are so, you know, so new so powerful and so complex, right, is really

215
00:48:10,000 --> 00:48:24,000
difficult to identify we have, we take informed consent as kind of this gold standard of ethical, ethical behavior.

216
00:48:24,000 --> 00:48:39,000
And what does it mean to be informed, you know, if you do a, if you take a 23 and meet test, they, they can send you back there's a, there's a set of snips that apparently are possible.

217
00:48:39,000 --> 00:48:53,000
And apparently are correlated with an increase in seven points seven IQ points. Right. And I don't know the name of the gene maybe some of you do.

218
00:48:53,000 --> 00:49:10,000
But, but this is what people are told. And then, as I'm sure everybody on the panel is well aware, people mistake probability for certainty right people don't understand probability.

219
00:49:10,000 --> 00:49:24,000
And then you've got a polygenic score that says you're, you know, 80% less likely to finish college than someone with, you know, a higher polygenic score.

220
00:49:24,000 --> 00:49:38,000
People think, Oh my God, my kids going to be going to be done going to drop out of high school. What do I do is probably going to be more inclined toward criminal behavior and and drug use and all sorts of bad things that correlate with low, you know, lower

221
00:49:38,000 --> 00:49:42,000
educational attainment for years in school.

222
00:49:42,000 --> 00:49:51,000
So there's some really important issues here, you know, around the question of informed consent and the informed part.

223
00:49:51,000 --> 00:50:02,000
What, what counts as informed when we're talking about genetics and these complex behavioral traits not now I'm going beyond at the moment.

224
00:50:02,000 --> 00:50:20,000
So, you know, we're talking about, you know, relatively simple cases like Alzheimer's disease or even cystic fibrosis and thinking more about say mental traits on schizophrenia or, or, or mental retardation or depression, things that are extremely

225
00:50:20,000 --> 00:50:25,000
complicated biology biologically as we've said.

226
00:50:25,000 --> 00:50:40,000
And so, we told that you can, you know, you can get people to tell you that that they can give you the genetic answer to your likelihood for schizophrenia and no matter how often they say, this is just a probability.

227
00:50:40,000 --> 00:50:45,000
People think, Oh my God, you know, my child's going to be schizophrenia.

228
00:50:45,000 --> 00:51:06,000
There's some really important issues here with the question questions surrounding informing the public people can't make good decisions we need to let people make the wrong decisions we can't, or obviously not going back to a state run eugenics program, but any kind of, you know,

229
00:51:06,000 --> 00:51:20,000
sort of liberal sort of program of allowing individuals to make these kinds of decisions hinges upon being actually informed and what that means is far from clear when we're talking about complex traits.

230
00:51:20,000 --> 00:51:21,000
Right.

231
00:51:21,000 --> 00:51:24,000
I'm sorry Robert I think had a question first.

232
00:51:24,000 --> 00:51:26,000
Yeah, just a few thoughts.

233
00:51:26,000 --> 00:51:34,000
I'm on from my phone, the LinkedIn work for my computer so it's hard to raise hands exactly but a few thoughts.

234
00:51:34,000 --> 00:51:39,000
One is I think just get back to the issue of risk.

235
00:51:39,000 --> 00:51:53,000
A problem is that risks themselves are not always clear we're talking about potential future risks and so in we need to weigh not just the benefits of using the technology but the risks will be and as mentioned some of the reports that have come out

236
00:51:53,000 --> 00:52:08,000
and said you know when it's safe enough safe enough is not a black and white line to know that the procedure is safe enough meaning following people for a generation or two, in other words if we create a child using this technology

237
00:52:08,000 --> 00:52:27,000
that they are not adverse effects on that child and perhaps that child's child for instance, and I think there are even in other kinds of research the FDA has gotten to controversy sometimes in terms of deciding when the benefits are sufficiently

238
00:52:27,000 --> 00:52:40,000
out out are sufficiently outweigh the risks whatever they are so it's even there there's some subjectivity involved.

239
00:52:40,000 --> 00:52:58,000
And so rather there's still a lot we don't know. So even with IQ for instance as mentioned my understanding is from scientists I trust that among the however many than been hundreds certainly of genes looked at for IQ, the one that's been most powerful I've heard gives you so just one

240
00:52:58,000 --> 00:53:13,000
of my two tests. So again many many genes involved and another problem is there's a sociologist whose work I admire peer Conrad who wrote a paper called Why has the gene for alcoholism been discovered five times.

241
00:53:13,000 --> 00:53:31,000
And it turns out that five times the New York Times reported the gene for alcoholism has been discovered, and only of course to have it reported somewhere buried in later pages, several months or years later that in fact, that was not replicated

242
00:53:31,000 --> 00:53:46,000
in a long history of claims for genes being associated with traits and diseases that are not replicated because if we look at a group of hundred people who have a disease and a group of hundred people who don't we look at literally

243
00:53:46,000 --> 00:54:01,000
the genes we're going to find some genes that are present in the one group, but not the other and some researchers may say well that's the cause when it's not. In terms of informed consent I think it gets even trickier when we're talking about designing future people

244
00:54:01,000 --> 00:54:18,000
obviously they can't consent so there have been cases some apocryphal some reported where deaf parents for instance have said I want to use P G D pre implantation genetic diagnosis to have a deaf child or dwarf parents have said I want to create a dwarf child because we feel

245
00:54:18,000 --> 00:54:33,000
these are not disabilities and we feel that this is the child we want. And again there too obviously the child can't decide for him or herself the child's not yet been born, which I think raises mistakes even more because there may be doctors who say yes I'm willing to

246
00:54:33,000 --> 00:54:51,000
do key G D for that purpose the parents may want it the child obviously is not there to say no we also have so called savior siblings where we have a child or parent who is a terrible disease and needs bone bone marrow transplants for instance so we can

247
00:54:51,000 --> 00:55:07,000
use the parents who P G D create a child will be a match to create sufficient bone marrow to serve as a donor obviously that child doesn't have a say in it so I think we need to be extra careful and I think that's an important role for bioethicists

248
00:55:07,000 --> 00:55:22,000
to play. Lastly just to put on the table I think one of the concern you that hasn't been mentioned is eugenics or it's been mentioned a little bit but you know when we've tried in the past historically to alter the genes of our society, it's led to disastrous results

249
00:55:22,000 --> 00:55:38,000
obviously with the Nazis and eugenics actually started in the United States in the 1920s there were efforts as waves of immigrants came from southern Europe Eastern Europe, there were eugenics fairs in the Midwest to give awards not just to the biggest pumpkin and the best

250
00:55:38,000 --> 00:55:52,000
pig but the best genealogy mean read you know was genealogist I think again culturally these are I think forming a background of why they're such interest in improving genes and why we need to be careful.

251
00:55:52,000 --> 00:56:11,000
So, taking the conversation, first of all, to another level higher level of complexity on one hand, and on another hand from the science fiction to the here and now. So we talked about what if someday we can use CRISPR safely and effectively

252
00:56:11,000 --> 00:56:28,000
combine that capacity with uses that are socially very controversial, what are we going to do that. But there's something that we can already do now and actually some private companies are beginning to sell it to prospective parents and that scares people like Hank and myself very much

253
00:56:28,000 --> 00:56:52,000
and that relates to the use of the well established technology of screening embryos in vitro before deciding which one to implant, not to look at one gene that causes a disease, but rather to look at multiple genes that increase in to various degrees, the risks of the more prevalent diseases

254
00:56:52,000 --> 00:57:02,000
of our disease, diabetes diseases that you know pop at a population level, we're really trying to tackle as a public health issue.

255
00:57:02,000 --> 00:57:19,000
Now, if you have imagine that you have 10 embryos in vitro and as parents, you know that there's a genetic disease that is very serious running in your family and the result of this test is here are the far five embryos that will be sick as children

256
00:57:19,000 --> 00:57:40,000
that carry the gene and the other ones will not suffer from this disease. Now you choose, you know, it's a sort of a simple decision because you tested from the beginning to screen against that gene right now imagine that for each of those 10 embryos, you get a map that tells you

257
00:57:40,000 --> 00:57:54,000
that for a heart disease, the risk will be at this percentage for these kinds of issues, but so that's a little higher over the general population but for diabetes, you're actually going to get for the same embryos lower than the general population

258
00:57:54,000 --> 00:58:17,000
Let's look at a variety of you know 10 other diseases and for each one you're going to get a different risk score, but also with different nuances within that risk score, no embryo of the 10 will be perfect or clean or free of risks, because we all including us on the screen, we all carry problematic genes

259
00:58:17,000 --> 00:58:34,000
And so what are we going to do with the reproductive decision making when each time we screen embryos, we face what I called at one point an avalanche of information that is extremely complicated, multi-dimensional

260
00:58:34,000 --> 00:58:51,000
And we don't have an obvious choice because one of those embryos is perfect, they all carry some problem, so we're really scared of such a future because on one hand we always say, oh more information is better, but at some point more information

261
00:58:51,000 --> 00:58:58,000
might actually become a disaster, how do we identify that one

262
00:58:58,000 --> 00:59:14,000
I think it's important for people to appreciate that what you're referring to a Bardeed is that there are certain diseases and many of the more common chronic diseases, many of them very serious have their polygenic there's not one or two genes that are associated with that condition

263
00:59:14,000 --> 00:59:31,000
There was a seminal paper about schizophrenia, some eight years ago that said they located at least 108 genes that were associated with some risk of schizophrenia, and they were still trying to work out now to what degree these various numerous genes have to interact with one another

264
00:59:31,000 --> 00:59:47,000
or be exposed to certain environmental circumstances that would raise the risk of schizophrenia in that individual, on the other hand, without doubt many of those 108 genes and there probably are more may confer some increased fitness, they have

265
00:59:47,000 --> 01:00:04,000
there are qualities among those genes that are all over the gene pool for all of us and which are probably good for us, so right it's much more complex the question then would be how do we educate people or who would be the who would be responsible for educating

266
01:00:04,000 --> 01:00:19,000
them so that they would understand this or be able to make better decisions or not be offered the option to be to make the decision.

267
01:00:19,000 --> 01:00:20,000
Thank you're muted.

268
01:00:20,000 --> 01:00:36,000
Okay, first time this week. Wow. That's pretty good it's Saturday I made it almost through the week without messing up my muting. So two things. One on this issue of the riskiness of particular genetic variations and I'm really glad that

269
01:00:36,000 --> 01:01:00,000
I've already brought up the PRS this polygenic risk score point. There are some things traits or diseases where it is really where a particular genetic variation is really, really powerful so if you've got more than 40 CAG repeats on your Huntington and Jane, the only way you're not going to die of Huntington's disease is to die first from something else.

270
01:01:00,000 --> 01:01:18,000
And then every other disease trait condition etc seems to have some genetic influence, but it's really complicated. And so you got if you did say whole genome sequencing you could look at 6000 or 10,000 different genes that are associated with

271
01:01:18,000 --> 01:01:36,000
particular rare diseases where special variations caused the disease with a high degree of confidence either 100% or something like BRCA one or two mutations which increase a woman's risk of breast cancer to about 80% increase the ovarian cancer risk from 1% to 30%

272
01:01:36,000 --> 01:01:55,000
in other ways is more significant even though we think of it as a breast cancer gene. And then you've got these statistical things looking at variations, not even an individual genes or sequences but at variations in markers, a million markers across the genome, and coming up with this

273
01:01:55,000 --> 01:02:12,000
controversy and sickening machine learning algorithms or artificial intelligence on them. And coming up with these numbers that are very scientifically uncertain, but are being sold to prospective parents already so you've got the

274
01:02:12,000 --> 01:02:28,000
known high risk for some things genes, which may also have unknown benefits as well. And then you've got this machine learning algorithm constructed gamish of a whole bunch of different markers.

275
01:02:28,000 --> 01:02:36,000
That's an important distinction to keep in mind, particularly since we're seeing the commercialization of the latter one I think way too prematurely.

276
01:02:36,000 --> 01:02:49,000
And I wanted to say is to go back to Robert and the consent of the embryo. Obviously right. On the other hand, I can't remember the consent for my sign saying, yeah I'd like to be born.

277
01:02:49,000 --> 01:02:58,000
And by the way I'd like to be born to this couple in Columbus, Ohio, etc, etc. You know I'm a parent.

278
01:02:58,000 --> 01:03:06,000
There's only three so we've survived not only childhood but teenagers, I've survived they've survived.

279
01:03:06,000 --> 01:03:15,000
We do all sorts of things without our kids consent. It's our job, you know you don't say, well, here are the advantages and disadvantages if you go into bed right now.

280
01:03:15,000 --> 01:03:27,000
And I want to make sure you fully understand them before you make the decision. It's your bedtime and what I swore I would never do before I had kids was do what my parents did and of course I broke this oath.

281
01:03:27,000 --> 01:03:32,000
Why, after 17 different wise, because I say so.

282
01:03:32,000 --> 01:03:46,000
At some point parents do those things. I do agree that the fact that the embryo can't consent makes it a higher raises the issues more highly but at some point.

283
01:03:46,000 --> 01:04:01,000
And so parents not only do but that's our job, in some sense and try to mold these babies these embryos feeders and babies into good happy loving people.

284
01:04:01,000 --> 01:04:17,000
So I think though the deafest example in particular is really interesting I have mixed feelings about whether a deaf couple should be able to choose a deaf embryo as opposed an embryo that would grow up to be deaf as opposed to embryos that wouldn't.

285
01:04:17,000 --> 01:04:28,000
I have no mixed feelings about whether a deaf couple should be able to, you know, artificially deaf and a child that's been born with hearing.

286
01:04:28,000 --> 01:04:40,000
I'm fairly sure that it's a defense that I have a defensible line there between birth after birth and before birth. In the second case you call Child Protective Services and the police.

287
01:04:40,000 --> 01:04:43,000
In the first case it feels different to me.

288
01:04:43,000 --> 01:04:46,000
But I'm not sure how I come out on it.

289
01:04:46,000 --> 01:04:49,000
Robert yeah I know you wanted to make a comment even before.

290
01:04:49,000 --> 01:04:59,000
Thanks comments so go take it we'll take it away. Yeah so I think that children are entitled to an open future as it's been said.

291
01:04:59,000 --> 01:05:07,000
So we don't want to be making it's one thing to say this is your bedtime you have to go to bed why because it's your bedtime and you have to go to bed.

292
01:05:07,000 --> 01:05:24,000
And to biologically sort of constrict and otherwise open future that a child would have within the range of open futures that are available to children so I think if we don't want to forcibly impose risks on children.

293
01:05:24,000 --> 01:05:39,000
When we otherwise don't need to and I think that's sort of the spirit in which I think that we need to be careful about and I should say some of this can be addressed through research to see children who were selected to be so called save your siblings.

294
01:05:39,000 --> 01:05:41,000
How do they feel about it we don't know.

295
01:05:41,000 --> 01:05:58,000
I feel I feel great I was created to be able to manufacture bone marrow for my sibling or my parent, where they may feel what a pain in their butt I mean I were pain in the hip I'm being you know having a needle shoved in my hip every few months to extract bone marrow so again I think

296
01:05:58,000 --> 01:06:15,000
empirical data can help somewhat think about some of these issues. I wanted to come back to the issue with understanding genetics also though because I think one, one problem is that as Hank said commercialization is playing a huge role in the space

297
01:06:15,000 --> 01:06:32,000
for deep mentioned with companies that are selling sort of polygenic risk score tests of parents into physicians. There's a lot of money to be made here by our companies are making a lot of money and so they're often I think the ones pushing the agenda even when it may not be in

298
01:06:32,000 --> 01:06:50,000
the consumer the patient the perspective parents best interest. And this affects not only perspective parents and patients but providers too so there are tests being sold to psychiatrists now and psychiatrists are buying them genetic tests to predict the risk of someone being

299
01:06:50,000 --> 01:07:08,000
in the hospital and the report comes back and it's also available to consumers as well they can have this test that you have an increased or decreased risk or increased or normal risk of schizophrenia. And what increased means is that your risk goes from 1% if it doubles to 2% which means

300
01:07:08,000 --> 01:07:24,000
that the average population risk is say 1% of schizophrenia if you test positive for this gene it doubles to 2% well people may just see you have twice the risk of schizophrenia and get scared seeing the so called road of risk without understanding

301
01:07:24,000 --> 01:07:41,000
that. So that's an absolute risk means that the chance goes to 1% to 2% that is as there's a otherwise in 99% chance you won't have schizophrenia to a 98% chance you won't have schizophrenia so I think we need to educate the public about statistics

302
01:07:41,000 --> 01:07:46,200
about science in general, not just regarding this, but in overall. And I think this is an area that

303
01:07:46,200 --> 01:07:51,480
has also not gotten as much attention as it should, and that I think would help us be able to deal

304
01:07:51,480 --> 01:07:55,560
with this in other areas where questions of our use of technology comes up.

305
01:07:56,440 --> 01:07:57,080
Nathaniel?

306
01:07:58,840 --> 01:08:07,960
Yeah, following up on Robert's comments, I wanted to raise the question of the ethical issues

307
01:08:07,960 --> 01:08:17,240
surrounding the free market. We have a very laissez-faire attitude toward economics in this country,

308
01:08:20,520 --> 01:08:27,400
and as someone said earlier, there's basically an unregulated market for PGD.

309
01:08:28,040 --> 01:08:36,600
And there's also an unregulated market for genetic testing, for genetic entertainment, for spitting

310
01:08:36,600 --> 01:08:47,880
in a tube and getting a report for just about any trait you can name or behavior, you can get

311
01:08:47,880 --> 01:08:58,120
someone to give you one of those risk scores. So there's a whole lot to be said about that.

312
01:08:58,120 --> 01:09:03,560
Maybe I'll come back to that later, say that for later in the conversation. But I did want to raise

313
01:09:03,560 --> 01:09:13,480
the question of the ethical issues surrounding the free market where a lot of decisions are made

314
01:09:14,360 --> 01:09:19,800
that we would oftentimes put under the heading of informed consent that are in fact strongly

315
01:09:20,760 --> 01:09:29,720
affected by things that we know have large psychological pressure, like advertising and peer pressure

316
01:09:29,720 --> 01:09:42,920
and so forth. So if you're marketed a test that promises to tell you what your IQ is going to be,

317
01:09:42,920 --> 01:09:49,000
what your children's or diseases are going to be, what so forth and so on, there's not really much,

318
01:09:49,000 --> 01:09:57,480
there are only very broad guidelines about what can be said and what can't. And I'm not an

319
01:09:57,480 --> 01:10:05,080
economist, so I mostly want to raise the question and see if the rest of you had thoughts on the

320
01:10:05,080 --> 01:10:11,240
marketing aspects of the new genetic technologies. Radi, you want to respond to that?

321
01:10:12,280 --> 01:10:19,400
Yes, so one technology that we haven't talked about so much yet and is actually one of the fastest

322
01:10:19,400 --> 01:10:24,600
spreading technologies with millions and millions of women around the world using it, even though

323
01:10:24,600 --> 01:10:29,480
it's only been around for about a decade, is a new way of testing fetuses during the pregnancy,

324
01:10:29,480 --> 01:10:36,680
but early on and without invading the uterus and causing a risk of miscarriage just by a simple

325
01:10:36,680 --> 01:10:42,040
blood test of the pregnant woman. And this is a technology that we call non-invasive prenatal

326
01:10:42,040 --> 01:10:50,280
testing, another acronym HANK and IAPT. And the reason I want to bring it up is that my research

327
01:10:50,280 --> 01:10:56,200
group has done a lot of thinking about the ethical and social dimensions of this technology.

328
01:10:56,200 --> 01:11:01,640
And we've been talking to pregnant women, to families and especially to families raising

329
01:11:01,640 --> 01:11:06,840
children with trisomy 21 or Down syndrome because this is one of the main conditions that this

330
01:11:06,840 --> 01:11:14,040
technology targets. And what we're hearing is that sometimes, you know, Nathaniel talked now about

331
01:11:14,040 --> 01:11:21,080
unconscious mechanisms, how we respond to societal pressures, economic pressures,

332
01:11:21,960 --> 01:11:25,880
but some people are telling us that they're very conscious of these pressures. For example,

333
01:11:25,880 --> 01:11:33,560
they say, I would love to welcome into our family a child with Down syndrome, but society will not

334
01:11:33,560 --> 01:11:38,200
provide me with the support mechanisms that I need. What happens to my child when I'm

335
01:11:38,200 --> 01:11:44,120
too old to take care of him or her? I don't want the child to become a burden on their siblings.

336
01:11:44,840 --> 01:11:49,480
We won't have enough financial support. So sometimes the same pressures that

337
01:11:49,480 --> 01:11:55,000
Nathaniel mentions are very explicit in people's decisions about terminating certain pregnancies,

338
01:11:55,000 --> 01:12:00,760
not because they think that the condition in itself is, as we said, very serious or the quality of

339
01:12:00,760 --> 01:12:05,160
life will be so terrible that they don't think it's a life worth living, but because they feel

340
01:12:05,160 --> 01:12:11,000
society would either not support their decision or that they would be judged and criticized.

341
01:12:12,200 --> 01:12:18,760
So when we say in front consent, what about free consent? When are we actually free to make these

342
01:12:18,760 --> 01:12:25,880
decisions knowing that we live in a society that would support us and our child because it's a

343
01:12:25,880 --> 01:12:32,920
society that has diversity, that appreciates diversity, that has a high degree of tolerance

344
01:12:32,920 --> 01:12:38,840
towards difference, or are all these technologies gradually closing up what we consider to be

345
01:12:38,840 --> 01:12:49,720
acceptable so that only Savalesca's best children deserve to be born and the parents will be judged

346
01:12:49,720 --> 01:12:56,040
for even having them. And the last point I want to make today is a story. A nurse once came to me

347
01:12:56,040 --> 01:13:01,000
after a talk that I gave about this technology, about NIPT, and said, you know, I'm coming back

348
01:13:01,000 --> 01:13:08,840
from a shift now and we were in the ER. A couple arrived with a very young child suffering from

349
01:13:08,840 --> 01:13:15,320
a disease and the first thing I heard the doctor tell them is you didn't test. What did the doctor

350
01:13:15,320 --> 01:13:23,800
mean? Didn't you test this fetus before it was born to find out that it had this disease and

351
01:13:23,800 --> 01:13:29,080
therefore terminate? What was implicit in the question? Why am I even seeing this child?

352
01:13:29,080 --> 01:13:33,800
The child shouldn't be here. So the first reaction the parents get when they rush to the hospital

353
01:13:33,800 --> 01:13:38,440
with a sick child is your child shouldn't even be here. We have technologies in place

354
01:13:38,440 --> 01:13:43,320
to screen out this child before birth. Why are you creating a burden on me and on society?

355
01:13:43,320 --> 01:13:49,320
And that's my last word of caution because all these technologies can push us into that corner

356
01:13:49,880 --> 01:13:54,440
and that's my greatest fear. Ankh, I think you had a comment also.

357
01:13:54,440 --> 01:14:04,920
Yes, and I'm actually not muted. So really three quick things. First, I think Nathaniel's question

358
01:14:04,920 --> 01:14:10,280
about the role of the free market is a very important one and particularly the role of the

359
01:14:10,280 --> 01:14:17,080
free market and an increasingly constitutionally protected world of advertising where the Supreme

360
01:14:17,080 --> 01:14:23,880
Court has held more and more so-called commercial speech is actually protected by the Constitution.

361
01:14:23,880 --> 01:14:28,520
We are one of only two countries in the world that allows advertising of prescription drugs.

362
01:14:30,040 --> 01:14:34,200
I don't know why New Zealand does it but I think I know why we do it because it makes a lot of

363
01:14:34,200 --> 01:14:40,680
people including a lot of media outlets a lot of money and it sells things and I think

364
01:14:41,880 --> 01:14:47,400
the problem of consent is not just a problem of advertising but the two exacerbate each other.

365
01:14:47,400 --> 01:14:55,560
Second, the disability points and I'm glad that you just talked about it at some length. To me,

366
01:14:55,560 --> 01:15:00,680
they're the hardest issues in this whole area. There's one set that gets a fair amount of attention

367
01:15:00,680 --> 01:15:05,960
because it's kind of titillating or exciting and that should the deaf parents be able to have deaf

368
01:15:05,960 --> 01:15:13,080
kids or should a cadre-placic parents be able to have little people, children. It's significant.

369
01:15:13,080 --> 01:15:19,400
I don't want to dismiss the importance of that but it's relatively minor in terms of the

370
01:15:19,400 --> 01:15:25,240
percentage of the population involved. There are a lot of disabilities out there and I had

371
01:15:26,200 --> 01:15:31,000
I was on a panel once with a Stanford graduate, a woman with something called spinal muscular atrophy,

372
01:15:32,360 --> 01:15:38,120
genetic disease. It comes in a variety of different degrees of seriousness. Some are fatal early,

373
01:15:38,120 --> 01:15:45,480
her's header in a wheelchair from about 18 on and we were talking about this stuff in a panel and

374
01:15:45,480 --> 01:15:51,320
she said, well what do people are saying is I should never have been born. I sure as hell didn't

375
01:15:51,320 --> 01:15:58,440
want to say yes, that's what we're saying. So of course I sort of intentionally side-stepped

376
01:15:58,440 --> 01:16:03,160
and said, well no, what people on that side are saying is that you should have been born but

377
01:16:03,160 --> 01:16:08,520
without your disease and she being a very smart person immediately said well without my disease

378
01:16:08,520 --> 01:16:15,080
I would not have been me. I don't know where we go with that. I mean that's sort of the if

379
01:16:16,600 --> 01:16:23,000
on the one hand I don't see any problem with preventing the birth of children who have

380
01:16:23,720 --> 01:16:30,440
just really inevitable nasty awful diseases, Tay-Sach's disease or Lesch-Nihan where children

381
01:16:30,440 --> 01:16:35,800
are intellectually disabled and at the age two they start chewing on their hands and feet and

382
01:16:36,360 --> 01:16:44,520
disfigure themselves. These are terrible things but when you get into the the gray area I can see

383
01:16:44,520 --> 01:16:52,280
why parents wouldn't want to have a child with SMA but should we stop them from doing that because

384
01:16:52,280 --> 01:16:57,320
of the people who have SMA or wouldn't want to have a child with Down syndrome should we stop

385
01:16:57,320 --> 01:17:01,000
them from doing that because of the people who have children with Down syndrome or the people

386
01:17:01,000 --> 01:17:06,600
who have Down syndrome and not just the psychological effect on them of knowing the world thinks I

387
01:17:06,600 --> 01:17:13,480
shouldn't have been born but the shortage the diminution of research funding going into the area

388
01:17:14,040 --> 01:17:20,280
physicians specializing in their treatment social support for their condition all those are real

389
01:17:20,280 --> 01:17:27,000
problems that the ability to avoid the birth of people with certain disabilities brings to the

390
01:17:27,000 --> 01:17:32,200
people who have already been born or will in the future be born with those disabilities and then

391
01:17:32,200 --> 01:17:42,280
finally earlier this week on Wednesday we saw pretty much the herd pretty much the death

392
01:17:42,280 --> 01:17:49,160
now for Roe v Wade sounded at the US Supreme Court the only question I think at this point is when

393
01:17:49,160 --> 01:17:54,360
in June they come out with the decision it will eliminate Roe entirely or just say well right now

394
01:17:54,360 --> 01:18:01,320
we're just saying up to 15 weeks you can ban it after 15 weeks and we'll deal with the others later

395
01:18:01,880 --> 01:18:09,560
I think there's a really interesting question about how the death of Roe v Wade is going to affect

396
01:18:09,560 --> 01:18:17,960
the assisted reproduction field industry whichever you prefer and the use of genetics and the possible

397
01:18:17,960 --> 01:18:26,680
uses of genetics afterwards so there's a big one to throw on the table Robert you have another

398
01:18:28,120 --> 01:18:32,360
oh yes i love it Robert had a question he wanted the or a comedy one of the make and i want to let

399
01:18:32,360 --> 01:18:37,560
him do that and then we could open up the floor to some questions right just a few quick comments

400
01:18:37,560 --> 01:18:44,520
interestingly in terms of the pro-life movement and the religious right when pgd was developed

401
01:18:44,520 --> 01:18:50,680
that is screening embryos those clinicians were concerned that the religious right might shut them

402
01:18:50,680 --> 01:18:58,440
down and in fact what happened is that people on the right felt gee if i can afford to have a better

403
01:18:58,440 --> 01:19:05,400
child i should have the right to do so so what's interesting is that a certain libertarian attitude

404
01:19:05,400 --> 01:19:11,160
prevailed that has allowed some of the things that we're actually concerned about as well as

405
01:19:11,160 --> 01:19:17,560
potentially some benefits beneficial things like pgd out there so i think it's hard to break

406
01:19:17,560 --> 01:19:22,600
what's going to happen though i certainly worry a lot about the future of ro v wade as hank was just

407
01:19:22,600 --> 01:19:30,520
saying just on nipt the sort of way of looking at the genes of the fetus just by taking blood

408
01:19:30,520 --> 01:19:35,880
from the mother's arm one issue that comes up with that which is what vardy was talking about a few

409
01:19:35,880 --> 01:19:42,760
minutes ago that has a lot of folks i know concerned is that those tests often give the

410
01:19:42,760 --> 01:19:48,600
results of say 70 different diseases and the actual sort of validity of those tests for all

411
01:19:48,600 --> 01:19:53,640
seven diseases has not been determined so patients again are coming in with these reports look at all

412
01:19:54,440 --> 01:20:01,240
the diseases the 70 diseases that the test showed that i have and they say to their their obgyn what

413
01:20:01,240 --> 01:20:07,000
do i do with this information and often doctors themselves are not sure you know should i abort

414
01:20:07,000 --> 01:20:11,880
the fetus or not given it that it has a say you know 30 or 40 percent chance of having whatever

415
01:20:11,880 --> 01:20:16,520
the disease is because these are not always predictive tests unlike in the case of downs where

416
01:20:16,520 --> 01:20:21,720
we're much more able to predict it so again a lot of confusing issues i would just say with the free

417
01:20:21,720 --> 01:20:27,880
market question that nephaniel raised we have a free market we also have an fda and we do have

418
01:20:27,880 --> 01:20:33,080
concerns about protecting consumers protecting patients protecting their rights as well and i think

419
01:20:33,080 --> 01:20:37,640
for those who are not familiar with bioethics this is a lot of what bioethics is is often trying to

420
01:20:37,640 --> 01:20:43,480
weigh conflicting principles and conflicting issues well this has been a very stimulating

421
01:20:43,480 --> 01:20:50,120
talk so far i hate to jump in um but we do have some questions that we want to start with a question

422
01:20:50,120 --> 01:20:58,040
yes it for for all these considerations it seems the genie is really out of the bottle though and

423
01:20:58,040 --> 01:21:08,120
it's going to affect family psychology sociology theology etc and one sort of non sci-fi horror

424
01:21:08,120 --> 01:21:13,880
is you could imagine a child saying mommy why didn't you take the gene out for my adhd

425
01:21:13,880 --> 01:21:21,000
i mean there are going to be so many different kinds of reverberations about what one didn't do

426
01:21:21,560 --> 01:21:28,360
even from the child's point of view as well as what one did do so we're in for quite a ride

427
01:21:30,280 --> 01:21:36,280
but thank you you you were all just marvelous i really appreciate the thoughtfulness and consideration

428
01:21:36,280 --> 01:21:43,960
great thank you berylline all right Alex you want to uh Beverly thank you so Alex you want to

429
01:21:43,960 --> 01:21:49,400
uh start to read some of these questions and see what the panelists have to say and respond uh yeah

430
01:21:49,400 --> 01:21:55,880
yeah and um everyone watching on zoom and youtube on zoom you could write in questions on the bottom

431
01:21:55,880 --> 01:22:01,080
panels you see it buttons this q&a and then on youtube just you could write it in the comments so

432
01:22:01,080 --> 01:22:08,840
from al danielle on youtube um they're wondering i mean given everything you talked about do you

433
01:22:08,840 --> 01:22:14,920
think there's anything you could add when you look at trauma so any given the intergenerational

434
01:22:14,920 --> 01:22:19,480
effects of pdsd the epigenetics so do you think there's any comments you could add given that frame

435
01:22:19,480 --> 01:22:26,040
i know you've talked about every other possible disease or what have you that could occur so anything

436
01:22:26,040 --> 01:22:35,720
to add there i would just say that for most psychiatric can you hear me yes for most psychiatric conditions

437
01:22:36,520 --> 01:22:42,280
uh the genetics are much more complicated and the gene environment interactions are much more

438
01:22:42,280 --> 01:22:49,080
complicated so it's easier to find genes for cancer say than it is for most psychiatric conditions

439
01:22:49,080 --> 01:22:55,960
including pdsd so i think we're just uh the genetics of that i think are far away from our

440
01:22:55,960 --> 01:23:00,760
understanding at the moment and i'd add i think the questioner may have also been interested in

441
01:23:00,760 --> 01:23:06,920
the epigenetics which is not so much the sequence itself but the way the sequence gets expressed

442
01:23:06,920 --> 01:23:14,600
because of things that are above the the sequence that determine when it gets when certain genes

443
01:23:14,600 --> 01:23:22,760
could use or not the existence and extent of effort of inherited epigenetic markers and humans is

444
01:23:22,760 --> 01:23:29,800
very unclear and very controversial it's not and it would really be very hard to test for example

445
01:23:31,000 --> 01:23:36,520
the extent to which epigenetic markers may have some role in children of somebody with pdsd

446
01:23:36,520 --> 01:23:42,440
having issues one thing that is quite clear though is we pass on things to our kids in lots of ways

447
01:23:42,440 --> 01:23:47,720
that don't have anything to do with our genes an apparent with pdsd or apparent with a mental illness

448
01:23:47,720 --> 01:23:54,440
or apparent with a physical disability is changing those conditions are going to affect how the kid

449
01:23:54,440 --> 01:24:03,960
grows up in a sense this goes back to roberts argument about an open future our our characteristics

450
01:24:03,960 --> 01:24:09,960
as parents to some extent and where we're born and what country and what socioeconomic status and so

451
01:24:09,960 --> 01:24:15,080
uh these all close in our children's futures and affect our children's futures in ways that are

452
01:24:15,080 --> 01:24:21,160
usually much more important except for the few really unfortunate outliers who get some really

453
01:24:21,160 --> 01:24:26,760
nasty early onset genetic disease these are much more important than what genes we pass on

454
01:24:27,560 --> 01:24:33,880
I think also we might have another panel some years hence to discuss the ethical

455
01:24:33,880 --> 01:24:42,120
uh contour uh confusion sown by epigenetic manipulation uh that that technology is not

456
01:24:42,120 --> 01:24:49,960
really here yet but it's coming okay thank you yay all for that question next we have carol

457
01:24:49,960 --> 01:24:56,600
gerson who has a comment then a question so the comment goes I once asked the fertility doctor

458
01:24:56,600 --> 01:25:03,720
to whom do you say no and his answer was pretty much no one and then her question based on how

459
01:25:03,720 --> 01:25:10,520
she wrote in the q&a part I assume this is her question um was supposed one is not a consequentialist

460
01:25:10,520 --> 01:25:16,040
who is primarily concerned about unintended negative consequences of unregulated gene editing

461
01:25:16,840 --> 01:25:22,120
how does the panel think about arguments from thinkers like michael sandell or william may

462
01:25:22,120 --> 01:25:27,480
that gene editing encourages us to use values appropriate for evaluating manufacture things

463
01:25:27,480 --> 01:25:34,920
to pierce ends and that this undermines the basis for human dignity inequality etc

464
01:25:36,840 --> 01:25:41,720
um I think this throws us back to a distinction that hank put on the table between those who think

465
01:25:41,720 --> 01:25:49,480
that gene editing is inherently a bad idea for variety reasons but it's not about the safety or

466
01:25:49,480 --> 01:25:57,480
the efficacy it's just that as a species we should not start to meddle and mess up at the level of

467
01:25:57,480 --> 01:26:04,840
designing our own DNA here I finally did work the the work design into a comment we should not try

468
01:26:04,840 --> 01:26:11,400
to intentionally design our DNA either because you take a theological position that we shouldn't

469
01:26:11,400 --> 01:26:15,400
play god or because you think that it would never be safe enough or because you think

470
01:26:15,400 --> 01:26:19,720
deontologically there are certain things humans should not do because it violates human dignity

471
01:26:20,440 --> 01:26:25,160
those people have already made up their mind right so to them it's not about where is the

472
01:26:25,160 --> 01:26:30,680
science going what is the condition that we're targeting what about off-target when will we

473
01:26:30,680 --> 01:26:36,840
be ready for first in human clinical trials to them you know the decision has been made but I think

474
01:26:36,840 --> 01:26:43,560
if I look at you know the community of thinkers that's a minority and the majority of bioethical

475
01:26:43,560 --> 01:26:49,240
thinking is about those questions that I just mentioned where is the science how do we define

476
01:26:49,240 --> 01:26:56,280
safety and efficacy and especially what genes do we want to target once it is safe enough

477
01:26:57,320 --> 01:27:05,160
so you know that that minority that sees this as inherently forever something that should be

478
01:27:05,160 --> 01:27:10,280
banned there's no conversation there right it's not about anything that's going to change it's

479
01:27:10,280 --> 01:27:16,120
just an in principle position that the shuts down the conversation about the technology

480
01:27:17,720 --> 01:27:23,960
I would just add I would put Vordid said Hank early on mentioned mitochondria replacement

481
01:27:23,960 --> 01:27:29,320
therapy which is that a small amount of human genes are not in the so-called nucleus of the

482
01:27:29,320 --> 01:27:36,360
cell but in mitochondria and scientists have developed ways of using another woman's

483
01:27:36,360 --> 01:27:44,040
sort of mitochondria so to speak through mitochondria placement therapy and this is

484
01:27:44,600 --> 01:27:52,520
altering the genes arguably of a future child to prevent terrible diseases and I think that there

485
01:27:52,520 --> 01:27:57,480
is some distinction morally between using these technologies to prevent terrible diseases

486
01:27:58,040 --> 01:28:03,240
versus adding some IQ points or some of the other milder conditions that we're talking about and

487
01:28:03,240 --> 01:28:10,440
I think that distinction is something that a lot of people find helpful. So going back to the argument

488
01:28:10,440 --> 01:28:16,760
that Sandell and May made and that was referred to in the question you know I think Sandell makes

489
01:28:16,760 --> 01:28:23,000
that argument as well as it can be made I don't personally find it very compelling or convincing

490
01:28:23,560 --> 01:28:29,720
in two ways one I look at people who were born as a result of indetra fertilization the same

491
01:28:29,720 --> 01:28:36,200
arguments about viewing children as a commodity as a manufacturer as a product were made 40 years

492
01:28:36,200 --> 01:28:42,440
ago with respect to IVF. I typically in the seminar undergrad seminar I do these days I have

493
01:28:42,440 --> 01:28:49,080
usually at least one or two people who are IVF kids they don't seem different they don't seem

494
01:28:49,080 --> 01:28:56,600
unloved they don't seem viewed as a manufacturer as an it's actually an empirical statement about

495
01:28:56,600 --> 01:29:03,480
how people are going to react to these sorts of technologies that I think that we have no evidence

496
01:29:03,480 --> 01:29:09,800
to believe it's that the technologies are changing the way people look at their children viewing them

497
01:29:09,800 --> 01:29:17,240
as less gifts and more products to be perfectly designed and you know return to return to manufacture

498
01:29:17,240 --> 01:29:22,600
if you know to get your money back if it didn't work out right. The other side of it is you know

499
01:29:22,600 --> 01:29:27,080
parents have kids for all sorts of different reasons parents have kids because they need

500
01:29:27,080 --> 01:29:31,480
somebody to work on the farm parents have kids used to and in some societies still do parents

501
01:29:31,480 --> 01:29:36,120
have kids to provide for them when they're old and in firm if there's no social security parents

502
01:29:36,120 --> 01:29:41,560
have kids because it seemed like a good idea at the time parents have kids without even intending

503
01:29:41,560 --> 01:29:48,040
to have kids there are all sorts of reasons parents have kids whether this argument saying

504
01:29:48,040 --> 01:29:54,760
parents will view and treat their children differently as a result of this I haven't seen any evidence

505
01:29:54,760 --> 01:30:01,320
for it I don't find it compelling. Great Alex the next question. Thank you Carol and I just want to

506
01:30:01,320 --> 01:30:07,720
add my parents had me just so I could open up PDFs for them I'm kidding I know how to do that.

507
01:30:07,720 --> 01:30:10,280
I know how to do that. I believe that.

508
01:30:13,080 --> 01:30:16,840
Okay so then you Carol then we have anonymous sorry hold on we have an anonymous

509
01:30:16,840 --> 01:30:23,320
a questioner on zoom and they asked is it even feasible to test the efficacy and safety

510
01:30:23,320 --> 01:30:25,560
of germline editing in an ethical manner.

511
01:30:29,800 --> 01:30:35,320
So let me take that on I I wrote a book about the CRISPR babies called CRISPR people that came

512
01:30:35,320 --> 01:30:40,280
out this past February and there's a whole chapter devoted to if you did want to try to prove it

513
01:30:40,280 --> 01:30:45,400
was safe and effective how would you go about it and you would go about it I think using the

514
01:30:45,400 --> 01:30:51,400
sort of things that the FDA normally wants but pretty particular focus and and more than usual

515
01:30:51,400 --> 01:30:57,480
requirement for proof given that you're dealing with the birth of infants who haven't been able

516
01:30:57,480 --> 01:31:04,760
to consent. One thing you would do is non human animal studies and you need more than mice and

517
01:31:04,760 --> 01:31:10,200
rats for this I think you've got to use non human primates certainly monkeys follow them for a

518
01:31:10,200 --> 01:31:17,880
couple of generations look to see is and use large numbers hundreds because if you're looking for

519
01:31:17,880 --> 01:31:23,960
say a 5% problem you're not going to see it if you only use 10 and you may not see it if you use 20.

520
01:31:24,760 --> 01:31:33,480
So do germline editing in a couple hundred rhesus macaques and see what the results are in terms

521
01:31:33,480 --> 01:31:41,240
of the health of the babies as well as the efficacy of the actual editing. Do human embryo studies

522
01:31:41,240 --> 01:31:46,760
where you modify the embryos and then watch to see watch them as long as you are allowed to up to

523
01:31:46,760 --> 01:31:52,920
14 days under current guidelines maybe longer in the future depends in part also on what your

524
01:31:52,920 --> 01:31:57,640
restriction you're in and see if they look normal if they act the way same way that normal human

525
01:31:57,640 --> 01:32:03,000
embryos act but then at some point you've got to hold your breath cross your fingers or assault

526
01:32:03,000 --> 01:32:08,600
over your shoulder you know launch prayers do whatever else you do and go to first assuming

527
01:32:08,600 --> 01:32:14,920
everything all that work all that preclinical work says we don't see any real big issues here

528
01:32:15,800 --> 01:32:21,320
you have to try it in humans and you try it in a small number of humans who are very carefully

529
01:32:21,320 --> 01:32:25,960
studied and typically I think you would try it in the humans for whom the need seems most strong

530
01:32:25,960 --> 01:32:34,280
and see what happens will you wait for 70 years no how long will you wait that's a good question

531
01:32:34,280 --> 01:32:41,640
it could well be that every baby born from IVF will drop dead at age 44 because Louise is now 43

532
01:32:42,520 --> 01:32:47,240
no reason to think that they will but we can't know until we wait it out nobody's going to wait

533
01:32:47,240 --> 01:32:55,560
that long but yes I think there are ways to try to try to not prove safety not prove not prove

534
01:32:55,560 --> 01:33:00,840
unacceptable risk proving a negative is always problematic but there are ways to try to get

535
01:33:00,840 --> 01:33:07,000
some more confidence that this could be done in a relatively safe way buried in mind that safety

536
01:33:07,560 --> 01:33:13,880
is always a relative term I mean as good as guidelines are not much different than the ones you might

537
01:33:13,880 --> 01:33:19,080
rely on for just drug development yes that's right although a problem with this is

538
01:33:19,080 --> 01:33:31,480
it is not entirely clear whether or not those FDA rules apply to this kind of work the FDA has

539
01:33:31,480 --> 01:33:39,880
taken the position that it does going back to the early cloning hysteria I took the position in 1980

540
01:33:40,440 --> 01:33:48,520
I'm sorry in 2000 that cloning would be a clone human embryo would be a drug or biological product

541
01:33:48,520 --> 01:33:54,120
subject to FDA jurisdiction that's never been tested in court I think they probably should

542
01:33:54,120 --> 01:33:59,400
win on that but I can certainly imagine a federal judge saying wait you're telling me that a human

543
01:33:59,400 --> 01:34:05,720
embryo is a drug get out of there where does it say that in the 1938 federal food drug and cosmetic

544
01:34:05,720 --> 01:34:12,840
act Robert it's not clear that that legally FDA would have that power I think it should and I

545
01:34:12,840 --> 01:34:19,400
hope it does and I agree with everything Hank said but to answer the question I would also add it's

546
01:34:19,400 --> 01:34:26,040
not clear that there is enough benefit to justify the risk yet in other words for what medical

547
01:34:26,040 --> 01:34:31,640
condition would we even do the things that Hank rightly says would need to be done and I think

548
01:34:31,640 --> 01:34:36,520
that as I mentioned they report from the National Academy of Science saying well if both parents

549
01:34:36,520 --> 01:34:44,440
had Huntington's disease that it's not clear that that ever happens in the west and so again

550
01:34:44,440 --> 01:34:49,560
it's good to keep an open mind but I think we need to be careful that we don't rush into this for

551
01:34:49,560 --> 01:34:56,280
the wrong reasons which is capitalism sort of pushing us there. I think we should move on to the next

552
01:34:56,280 --> 01:34:59,720
question I was going to think we should move on to the next question because we have a quite a

553
01:34:59,720 --> 01:35:04,760
number of questions I think Alex have I read you this is of two more all right so let me let me

554
01:35:04,760 --> 01:35:12,920
follow up on Robert I think one plausible example of a need would be a couple where both members

555
01:35:12,920 --> 01:35:19,800
have cystic fibrosis the life expectancy for cystic fibrosis used to be under 10 it's now

556
01:35:19,800 --> 01:35:24,600
people in their 40s every decade it seems to get a decade longer which is a nice thing

557
01:35:25,240 --> 01:35:30,200
it's still not a good disease you don't want to have it it's a real problem to deal with and

558
01:35:30,200 --> 01:35:37,320
life expectancy is shorter and morbidity is higher but people live into their 20s 30s and 40s and

559
01:35:37,320 --> 01:35:42,440
some of them are going to be healthy enough that they want to have kids and I think it's not irrational

560
01:35:43,080 --> 01:35:48,120
unrealistic to think that two people with CF will meet bond and decide they want to marry and have

561
01:35:48,120 --> 01:35:54,760
kids together we're not to have kids together they would say the only way we can have a child

562
01:35:54,760 --> 01:36:04,120
that would not have cystic fibrosis is to use genome editing so I would just say I don't know of any

563
01:36:04,120 --> 01:36:11,800
documented cases of people of a couple where both have cystic fibrosis wanting children maybe it's

564
01:36:11,800 --> 01:36:19,000
out there but IVF docs I've talked to say this is a hypothetical yes yeah no known case to have

565
01:36:19,000 --> 01:36:26,840
happened thus far not a good disease but if people have if treatments are getting better for CF

566
01:36:26,840 --> 01:36:32,600
there are people who if someone's making it to 50 60 with CF do we need to be getting rid of the

567
01:36:32,600 --> 01:36:38,200
disease this gets back to the issue if it's not that bad that people are making it to 60 and want

568
01:36:38,200 --> 01:36:45,640
to have kids along the way should we be getting rid of it so again just to make sure the parents

569
01:36:45,640 --> 01:36:50,200
for the government right for the bioethicists yeah I'm just saying we need to think about the

570
01:36:50,200 --> 01:36:55,640
bioethicists right you know the relative risks and benefits and what would the benefits be it's

571
01:36:55,640 --> 01:37:05,160
your Alex next question um yeah so thank you anonymous viewer uh this is some Charles

572
01:37:05,160 --> 01:37:12,360
Barkowski and he asked what's the current understanding of ALS genetically I could just add as an

573
01:37:12,360 --> 01:37:18,680
addendum to that I know pathologically it has to do with um epicordination problems so

574
01:37:18,680 --> 01:37:23,240
epicordinated proteins not being properly disposed of in the cells and then the buildup of that

575
01:37:23,240 --> 01:37:30,680
leads to um cell death so anyone want to add on to that I know a little bit about this if

576
01:37:30,680 --> 01:37:35,960
somebody knows a lot about it I would be happy to defer but I think it's like a lot of diseases

577
01:37:35,960 --> 01:37:43,880
a few cases are powerfully caused by a known genetic variation in this case it's a mutation

578
01:37:43,880 --> 01:37:52,120
in a gene called SOD2 sodium oxidase dismutease or something might be SOD1 I forget whether it's SOD1

579
01:37:52,120 --> 01:37:58,360
or SOD2 and that makes up one or two percent of patients with ALS there are a whole bunch of

580
01:37:58,360 --> 01:38:04,040
other genetic variations that increase your risk of ALS but not enormously and then there are a

581
01:38:04,040 --> 01:38:09,560
whole bunch of patients with ALS who have no genetic no known genetic predisposition at all

582
01:38:11,080 --> 01:38:15,640
almost every disease almost every common disease seems to fall into that pattern

583
01:38:15,640 --> 01:38:19,800
Alzheimer's there are some genetic mutations that give you a hundred percent chance of early

584
01:38:19,800 --> 01:38:25,240
onset Alzheimer's it's about one person in a thousand carries them there's a genetic variation

585
01:38:25,240 --> 01:38:30,920
that 20% of the population carries that doubles your risk of Alzheimer's but most people with

586
01:38:30,920 --> 01:38:37,640
Alzheimer's don't have either of those risk factors so ALS is partially heavily genetic but the SOD1

587
01:38:37,640 --> 01:38:43,080
gene partially weakly genetic with a bunch of other genes and as far as we can tell partially

588
01:38:43,080 --> 01:38:49,160
not genetic at all and and we're going to see that we are seeing that more and more with disease

589
01:38:52,440 --> 01:38:54,200
Alex you want to get to the last question for us

590
01:38:54,200 --> 01:39:01,880
um let's see on YouTube okay yeah this is the last question on zoom anonymous viewer asks

591
01:39:02,760 --> 01:39:09,160
how common is finding a doubling of maternal or paternal DNA when companies like 23andMe do testing

592
01:39:12,680 --> 01:39:19,480
you mean a false paternity is that the person further wrote I asked because I was found to be

593
01:39:19,480 --> 01:39:24,520
a half sibling to my sister and brother although the most likely explanation is a different bio

594
01:39:24,520 --> 01:39:32,280
father I've read that a doubling of one's parents DNA is another explanation I've not heard of it

595
01:39:32,280 --> 01:39:39,160
I mean 23andMe as I understand it usually if they say you're only a half sibling of someone who

596
01:39:39,160 --> 01:39:46,520
thought was your sibling that the vast majority of those cases are due to so-called quote false

597
01:39:46,520 --> 01:39:51,720
paternity that is that there are surprising number of people I've heard reports a good 1%

598
01:39:51,720 --> 01:39:57,720
of the population they find that the person they thought was their father was not their father

599
01:39:58,600 --> 01:40:03,880
I should add I wrote a book called Designing Babies how technologies change in the ways we

600
01:40:03,880 --> 01:40:09,160
create children and in that I looked at people who were created through sperm donation or egg

601
01:40:09,160 --> 01:40:14,520
donation and the vast majority of those people are never told by their parents they were created

602
01:40:14,520 --> 01:40:21,880
by sperm or egg donation most men don't want to say I was infertile I was impotent women also are

603
01:40:21,880 --> 01:40:26,920
afraid to say we created using someone else's egg their parents are afraid the child will love

604
01:40:26,920 --> 01:40:31,880
them less so that's turned out not to be the case and so people are not told and are now finding

605
01:40:31,880 --> 01:40:40,840
out through 23andMe that in fact they were not from the genes of one of their parents but rather

606
01:40:40,840 --> 01:40:49,080
there was an egg or sperm donor use in some way I think that's the most likely thing.

607
01:40:49,080 --> 01:40:51,400
Yeah Vardeed I think you had a comment.

608
01:40:51,400 --> 01:40:58,040
Yeah it would be inappropriate to finish this pandas interesting conversation without noting

609
01:40:58,600 --> 01:41:06,040
the dangers of going through direct to consumer testing without understanding the potential

610
01:41:06,040 --> 01:41:10,520
things you might learn people think of it as fun you know somebody will tell me how fast I

611
01:41:10,520 --> 01:41:16,920
metabolize caffeine or that I'm you know I have 5% indigenous that I didn't know about oh that's

612
01:41:16,920 --> 01:41:23,000
curious that's fun but they don't realize that sometimes the results come with a disaster with

613
01:41:23,000 --> 01:41:28,760
information that can be disastrous for family relationships for their psychology for their identity

614
01:41:28,760 --> 01:41:34,440
so this is an interesting opportunity to mention a book that Hank edited that just came out I

615
01:41:34,440 --> 01:41:39,560
received it just received it in the mail it's hard to see it's called consumer genetic technologies

616
01:41:39,560 --> 01:41:47,000
ethical and legal considerations and in it is a chapter a fascinating chapter about a family that

617
01:41:47,000 --> 01:41:52,680
went through this fun testing and found out that they have a half sister they never knew about

618
01:41:52,680 --> 01:41:58,680
and it turns out their mother was raped as a young woman had a child and gave up this child's

619
01:41:58,680 --> 01:42:06,920
for adoption and then decades later the story emerges and throws the entire family dynamics

620
01:42:06,920 --> 01:42:14,600
into havoc and exposes a secret that the mother kept her whole life so just fascinating fascinating

621
01:42:14,600 --> 01:42:21,960
example of things that can come up unintended people don't think about this in advance they just

622
01:42:21,960 --> 01:42:28,600
send out their DNA and think this will be fun so a big you know red flag and a warning to all of

623
01:42:28,600 --> 01:42:35,560
us before we just use this testing for fun to think through all the things that might happen I feel

624
01:42:35,560 --> 01:42:41,320
the need to give a disclaimer I was one of four co-editors on that book along with Nita Farahani

625
01:42:41,320 --> 01:42:51,160
Glen Cohen and Carmel Chacar and I was clearly the one who did the least work so it's it's a good

626
01:42:51,160 --> 01:42:55,720
book probably because I did so little work on it and it has a lot of chapters from great people

627
01:42:55,720 --> 01:43:05,000
including I think uh pardon ah Bravo now anyone have any other sort of last comments they want to add

628
01:43:05,000 --> 01:43:09,560
yeah I just want to get Vicki Madden's comment on YouTube just so she knows that we're paying

629
01:43:09,560 --> 01:43:14,920
attention it's just no it's no question it's the comments she just noted that um when I think

630
01:43:14,920 --> 01:43:20,840
during one of the question answer responses um she noted that the issues raised about privilege

631
01:43:20,840 --> 01:43:27,400
are already visible they move from an affluent area to a more socially mixed area and they

632
01:43:27,400 --> 01:43:32,200
they experience an increase in people with Down syndrome and other conditions and they sort of

633
01:43:32,200 --> 01:43:38,520
related that to affluent couples not having as many kids as the less affluent couples so

634
01:43:39,160 --> 01:43:44,280
just want to thank Vicki for that comment well I would just say it's affluent couples are more

635
01:43:44,280 --> 01:43:50,600
able to afford these technologies I mean IVF is expensive uh insurance cover is very little of it

636
01:43:51,160 --> 01:43:56,120
uh and I think that's that's a major problem are the justice issues or the injustice issues and the

637
01:43:56,120 --> 01:44:01,560
fact that the gap these technologies are being used so far at least in the US in ways that I think

638
01:44:01,560 --> 01:44:10,440
unfortunately increase the gaps between the haves and have nots. So it feels like we're getting

639
01:44:10,440 --> 01:44:16,680
toward the end um and maybe each of us could take a shot at something we think is really

640
01:44:16,680 --> 01:44:21,880
important that hasn't been discussed and I'm preemptively going to do that because I'm on a

641
01:44:21,880 --> 01:44:29,320
I've got a I'm on a hobby horse right now I think that our species has many characteristics but

642
01:44:29,320 --> 01:44:37,480
one of the strongest is we do not lack for self-esteem we are very species centric and we are paying

643
01:44:37,480 --> 01:44:42,760
way too much attention in my mind to the effects of these technologies when they're used for human

644
01:44:42,760 --> 01:44:48,680
reproduction which I think is going to lag in part because they're not going to be that useful

645
01:44:49,480 --> 01:44:54,600
and in part because we won't take lots of risks you know we don't want to take a lot of risks with

646
01:44:54,600 --> 01:45:02,360
babies but with nine humans we have at the other 99.9999 a couple more nines percent of the

647
01:45:02,360 --> 01:45:09,160
species on this planet we have the ability to make mass changes in the biosphere we're doing it

648
01:45:09,160 --> 01:45:15,880
already we've been doing it for a long time the tools allow us to do it better um we are much less

649
01:45:15,880 --> 01:45:24,280
concerned about the risks of deformities or still births in cattle than we are in babies we're still

650
01:45:24,280 --> 01:45:30,600
less concerned about it in mosquitoes and we're not concerned about it at all in bacteria we are

651
01:45:30,600 --> 01:45:37,240
going to remake the biosphere very quickly using these tools and our regulatory mechanisms

652
01:45:38,040 --> 01:45:46,600
stink that's where I think we should be spending more attention um and less than this on us you

653
01:45:46,600 --> 01:45:51,880
know the biosphere is not just about us even though we like to think it is.

654
01:45:51,880 --> 01:45:54,600
Nathaniel I think that's my sermon for the end.

655
01:45:56,920 --> 01:45:57,720
Nathaniel?

656
01:45:57,720 --> 01:46:05,720
Um yeah first of all just thank you Hank for for that comment we didn't get at all into things

657
01:46:05,720 --> 01:46:12,760
like gene drives and environmental engineering which maybe it could be a topic for a future

658
01:46:12,760 --> 01:46:21,640
conversation like this um I guess um if I were going to make two if I had two quick closing points

659
01:46:21,640 --> 01:46:27,720
just to raise a couple of issues that we didn't get to very much in this conversation that I think

660
01:46:27,720 --> 01:46:35,160
really are important for um for the for everyone to consider who's thinking about genetic technologies.

661
01:46:36,680 --> 01:46:44,120
One is we've talked a lot about genetic engineering um and we also mentioned that briefly at the

662
01:46:44,120 --> 01:46:52,440
beginning of polygenic scores polygenic uh risk scores or polygenic indexes and I think genetic

663
01:46:52,440 --> 01:47:01,320
prediction is going to be just as important if not more important as far as having an impact on

664
01:47:01,320 --> 01:47:11,000
the everyday person's life um and genetic engineering and so and there are a lot of really

665
01:47:11,000 --> 01:47:20,280
foreigny hairy ethical issues tied up with predicting traits especially complex behavioral traits

666
01:47:21,800 --> 01:47:28,760
before they happen and you know the notion is well we could provide a better environment

667
01:47:28,760 --> 01:47:33,720
or we could you know do things that would mitigate any kind of uh condition whether it's you know

668
01:47:33,720 --> 01:47:40,360
mental retardation or schizophrenia or you know uh lower predicted school behavior.

669
01:47:40,360 --> 01:47:47,800
So I would just urge people to pay attention to things uh to these ideas of genetic prediction

670
01:47:47,800 --> 01:47:54,360
as they come out through um you know direct to consumer uh marketing and and so forth these

671
01:47:54,360 --> 01:48:03,000
are really important and tied with that uh we never really to talk today much about about race and

672
01:48:03,000 --> 01:48:10,920
I think there are some important racial issues tied up in um in a lot of these questions

673
01:48:12,120 --> 01:48:19,320
for example and some of them are hidden uh it's not that obvious for example the uh the the

674
01:48:19,320 --> 01:48:28,280
biobanks where the sequence is um the people are using to do the big genome wide association

675
01:48:28,280 --> 01:48:33,560
studies and calculate polygenic scores and and make all these predictions whether it's disease

676
01:48:33,560 --> 01:48:41,240
or behavior or intellectual you know capacity or whatever um it's still the case that the overwhelming

677
01:48:41,240 --> 01:48:49,560
majority of the sequence that's being used is uh it comes from people of European descent and so

678
01:48:49,560 --> 01:48:58,520
we have no idea what the effects are we you know what what such a score would mean to someone of

679
01:48:59,720 --> 01:49:05,880
Hispanic or or you know with immediate African ancestors or or Asian they have very very little

680
01:49:05,880 --> 01:49:16,280
data on this and so um that's I know some people who are trying to uh who are trying to address that

681
01:49:16,280 --> 01:49:26,680
and that's important and getting a more diverse um uh data set that more diverse data sets to work

682
01:49:26,680 --> 01:49:35,960
with but the flip side of that is that that can can reify those um by you know those supposed

683
01:49:35,960 --> 01:49:43,080
racial boundaries and uh and and make and make race racial differences seem more biological than

684
01:49:43,080 --> 01:49:51,720
they are so um so there's some complex and often hidden racial issues involved with this that I think

685
01:49:51,720 --> 01:50:02,280
are worth worth bearing in mind great anyone else? I would or I'm happy to say something too sure

686
01:50:03,160 --> 01:50:08,680
uh so I would say uh and I agree with everything that's been said I think a major issue is education

687
01:50:08,680 --> 01:50:14,120
need for public education uh about a lot of these issues and I think the point about race is

688
01:50:14,120 --> 01:50:20,680
extremely important one problem I know I'm at Columbia and we are one of the centers that are

689
01:50:20,680 --> 01:50:27,160
involved in the all of us project to try to uh do whole genome sequencing on a diverse

690
01:50:27,160 --> 01:50:32,920
group of people and it's been very hard to get people from certain ethnic and racial groups who've

691
01:50:32,920 --> 01:50:38,040
experienced terrible discrimination in the health care system to want to give their DNA to be

692
01:50:38,040 --> 01:50:47,880
studied uh and uh do we need to uh definitely have a more diverse uh set of people uh whose DNA we can

693
01:50:48,760 --> 01:50:54,440
examine to see what genes are quit them at risk of disease but at the same time we need to educate

694
01:50:54,440 --> 01:50:59,880
and work with these groups and I think that uh the scientific community has been trying I think

695
01:50:59,880 --> 01:51:04,680
can try harder but has not done a very good job I think there's a lot of understandable suspicion

696
01:51:04,680 --> 01:51:09,640
and weariness as I said given past abuses and discrimination I think that's something we need

697
01:51:09,640 --> 01:51:17,160
to work on uh Nathaniel's point about the genetic prediction uh here too I think uh I agree and I

698
01:51:17,160 --> 01:51:22,600
think at some point in the near future maybe 10 years from now when we all go to see our doctor

699
01:51:22,600 --> 01:51:27,720
our complete genome will be on in the medical record uh and doctors will be able to say you have

700
01:51:27,720 --> 01:51:32,840
genes associated with say increased risks of Alzheimer's disease and there are major questions

701
01:51:32,840 --> 01:51:39,160
that would not discuss but as suggested might be great for future discussion on do people want

702
01:51:39,160 --> 01:51:45,320
that information how will they understand that especially when again these are uh uh uh are not

703
01:51:45,320 --> 01:51:51,720
highly predictive genes in other words your risk of Alzheimer's may go up three times from say 5

704
01:51:51,720 --> 01:51:57,880
percent to 15 percent depending on your age or 15 percent to 45 percent so these are partial numbers

705
01:51:57,880 --> 01:52:03,160
and we're not good at thinking about this or brains or did not evolve think about these kinds of

706
01:52:03,160 --> 01:52:08,760
complex numbers and lastly I would just say uh these are global phenomena and so the question

707
01:52:08,760 --> 01:52:15,240
of who's going to decide it may be researchers and patients in a country uh that is not one in which

708
01:52:15,240 --> 01:52:23,160
we are now sitting uh as mentioned earlier it was in China that the first uh uh uh CRISPR uh first

709
01:52:23,160 --> 01:52:30,040
use of CRISPR in human embryos occurred uh it was then decided okay you can do CRISPR on embryos

710
01:52:30,040 --> 01:52:35,320
but don't implant them into the womb and then in China again embryos were implanted into the womb

711
01:52:35,320 --> 01:52:41,720
so it may be in a country that is not one of ours uh where this moves forward I think that's

712
01:52:41,720 --> 01:52:47,480
important to be aware of and to try to think about ways to encourage as much cooperation with the

713
01:52:47,480 --> 01:52:51,400
kinds of guidelines that have come out and the kinds of ethical concerns that we've been talking

714
01:52:51,400 --> 01:53:00,200
about today. Mardee. Thank you Hank for inviting us to give sort of a concluding word um we talked

715
01:53:00,200 --> 01:53:06,440
about plants and animals and adults uh but I think where bio-effects is most concerned is

716
01:53:06,440 --> 01:53:11,560
in the area of reproduction right what's children these technologies allow us to have the

717
01:53:11,560 --> 01:53:18,920
the level of control that we can have over future children and my last thought is this we tend to

718
01:53:18,920 --> 01:53:25,960
think of having children as a profoundly personal choice uh we need in light of these technologies

719
01:53:25,960 --> 01:53:33,880
to be acutely aware of how our personal choices accumulate uh at a population level to create the

720
01:53:33,880 --> 01:53:41,480
society of the future and if all of our choices start excluding certain individuals in a way that

721
01:53:41,480 --> 01:53:51,000
as a society we have less tolerance for diversity and for differences I think we're paying a terrible

722
01:53:51,000 --> 01:54:00,200
price um you know as a species uh for allowing these decisions to occur in the privacy of you

723
01:54:00,200 --> 01:54:07,080
know people's uh you know own personal reflections without engaging with the societal implications

724
01:54:07,080 --> 01:54:13,000
so invite all of us to take this into account when we uh you know have these very very private

725
01:54:13,000 --> 01:54:20,280
conversations uh with ourselves with our partners with our family and friends um about what what

726
01:54:20,280 --> 01:54:29,800
it is that our personal decisions uh imply uh for the future of humanity. Great well I want to just

727
01:54:29,800 --> 01:54:34,280
tell everyone here I'll thrill them with how wonderful this conversation has been and how

728
01:54:34,280 --> 01:54:40,200
enlightening and I actually personally feel that to whatever degree there are and there must be

729
01:54:40,200 --> 01:54:45,880
open issues I think in many instances we outlined the sorts of issues that should be open for discussion

730
01:54:46,520 --> 01:54:53,160
uh politically uh with one's doctor with one's conscience and I think it's fascinating to reflect

731
01:54:53,160 --> 01:55:00,600
that so far from uh these sorts of technologies robbing us of uh human dignity um actually

732
01:55:00,600 --> 01:55:07,480
dialogues like this I actually think enhance when they're as as well thought out as these were

733
01:55:07,480 --> 01:55:11,160
today they really enhance our human dignity I think having the opportunity to have these

734
01:55:11,160 --> 01:55:19,000
conversations is uh it's incredible so I want to thank you all again and uh look forward to

735
01:55:20,200 --> 01:55:24,040
our audience coming back to see us uh for our next talk

736
01:55:26,040 --> 01:55:30,040
thank you everybody thank you thank you thank you fellow panelists

737
01:55:30,040 --> 01:55:37,560
it was fun great bye bye bye bye bye

738
01:56:00,040 --> 01:56:00,680
you

