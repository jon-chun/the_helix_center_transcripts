 Yeah, I'm sad but he is so happy. I'm so happy that one of the boys was really like, did you meet him? I saw the brothers, I think they were like a piece of this. My sixth grade was the seventh grade. My sixth grade was the third grade. My sixth grade was the third grade. My second grade was the third grade. I had put in my girlfriend in years like once. She was like, oh, I forgot her. We couldn't go to the school. What did you think about lecturing? That lecture two days ago on complexity in the task. I know I saw you talk but I'm talking about what Tucker was. This is like our choice task and it was a question about levels of complexity. You know, creating models, how people created models of the task. No, I'm going to be here. Can people hear me? Hi, good afternoon everybody. I'm Gerald Horowitz, associate director here at the Hillick Center. Welcome to a very interesting roundtable today entitled Math Models Mind. I wanted to make a quick announcement that coming up in future roundtables, we have a March 9th life in the universe which we've established actually right now today. There is life in the universe but there's going to be more to say about that topic. We have assembled the following roundtable participants. Caleb Sharves, astrophysicist at Columbia University. Yale astrophysicist Priyem Bada, Natar Rayan. Kenneth Dill, chemist at Stony Brook University. Edward Turner, a physicist from Princeton. Dennis Overby, a New York Times science correspondent. So that's March 9th and I'm sure it's going to be really quite a lively, interesting talk. In April, I don't know if we have an exact date yet but I don't have it here. We're going to have a discussion on climate change and the Anthropocene era, which is among us, which we're living through now. And on May 18th, you don't want to miss it or else you'll be in trouble. We're having a talk on shame. Today's panel, I'll quickly introduce and you can raise your hand when I mention your name. First is Larry Amsel and Larry is a clinical research psychiatrist on the faculty of Columbia University. He's had a long background in mathematics and was an early proponent of using decision theory, gain theory, and behavioral economics in psychiatric research. I'm going to keep these short so we have more time to talk. Cheryl Corcoran is associate professor of psychiatry and program leader in psychosis risk at the ICON School of Medicine at Mount Sinai. Together with Dr. Chechi of IBM, she has identified patterns of language that proceed on set of psychosis, including reduction in coherence and complexity of the speech. Andrew Gerber is a psychologist, psychiatrist, and psychoanalyst who is now the president director at Silver Springs Hospital. Silver Hill Hospital. I was wondering where Silver Springs Hospital is. That's what it wrote and that's what I read. I'm sorry. Ken Miller is professor of department of neuroscience and department of physiology and is director for the center of theoretical neurobiology at Columbia University. He's co-director of Columbia's sports program in theoretical neurobiology, it's center for theoretical neuro science as well as its neurobiology and behavior graduate program. And John Narry is assistant professor of psychiatry, neuroscience, and physics at Yale University School of Medicine where he directs a research program in computational neuroscience where they focus on computational models of neuropsychiatric disorders. He received his PhD in physics at Yale University. We have one missing member. I'm going to give you his background in case he does show up. It's our D. John Rondon. He's an associate professor in the mathematics department at NYU and he's completed his postdoctoral work at NYU. His research has focused for many years on computational and theoretical models of sensory processing, particularly vision and all faction. So thank you all and we can get started. Sure. I thought because the topics here are somewhat... Oh, do we are? We just announced your meetings. Thanks for doing this. I was about to say that we were just getting started. It's not perfect. Some of the topics were we discussed today are a little arcane and I thought it would be helpful for the participants to maybe give a brief summary of the kind of research they've done and more they're interested in the topic of mathematics as a search for modeling behavior and the psyche. So where would you start from? What I've worked on is the circuitry of cerebral cortex, of sensory cerebral cortex, primarily visual cortex, but trying to understand how the circuits... Trying to understand general principles of how the circuits of cortex work and basically trying to understand what operations the circuits are doing to produce the responses to sensory stimuli that we see, how those circuits develop through learning rules based on the activity in the neurons. And the far away goal is to understand from that really what computation cortex does. Cortex is a very uniform structure. Half full, half empty. There's a lot of differences between the different areas, but the first thing you notice is basically the same architecture with variations on the theme. And so there's a sense that there's been a unit of mammalian intelligence that's been developed and then duplicated and applied to almost everything that we do. And some day I would like to understand what exactly it does to the input it receives and how it represents it, how it transforms it, how it learns from it. So my research is also kind of focused on theoretical models of neural, especially cortical systems. As is Kins, we primarily focus on computations associated with association cortex in contrast to sensory cortex, looking at kind of fundamental cognitive computations such as working memory or decision making. And then we're very interested in understanding how synaptic level disruptions of those circuits could give rise to cognitive impairments as we see in psychiatric disorders, such as schizophrenia. And so we collaborate with experimentalists and study, you know, disease processes and pharmacology in these computational models of neural circuits. And it is on? Yeah. I too have spent a few years looking at computational models of neural circuits. In this case, I worked a little bit on vision, but I spent most of my last several years working on old-faction, trying to understand the kinds of computations that go on inside the old-factory system of insects. And as Ken was saying, there are many similarities between the old-factory systems of different animals. And at first I was seduced by this thinking that perhaps there would be a similarity to the computations that these different old-factory systems perform. However, the more I look at it, the more I've come to realize in recent years that it's almost like there's different operating systems running on the same hardware. So we can talk more about that later. No, I'm left. Okay. So to sort of shift a little bit, I'll work backwards. My current role in some ways is as a translator between different languages around mental illness. So in leading a psychiatric hospital, my predominant interest is how to get people to talk to one another, not just between our staff and our patients or the patient's patients, but between the staff and each other. And one of the languages that's been very important to me is the language of math and, or more broadly speaking, of modeling. And I find, somewhat to my dismay, that that language isn't taught in most clinical programs. And there's a way in which there's a sort of urgency for an answer. And I think this pervades maybe all of medicine, but particularly in psychiatry and psychology, makes people not understand the value of models that are good but not perfect. And one of the most common quotes I use, which others may be familiar with, is from George Box, who said all models are wrong, but some are useful. And to incorporate that is basically one of my main missions. Prior to being a president of a hospital, I had run the MRI research program up at Columbia. And so I was particularly interested in the use of structural functional MRI to test various mathematical models of neurocognitive processing. And that's exactly the stuff that you all are talking about. I'm a believer that there are a set of neurocognitive processes that underlie our psychiatric disorders that actually will end up looking quite different from the symptomatic descriptions that we now use. So the terms of depression, anxiety, even psychosis are appeal because they're very experienced near to the clinician. But that the underlying neurocognitive vulnerabilities probably, in my opinion, will look quite different. And we're not quite at the point yet where we understand those. So that's been a sort of overriding theme of my research. So I'm a psychiatrist and I collaborate with people who do computational modeling. And I collaborate with Guijima Cheki and his team at IBM. And he has applied computational analyses to behaviors such as language. So we think of language as really big data at the level of the individual. Language as semantics and syntax and there's pragmatics. And probably facial expression also has semantics and syntax as well as gesture. And we believe this behavior in and of itself can be modeled. And I think what we do as psychiatrists is we observe people, I do think that data is very important. And not only can computational scientists help us, but they really feel that we can help them in terms of building the model. So I've been to a few conferences, the NIPS conference, neuro informatics. Yoshua Bajio was there. I'm talking about deep learning. And someone in the audience asked him, you know, what are your thoughts about what you could learn from cognitive neuroscience, human neuroscience? And he said, I don't know and I don't care, which was very interesting. But the people that I'm working with who really do think about artificial intelligence a great deal feel that we have a lot that we can teach them. They really want to model what we do. And the other thing I want to just say briefly, I looked at the kind of description of the history. And it's, you know, has this feeling of kind of a guy on a hill, right, and the environment. But if we think about behavior, behavior at the level of milliseconds is very interactive. And so we want to model discourse as well in all of what anybody does here who's an analyst or a therapist. That kind of discourse is kind of key to our therapeutics. And we'd like to sort of understand what is going on in a successful interaction, therapeutic interaction, if that can be modeled by the computational scientists. And then with that model, use that to help you all in teaching other people what you do. Hi, so I'm Larry Absalah, and I got interested in this stuff almost 20 years ago. And actually got interested in it because it seems to me that within the social sciences, the economics was the social science that most used mathematical models. So I got very interested in economic models. So I think we're in this panel, we're at wonderfully different levels. Some people are doing stuff at neuron level, at small circuit level. Andrew and I are more interested in the whole, in sort of the patient, and in general words, in the whole patient level. But I think this stuff can be very abstract, and so Jerry and I agreed that we'll have me give like a three minute talk on a trivial example. And if I can just have you guys help me pass these out. This is the slide. This is the slide. It's a single slide, but I actually need one back myself. Thank you. So if we could go get those moving around very quickly, I would appreciate that. So I would say that what actually happened is that I was interested in, I was watching, as the managed care movement was taking over medicine, and I decided I needed to understand some economics, so I went and took a course in the economics of medicine, and I bumped into decision theory and game theory, and I realized that the economists really have some very interesting insights, very interesting insight into human behavior. And the thing that I had come from math, I dropped out of graduate schools, a math graduate school, to go to medicine, because I looked around the room and I realized I'm good in math, but I'm not going to have a job. So you had to be great, right? So I got interested in these economic models, and then I found myself working in a suicide research lab, and I started talking to people about the architecture, thinking like an economist, what is the architecture of a suicide decision? If you look at this, this is a very, very simple basic model, and the point of this is simply to show a trivial example about how a mathematical application may change the way we think about something. So in thinking about the architecture of a suicide decision, there's three small assumptions that I think people might agree with, and that is that agents, and that's another word for decision makers, they have preferences over orderings. You know what you like, vanilla, better than chocolate, you have preferences over outcomes. There are outcomes in the world, and you have preferences over them, you like one thing rather than the other. The second is that agents can choose actions, but they can't choose the outcome. So you can go and order the chocolate ice cream, but you can't define whether it's going to be good. There's always a probability. It may be good chocolate ice cream, maybe not good chocolate. So I can choose actions, but I can't always choose my outcomes. And the last one is that when I make my choices, I try to maximize my preferences. I do what I want to do rather than what I don't want to do. It's very trivial, and yet these three very, very, I think easy assumptions that are not that hard to believe give rise to this decision tree, which is that when someone's facing this decision, they can either make a suicide attempt or not. If they make no attempt and they remain in the status quo, and that's the branch on top, if they do make an attempt, those are probabilistic, and they could end up dead, or they could end up surviving the attempt. So there's three possible outcomes in the decision architecture, and here's where the trivial mathematics thing, because if you take discrete mathematics on day one, they will teach you that three things can be ordered in six ways. Three things can be ordered in six ways. Chocolate ice cream, vanilla ice cream, strawberry ice cream, there are six kinds of attitudes that you can have depending on your ordering. So the mathematics forces me to believe that there are six types of clinical people, six different types of people in their approach to suicide. Let's see if that's true. Well, the person number one is the healthy normal person is not suicidal. He prefers the status quo. His second choice would be to survive a suicide attempt, and he really doesn't want to die. That's his last choice. On the opposite end is somebody whose death is their first choice, and they are willing to survive an attempt, because the status quo is their absolute last choice. And this is somebody who would make any level lethality attempt. They don't care about the probability, they would make any lethality attempt. The third type, again, this is purely mathematically driven, the third type is someone who's surviving the attempt is their first choice, the status quo is their second choice, and death is their last choice. And this is what we used to call manipulative suicide. But these are the people who want for one reason or another to have made an attempt, but to survive the attempt, because that would either change them or change the environment that they're in. We've all treated patients like this who suicide attempt think these people will not make a high level suicide attempt. They will only make a low level suicide attempt. They're not at danger using a gun, they're only at danger of a low-suicide attempt. The fourth one is somebody who is fear, who really wants to take their lives, let's say they're ill, they're terminally ill people, but they're terrified, right? We're facing this so much, they're terrified of making an attempt at ending up worse, right? So this is the reason for the Hamlet Society, and the reason for people like Kavorkian, and it's the whole idea of euthanasia. It's the people who feel it's their time to die, but they're terrified of making an unsuccessful attempt. That's the fourth type. The fifth type is somebody who, their whole goal is to get away from the status quo. The status quo is their last option, and anything else is better for them. And finally, the sixth type is a little bit odd. It's somebody for whom the status quo is fine, but if they were to make an attempt, they would not want to survive the attempt. And that's a samurai or also has to do with dueling cultures. It has to do with honor cultures. Now, the point is that I made three very simple assumptions that 90% of people I talk to agree with is the trivial model, and the trivial model because of one piece of mathematics that three things can be ordered six ways, predict six types of suicide attitudes. And most clinicians I talk to say I recognize those guys. I recognize those people. Those are real categories of people. End of talk. I'm not amazed at the gamut of applications, mathematical applications here, as Laura mentioned, just a few minutes ago from the neuro-entomical cellular all the way to systems, actually, not just in the vision of systems, and people involved in a web of relationships with others. So, I'm straining to think of a way to get ball rolling with a conversation, because this is dealing, there was a series of guesses on mathematical models. I thought it would be a way to get started with just the following question. I think a lot of people who are interested in mathematics and get into this field often find themselves a little bit frustrated, or at least historically, of late. They found themselves frustrated by the lack of mathematical intuition apart of a lot of people that your, the people who typically have done the kind of research you've done may not be so well-versed, or interested in mathematics. So, I guess I want to know, how do you think mathematics is an improvement over a similar approach to what you've been engaged in that does not involve math? I mean, I can jump in on that. So, I'm trying to write a popular book on this, and it's very hard. It's really very difficult, but I'm working on it. It seems to me I was trying to understand what is the difference between a mathematical model and a verbal model. I mean, I grew up in the analytic world, right, and we had a lot of verbal models. And I think the difference is that when you write a mathematical model, you are committed to the consequences of that. So, that's kind of a thing. There's an equation, you're committed to the consequences of that equation. Whereas verbal models, and we saw this in Popper's critique of psychoanalysis, right, was non-falsifiable because, you know, the psychoanalytic statements were sort of vague and what the consequences were, I think. But when you write down a mathematical model, you are committing yourself to all the deductive and computational consequences of that model. And I think that's different than verbal models, but you guys would know better. Yeah, what I would say is that by, certainly for me, working on circuits, by exploring a mathematical model of a circuit, you discover things that you would never get just by thinking about it. And I think of a model as a scaffolding that you use to develop new intuitions. Once you've got them, you can apply them without the math, but you'll never get them without the math. And I can give an example in the brain and the cortex, but across the brain, there are tells that either that are excitatory, they excite other neurons or they're inhibitory. They suppress the activity of other neurons. So there's a phenomenon called surround suppression where if you have a visual stimulus right where a particular cell is looking, it'll respond to that stimulus. But if you put other stuff outside of that region, it'll tend to suppress the response to the center stimulus. And so everybody imagined that the only long range connections are excitatory. So everybody imagined you're sending excitation into the local circuit. So you must be exciting the inhibitory neurons. And so they don't get surround suppressed. They get surround enhanced and then they suppress everybody else. But then David first there did an experiment that showed that when you add the surround, the inhibition of the cells received goes down. The excitation they receive also goes down and that's what's causing them to get suppressed. And so then we had to figure out how can that happen? How can you add excitation into a local circuit and make both the excitatory cells and inhibitory cells all get suppressed by adding excitation? It turns out there's a really simple mathematical answer to that, which we had to, you know, start off for a little while to understand. But then once you understand the mechanism, then you have a new understanding of how these things can work that you then make predictions that you didn't anticipate, then experimental can go out and test. I mean, I would say that, you know, the distinction between verbal models and mathematical models is more important than the distinction between using models or not. There's often the kind of a take of you're using a simplified model. But the reality is that in science, we're always using simplified models, right? If you don't have a mathematical model, you have some verbal model, some picture model. We've got some dioceros and this is that. This is how we kind of synthesize different facts, plan new experiments, et cetera, et cetera, right? And so there's always, you know, some kind of model that people are using or assuming even if they're not making it explicit, right? And so by using a mathematical model, you number one, yeah, commit to making an argument for the sufficiency of something. Such and such mechanisms are sufficient to produce this phenomenon, which is kind of all you can do with models is really make kind of sufficiency arguments, I would say. In this kind of thing, we discover, you know, counterintuitive things because there are, you know, you can use the word kind of emergence that when you have interacting elements in a complex way, you can have resulting phenomena that emerge at a higher level that are not really, you know, clear, it's hard to predict that from even the properties of the low-level property elements. And, you know, I would say that a key role in mathematical modeling is about bridging these different levels, right, where we understand something about, you know, to take Ken's example about the synaptic properties and interactions of excitatory inhibitory neurons, you know, that's at the real, you know, kind of cellular synaptic level. And then the phenomenon of surround suppression really emerges in the circuit at the physiological level. And, you know, it's through mathematical models that we're able to show how the elements at the low level produce the phenomenon at the higher level. Actually, one other thought that occurs to me, you know, you said the, you know, all models are wrong, but some are useful. And when you said that, it occurs to me, what I actually think is all models are incomplete. I don't think they're necessarily wrong. Like, for example, I don't think our model of how it is that when you add excitation to the local circuit, everybody gets suppressed, I don't think it's wrong, but it's incredibly incomplete. It's a very, very, very simplified model. But I think Bob was being intentionally provocative when he said it that way. I think he would agree with what you had thought of it too. So my thought about your question, though, is to try to disentangle a little bit the notion of use of mathematical models from the personality of the person who's asking or applying the model. Because I feel like these things get conflated often. And it's one of the struggles I think that exists in the clinical, particularly in psychiatry and psychology world, which is, I think there's a disproportionate number of people who get attracted to clinical fields because of a pleasure in thinking in sort of almost rebellious ways that at any time you hear something, you sort of think, well, how's that also not true? And how's that incomplete? And what's being left out of that? Which is a personality style, it's a personality style that I like and that I think is very valuable in clinical work. But it's interesting because it's often seen as a personality style that's at least in people who are non-mathematical as being incompatible with mathematics. And I don't think that's true at all. I, in fact, think that when you have a set of rules, when you have a set of practices, a constraint, you can actually think out of the box in even still more a provocative way. And I think getting, that's a nuanced way of describing the use of math that I think many people don't get. They assume that if you do math, you're content with vast oversimplifications and it never occurs to you that there, and I see you laughing because I've never met someone who's mathematically inclined who was content with a vast oversimplification. You know, to pick up on one of the things that Andrew said about character and the people who were attractive, I mean, one of the things that it seemed to me as I wondered as to why, you know, psychiatry had not become mathematical. I mean, cardiology is mathematical. There's a lot of more mathematics in cardiology than there is in psychiatry. And psychiatry about the brain, so you would think. And I think that, you know, there was a famous book by C.P. Snow called The Two Cultures, talking about, you know, the time when there was a time when people knew everything and then there was a time where people sort of divided into the, quote, unquote, the humanities and the sciences. And I always wonder whether people who were drawn to psychiatry were sort of the same sort of people who were sort of thought humanistically. And that means that they like to think in metaphors rather than informal math models, right, that you think in terms of metaphors, that you think in terms of similes. And that I think is the difference between sort of the humanities and the hard sciences. And that psychiatrists were generally drawn from those kinds of people. But I could be wrong. Of course, what is a metaphor if not a model? And so that's, you know, people make this argument frequently and I agree with you as a cultural level. And then I think, why can't we get beyond that? Why can't we see that you can actually apply math to these kinds of more humanities, you know, the models without doing any damage. There's a wonderful quote in the beginning of Freud's biography of Leonardo da Vinci, which I always remember, where he says that some people have criticized him for embarking on a psychoanalytic study of Leonardo's life. And those of you who read it more recently than I can correct me if I'm wrong here. But he says, he thinks exactly the opposite. He thinks by applying a psychoanalytic understanding to Leonardo's life, rather than oversimplifying or somehow reducing Leonardo's brilliance, he's actually expanding and making it even more exciting that Leonardo ended up as he did. And that's the same relationship I think of math to models that come out of the humanities, which is it actually doesn't reduce them, but rather gives you the opportunity to work out. And that's it. This is occurring. In fact, about two years ago, someone came out with a game theoretical analysis of some classic pieces of literature of Jane Austen, for example. So it was a game theory model of Jane Austen's novels, which is a really beautiful piece of the kind of synthesis that you're talking about. But I think where I find the math, you have to know, be able to know if you're right or wrong. You're up with a pretty math model, but you have no way of telling if you're right or wrong. It doesn't get you very far. Although, you know, I have to something physicists debate and I was super strength theory, but that's a whole nother topic. But at least for the rest of us, it's important that you be able to, you come up with testable predictions that you wouldn't have thought of otherwise and that they can be tested. And without that, you're kind of, you have an insight that might be right, might not be right, and you don't know what to do with it. And then I think the other element of being successful is really what John said is that interactions of one, when I first was looking to do theory in biology, I was trained as a physicist, but I wanted to work in biology. All the biologists I talked with told me, you can't. Biology is a experimental science. We just find out the facts. And if you want to do theory, you should stay in physics. But why neuroscience started to need theory was when we started to collect enough data at different levels that we had to know how the interactions at one level could create the behavior at another level. And those aren't just facts. You can't just think your way through that. And that's where you really, and then the field of theoretical neuroscience, mathematical neuroscience has exploded since about the time I entered the field. I happened to enter at a very good time when several people were entering and that's when the field exploded. But that's, yeah, if you're not dealing with sorts, you know, how do the rules of how a neuron's activity evolves based on the input it receives, excitatory or inhibitory from other neurons? How does that lead to this behavior, which is more than the behavior that you can get from any one neuron? It's those kind of questions that where you really can't do it without math. I think there's a lot in this question of what does it mean in the mental health field to be right or wrong? Because I think that is a place that there's some vulnerability. One can say, what does it mean to be right or wrong about the ways a person with psychosis or person with depression functions? And I think that part is part of why I like George Boxes so much because I don't know that we are at the stage now where we can, we have ways of measuring right or wrong. We have ways of measuring useful or not useful though. And I think that one of the things the mathematical models do in our field is generate new ideas, generate new hypotheses that I think is one of you were saying, one wouldn't have already just immediately concluded that emerged from the model and then you try it. And sometimes it leads to something useful and sometimes it doesn't. And what has to be willing to go down that path even with an absence of certainty. Yeah, but that's what makes the models right or wrong is that they do make different dissociable predictions. You can test them yes or no, right? So I think we can distinguish that that good modeling in neuroscience or behavior is kind of goal oriented. We're trying to explain a certain phenomenon. We're trying to make some actual testable predictions. And so that's in contrast to I think two approaches, right? One would be trying to say, well, I want to build a correct model. I want as much detail as I can in there and have a complete model, right? And I think the point is that that's a futile effort and not actually a good path to generating understanding or advancing what kind of experiments we should measure, et cetera. That's on one end. And the other is on being kind of too abstract, too much of a toy problem, which some people from physics and mathematics have a tendency toward. But then there ends up being a gap between you have a toy model. You can study some interesting properties. But there's a real gap between how you can connect to that to experiment and to real data. And so I think there are kind of two ends that you can fall off the edge in terms of being useful for modeling. I'll give you just a clinical example. So a clinical example you're saying in terms of how some of these models actually being clinically applied. So because of where we're located, we had a huge 9-11 population of firemen and cops after 9-11. I was in the Toronto section in those years. And we had a lot of, I mean, there are validated treatments for PTSD and we always use those kinds of things. But what I found was that one of the things that drove the firemen I was treating completely crazy because they're straightforward, ration, they're straightforward, sort of very straightforward people. The firemen are very straightforward people. They're not very introspective. They really bothered them that they knew that getting into an elevator was safe and they also knew they couldn't get into an elevator. And it was ruining their lives. They lost their jobs over this. And I found you simply take a reward learning model, right? And I said, let me explain to you how this works. Your brain works in a reward learning model. And you've had this one shot, very negative learning thing in which getting into an elevator is that it's working in your amygdala. It's not working in your frontal cortex. So talking about it's not going to change it. Only behavior is going to change it. And giving them that model, giving them that reward learning model really changed things. So it made them feel less crazy. It made them feel hopeful. And it made a huge difference. That was your idea. I just want to make one quick. So maybe clarifying comment. I hope it's clarifying anyway. Larry and Ken both refer to the idea that mathematics, once you engage in the mathematical model, you sort of committed yourself to the consequences of the mathematics of it. And I think there could be this misunderstanding that means that mathematics is rigidly inflexible. And therefore risks being reductionistic and missing something. And Andrew said something very interesting. I think about real mathematicians in the real world, or anyway, in applied mathematics, where the whole idea is, OK, if there's a remainder, if there's a false, I'm calling it a remainder. If there's a false outcome or an hypothesis that's been disproved, put it back in a hopper. Let's use it and build another model based on that. And that is a way to keep the mathematics from falling into being excessively rigid. OK. But having said that, I want to ask the following question. So there's a lot of talk about whether or not computers, whether the brain is a computer. OK, I want to ask something slightly broader. Of course, let's go to overlap with that question. Is the brain mathematical? Of course. Of course. This whole discussion about mathematical models. What is the difference between a mathematical model and a careful explanation? It seems like you might have to make it. Careful explanations don't go into equations which could be manipulated to give you other consequences. Why not? Well, that doesn't become mathematical. Then it becomes mathematical. So there are the beatabits. It's all the way. I would argue. So my argument back to you would be to say, at the point where it's exact enough and exact enough, I would say it has two properties. One is all the variables that you're referring to are measurable things in the universe, agreed measurable things in the universe, and the relationship that they have with each other in the universe corresponds to the relationship that they have in your model, whether it's a verbal model or an equation model. So that there's a correspondence. But if you've got a verbal model that has those two qualities, it's a mathematical model. Newton's three laws are written in words. But I'm with you in the sense that I think the word math gets used for a funny purpose here. It's used as to sort of sit in him for thinking carefully. And that gets very confusing. I think you have to define what one means when one's having this debate. I think the times you think you're thinking carefully, and then when someone forces you, I mean, this is sort of when you do an applied math course, right? So you say, oh, I think I have a good model. I think, and then when you try to put it down in a mathematical way, mathematics, I think the formalism, I'm not disagreeing with you, but I'm saying the formalism of mathematics does force you to make sure that you can probably do that on the other one. So I do. You're thinking about the relationships carefully. An empiricist, right? I do science. I don't do modeling. To me what seems like the difference is that when you have a computational or mathematical model, you can look at latent variables that are not evident to the person doing empirical work. And that seems to me to be the difference. You can argue second analysis was doing that from the beginning without using math, but it was often not doing it in a very precise way. I wasn't even thinking of psychoanalysis. That sort of adds to it. But I think within sort of research, you know, I use statistics. I can use very advanced statistics, but to model, you have to, it seems to me you're looking for latent relationships and variables that necessarily are. That's one thing is that you look for a much lower dimensional set of variables that explain some high dimensional data. But another is that you're just looking more like a dynamical system. That's just understanding how the dynamics of the interactions lead to certain results. And I wouldn't call that latent variables. That's sort of just a different thing. That makes sense. Let me ask the question a different way because I got such a smackdown from the last time. I don't know, that's the right thing. No, there are things about the way the mind or people that have to be just or the brain cannot be accessed through math. That's a different way to ask the, I think, the same question. So here's an example. So I don't know if everyone is familiar with the recent advances in artificial intelligence through what's called deep nets. But these are very, very, very loosely modeled on neurons, what they call neural networks. And by being deep, you just mean you have layers and layers of them. So this one was predicted. This one was predicted. This one was predicted. This one. And that program has been going on for a long time. And it almost died. There were a few hardy souls who kept it alive through a period when most of the field didn't believe in it. And then they had a spectacular breakthrough about six years ago, seven years ago. And now it's completely taken over every field of artificial intelligence. So Jeff Hinton, who was really one of a few leaders, but to my mind, the leader in the field through all those years, brilliant guy. And he's the one, actually his group made the breakthrough that broke everything open in 2012. But he was asked, so there's a big question with the deep nets, which is the question that they have like a billion parameters, a billion synaptic weights that have to be learned from by just knowing for every input what output you want. And then you have an algorithm to make to learn those billion parameters to make this input produce that output. And so there's a big problem is there are black box. We want to know what they're doing. We want to know how they decide that this is a car and this is a German Shepherd. And we don't. It's just a black box, but it works really well. And so somebody was asking Jeff, you know, are we going to be able to understand these things? And he said, no, he said these involve a billion parameters. If it was reducible to some nice simple operation, the problem would have been solved a long time ago. People tried to solve it by using nice simple operations. They didn't get anywhere. And so that's an example of a level at which, no, you can't reduce it to any nice method. I mean, it is mathematics. You know, there's a mathematical set of equations that are these deepness, but we can't. It's not understandable mathematics. It's understandable at the level of what you're trying to optimize and what your learning rules are, but not what it's doing when you present an input at the bottom and it works this way to the top. That part doesn't seem to be understandable. That's a key thing. I see using that example, as I said, some of the parts of that are understandable, right? The learning rule is, you know, one equation, the loss function is one of which what is it trying to optimize? And so in one sense, it's a very simple description of what goes into the model. But again, you're training the seep network to classify, you know, visual images. And so all of the complexity of the visual world of all of those images is being, you know, parsed and extracted. And that goes into those billion parameters. And so in some sense, the model has to be complex because it's processing complex data. And that goes into the parameters. And so in some sense, you know, we understand something about those models. What are they doing? But the final solution is very complex. And I think a lot of neuroscience will be the same way, right? But it's not even so different from physics, right? We understand, you know, Newton's laws, but, you know, we can't predict the weather, right? We can't predict the hurricane. There's, you know, but we still think the same basic fundamental interactions are there. But it's a level of complexity that we're never going to understand on the same intuitive level as, you know, in a simple, inelastic collision of two particles. And so in the same way in neuroscience and psychology, we often will build kind of, you know, simplified models where we want to understand some principles. And then as we're saying, it goes back to metaphor, but often our metaphors are from, you know, simple models are very constrained behaviors that we can model, that we can study, that we can, you know, look at in humans, in animals, et cetera. And then there's this process of extrapolation and metaphor to the kind of full richness of human behavior. Yeah, I think a clarification, and if we were actually worried about this coming into this talk, is the clarification is that, and I always worry about the term computational psychiatry. I used to call it mathematical when I started doing it, because what I was doing was model it, right? Model a model, a math model of behavior. But computational psychiatry encompasses two things that are actually at the polar opposite, one in which you have specific models, like a specific reward learning model for the way a mouse is going to behave in a maze, and you have very specific models. But then you have these computational things, which are absolutely black boxes. So it encompasses both these things, in which not only are there no mathematical models for the beginning to end thing, it's not even possible, it will never be possible as you point out, because, you know, deep networks will never be reducible. That's why they work. It seems to me that the subtlety you're talking about though between a subset level, levels of complexity and how much you can simplify these models, is different than what people mean about is it mathematical or not. From that question, at least the way I understood your question, it's all mathematical. Yes, how many parameters you have, yes, to what extent is it computational versus solvable into a simple equation, that's different. But I heard your question and tell me, as being more connected to the question of are we dualists or not? This is true dualism, and Larry and I have had this debate just recently, to my mind suggests that there is an aspect of the universe that does not obey these same laws, that is not, quote unquote, reducible to the sort of principles by which we use. Now, I am not a dualist. I may be misrepresenting, but if you don't believe in dualism, if you really believe in monism, that there's one universe and there's one set of principles that governs it, then it's hard for me, then I don't think that there's anything that isn't at some point imaginable to the use of math. I agree with that. Are you serious? Yep, okay, to me, I think that I don't know anything about philosophy, but to me it seems very obvious that I feel a certain way being a conscious thing. I don't think that if you make the assumption that consciousness is some emergent property of a complex system, it seems plausible. I don't think mathematics as it currently stands has any foothold on that question. There's no language that mathematicians have access to today that can begin to untangle why it is that I feel the way that I do about anything. And just to answer me to push this analogy a little bit further, if you assume that we're conscious to whatever degree, and other similar complicated systems that somehow perpetuate themselves are also conscious, maybe bacteria or sharks or dogs or cities or the estal stock exchange, if there's consciousness in these large complicated systems, I have no idea how to address it. And I don't think any mathematician, I don't think math, if you say careful thinking will eventually understand things, sure, but if you look at the current set of tools that mathematicians have access to, no way. Actually, I think I agree with both of you. Because I think that it is very rabbinic. What you're saying is basically, look, it's a physical system that obeys the laws of physics. And in that sense, you can describe it in principle with those laws. You can't in practice because it's too complicated, but you can describe bits and pieces of it. But it is a physical system that operates according to some actual laws and isn't just doing whatever it feels like doing it in a moment. But there are properties that emerge from that system that are very hard to describe. When a physicist describes the properties of water and why it's wet in terms of the atoms in the water, you can derive from statistical physics the attributes that you can recognize as how wet things behave. But so there you can actually see the emergence. Consciousness, I tend to think that why material things have a subjective experience is not a scientifically addressable question to why. But the what, which material things end up creating subjective experience with the correlation between the material things and the subjective experience? I think we'll be able to, in principle, describe that perfectly. So why isn't it a zombie? Why doesn't it have subjective experience? I think that's not a scientific question. I don't know how science could possibly address that. So Andrew and I have had this ongoing, and I would say I'm a dualist all the way down, which is to say the turtle's all the way down, which is to say I don't think you have to, I agree with your argument that I don't think I need human consciousness to do it. I think if you simply look at a single cell protozoan that if you put it in a, if you put it in a, in a, in a petri dish, it will, it will swim toward up the sugar gradient, right? And so that protozoan swims up the sugar gradient. Now, I can describe the mathematics of the turning of its, you know, you know, its turning and its tail and how it turns and I can get a perfectly, probably get a perfectly good description of how that does. But that will never replace the description that the protozoan, that, that creature is swimming right towards the sugar, right? And those, so the mathematical description will never replace the same, the intuition and the description of what's going on. And I think those are the two levels and I think that's exactly what you're saying. So it's not even only the human being consciousness level, I don't think science can ever, I don't think mathematical things can ever, they can explain the mechanism of it, but you lose something when you right move away from the thing of oh what's going on, oh it's swimming towards the sugar. Well, I'm going to, you can build a mathematical model. But you mis, argue missing something as in a description of observing this if you leave out the idea that it's, it's swimming up a gradient and that's swimming up a gradient wouldn't be in the mathematics. Sure, it could be. You're missing something in every model, it depends what the questions are, but you, you can model those behaviors, this is what mathematical psychology does, right? You're trying to explain the pattern of behavior in relationship to the stimuli and you have real kind of, you know, they're truly mechanistic, they're generative models of, but if psychological processes not of neurons, right? And those are perfectly good quantitative mathematical models meant to address, you know, kind of again the level of, of behavior in relationship to a stimuli or learning, right? And that's again bridging those two levels of analysis and then there's the challenge, not how does a model connect two different levels, how do we connect two different modeling levels of analysis, the models of the level of circuits versus models of the level of circuits? I think this debate is incredibly clinically relevant because back to your original scenario, the typical occurrence is a patient comes to see me or one of us and says I'm having a subjective experience, a deeply subjective conscious experience that I don't understand or they say that, that, that is upsetting to them in some ways, whether they're anxious or they're angry or they're sad. And there's, there's a question on the table as to whether any kind of, and I'm going to use the word analytic, not in the psychoanalytic way, but any kind of mathematical or analytic thinking has any value. Maybe there's nothing I can offer that, that that's one hypothesis, that patient because what they are coming to me with is so intrinsically subjective and doesn't follow any standard set of rules that no amount of experience I have could ever really impact them. I don't believe that. I believe that using my experience, using the models that I have about why some people get sad, why some people get angry, why some people get anxious actually has a value for them, not just in a kind of, oh let me tell you an eye story and therefore you'll feel better, but rather in that you'll learn something about your subjective experience that is going to be useful to you. And so that's to me why there's a bridge between those two. Now are there aspects of subjective experience we don't understand yet? Absolutely. We don't understand, but some of it we understand in small ways and I think that's proven to be very useful and I think that's going to continue to grow. So this is why in clinical psychiatric research there's such a push to go beyond kind of subjective evaluation toward actual quantitative behaviors. Can we relate subjective experiences of anhedonia to the parameters of sensitivity to reward and punishment in a reinforcement learning model that we can actually set, can we relate delusions in schizophrenia? Can we encapsulate that in a more quantitative mathematical formalism of Bayesian inference and how we bring prior information in combination with sensory evidence? And if we can do that, then we have, there's still that metaphor that jumped between the simple computation and the full subjective experience, but now we can study that, quantify it, study that in animals, understand what the neural correlates are. And that gives us, I think, a foothold in terms of bridging these levels of analyses, which ultimately we need to, in psychiatry, if we're going to talk about how pharmacology can affect brain circuits and ultimately alleviate symptoms. I think you just kept on how smart we are compared to computers. So if I were to go head to head with your model and evaluating people for delusions, I would win. Sure. So what am I doing that is not in your model? The interesting thing there is that neural networks are starting to get better at humans at a lot of jobs like that. Human networks are starting to get better than humans at a lot of things that involve complicated human judgment. Like what? Radiology. Well, no, no way. Just go. It's like psychiatry. Yeah, just go. Okay. How about what they need right now to work is they need a huge training database. But if you had a training database of, you know, the conclusions you want to reach and the information that goes into it and you had a lot of that, a machine might learn to do it better than you. So when I and all of you look at a people, look at somebody and their facial expression. You do instantaneous calculation that's better than any computer. So far. So far. There are lots of learning to do that, but you wouldn't know if that's a good label. I'm not talking about identity. Yeah, no, I know. They're learning recognizing motions too, but they're not as good at it yet. But there are all sorts of nuances. And then in terms of context, I mean, computationally, we are very complex. We are. But we're starting to build machines that are equally complex. Right. And also, I would point out that by virtue of evolution, you've had a training. You have been exposed to training sets over a billion years. Right. And a billion years of training sets have selected you to be the best facial recognizer. Right. And the people who are not as good facial recognizer as not so. Evolution has been a training set over a billion years. We sometimes discount that. That, you know. No, but evolution has acted on the genes that has selected for the genes that can lead to those computational ability. You know, I'm not Lamarckian, even though you could do gene epigenetics, right? It's a little bit Lamarckian, that's right. But I have had several years of pattern recognition, but that even really thinking about it. And I'm awfully good at it. And I. But that is a huge training data set from an interactive way, a closed loop interaction with the environment. Yes, it is. Will we be replaced? We have clinicians be replaced by psychiatrists, maybe by computers. I'm trying to say is not that humans are going to be replaced soon, because the only things we really know how to do in neural networks right now are when we have a huge database of input to output, then that we can get the machines to learn it, sometimes better than us. No, no, no, no. But what it shows is. Learn wrong. Excuse me. These neural networks have never learned the damn thing. They're trained to perform a classification task. They're not learning anything. Well, what's your definition of learning? They have no values. This goes to the Chinese room market. I want to make sure. I just wanted to finish that. The point is that some things that we think of as our unique human complex intelligence are starting to be done by machines better than us, like playing Go, like playing just. And like some kinds of recognition of objects and so forth. And I'm not saying that it'll all be replaced. I'm just trying to say that there's not obvious that there's something in us that is so special that we can't someday get machines to do it better. I agree. I agree. It's a question. And it also shows how morally complicated this is. So I think you would agree. I think you would agree too, Larry, that one of the things that we wish we were better at as clinicians is predicting who will commit suicide. That we do our best. And when we work in the emergency room or work on the inpatient unit, we make those decisions all the time as to who to keep involuntarily and who not to and not infrequently we get strong. So let me finish the story. I have a friend who works at Google. He says that it is kind of an openly known at Google that there are algorithms that they can apply that enable them to predict who's going to kill themselves to a frighteningly precise degree. The problem, they have enormous data sets. They have enormous access to data that we have clinicians do not. And then the question becomes, does Google want to admit that they know that or not? Facebook has now started to admit that and doing little things here and there. Is it enough? I'm not sure. But what do we as a society do? And the danger to me of too much prioritizing of the clinical superiority would be that we might not take advantage of some of these other data sources that could help us save a lot. I want to pit myself against computers. I meant that to be provocative. I've done research in this area. So I've done research that shows, again in collaboration with Guillermo, that IBM Watson, when it looks at language patterns and individuals at risk for psychosis of whom 20% develop psychosis in two years does better than me. I mean, I've published that. In terms of suicide, I'm sure Google has much more than what's in the literature because they have a lot of resources. But in the literature, there is a good literature that if you look at language and it's across its people texting, talking, all kinds of things, I reviewed this for a grant that I put in. And Guillermo did an article actually looking at poems, poets who committed suicide and those who didn't, and looked at the actual language in their poems as to what we predict. Consistently across the board, it's using words that have semantic content that has similarity with hopelessness and depression. So these are tools. I mean, I don't want to put all of us out of a job. But I just brought that up in a sort of provocative way in terms of the models because we're also models, right? Doing computations. We don't understand our own computations, but... Okay, Adi, I'm curious if you could expand on your idea about learning and why neural nets don't learn? So even these words, I feel learning, training, et cetera, even those are very loaded. As you said before, these deep neural nets are complicated functions with many parameters, hyperparameters even, if you take into account the network architecture. And there are objective functions that are set up, which are minimized, to fit the parameters of that function so that at the end, the function has certain specific input-output properties. Okay. It's tempting to take a look at the go. What is this called? What was the go thing? Alpha go. Alpha go. Alpha go. Or deep blue and say, wow, it knows how to play chess. It knows how to play go. It's a giant lookup table that has been... Because I'm constrained. That has been pruned and refined over many, many, many iterations given lots of data. If you sat Alpha go down on the table opposite of whoever the gentleman was that Alpha go was playing, and you said, okay, guys, new rule. If you head off the left side of the board, you come on the right side of the board. You're playing on a cylinder now, or a torus. Alpha go wouldn't even be able to take the first move. It's database would be inapplicable. You sit down, Gary Kasparov, against deep blue, and you say, okay, guys, new rule. The queen, by the way, it's no longer a queen. It's like a rook in a bishop. I'm sorry, a rook in a knight. It's like a rook in a knight, but it doesn't move like a bishop anymore. Okay. Gary Kasparov would still kick my ass, but deep blue wouldn't be able to do anything. And so I'm not saying that there won't come a time where the types of functions and the types of parameters that people are able to bake into these neural networks are sophisticated enough that maybe there are some parameters that can be left to be tuned on the fly after the machine sits down and sees the clock. But right now, we're definitely not there. So this issue is actually in a philosophical issue. This is philosophical debate about something called the Chinese room problem. I don't want to get into it, but it's exactly the day as to whether it's something is... Why not? It's a little war. It's not. It's Johnson. Look at the scrubbing pre-cream. The argument is if I have someone in a room who has all this right, you know the argument right here, and he has all of these dictionaries, Chinese English dictionaries in the room. And if I give him a sentence written in English, he can translate right, he can then look everything up and he can and respond properly in Chinese. Yet, there's nobody who knows Chinese. So that's the Chinese room argument. There's nobody who knows Chinese. But he can't. And the two sides of the argument are one side says that proves what your point is that the machine doesn't know anything. And the other side of the argument says no, the entire system knows Chinese. And that's what we mean by knowing Chinese. No, no, no. It applies to the Chinese room because if you... It's apocryphal, right? All those stories about like the spirit, the flesh is weak, but the spirit is strong, right going into Russian and then being back translated as the meat is rotten and the alcohol is bad, right? So it doesn't work that way with language. So whatever he came up with, without knowing... When you put a person in there, they have a flexibility that the... In the Chinese room argument, the person is really acting just complex. It's not as right a person. I mean, images are... But then you're getting into a strictly rule-based language. If you believe in Chomsky's sort of hierarchy, now you're at the bottom. And Chomsky would say for like a human, sophisticated grammar, you need it. You can't... It has to be probabilistic. It can be rule-based. You can build all those things, but it's complicated. And that's the Turing test. The Chinese remiss the Turing test. But the Chinese room problem captures... Tries to capture this difference between what do we mean? What is our intuition when we say somebody knows something or somebody has learned something? And it challenges that thing and it challenges... As you did this question of whether we're gonna... That's the purpose of the argument, is to challenge the use of that meaning. Just want to make one other point that I run into whenever I try to talk about this. And that is that we all have folk science in addition to a formal science. It's folk philosophy that cultures have folk philosophy. We have folk chemistry and things like that. And they're not very good. I mean, people have survived before formal science came in because they had these theories. But folk psychology is really quite good. Pre-scientific psychology is actually much better. We're pretty good psychologists just intuitively. We have to be. We've evolved to be pretty good psychologists. And I think that is one of the reasons a lot of these things get confused is because folk psychology is so good. It is hard for scientific psychology to sometimes compete. And there's a much more sophisticated language within folk psychology than there is, for example, in folk physics or in folk notions of mathematics. And that gets in the way. I want to just respond briefly to Adi. I agree with your criticism that they have a limited range. And if you change the rules on them, they haven't been taught to adapt. But it's not to say that they couldn't be taught to adapt. But the other thing is that I don't think it's right to say they're a lookup table. Because AlphaGo, well, on any given game, you can't see a board position that no human has ever seen before and that the machine has never seen before. And it'll still outplay LisaDoll. Because it's learned somehow implicit in its brilliant parameters. It's learned some principles of how to play Go. But it can deal with entirely new situations and outplay any human. And the same with AlphaChests or whatever they call it. AlphaZero. Yeah. So I don't think it's right. I think DeepBlue was basically a lookup table. But I think these new things are not. So they're probabilistic now. No, but the point is that it really understands some principles in a way that, I mean, DeepBlue just did a deep search and said, you know, if I look ahead, 10 moves, if I do this, am I going to be better off or worse off? And it didn't know anything really. I mean, what a new evaluate better off or worse off was really simple, but it had this powerful ability to search. But that's not what these new things are doing. They don't search nearly so deeply. They learn principles that they can then outplay any human. But the most philosophical pushback to you would be when you say it understands, right? Well, I didn't say it. It behaves as if it understands. I said they're a principle built into these brilliant parameters that can now outplay any human. But those principles, I understand you also kind of, you know, consults. That's observing a pattern and then getting some kind of value function or if it's going to play here or not there. Not necessarily, you know, rule-based or articulable or articulable. I can't even articulate it. You know, decisions, but basically kind of, it's a form of pattern recognition. But you know, that also underlies a lot of our cognition, the way we recognize emotions, the way, you know, probably a good chess player can just kind of get a flash of the chessboard and get a sense of, is this a good game to play or not? This is a good move or not in that kind of intuitive way. A lot of our cognition, we can't necessarily explain. Right. So they're mathematical models for Gestalt. That kind of Gestalt perception that we're all so good at as people. I mean, I would say a lot of the visual recognition, the same way that people use, you know, deep networks for this. You know, we can argue about whether it's kind of training or learning by the same rules. But you know, as a metaphor of the general principle of, you know, how does our eventual visual system work for object recognition of it being kind of successive, you know, layers of feed forward processing with some kind of flexible learning such that there are presentations at the intermediate layers of your vision, you know, are guided by the final, you know, output recognition and decision and action is, you know, I think where you would say that model is some sense a good model of human vision. Do we already have our own neural net for identification? I think it's only still a very impoverished analogy to what we do. But already just with that impoverished analogy, it can outdo us on some test. We can sometimes outdo ourselves in tasks that we don't think we're proficient at, right? There are examples of people being able to do fairly complex thinking without realizing in advance they know how to do it. So you could consider that analogy to what some of these computers are doing, perhaps. Yeah. But you can also bring these back into cognitive neuroscience, right? So these deep networks, not only do they, you know, do object recognition, it seems like they do it in a similar way as us. So we can do, you know, recording from single neurons and monkeys. We can do functional MRI in humans and we can look at what kind of neural representations there are in say, different layers in visual processing and compare that to the different layers of processing in these deep networks. And there are correspondences. And so, you know, it's considered they're trained in impoverished way. They're not relaxing some things. But where we can actually try to check the actual internal mechanisms, they seem to have some validity in terms of explaining not only our behavior, but even how the brain works, our representation. I think I would definitely agree that there is some analogy between what we're doing. And what strategies are used to make these deep neural networks. That's true. But I also agree that it is impoverished and not. But to Jerry's point about our doing computations that we don't know, I mean, as anybody who had the experience of these phony rocks that are really very light, but they think, you know, you look at the, it looks like a rock, but it's actually foam. And when you try to pick that up, you completely miss, right? You completely miss the motoric thing. Because we take absolutely for granted that the incredible computation that goes into a simple motor thing of lifting something up and putting the right pressure on it. And I can fool you by giving you a misestimation of what the weight of the thing is. But so we're doing incredibly complex computations, right? Just for that simple motor action. We have to plan it very carefully and we have to know what it's doing otherwise. To give credit for credits too, I think that's one of the early contributions to psychoanales. I think for a motor movement, not on motor movement, but to acknowledge the complexity of these models outside of awareness. Because I think that's the literature that was early literature on what was outside of awareness was that it had to be incredibly simple. And that more complex processes therefore had to be conscious. And we now know, and I don't even think it's controversial in the cognitive neuroscience world, that the kinds of processing that can go on completely outside of awareness can be enormously complex. Absolutely. And this was something that Freud was talking about, you know, 100 more years ago. And that example highlights one of those key computations is prediction, right? And so that actually gives us a hugely rich data set. Because we're not just, you know, training the human brain on, you know, discrete supervised learning, right? But on predicting the future, what are the properties of things in the service of predicting how I will interact with them, how they will move in the future, etc. So, I want to take a question. No, no, no. Okay. Later. Later. Later. Later. Okay. The. The. Speak one of the things about the computation computation. Sir, please have a seat. We have an opportunity later to speak, okay. I already mentioned earlier that, you know, in mathematical models, we have these variables that are all well defined in which we can then check on or be aware of. And the interesting thing is that when there are all these hidden units, and in some forms of mathematics as well, you can only say that theoretically they can be checked on. Theoretically what? Theoretically they can be. They can be possibly accessible to being accessed. But in fact, in the process of doing the computation, some of those things are just, they're x's and y's. They're not really specified, right? I mean, I guess I may need a distinction. I'm not good at that. Okay. Neither. Okay. Thank you. No, I think you're not alone. I think you're pointing out deep in the deep neural net, you may understand, you may understand individual weights, but you don't actually understand how the process is leading to the proper outcome. So that is it. Absolutely hidden. There's an intuition in the black box. That's a camera for it that is a black box. Right. There's an intuition we have about what it means to really learn something that I think does involve our knowing the steps quite well, and then having an intuition that we know those steps. That's what we call, I'll say for the purpose of this comment, that's learning. But when we don't know those steps or when they're invisible and they're being manipulated all the while, we then have this thought, well, maybe we don't know. That's how we might be able to do things unconsciously. Because we're not aware of all the variables being affected. But I think that sense that we know what we're doing is an illusion. Because when we've, I mean, artificial intelligence for many years until the deep net revolution about six or seven years ago was focused on trying to do things by writing down the rules, trying to do vision by writing down the rules, trying to play chess or go by writing down the rules. And it failed miserably. Because we don't know the rules. The rules, and actually to go to Jeff Hinton's point, you can't reduce it to the rules. It's a way more complicated thing than that. I was trying to capture why we might have an intuition of how learning is different from what computers do. So whether or not it's good, at it or it's accurate, that may be what gives us the feeling whether intuition that we've learned something as opposed to just following the recipe. Well, I think I learned something when I can teach somebody else. I don't know if there's an analogy for these nets. Babies are. Maybe they have so much as necessary. Maybe they can feel they can teach other nets. Well, I can make a bad analogy, which is that the people can take a neural net that's learned to do something and then it can teach another simpler net to do it. It can teach something else to do it more compactly. Teach it in the sense of being the one who tells it what the right answer is. So, I mean, people do use kind of one net to teach another in very simple ways right now. Okay. Sure. I think that goes in that storm really interact. Yeah. It's not what we're talking about. It's not what we're talking about. It's not what we're talking about. Maybe something like that. I think that's what I was trying to get at when I talked about the folks, the folks psychological language is to say that we have this whole language that is that we have evolved and it's about ourselves, understanding ourselves and understanding others, a folk psychology. And then we have these words and then we apply these words and then those words have very specific human meanings. So I think you're right there. When we say learn, we've got to be careful. We should have two words, right? We shouldn't say a machine learns. Because learn has a very specific meaning. It has a very specific human, humanistic meaning. It has to do with experience and it has to do with feeling. And so I think that we apply the word incorrectly because we take folk psychology which was developed for human beings and we apply to machines and those kinds of things and we don't have other words. But we really should have other words. We do qualify kind of, there's reinforcement learning and unsupervised learning and supervised learning for different ways that we learn. And again, your reinforcement learning, like you said, may engage the amygdala in an unconscious way which may be different than supervised training as well as just kind of general experience or prediction which may be your less conscious. It is interesting to me how many conversations I think can evolve into arguments around the semantics in exactly the way you're describing between the folk psychological use of a term which people didn't want to defend in a certain way and then the other uses which may be narrower broader but are carefully defined. And I think ultimately since we're not going to discourage people from using those words, you just have to get people to define them when they're using them because people use the same words in different ways. We can psychoanalysis as I had this problem for a long, long time which is we all talk about transference, we all talk about libido and we can have very long conversations meaning entirely different things with the same word that often can be done. Cheryl mentioned the Turing test which was the definition of intelligence, right? So that was a debate, you know, 40 years ago on debates on what does it mean to be intelligent and they tried to define that. The Turing test is I think is alive and well. Say that again? The Turing test. The idea of the Turing test I think is alive and well. Who are alive? Maybe you should tell people what it is. Yeah, please. Oh, so Alan Turing said that had a test that for artificial intelligence that if a computer could pass as human in conversation with another, with a human, it will have passed the Turing test. So you know, you can think chatbots, they can, as a simulation, for a limited amount of time, seem almost human. But if you really push, we don't have any machines yet that really pass the test. My mom, I think my father could pass the Turing test. Now, if I talk to your father, I wouldn't think he was human. If you communicate with him via text or email, I think he would think he was a chatbot. He might. So, no, no, but the chatbot is not part of the Turing test. The Turing test was before chatbots existed. What I'm saying is a chatbot is getting close in some circumstances to appearing human. Nice. But no one has, where is the status of that? No machine has passed the Turing test. No, I don't think so. I think there was one chatbot which kind of passed by acting as if it were a child who's a non-native English speaker. And Laura Mar. Yeah, Laura Mar. I think there's a time I have to announce. I'm actually a robot. I think we're going to stop now, though it's been such a wonderful and lively conversation and invite people to ask questions. Why don't you come up to the microphone? I just assumed everyone's got a Turing test. And please, if you want to see the movie, questions and comments to be kept on the brief side, please. All right. Thank you for this engaging and live discussion. It's interesting because when you were talking about applying mathematical models to psychological states, let's say, it seemed as though you were mainly talking about behavior, decision-making, in action. And so I could see how models of probability could determine, could be used to determine particular outcomes. And so the same thing when you were talking about the computers playing chess, right? That's how do they make decisions? How do they act? How do they behave? What information do they have access to? But what about mathematical models applied to, let's say, experience? How one experiences or to consciousness in general? That seems to be a little bit different than the direction you were heading. It's like art, humor. Yeah. Yeah. How one experiences are, to what creation is, mathematics. Aesthetics. Yeah, exactly. But even experience states, right? How do I know what I experience and what do I experience? And is that something that can be described mathematically given you have enough information and data, let's say? I think right now we couldn't say anything about the in principle when we have way more ability to watch what's going on in brains and to, at some point we're going to be, as I said before, at some point we're going to be able to say, these kinds of neuroscientists and neuro patterns of activity reach consciousness and lead to this feeling or this experience. And these other kinds of neuroactivity don't go to consciousness. But why do they have conscious experience? I don't know, but we'll be able to make a nice amorphism between the behavior of the neurons and what different things feel like. But that's way far in the sense of computer. We couldn't even touch that now. I would say that the why question, depending on how you define it, sure, I can see that being far in the future, what I don't think is far in the future is models that are relevant to affective experience. And Cheryl's work is one example of that. But there's many other examples now of various relatively simple models that look at the sort of dynamics of various affective states and why one reacts in certain ways to different things and the correspondence of that between facial expressions and behaviors and so on. That's a model of the... I agree with you. That's a model of different level. I guess what I was addressing was the neurons. Can we talk about feelings? That's way far in the future. But that's also... When you're discussing modeling affective states, that's also what gives rise to the affective state or the behavior of the affective state but not the experience of the affective state. That's why I was drawing this depiction with the why. I think one can always carve out a realm of the why that we don't have access to. But I think that's shrinking. I mean, the example I'll give of that is I had a classmate, Natalie Training, who remained famous, who we used to have this debate about whether there was possible or worthwhile to measure anything in the psychoanalytic process. So he told me that his definition of psychoanalysis was that which I could never measure. So by that definition, as I got better in measuring things, his diagnosis got smaller and smaller. He was okay with that definition. But I guess what I would argue is that, sure, one can always carve out a why that is inaccessible. But I think it's relevant to the why the more and more we know about the dynamics of these affective states. Or the what, actually. Yeah, well, but philosophers talk about the hard problem, and I think that remains obviously an open question. And I don't know whether that's a scientific question or remains forever a philosophical question as to how you can bridge between mechanism and experience. I think that the hard problem is a hard problem for a good reason. I guess it's an empirical point as to whether we'll ever be able to bridge that. I'm betting no. But we'll see. So what can I just go back to an example you said earlier just to see where we stand on things. Let's take your protozoa in the dish going up the chemical gradient. As Larry pointed out, you can have a, sorry, can, sorry. Just can't point it out. You can, I called it you can earlier though. I'm two for three, but you can write a complicated differential equation that has every atom, neuron, whatever in that worm. And your model will climb up the chemical gradient. And you can point to every little bit in your model and explain in a particular way why that thing is climbing the chemical gradient. But would you ever understand how it feels? I don't think it feels any feels. How it experiences climbing up the chemical gradient. And you say, no. That's what you say. Well, I will say no when I would say they're different languages. Because by the way, when you say that something's climbing up a chemical gradient, you're giving a teleological explanation, right? You're explaining something by the end, right? And classic Aristotelian, teleological model, which is not a scientific model. You can't describe something that you can't postulate a cause that happens later, right? That it's climbing up the thing in order to get sugar. That's a reason and can never be a mechanism. I mean philosophically. So that you can certainly build a model of things that follow gradients and what how they behave. Right. And you can have model at that level. Right. But what's my favorite thing that I described when I described it, it's doing this for this purpose. I've gone. It can still be mechanistic. So as internal states about the past histories, you can tell whether you're increasing or decreasing the gradient. And so even in this case, for subjective, affective states, people have done things of within, again, the limited context of sequential learning and decision making and reward, you can even say, how does your affective rating of happiness correlate with rewards and reward prediction errors, right? With humor, I think there is some work on seeing in simplified settings, can we show how humor relates to violations of predictions of expectations a little bit? It's really pretty inadequate. But what happens to that? What happens to that? A program, right? It's just not going to speak to the subjective experience. Yeah. There's some rules. But what are the kind of computations, right? At the level of inputs and outputs, you can relate these things to actual computations that guide behavior in a mathematical way, I would say. For humor, you can find some rules. But then to try to create humor using those rules is where it hits the screen. There's a catastrophe where he's a model of humor, which actually works pretty well. Fantastic. It's a discussion of the fact that the diary is a novel, a environmental word of pettiology. And I think that is something that humans, we have reasons for doing things that so far have not been built into sort of computational models. No, no, you can model that, absolutely. Absolutely. You can model agents that have goals and that have some relationship between their actions and their goals and their outcomes. And they learn from that. You can model that. Put it in the context of evolution, too. Yeah. What's selective? We would also say that we have good evidence that there are times when we think we are motivated to do things and that there's good evidence to suggest that we have told ourselves a story about wanting to do something that we were doing for a completely other reason. And habits that are not very free. So, introduce yourself. Introduce yourself. Oh, no. I'm a new shy work with Cheryl. I'm a neurologist. So from my perspective, there has to be sort of an answer to all of this. And so I guess my question is, you know, one of the limitations I see with models and computers is that they have to be created by humans, right? So is it conceivable that perhaps the reason some of their limitations are because we as humans are not smart enough, at least now, to really create these models and perhaps with evolution or with human learning, we could learn to create these models and computers that could account for more complex psychiatric functions? Well, from the point of view of the history of science, the history of science is kind of on your side because there were all kinds of things that people said will never be explained by science, including urea, right? Right? The production of urea in the human body was something that people thought couldn't be replicated. So the history of science is sort of pushes to that. But I would say that the human brain is the final frontier and we don't know whether our historical experience with science being able to progress will be able to do that. But even so, that would be a limitation of us in our ability to create the model as opposed to a limitation to models in general. Couldn't you argue that one of the ways of thinking about artificial intelligence is that it is teaching a machine to create new models? I could imagine, certainly, and maybe this is already happening, building a machine that builds new models that we ourselves as humans couldn't build. No, it has to appreciate art and tell jokes and it has to be human. That's a directive. I wouldn't argue with that. There's some intrinsic limitation to how complicated a thing humans can create. It's just a matter of just the whole way science has been built up. You've got to understand some things and then you build on that and then you build on that and then you build on that. We're ways from getting there, but I don't think there's any intrinsic limit to how far we can go. Humans are stupid, but humanity is smart. Humans can be stupid, but humanity is smart. That's a good point. Thank you all very much. The gentleman right there, when you mentioned the word philosophy and then before you wanted a definition of the word math, I thought of the confrontation between the analytical philosophers and the continental. So the logical positivist, Witton Stein and Bertrand Russell thought math was the answer. Logic was the answer. Could this be a little bit of what we're dancing around here? Yeah, Fragan was in there. I would say, yeah, I would say that, and again, Andrew and I have had a number of conversations about this about what are some of the, what in conversations like this, what are some of the fundamental things? And Russell had a famous quote about the difference between mind and matter, right? And he said, what is mind, not matter, what is matter, never mind. So the mind, body problem underlies all this. The use of folk psychological language to describe scientific psychology are problems like this. And I think that those go to the positivist, questions of the positivist about whether you could ultimately come up with a set of definitions and a set of non-falsifiable statements and whether you could do that or not. This hasn't, while philosophy has moved past that and rejected that, I think working scientists have never fully, have never rejected the logical positivist position. At least as a matter of practice, I don't know if anyone has anything to do with that. When you ask that, what do you think of as the alternative? And your question to me was implicit that, you know, is this just kind of skirting around logical positivism as opposed to what else should we perhaps be bringing in and considering? That's the implicit part of your question. I think what was the problem with the code? If we can't get that, you know, we can't really get to it. We can't be started. Yeah. I can't. They can start. Yeah. And this will be our last question. Thank you. Please, not too long. This is seems to us to have gap, abysm between psychology and philosophy because it depends on where we turn our attention and our focus of attention. Because this, I think this gap is artificial because in order to, I'll give you some example, in order to aware that every experience requires awareness, requires consciousness, hidden in your way. For example, Freud and Jung built his theory about unconscious from the point of view, not of unconscious, from the point of view of conscious. Therefore, do you see some animal to write book about biology? No. Men who is higher ontological culture write book about biology. I wish to only to say that the, not only the, say, I'm a psychiatrist, but research, not only our science. So we get to a question. Ask a question so we can respond. Excuse me, sir. I didn't wrote so many books in order to only ask questions. I wish to say some missing great point of contemporary physics, especially in physics, because computation upon physics. Few genes, the massive genes, he tried to deviate this general intention of thought that a universe is not computer. The universe is a mind because ever mathematics need of mathematicians. What present in itself mathematical equation without interpretation? Okay. This is not my question. My question, my team was to say something, I think very important. Now we are aware that the whole science meets time, temporality, because see, every, all the computers and all the living systems process information in time. Time substitute the, time is like work. We are not out of time actually. So I'm happy. You don't wish to listen to the, why sir? I'm sorry. Sir, do you have some esteem? I'm going to have to stop now unfortunately. I did, I did, because the time went out. So I must. I'm sorry. I apologize. Do we, do we have the panel responder or do you want to just, okay, then sit down and let's hear what the response we get, please. Sir, after we should be able to ask the panelists independently. I told you that all the living systems and all the biological systems process information in time. I think, I guess the question, the human brain is all of the process, all of the process stand into the flow of information. Okay. You make something very important. It helps now write to, to. Yes. I'll stop you now with that. It is actually an interesting point. If you have a response, they will not have knowledge and functions. Okay. Because to be cautious that means double status. Thank you. All the time process is pretty big and it's been a few days together. Okay. Now it happens that your comment, that one of the, my comment, concerned about the time. Thank you. Thank you. Thank you. Now one of the, one of the people that I, that we reference in the description of today's talk was on Ray Bergson, who did supply that similar sort of analysis to making a connection between the mathematics and, and subjective experience. So in that sense, you're in a good company. Thank you very much. And thank you everyone else here today for a really wonderful round table. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Just to say, I Explosions, we'll nitrate an entirely Rudrise moving forward.