Yeah, wasn't that sad.
But he's not.
I don't have to.
I'm happy too.
Wh Woah.
So I'm happy.
So Ken, what did you think about lecturing?
What's that?
That lecture two days ago on complexity in the task.
No, I couldn't have it.
I couldn't have it.
I couldn't have it.
I'm trying.
I know I saw you talk, but I'm talking about what Tucker was.
I'm wondering, I just think.
This is like, I'm about choice task, and it was a question about levels of complexity.
I'm really excited.
You know, it's like creating models, how people created models of the task.
No, I'm going to be here.
Can people hear me?
I think it's prime age.
Hi, good afternoon, everybody.
I'm Gerald Horowitz, I'm associate director here at the Hill Center.
Welcome to a very interesting roundtable today entitled Math Models Mind.
I wanted to make a quick announcement that coming up in future round tables, we have
a March 9th life in the universe, which we've established actually right now today,
that there is life in the universe.
But there's going to be more to say about that topic.
And we have assembled the following roundtable participants, Caleb Sharf's astrophysicist
at Columbia University, Yale astrophysicist, Priyem Bada, Natar Rayan, Kenneth Dill,
chemist, Stony Brook University, Edward Turner, a physicist from Princeton, and Dennis over
by a New York Times science correspondent.
So that's March 9th, and I'm sure it's going to be really quite a lively, interesting talk.
In April, I don't know if we have an exact date yet, but I don't have it here.
We're going to have a discussion on climate change and the Anthropocene era, which is
among us, which we're living through now.
And on May 18th, you don't want to miss it or else you'll be in trouble.
We're having a talk on shame.
Today's panel, I'll quickly introduce, and you can raise your hand when I mention your
name.
First is Larry Amsel.
And Larry is a clinical research psychiatrist on the faculty of Columbia University.
He's out of long background in mathematics and was an early proponent of using decision
theory, gain theory, and behavioral economics in psychiatric research.
I'm going to keep these short so we have more time to talk.
Cheryl Quarkrin is associate professor of psychiatry and program leader in psychosis
risk at the ICON School of Medicine at Mount Sinai.
Together with Dr. Chechi of IBM, she's identified patterns of language that proceed on set of
psychosis, including reduction in coherence and complexity of the speech.
Andrew Gerber is a psychologist, psychiatrist and psychoanalyst who is now the president
director at Silver Springs Hospital.
Silver Hill Hospital.
I was wondering where is Silver Springs Hospital?
That's what it wrote and that's what I read.
I'm sorry.
Ken Miller is professor of department of neuroscience and department of physiology and is director
for the center of theoretical neurobiology at Columbia University.
He's co-director of Columbia's sports program in theoretical neurobiology, it's center
for theoretical neuroscience as well as its neurobiology and behavioral graduate program.
And John Murray is assistant professor of psychiatry, neuroscience and physics at Yale University
School of Medicine where he directs a research program in computational neuroscience where
they focus on computational models of neuropsychiatric disorders.
He received his PhD in physics at Yale University.
We have one missing member, I'm going to give you his background in case he does show up.
It's our D.J.
Rangan, he's an associate professor in the mathematics department at NYU and he's completed his post-doctoral work at NYU.
His research has focused for many years on computational and theoretical models of sensory processing,
particularly vision and all faction.
So thank you all and we can get started.
Sure.
Sure.
Sure.
Sure.
Sure.
Sure.
Sure.
Sure.
Sure.
Sure.
So, I thought because the topics here are somewhat...
Oh, do you really are?
We just announced your minutes.
Thanks for joining us.
I was about to say that we were just getting started.
Oh, it's not perfect.
The topics, some of the topics were we discussed today are a little arcane and I thought it would be helpful for the participants to maybe give a brief summary of the kind of research they've done and more they're interested in the topic of mathematics
as a search for modeling behavior and the psyche.
So where would you start to find?
So what I've worked on is the circuitry of cerebral cortex, sensory cerebral cortex, primarily visual cortex, but trying to understand how the circuits...
Trying to understand general principles of how the circuits of cortex work and basically trying to understand what operations the circuits are doing to produce the responses to sensory stimuli that we see, how those circuits develop through learning rules based on the activity in the neurons.
And the far away goal is to understand from that really what computation cortex does.
And so there's a sense that there's been a unit of mammalian intelligence that's been developed and then duplicated and applied to almost everything that we do.
Someday I would like to understand what exactly it does to the input it receives and how it transforms it, how it learns from it.
So my research is also kind of focused on theoretical models of neural especially cortical systems. As is Ken's, we primarily focus on computations associated with association cortex in contrast to sensory cortex, looking at kind of fundamental cognitive
limitations such as working memory or decision making. And then we're very interested in understanding how synaptic level disruptions of the circuits could give rise to cognitive impairments as we see in psychiatric disorders such as schizophrenia.
And so we collaborate with experimentalists and study inter-disease processes and pharmacology in these computational models of neural circuits.
And it is on. I too have spent a few years looking at computational models of neural circuits. In this case, I worked a little bit on vision, but I spent most of my last several years working on old-faction trying to understand the kinds of computations that go on inside the old-factory system of insects.
And as Ken was saying there are many similarities between the old-factory systems of a lot of different animals.
And at first I was seduced by this thinking that perhaps there would be a similarity to the computations that these different old-factory systems perform.
However, the more I look at it, the more I've come to realize in recent years that it's almost like there's different operating systems running on the same hardware.
So we can talk more about that later.
No, I'm left.
Okay. So to sort of shift a little bit, I'll work backwards.
My current role in some ways is as a translator between different languages around mental illness. So in leading a psychiatric hospital, my predominant interest is how to get people to talk to one another, not just between our staff and our patients, or the patient's patients, but between the staff and each other.
And one of the languages that's been very important to me is the language of math, and or more broadly speaking, the language of modeling.
And I find, somewhat to my dismay, that that language isn't taught in most clinical programs.
And there's a way in which there's a sort of urgency for an answer, and I think this pervades maybe all of medicine, but particularly in psychiatry and psychology, makes people not understand the value of models that are good but not perfect.
And one of the most common quotes I use, which others may be familiar with, is from George Box, who said all models are wrong, but some are useful.
And to incorporate that is basically one of my main missions.
Prior to being a president of a hospital, I had run the MRI research program up at Columbia.
And so I was particularly interested in the use of structural functional MRI to test various mathematical models of neuro cognitive processing, exactly the stuff that you would like to do.
And I think that's the stuff that you all are talking about.
I'm a believer that there are a set of neuro cognitive processes that underlie our psychiatric disorders that actually will end up looking quite different from the symptomatic descriptions that we now use.
So the terms of depression, anxiety, even psychosis are appeal because they're very experienced near to the clinician, but that the underlying neuro cognitive vulnerabilities probably, in my opinion, will look quite different.
And I'm not quite at the point yet where we understand those.
So that's been the overriding theme of my research.
So I'm a psychiatrist and I collaborate with people who do computational modeling.
And I collaborate with Guizhemo Cheki and his team at IBM.
And he has applied computational analyses to behaviors such as language.
So we think of language as really big data at the level of the individual, the language has semantics and syntax and there's pragmatics.
And probably facial expression also has semantics and syntax as well as gesture.
And we believe this behavior in and of itself can be modeled.
And I think what we do as psychiatrists is we observe people, I do think that data is very important.
And not only can computational scientists help us, but they really feel that we can help them in terms of building the model.
So I've been to a few conferences, the NIPS conference neuro informatics.
Yoshua Bajio was there.
I'm talking about deep learning.
And someone in the audience asked him, you know, what are your thoughts about what you could learn from cognitive neuroscience, human neuro science?
And he said, I don't know and I don't care, which was very interesting.
But the people that I'm working with who really do think about artificial intelligence a great deal feel that we have a lot that we can teach them.
They really want to model what we do.
And the other thing I want to just say briefly, I looked at the kind of description of the history.
And it has this feeling of kind of a guy on a hill, right, and the environment.
But if we think about behavior, behavior at the level of milliseconds is very interactive.
And so we want to model discourse as well in all of what anybody does here who's an analyst or a therapist.
That kind of discourse is kind of key to our therapeutics.
And we'd like to sort of understand what is going on in a successful interaction, therapeutic interaction, if that can be modeled by the computational scientists.
And then with that model, use that to help you all in teaching other people what you do.
Hi, so I'm Larry Absola and I got interested in this stuff 20 years ago.
And actually got interested in it because it seems to me that within the social sciences, the economics was the social science that most used mathematical models.
So I got very interested in economic models.
So I think in this panel we're at wonderfully different levels.
Some people are doing stuff at a neuron level, a small circuit level.
Andrew and I are more interested in the whole, in sort of the patient, and in general, in the whole patient level.
But I think this stuff can be very abstract. And so Jerry and I agreed that we'll have to give like a three minute talk on a trivial example.
And if I can just have you guys help me pass these out.
This is the slide. This is the slide. It's a single slide. But I actually need one back myself.
Thank you. So if we could go get those moving around very quickly, I would appreciate that.
So I would say that what actually happened is that I was interested in watching as the managed care movement was taking over medicine.
And I decided I needed to understand some economics. So I went and took a course in the economics of medicine.
And I bumped into decision theory and game theory and I realized that the economists really have some very interesting insights.
Very interesting insight into human behavior. And the thing that I had come from math, I dropped out of graduate schools, of math graduate school, to go to medicine.
Because I looked around the room and I realized I'm good in math, but I'm not going to have a job. So you had to be great.
So I got interested in these economic models. And then I found myself working in a suicide research lab.
And I started talking to people about the architecture, thinking like an economist, what is the architecture of a suicide decision?
So if you look at this, this is a very, very simple basic model. And the point of this is simply to show a trivial example about how a mathematical application may change the way we think about something.
So in thinking about the architecture of suicide decision, there's three small assumptions that I think people might agree with.
And that is that agents, and that's another word for decision makers, they have preferences over orderings.
You know what you like vanilla, better than chocolate. You have preferences over outcomes. There are outcomes in the world and you have preferences over them.
You like one thing rather than the other. The second is that agents can choose actions, but they can't choose the outcome.
So you can go and order the chocolate ice cream, but you can't define whether it's going to be good. There's always a probability.
It may be good chocolate ice cream, maybe not the chocolate. So I can choose actions, but I can't always choose my outcomes.
And the last one is that when I make my choices, I try to maximize my preferences. I do what I want to do rather than what I don't want to do.
It's very trivial. And yet these three very, very, I think easy assumptions that are not that hard to believe give rise to this decision tree, which is that when someone's facing this decision,
they can either make a suicide attempt or not. If they make no attempt and they remain in the status quo, and that's the branch on top, if they do make an attempt,
those are probabilistic. If they could end up dead or they could end up surviving the attempt.
So there's three possible outcomes in the decision architecture. And here's where the trivial mathematics thing, because if you take discrete mathematics on day one, they will teach you that three things can be ordered in six ways.
So chocolate ice cream, vanilla ice cream, strawberry ice cream, there are six kinds of attitudes that you can have depending on your ordering.
So the mathematics forces me to believe that there are six types of clinical people, six different types of people in their approach to suicide.
Let's see if that's true. Well, the person number one is the healthy normal person is not suicidal. He prefers the status quo.
His second choice would be to survive a suicide attempt, and he really doesn't want to die. That's his last choice. On the opposite end is somebody who death is their first choice,
and they are willing to survive an attempt because the status quo is their absolute last choice. And this is somebody who would make any level lethality attempt.
They don't care about the probability they would make any lethality attempt. The third type, again, this is purely mathematically driven.
The third type is someone who surviving the attempt is their first choice. The status quo is their second choice, and death is their last choice.
And this is what we used to call manipulative suicide, but it leads to people who want, for one reason or another, to have made an attempt, but to survive the attempt, because that would either change them or change the environment that they're in.
We've all treated patients like this who suicide attempt think these people will not make a high level suicide attempt. They will only make a low level suicide attempt.
They're not a danger using a gun. They're only a danger of a low-suicide attempt. The fourth one is somebody who really wants to take their lives.
Let's say they're ill, they're terminally ill people, but they're terrified. We're facing this so much. They're terrified of making an attempt at ending up worse.
This is the reason for the Hamlet Society and the reason for people like Kavorkian. It's the whole idea of euthanasia.
It's the people who feel it's their time to die, but they're terrified of making an unsuccessful attempt. That's the fourth type.
The fifth type is somebody whose whole goal is to get away from the status quo. The status quo is their last option, and anything else is better for them.
Finally, the sixth type is a little bit odd. It's somebody for whom the status quo is fine, but if they were to make an attempt, they would not want to survive the attempt.
That's a samurai or also has to do with dueling cultures. It has to do with honoric cultures.
The point is that I made three very simple assumptions that 90% of people I talk to agree with is the trivial model, and the trivial model because of one piece of mathematics that three things can be ordered six ways, predict six types of suicide attitudes.
Most clinicians I talk to say I recognize those guys. I recognize those people. Those are real categories of people. End of talk.
The kind of applications, mathematical applications, as Laura mentioned, just a few minutes ago from the neuro anatomical cellular all the way to systems actually, not just individuals, but also systems.
I think it involves in a web of relationships with others. I'm straining to think of a way to get ball rolling with a conversation. Because this is dealing, there was a CRI guess on mathematical models.
I thought it would be a way to get started with just the following question. I think a lot of people who are interested in mathematics and get into this field often find themselves a little bit frustrated, where at least historically, of late, they found themselves frustrated
by the lack of mathematical intuition, a lot of people. The people who typically have done the kind of research you've done may not be so well-versed, or interested in mathematics.
I guess I want to know, how do you think mathematics is an improvement over a similar approach to what you've been engaged in that does not involve math?
I can jump in on that. I'm trying to write a popular book on this, and it's very hard. It's really very difficult.
It seems to me I was trying to understand what is the difference between a mathematical model and a verbal model. I grew up in the analytic world.
We had a lot of verbal models. I think the difference is that when you write a mathematical model, you are committed to the consequences of that.
That's kind of a thing. There's an equation you're committed to the consequences of that equation. We saw this in Popper's critique of psychoanalysis.
It was non-falsifiable because the psychoanalytic statements were vague, what the consequences were.
But when you write down a mathematical model, you are committing yourself to all the deductive and computational consequences of that model.
I think that's different than verbal models, but you guys would know better.
What I would say is that by, certainly for me, working on circuits, by exploring a mathematical model of a circuit, you discover things that you would never get just by thinking about it.
I think of a model as a scaffolding that you use to develop new intuitions. Once you've got them, you can apply them without the math, but you'll never get them without the math.
I can give an example. In the brain and the cortex, but across the brain, there are tells that either that are excitatory, they excite other neurons, or they're inhibitory.
They suppress the activity of other neurons. There's a phenomenon called surround suppression, where if you have a visual stimulus, right where a particular cell is looking, it'll respond to that stimulus.
If you put other stuff outside of that region, it'll tend to suppress the response to the center stimulus.
Everybody imagine that the only long range connections are excitatory, so everybody imagined you're sending excitation into the local circuit.
You must be exciting the inhibitory neurons, so they don't get surround suppressed. They get surround enhanced, and then they suppress everybody else.
But then David First, there's an experiment that showed that when you add the surround, the inhibition of the cells received goes down.
The excitation they receive also goes down, and that's what's causing them to get suppressed.
So then we had to figure out how can that happen? How can you add excitation into a local circuit and make both the excitatory cells and inhibitory cells all get suppressed by adding excitation?
It turns out there's a really simple mathematical action of that, which we had to, you know, start off for a little while to understand.
But then once you understand the mechanism, then you have a new understanding of how these things can work, that you then make predictions that you didn't anticipate, then experimentalists can go out and test.
I mean, I would say that, you know, the distinction between verbal models and mathematical models is more important than the distinction between using models or not, right?
There's often the kind of a take of you're using a simplified model, but the reality is that in science, we're always using simplified models, right?
If you don't have a mathematical model, you have some verbal model, some picture model, we've got some diaphragm, arrows, and this is how we kind of synthesize different facts, plan new experiments, et cetera, et cetera, right?
And so there's always, you know, some kind of model that people are using or assuming, even if they're not making it explicit, right?
And so by using a mathematical model, you number one, commit to making an argument for the sufficiency of something such and such mechanisms are sufficient to produce this phenomenon, which is kind of all you can do with models is really make kind of sufficiency
arguments, I would say.
As kimnessing, we discover counterintuitive things because you can use the word kind of emergence that when you have interacting elements in a complex way, you can have resulting phenomena that emerge at a higher level that are not really clear.
It's hard to predict that from even the properties of the low level, property elements.
And I would say that a key role in mathematical modeling is about bridging these different levels, right, where we understand something about, you know, to take Ken's example about the synaptic properties and interactions of excitatory inhibitory neurons.
You know, that's at the real, you know, kind of cellular synaptic level.
And then the phenomenon of surround suppression really emerges in the circuit at the physiological level. And, you know, it's through mathematical models that we're able to show how the elements at the low level produce the phenomenon at the higher level.
Actually, one other thought that occurs to me, you know, you said the, you know, all models are wrong, but some are useful.
And when you said that, it occurs to me, what I actually think is all models are incomplete.
I don't think they're necessarily wrong. Like, for example, I don't think our model of how it is that when you add excitation to the local circuit, everybody gets suppressed.
I don't think it's wrong, but it's incredibly incomplete. It's a very, very, very simplified model.
I think Bob was being intentionally provocative when he said that way.
Yeah.
I think he would agree with that.
Yeah.
So my thought about your question, though, is to try to disentangle a little bit the notion of use of mathematical models from the personality of the person who's asking or applying the model.
Because I feel like these things get conflated often.
And it's one of the struggles, I think, that exists in the clinical, particularly in psychiatry and psychology world, which is, I think there's a disproportionate number of people who get attracted to clinical fields.
Because of a pleasure in thinking in sort of almost rebellious ways that at any time you hear something, you sort of think, well, how's that also not true?
And how's that incomplete? And what's being left out of that?
Which is a personality style, it's a personality style that I like and that I think is very valuable in clinical work.
But it's interesting because it's often seen as a personality style that's at least in people who are non-mathematical as being incompatible with mathematics.
And I don't think that's true at all.
I, in fact, think that when you have a set of rules, when you have a set of practices, constraints, you can actually think out of the box in even still more a provocative way.
And I think getting, that's a nuanced way of describing the use of math that I think many people don't get.
They assume that if you do math, you're content with vast oversimplifications and it never occurs to you that they're, and I see you laughing because I've never met someone who's mathematically inclined who was content for the vast oversimplified.
No, I, to pick up on one of the things that Andrew said about character and the people who were attractive, I mean, one of the things that it seemed to me as I wondered as to why, you know, psychiatry had not become mathematical.
I mean, cardiology is mathematical. There's a lot of more more mathematics in cardiology than there is in psychiatry.
And psychiatry about the brain, so you would think.
And I think that, you know, there was a famous book by C.P. Snow called The Two Cultures talking about, you know, the time when there was a time when people knew everything and then there was a time where people sort of divided into the humanities.
Quote, quote, the humanities and the sciences.
And I always wonder whether people who were drawn to psychiatry were sort of the same sort of people who were sort of thought humanistically.
And that means, that means that they like to think in metaphors rather than informal math models, right, that you think in terms of metaphors that you think are going to be similes.
And that I think is the difference between sort of the humanities and the hard sciences.
And that psychiatrists were generally drawn from those kinds of people, but I could be wrong.
Of course, what is a metaphor, if not a model?
And so that's, you know, people make this argument frequently and I agree with you as a cultural level.
And then I think, why can't we get beyond that? Why can't we see that you can actually apply math to these kinds of more humanities, you know, models without doing any damage?
There's a wonderful quote in the beginning of Freud's biography of Leonardo da Vinci, which I always remember, where he says that some people have criticized him for the fact that he's not a
psychoanalytic study of Leonardo's life. And those of you who read it more recently than I can correct me if I'm wrong here.
But he says, he thinks exactly the opposite. He thinks by applying a psychoanalytic understanding to Leonardo's life, rather than oversimplifying or somehow reducing Leonardo's brilliance.
He's actually expanding and making it even more exciting that Leonardo ended up as he did.
And that's the same relationship I think of math to models that come out of the humanities, which is it actually doesn't reduce them, but rather gives you the opportunity to do with it.
And that's it. This is occurring, in fact, about two years ago, someone came out with a game theoretical analysis of some classic pieces of literature of Jane Austen, for example.
So it was a game theory model of Jane Austen's novels, which is a really beautiful piece of the kind of synthesis that you're talking about.
But I think where I find the math, you have to know, be able to know if you're right or wrong. If you come up with a pretty math model, but you have no way of telling if you're right or wrong, it doesn't get you very far.
Although, you know, that's something physicists debate now with super strength theory, but that's a whole nother topic. But at least for the rest of us, it's important that you be able to, you come up with testable predictions that you wouldn't have thought of otherwise.
And that they can be tested. And without that, you're kind of, you have an insight that might be right, might not be right, and you don't know what to do with it.
And then I think the other element of being successful is really what John said is that, you know, interactions of one, when I first was looking to do theory in biology, I was trained as a physicist, but I was wanted to work in biology.
All the biologists I talked with told me, you can't. Biology is an experimental science. We just find out the facts. And if you want to do theory, you should stay in physics.
And, but why neuroscience started to need theory was when we started to collect enough data at different levels that we had to know how the interactions at one level could create the behavior at another level.
And that, those aren't just facts. You can't just think your way through that. And that's where you really, and then the field of theoretical neuroscience, mathematical neuroscience has exploded since about the time I entered the field.
I happened to enter at a very good time when several people were entering and that's when the field exploded. But that's, it's, yeah, if you're not dealing with sorts, you know, how do the rules of how a neurons activity evolves based on the input it receives,
or inhibitory from other neurons, how does that lead to this behavior, which is more than the behavior that you can get from any one neuron?
It's those kind of questions that where you really can't do it without math.
I think there's a lot in this question of what does it mean in the mental health field to be right or wrong? Because I think that is a place that there's some vulnerability.
One can say, what does it mean to be right or wrong about the ways of a person with psychosis or person with depression functions?
And I think that part is part of why I like George Boxes so much because I don't know that we are at the stage now where we can, we can, we have ways of measuring right or wrong.
We have ways of measuring useful or not useful though. And I think that one of the things the mathematical models do in our field is generate new ideas, generate new hypotheses that I think is one of you were saying, one wouldn't have already, one wouldn't have already just immediately concluded
that emerged from the model, and then you try it. And sometimes it leads to something useful and sometimes it doesn't. And what has to be willing to go down that path even with an absence of certainty?
Yeah, but that's what makes the models right or wrong is that they do make different dissociable predictions. You can't test them yes or no, right?
So I think we can distinguish that that good modeling in neuroscience or behavior is kind of goal oriented.
We're trying to explain a certain phenomenon. We're trying to make some actual testable predictions. And so that's in contrast to, I think, two approaches, right? One would be trying to say, well, I want to build a correct model.
I want as much detail as I can in there and have a complete model, right? And I think the point is that that's a, you know, some of a futile effort and not actually a good path to generating understanding or advancing, you know, what kind of experiments, what we should measure, et cetera.
And that's on one end. And the other is on being kind of too abstract, too much of a toy problem, which, you know, some people from physics and mathematics have a tendency toward.
But then there ends up being a gap between you have a toy model. You can study some interesting properties. But there's a real gap between how you can connect to that to experiment and to real data.
And so I think there are kind of two ends that you can fall off the edge in terms of being useful for modeling.
I mean, just in clinical example, so clinical example, what you're saying in terms of how some of these models actually being clinically applied.
So because of where we're located, we had a huge 9-11 population of firemen and cops after 9-11. And I was in the Toronto section in those years.
And, you know, we had a lot of, I mean, there are validated treatments for PTSD, and we always use those kinds of things.
But what I found was that, you know, one of the things that drove the firemen I was treating completely crazy, because they're straightforward ration, they're straightforward, sort of very straightforward people.
The firemen are very straightforward people. They're not very introspective. They really bothered them that they knew that getting into an elevator was safe, and they also knew they couldn't get into an elevator.
And it was ruining their lives. They lost their jobs over this. And I found you simply take a reward learning model, right?
And I said, let me explain to you how this works. Your brain works in a reward learning model, and you've had this one shot, very negative learning thing, in which getting into an elevator is that it's working in your amygdala.
It's not working in your frontal cortex. So talking about it's not going to change. It only behavior is going to change it.
And giving them that model, giving them that reward learning model really changed things. So it made them feel less crazy.
It made them feel hopeful, and it made a huge difference. That was your idea.
I just want to make one quick, certainly clarifying comment. I hope it's clarifying anyway. Larry and Ken both refer to the idea that mathematics, once you engage in the mathematical model, you sort of committed yourself to the consequences of the mathematics of it.
And I think there could be this misunderstanding. That means that mathematics is rigidly inflexible. And therefore risks being reductionistic and missing something.
And Andrew said something very interesting, I think, about real mathematicians in the real world, or any way, in applied mathematics, where the whole idea is, okay, if there's a remainder, if there's a false, I'm calling it a remainder.
If there's a false outcome, or an hypothesis that's been disproved, put it back in a hopper. Let's use it and build another model based on that.
And that is a way to keep the mathematics from falling into being excessively rigid. Okay. But having said that, I want to ask the following question.
So there's a lot of talk about whether or not computers, whether the brain is a computer. Okay. I want to ask something slightly broader. Of course, let's go to overlap with that question. Is the brain mathematical?
Of course. This whole discussion about mathematical models. What is the difference between a mathematical model and a careful explanation?
Okay. Careful explanations don't go into equations which could be manipulated to give you other consequences. Why not?
Well, that'll become mathematical. Then it becomes mathematical. So there are beatable. So my argument back to you would be to say, at the point where it's exact enough, and exact enough, I would say has two properties.
One is all the variables that you're referring to are measurable things in the universe, agreed measurable things in the universe, and the relationship that they have with each other in the universe corresponds to the relationship that they have in your model, whether it's a verbal model or an equation model, right? So that there's a correspondence.
But if you've got a verbal model that has those two qualities, it's a mathematical model.
I mean, Newton's three laws are written in words. But I'm with you in the sense that I think the word math gets used for a funny purpose here.
It's used as to sort of sit in him for thinking carefully, and that gets very confusing.
I think you have to define what one means when one's having this debate.
I think the times you think you're thinking carefully, and then when someone forces you, I mean, this is sort of when you do an applied math course, right? So you say, oh, I think I have a good model.
And then when you try to put it down in a mathematical way, mathematics, I think the formalism, I'm not disagreeing with you, but I'm saying the formalism of mathematics does force you to make sure that you can probably do that over.
So I do. So I do. I'm an empiricist, right? I do science. I don't do modeling.
To me, what seems like the difference is that when you have a computational or mathematical model, you can look at latent variables that are not evident to the person doing empirical work.
And that seems to me to be the difference.
You could argue second analysis was doing that from the beginning without using math, but was often not doing it in a very precise way.
I wasn't even thinking of psychoanalysis as that sort of adds to it, but I think within sort of research, you know, I use statistics.
You can use very advanced statistics, but to model, you have to, it seems to me you're looking for latent relationships and variables that necessarily are.
Well, that's one thing is that you look for, you know, a much lower dimensional set of variables that explain some high dimensional data, but another is that you're just looking more like a dynamical system.
Understanding how the dynamics of the interactions lead to certain results in this. I wouldn't call that latent variable. That's sort of just a different thing.
That makes sense.
Let me ask the question a different way because I got such a smackdown for the last time.
No, no, no, no. There are things about the way the mind or people that have to be just for the brain cannot be accessed through math.
That's a different way to ask the, I think, the same question.
So here's an example.
So I don't know if everyone is familiar with the recent advances in artificial intelligence to what's called deep nets.
But these are very, very, very loosely modeled on neurons, what they call neural networks.
And by being deep, you just mean you have layers and layers of them. So this one was predicted. This one was predicted. This one was predicted. This one.
And that program has been going on for a long time. And it almost died. There were a few hardy souls who kept it alive through a period when most of the field didn't believe in it.
And then they had a spectacular breakthrough about six years ago, seven years ago.
Now it's completely taken over every field of artificial intelligence. So Jeff Hinton, who was really one of a few leaders, but to my mind, the leader in the field through all those years, brilliant guy.
And he's the one, actually his group made the breakthrough that broke everything open in 2012. But he was asked, so there's a big question with the deep nets, which is that they have like a billion parameters,
a billion synaptic weights that have to be learned from by just knowing for every input what output you want. And then you have an algorithm to make to learn those billion parameters to make this input produce that output.
And he was so there's a big problem is there are black box. We want to know what they're doing. We want to know how they decide that this is a car and this is a German Shepherd.
And we don't. It's just a black box, but it works really well. And so somebody was asking Jeff, you know, are we going to be able to understand these things? And he said, no, he said, these involve a billion parameters.
If it was reducible to some nice simple operation, the problem would have been solved a long time ago. People tried to solve it by using nice simple operations. They didn't get anywhere.
And so that's an example of a level at which, no, you can't reduce it to any nice math. I mean, it is mathematics. You know, there's a mathematical set of equations that are these deep nets, but we can't.
It's not understandable mathematics. It's understandable at the level of what you're trying to optimize and what your learning rules are, but not what it's doing when you present an input at the bottom and the works is way to the top. That part doesn't seem to be understandable.
That's a key thing. I see using that example, as I said, some of the parts of that are understandable, right? The learning rule is, you know, one equation, the loss function.
What is it trying to optimize? And so, in one sense, it's a very simple description of what goes into the model. But again, you're training the seep network to classify, you know, visual images.
And so all of the complexity of the visual world of all of those images is being, you know, parsed and extracted, and that goes into those billion parameters.
And so in some sense, the model has to be complex because it's processing complex data, and that goes into the parameters.
And so in some sense, you know, we understand something about those models. What are they doing? But the final solution is very complex.
And I think a lot of neuroscience will be the same way, right? But it's not even so different from physics, right? We understand, you know, Newton's laws, but, you know, we can't predict the weather, right?
We can't predict the hurricane. There's, you know, but we still think the same basic fundamental interactions are there.
But it's a level of complexity that we're never going to understand on the same intuitive level as, you know, in a simple, inelastic collision of two particles.
And so in the same way in neuroscience and psychology, we often will build kind of, you know, simplified models, where we want to understand some principles.
And then, as you're saying, it goes back to metaphor, but often our metaphors are from, you know, simple models are very constrained behaviors that we can model, that we can study, that we can, you know, look at in humans, in animals, et cetera.
And then there's this process of extrapolation and metaphor to the kind of full richness of human behavior.
Yeah, I think a clarification, and if we were actually worried about this coming into this talk, is the clarification is that, and I always worry about the term computational psychiatry.
I used to call it mathematical when I started doing it, because what I was doing was model it, right? Model a model, a math model of behavior.
But computational psychiatry encompasses two things that are actually at the polar opposite, one in which you have specific models, like a specific reward learning model for the way a mouse is going to behave in a maze.
And you have very specific models. But then you have these computational things, which are absolutely black boxes.
So it encompasses both these things in which not only are there no mathematical models for the beginning to end thing, it's not even possible.
It will never be possible as you point out, because deep networks will never be reducible.
That's why they work.
It seems to me that the subtlety you're talking about though between a substantial levels of complexity and how much you can simplify these models is different than what the
people mean about it mathematical or not.
From that question, at least the way I understood your question, it's all mathematical.
Yes, how many parameters you have, yes, to what extent is it computational versus solvable into a simple equation?
That's different.
But I heard your question and tell me, as being more connected to the question of are we dualists or not?
Because true dualism, and Larry and I have had this debate just recently, to my mind suggests that there is an aspect of the universe,
that does not obey these same laws, that is not, quote unquote, reducible to the sort of principles by which we use.
Now, I am not a dualist.
I'm not a dualist.
So I may be misrepresenting.
But if you don't believe in dualism, if you really believe in monism, that there's one universe and there's one set of principles that governs it, then it's hard for me,
then I don't think that there's anything that isn't at some point amenable to the use of math.
I agree with that.
Are you serious?
Yep, okay.
To me, I don't know anything about philosophy, but to me it seems very obvious that I feel a certain way being a conscious thing.
I don't think that if you make the assumption that consciousness is some emergent property of a complex system, it seems plausible.
I don't think mathematics, as it currently stands, has any foothold on that question.
There's no language that mathematicians have access to today that can begin to untangle why it is that I feel the way that I do about anything.
I mean, and just to answer me to push this analogy a little bit further, if you assume that we're conscious to whatever degree, another similar complicated systems that somehow perpetuate themselves are also conscious, maybe bacteria or sharks or dogs or
cities or the esthetic change, if there's consciousness in these large complicated systems, I have no idea how to address it.
I don't think any mathematician, I don't think math, if you say careful thinking will eventually understand things, sure, but if you look at the current set of tools that mathematicians have access to, no way.
Actually, I think I agree with both of you.
I mean, what you're saying is basically, look, it's a physical system that obeys the laws of physics, and in that sense, you can describe it in principle with those laws.
You can't in practice because it's too complicated, but you can describe bits and pieces of it, but it is a physical system that operates according to some actual laws and isn't just doing whatever it feels like.
It's just doing whatever it feels like doing it in a moment, but there are properties that emerge from that system that are very hard to describe.
When a physicist describes the properties of water and why it's wet, in terms of the atoms in the water, you can derive from statistical physics, the attributes that you can recognize as how wet things behave.
So there you can actually see the emergence. Consciousness?
I tend to think that why material things have a subjective experience is not a scientifically addressable question to why, but the what, which material things end up creating subjective experience with the correlation between the material things and the subjective experience?
I think we'll be able to, in principle, describe that perfectly.
So why isn't it a zombie? Why doesn't it have subjective experience? I think that's not a scientific question. I don't know how science could possibly address that.
So Andrew and I have had this ongoing, and I would say I'm a dualist all the way down, which is to say the turtles all the way down, which is to say I don't think you have to...
I agree with your argument, but I don't think I need human consciousness to do it. I think if you simply look at a single cell protozoan that if you put it in a petri dish, it will swim up the sugar gradient.
So that protozoan swims up the sugar gradient. I can describe the mathematics of the turning of its tail and how it turns, and I can probably get a perfectly good description of how that does.
But that will never replace the description that the protozoan, that creature is swimming towards the sugar.
So the mathematical description will never replace the intuition and the description of what's going on.
And I think those are the two levels, and I think that's exactly what you're saying. So it's not even only the human being consciousness level.
I don't think science can ever, I don't think mathematical things can ever, they can explain the mechanism of it, but you lose something when you move away from the thing of, oh what's going on? Oh, it's swimming towards the sugar.
Well, I'm going to put it in, you can build a mathematical model. But you argue missing something as in a description of observing this, if you leave out the idea that it's swimming up a gradient, and that swimming up a gradient wouldn't be in the mathematics.
Sure, it could be. You're missing something in every model, it depends what the questions are, but you can model those behaviors.
This is what mathematical psychology does, right? You're trying to explain the pattern of behavior in relationship to the stimuli, and you have real kind of, you know, they're truly mechanistic.
They're generative models, but if psychological processes is not of neurons, right? And those are perfectly good quantitative mathematical models meant to address, you know, kind of, again, the level of behavior in relationship to a stimuli or learning, right?
And that's, again, bridging those two levels of analysis, and then there's the challenge, not how does a model connect to different levels?
How do we connect to different modeling levels of analysis, the models of the level of circuits versus models of the level of circuits?
This is an incredible, I think this debate is incredibly clinically relevant, because back to your original scenario, the typical occurrence is a patient comes to see me or one of us and says, I'm having a subjective experience, a deeply subjective, a conscious experience
that I don't understand, or they say that is upsetting to them in some ways, whether they're anxious or they're angry or they're sad. And there's a question on the table as to whether any kind of analytic, not in the psychoanalytic way, but any kind of mathematical or analytic thinking has any value.
Maybe there's nothing I can offer that, that's one hypothesis, that patient, because what they are coming to me with is so intrinsically subjective and doesn't follow any standard set of rules that no amount of experience I have could ever really impact.
I don't believe that. I believe that using my experience, using the models that I have about why some people get sad, why some people get angry, why some people get anxious, actually has a value for them, not just in a kind of, oh, let me tell you a nice story, and therefore you'll feel better.
But rather in that you'll learn something about your subjective experience that is going to be useful to you. And so that's to me why there's a bridge between those two.
Now are there aspects of subjective experience we don't understand yet? Absolutely. Most don't understand. But some of it we understand in small ways.
And I think that's proven to be very useful. And I think that's going to continue to grow.
So this is why in clinical psychiatric research, there's such a push to go beyond kind of subjective evaluation toward actual quantitative behaviors.
Can we relate subjective experiences of anhedonia to the parameters of sensitivity to reward and punishment in a reinforcement learning model that we can actually set?
Can we relate delusions in schizophrenia? Can we encapsulate that in a more quantitative mathematical formalism of Bayesian inference and how we bring prior information in combination with sensory evidence?
And if we can do that, then we have, it's still that metaphor that jump between the simple computation and the full subjective experience.
And that gives us, I think, a foothold in terms of bridging these levels of analyses, which ultimately we need to, in psychiatry, if we're going to talk about how pharmacology can affect brain circuits and ultimately alleviate symptoms.
So if I were to go head to head with your model and evaluating people for delusions, I would win. Sure. So what am I doing that is not in your model?
The interesting thing there is that neural networks are starting to get better at humans at a lot of jobs like that.
Like what? Radiology.
Well, no, no way.
Just go.
Tell me in psychiatry.
Okay.
How about what they need right now to work is they need a huge training database, but if you had a training database of the conclusions you want to reach and the information that goes into it, and you had a lot of that, a machine might learn to do it better than you.
So when I, and all of you, look at a people, look at somebody and their facial expression, you do instantaneous calculation that's better than any computer.
So far.
No, they're not too learning to do that, but they don't, you wouldn't know if that's a good label.
I'm not talking about identity.
No, I know. They're learning recognizing motions too, but they're not as good at it yet.
But, but there are all sorts of nuances. And, and then in terms of context, I mean, computationally, we are very complex.
We are, but we're starting to build machines that are equally complex.
And also, I would point out that, that by virtue of evolution, you've had a training, you have been exposed to training sets, right? Over a billion years, right?
And a billion years of training sets have selected you to be the best facial recognizer, right?
And the people who are not as good facial recognizers.
No, no, no.
So evolution has been a training set over a billion years. We sometimes discount that, that, you know.
No, but evolution has acted on the genes, right?
Right.
That has selected for the genes that can lead to those computational ability.
You know, I'm not Lamarckian, even though, you know, you could do gene epigenetics, right? It's a little bit Lamarckian, that's right.
But I have had several years of pattern recognition, but that even really thinking about it, and I'm awfully good at it.
And I, I...
But that is a huge training data set of, from birth, in an interactive way, a closed loop interaction with the environment.
So, will we be replaced?
Will clinicians be replaced by psychiatrists?
Maybe by computers?
The only things we really know how to do neural networks right now are when we have a huge database of input to output,
then that we can get the machines to learn it, sometimes better than us.
No, no, no, no.
But what it shows is...
You learn wrong.
Excuse me?
These neural networks have never learned the damn thing.
They're trained to perform a classification task. They're not learning anything.
Well, it depends. What's your definition of learning?
They have no values.
This goes to the Chinese room market.
Yeah.
I want to make sure...
Well, I just wanted to finish that.
The point is that some things that we think of as our unique human complex intelligence are starting to be done by machines better than us,
like PlanGo, like PlanGIS, and like some kinds of recognition of objects and so forth.
And I'm not saying that it'll all be replaced.
I'm just trying to say that there's not obvious that there's something in us that is so special that we can't someday get machines to do it better.
I agree.
I agree.
It's a question.
And it also shows how morally complicated this is.
So I think you would agree, you would agree too, Larry, that one of the things that we wish we were better at,
is clinicians predicting who will commit suicide.
That we do our best, and when we work in the emergency room or work on the inpatient unit,
we make those decisions all the time as to who to keep involuntarily and who not to,
and not infrequently, we get strong.
So let me finish the story.
I have a friend who works at Google.
He says that it is kind of an openly known at Google that there are algorithms that they can apply that enable them to predict
who's going to kill themselves to a frighteningly precise degree.
The problem, they have enormous data sets, they have enormous access to data that we have clinicians do not.
And then the question becomes, does Google want to admit that they know that or not?
Facebook's now started to admit that, and doing little things here and there, is it enough?
I'm not sure.
But what do we as a society do?
And the danger to me of too much prioritizing of the clinical superiority would be that we might not take advantage of some of these other data sources
that could help us save a lot.
So I don't want to pit myself against computers.
I meant that to be provocative.
I've done research in this area, right?
So I've done research that shows, again in collaboration with Guillermo, that IBM wants it when it looks at language patterns
and individuals at risk for psychosis, of whom 20% develop psychosis in two years does better than me.
I mean, I've published that.
In terms of suicide, I'm sure Google has much more than what's in the literature, because they have a lot of resources.
But in the literature, there is a good literature that if you look at language, and it's across, it's people texting, talking, all kinds of things.
I reviewed this for a grant that I put in, and Guillermo did an article actually looking at poems, poets who committed suicide
and those who didn't, and looked at the actual language in their poems as to what we predict.
Consistently across the board, it's using words that have semantic content that has similarity with hopelessness and depression.
So, no, these are tools.
I mean, I don't want to put all of us out of a job.
But I just brought that up in a sort of provocative way in terms of the models, because we're also models, right?
Doing computations, we don't understand our own computations, but...
Okay, Adi, I'm curious if you could expand on your idea about learning and why neural nets don't learn?
So, even these words, I feel learning, training, etc.
Even those are very loaded.
As you said before, these deep neural nets are complicated functions with many parameters, hyperparameters, even if you take into account the network architecture.
And there are objective functions that are set up, which are minimized to fit the parameters of that function,
so that at the end, the function has certain specific input-output properties.
Okay.
It's tempting to take a look at the go.
What is this called?
What was the go thing?
Alpha go.
Alpha go.
Or deep blue, and say, wow, it knows how to play chess.
It knows how to play go.
It's a giant lookup table that has been...
Those are constrained.
That has been pruned and refined over many, many iterations, given lots of data.
If you sat Alpha go down on the table opposite of whoever the gentleman was that Alpha go was playing, and you said, okay, guys, new rule.
If you head off the left side of the board, you come on the right side of the board.
You're playing on a cylinder now, or a torus.
Alpha go wouldn't even be able to take the first move.
Its database would be inapplicable.
You sit down, Gary Kasparov, against deep blue, and you say, okay, guys, new rule.
The queen, by the way, it's no longer a queen.
It's like a rook in a bishop.
I'm sorry, a rook in a knight.
It's like a rook in a knight, but it doesn't move like a bishop anymore.
Okay?
Gary Kasparov would still kick my ass, but deep blue wouldn't be able to do anything.
I'm not saying that there won't come a time where the types of functions and the types of parameters that people are able to bake into these neural networks are sophisticated enough that maybe there are some parameters that can be left to be tuned on the fly after the machine sits down and sees the button.
Right now, we're definitely inapplicable.
I'm not there.
This issue is actually in a philosophical issue.
This is philosophical debate about something called the Chinese room problem.
I don't want to get into it, but it's exactly the day as to whether it's something in...
Why not?
Why not?
Why is it?
It's not?
It's not.
It's Johnson.
Look at the describing pre-cream.
The argument is if I have someone in a room who has walled this right, you know the argument right here, and he has all of these dictionaries, Chinese English dictionaries in the room.
And if I give him a sentence written in English, he can translate, right?
He can then look everything up and he can respond properly in Chinese.
Yet, there's nobody who knows Chinese.
So that's the Chinese room argument.
There's nobody who knows Chinese.
But he can't.
And the two sides of the argument are one side says that proves what your point is that the machine doesn't know anything.
And the other side of the argument says no, the entire system knows Chinese.
And that's what we mean by knowing Chinese.
No, no, no.
It applies to the Chinese room because if you, it's apocryphal, right?
All those stories about like the spirit, the flesh is weak, but the spirit is strong, right?
Going into Russian and then being back translated as the meat is rotten and the alcohol is bad, right?
So it doesn't work that way with language.
So whatever he came up with, without knowing, when you put a person in there, they have a face.
And in there, they have a flexibility that the sort of...
In the Chinese room argument, the person is really acting just completely in the middle of the person.
No, no, no, no.
But then you're getting into a strictly rule-based language.
If you believe in Chomsky's sort of hierarchy, now you're at the bottom.
And Chomsky would say for like a human, sophisticated grammar, you need it.
You can't, it has to be probabilistic.
It can be rule-based.
You can build all those things.
But it's complicated.
And that's the Turing test.
The Chinese remiss the Turing test.
The Chinese room problem captures, tries to capture this difference between what do we mean,
what is our intuition when we say somebody knows something or somebody has learned something,
and it challenges that thing, and it challenges, as you did this question of whether we're going to...
That's the purpose of the argument, is to challenge the use of that meaning.
Just want to make one other point that I run into whenever I try to talk about.
The other thing is that we all have folk science in addition to a formal science.
There's folk philosophy that cultures have folk philosophy.
We have folk chemistry and things like that.
And they're not very good.
I mean, people have survived before formal science came in because they had these theories.
But folk psychology is really quite good.
Right?
Pre-scientific psychology is actually much better.
We're pretty good psychologists just intuitively.
We have to be.
Right?
We've evolved to be pretty good psychologists.
And I think that is one of the reasons a lot of these things get confused is because folks' psychology is so good.
Right?
It is hard for scientific psychology to sometimes compete, and there's a much more sophisticated language within folk psychology
than there is, for example, in folk physics or in folk notions of mathematics.
And that gets in the way.
I want to just respond briefly to Audie.
I agree with your criticism that they have a limited range.
And if you change the rules on them, they haven't been taught to adapt.
But it's not to say that they couldn't be taught to adapt.
But the other thing is that I don't think it's right to say they're a lookup table.
Because AlphaGo, well, on any given game, you can't see a board position that no human has ever seen before
and that the machine has never seen before, and it'll still outplay Lisa doll.
Because it's learned somehow implicit in its brilliant parameters.
It's learned some principles of how to play Go.
That it can deal with entirely new situations and outplay any human.
And the same with Alpha Chess or whatever they call it.
AlphaZero.
AlphaZero.
Yeah.
So I don't think it's right.
I think Deep Blue was basically a lookup table, but I think these new things are not.
So they're probabilistic now.
No, but the point is that it really understands some principles in a way that, I mean, Deep Blue just did a deep search
and said, you know, if I look ahead, 10 moves, if I do this, am I going to be better off or worse off?
And it didn't know anything really.
What it knew to evaluate better off or worse off was really simple, but it had this powerful ability to search.
But that's not what these new things are doing.
They don't search nearly so deeply.
They learn principles that they can then outplay any human.
But this principle, the philosophical pushback to you would be when you say it understands, right?
Well, I didn't say it understand.
And the haves as it understands.
I said they're principles built into these billion parameters that can now outplay any human.
But this principle is, I understand we also kind of, you know, consults.
It's observing a pattern and then getting some kind of value function or if it's going to play here or not there.
Not necessarily, you know, rule-based or a particular ball, or a particular ball.
I can't even articulate it.
You know, decisions, but basically kind of, it's a form of pattern recognition.
But, you know, that also underlies a lot of our cognition, the way we recognize emotions, the way, you know, probably a good chess player can just kind of get a flash of the chessboard and get a sense of, is this a good game to play or not?
This a good move or not?
In that kind of intuitive way, a lot of our cognition, we can't necessarily explain.
So they're mathematical models for Gestalt, that kind of Gestalt perception that we're also good at as people.
I mean, I would say a lot of the visual recognition.
The same way that people use, you know, deep networks for this.
You know, we can argue about whether it's kind of training or learning by the same rules.
But, you know, as a metaphor of the general principle of, you know, how does our eventual visual system work for object recognition of it being kind of successive, you know, layers of feed forward problems?
And, you know, layers of feed forward processing with some kind of flexible learning such that the representations at the intermediate layers of your vision, you know, are guided by the final, you know, output recognition and decision in action is, you know, I think where you would say that
model is in some sense a good model of human vision.
So do we already have our own neural net for identification?
I think it's only still a very impoverished analogy to what we do.
But already just with that impoverished analogy, it can outdo us on some test.
We do fairly complex thinking without realizing in advance they know how to do it.
So you could consider that analogy to what some of these computers are doing, perhaps.
Yeah, but you can also bring these back into cognitive neuroscience, right?
So these deep networks, not only do they, you know, do object recognition, it seems like they do it in a similar way as us.
You know, recording from single neurons and monkeys, we can do functional MRI in humans, and we can look at what kind of neural representations that are in, say, different layers in visual processing and compare that to the different layers of processing in these deep networks.
And there are correspondences.
And so, you know, it's considered there, they're trained in impoverished way.
They're not lacking some things.
But where we can actually try to check the actual internal mechanisms, they seem to have some validity in terms of explaining not only our behavior, but even how the brain works, our representation.
I think I would definitely agree that there is some analogy between what we're doing and what strategies are used to make these deep neural networks.
That's true.
But I also agree that it is impoverished and not.
But to Jerry's point about our doing computations that we don't know, I mean, as anybody who has the experience of these phony rocks that are really very light, but they think, you know, you look at the, it looks like a rock, but it's actually foam.
And when you try to pick that up, you completely miss, right, you completely miss the motoric thing.
Because we take absolutely for granted that the incredible computation that goes into a simple motor thing of lifting something up and putting the right pressure on it, and I can fool you by giving you a mis-estimation of what the weight of the thing is.
But so we're doing incredibly complex computations, right, just for that simple motor action.
We have to plan it very carefully, and we have to know what it's doing otherwise.
To give credit for credits too, I think that's one of the early contributions to Psychone else.
Because I think for a motor, the Psychone else is not on motor movement, but to acknowledge the complexity of these models outside of awareness.
Because I think that's the literature that was early literature on what was outside of awareness was that it had to be incredibly simple.
And that more complex processes therefore had to be conscious.
And we now know, and I don't even think it's controversial in the cognitive neuroscience world, that the kinds of processing that can go on completely outside of awareness can be enormously complex.
And this was something that Freud was talking about, you know, hundred more years ago.
And that example highlights one of those key computations is prediction, right?
And so that actually gives us a hugely rich data set, because we're not just, you know, training the human brain on, you know, discrete supervised learning, right, but on predicting the future.
What are the properties of things in the service of predicting how I will interact with them, how they will move in the future, etc.
So, this is a characteristic of various things.
Questions later.
No questions later.
No, no.
No, no.
No, no.
Later.
Later.
Later.
Later.
The, um.
You speak well with the same team about the computation, computation.
Sir, please have a seat.
We have an opportunity later to speak.
Okay.
Thank you.
Larry mentioned earlier that, you know, in mathematical models, we have these variables that are all well defined, in which we can then check on, or be aware of.
And the interesting thing is that when there are all these hidden units, and in some forms of mathematics as well, you can only say that theoretically they can be checked on.
Theoretically what?
Theoretically they can be.
They are possibly accessible to being, you know, accessed.
But in fact, in the process of doing the computation, some of those things are just, they're, they're, x's and y's.
They're not really specified.
I mean, I guess I may need a distinction.
I'm not good at that.
Okay.
Neither.
Okay.
Thank you.
No, I think you're not allowed to.
I think you're a point about it in the deep neural net, and you may understand individual weights, but you don't actually understand how the process is leading to the proper outcome.
So that is it.
Absolutely.
There's an intuition in the black box.
That's a camera for it that is a black box.
There's an intuition we have about what it means to really learn something that I think does involve our knowing the steps quite well, and then having an intuition that we know those steps.
That's what we call, I'll say, for the purpose of this comment.
That's learning.
But when we don't know how those steps are when they're invisible and they're being manipulated all the while, we then have this thought, well, maybe we don't know.
That's how we might be able to do things unconsciously.
Because we're not aware of all the variables being affected.
But I think that sense that we know what we're doing is an illusion.
Because when we've, when, I mean, artificial intelligence for many years until the deep net revolution about six or seven years ago was focused on trying to do things by writing down the rules.
Trying to do vision by writing down the rules, trying to play chess or go by writing down the rules, and it failed miserably.
Because we don't know the rules.
The rules, and actually to go to Jeff Hinton's point, you can't reduce it to the rules.
It's a way more complicated thing than that.
I was trying to capture why we might have an intuition of how learning is different from what computers do.
So whether or not it's good, at it or it's accurate, that may be what gives us the feeling, whether intuition that we've learned something, as opposed to just following the recipe.
Well, I think I learned something when I can teach somebody else.
I don't know if there's an analogy for these nets.
Maybe they have some consciousness, maybe they can feel they can teach other nets.
Well, I can make a bad analogy, which is that the people can take a neural net that's learned to do something, and then they can teach another simpler net to do it.
It can teach something else to do it more compactly.
Teach it in the sense of being the one who tells it what the right answer is.
So people do use one net to teach another in very simple ways right now.
I think that goes in the next one.
I don't really interact with it.
It's just the input out.
It's not what we call teaching.
It's not what we call teaching.
Maybe something like that.
I think that's what I was trying to get at when I talked about the folks' psychological language, is to say that we have this whole language that is that we have evolved that we have evolved into the world.
And it's about ourselves, understanding ourselves and understanding others, our folk psychology.
And then we have these words and then we apply these words, and then those words have very specific human meanings.
So I think you're right there.
When we say learn, we've got to be careful.
We should have two words, right?
We shouldn't say a machine learns.
Because learn has a very specific meaning.
It has a very specific humanistic meaning.
It has to do with experience and it has to do with feeling.
And so I think that we apply the word incorrectly because we take folk psychology, which was developed for human beings, and we apply to machines and those kinds of things.
And we don't have other words.
But we really should have other words.
We do qualify.
There's reinforcement learning and unsupervised learning and supervised learning.
There's different ways that we learn and again, reinforcement learning, like you said, may engage the amygdala in an unconscious way, which may be different than supervised training as well as just kind of general experience or prediction, which may be your less conscious.
It is interesting to me how many conversations, I think, can evolve into arguments around the semantics in exactly the way you're describing between the folk psychological use of a term which people didn't want to defend in a certain way.
And then the other uses which may be narrower, broader, but are carefully defined.
And I think ultimately, since we're not going to discourage people from using those words, you just have to get people to define them when they're using them because people use the same words in different ways.
We can second announce this as had this problem for a long, long time, which is we all talk about transference.
We all talk about libido and we can have very long conversations meaning entirely different things with the same word that then often can be unproductive.
Cheryl mentioned the Turing test, which was the definition of intelligence, right?
So that was a debate, you know, 40 years ago on debates on what does it mean to be intelligent?
And they tried to define that.
The Turing test is, I think, is alive and well.
Say that again?
The Turing test.
The idea of the Turing test, I think, is alive and well.
How alive?
Maybe you should tell people what it is.
Yeah, please.
Oh.
So Alan Turing said that had a test that for artificial intelligence that if a computer could pass as human in conversation with another, with a human, it will have passed the Turing test.
So, you know, you could think chatbots.
They can, as a simulation, for a limited amount of time, seem almost human.
But if you really push, we don't have any machines yet that really pass the test.
My mom, I think my father could pass the Turing test.
Now?
If I talk to your father, I wouldn't think he was human.
If you communicate with him via text or email, I think he would think he was a chatbot.
He might.
So, no, no, but the chatbot is not part of the Turing test.
The Turing test was before chatbots existed.
What I'm saying is a chatbot is getting close in some circumstances to appearing human.
I see.
No one has, where does the status of that?
No machine has passed the Turing test.
No, I don't think so.
I think there was one chatbot which kind of passed by acting as if it were a child who's a non-native English speaker.
Yeah, a load of art.
I think there's a time I have to announce.
I'm actually a robot.
I think we're going to stop now, though it's been such a wonderful and lively conversation and invite people to ask questions.
Why don't you come up to the microphone?
I just assumed everyone's a Turing test.
And please, if you want to see the movie, questions and comments to be kept on the brief side, please.
All right.
Thank you for this engaging and live discussion.
It's interesting because when you were talking about applying mathematical models to psychological states, let's say,
it seemed as though you were mainly talking about behavior, decision making, and action.
And so I could see how models of probability could determine, you know, could be used to determine particular outcomes.
And so the same thing when you were talking about the computer's playing chess, right?
That's how do they make decisions?
How do they act?
How do they behave? What information do they have access to?
But what about mathematical models applied to, let's say, experience?
How one experiences or to consciousness in general?
That seems to be a little bit different than the direction you were heading.
It's like art, humor.
Yeah.
How one experiences art or what creation is, mathematics?
Aesthetics.
Yeah, exactly.
But even experience states, right?
How do I know what I experience and what do I experience?
And is that something that can be described mathematically given you have enough information and data, let's say?
I think right now we couldn't say anything about the in principle when we have, you know, way more ability to watch what's going on in brains.
And to, you know, at some point we're going to be, as I said before, at some point we're going to be able to say these kinds of neural patterns of activity reach consciousness and, you know, lead to this feeling or this or this experience.
And these other kinds of neural activity don't go to consciousness.
But, you know, why they have conscious experience?
I don't know what we'll be able to make a nice morphism between, you know, the behavior of the neurons and what different things feel like.
But that's way far in the sense of future.
We couldn't even touch that now.
I would say that the why question, depending on how you define it, sure, I can see that being far in the future, what I don't think is far in the future is models that are relevant to affective experience.
And, you know, Cheryl's work is one example of that. But there's many other examples now of various relatively simple models that look at the sort of dynamics of various affective states and why one reacts to certain ways to different things and the correspondence of that between, you know, facial expressions and behaviors and so on.
But that's a model of, I agree with you, but that's a model of different level. I guess what I was addressing was the neurons. Can we talk about feelings? No, that's way far in future.
But that's also, when you're discussing modeling affective states, that's also what gives rise to the affective state or the behavior of the affective state, but not the experience of the affective state.
I was drawing this distinction with the why. I think one can always carve out a realm of the why that we don't have access to, but I think that's shrinking.
I mean, the example I'll give of that is I had a classmate, Natalie Training, who remained famous, who we used to have this debate about whether there was possible or worthwhile to measure anything in the psychoanalytic process.
And so he told me that his definition of psychoanalysis was that which I could never measure. So by that definition, as I got better in measuring things, his diagnosis got smaller and smaller.
He was okay with that definition, but I guess what I would argue is that, sure, one can always carve out a why that is inaccessible, but I think it's relevant to the why, the more and more we know about the dynamics of these affective states.
Or the what, actually.
Yeah, well, but philosophers talk about the heart problem. I think that remains obviously an open question.
I don't know whether that's a scientific question or remains forever a philosophical question as to how you can bridge between mechanism and experience.
I think that the heart problem is a heart problem for a good reason.
I guess it's an empirical point as to whether we'll ever be able to bridge that. I'm betting no.
But we'll see.
Can I just go back to an example you said earlier just to see where we stand on things. Let's take your protozoa in the dish going up the chemical gradient.
As Larry pointed out, you can have a, sorry, Ken, sorry.
Ken pointed out, you can, I called you Ken earlier though.
You did.
I'm two for three.
But, but, but, but, I just can point out earlier, you can, you can write a complicated differential equation that has every atom, neuron, whatever in that worm.
And your model will climb up the chemical gradient.
And you can point to every little bit in your model and explain in a particular way why that thing is climbing the chemical gradient.
But would you ever understand how it feels?
I don't think it feels any feels.
How it experiences climbing up the chemical gradient.
And you say, no.
That's what you say.
Well, I will say no, and I will say that there are different languages because by the way, when you say that something's climbing up a chemical gradient, you're giving a teleological explanation, right?
You're explaining, right?
You're explaining something by the end, right?
And classic Aristotelian, teleological model, which is not a scientific model.
You can't describe something that you can't postulate a cause that happens later, right?
That it's climbing up the thing in order to get sugar.
That's a reason and can never be a mechanism.
I mean philosophically.
But you can certainly build a model of things that follow gradients and how they behave.
And you can model it at that level.
But what I describe it, when I describe it, it's doing this for this purpose.
I've gone.
It can still be mechanistic.
So as internal states about the past histories, you can tell whether you're increasing or decreasing the gradient.
And so even in this case, for subjective, affective states, people have done things within, again, the limited context of sequential learning and decision making and understanding.
And so, when you're learning and decision making and reward, you can even say, how does your affective rating of happiness correlate with rewards and reward prediction errors, right?
With humor, I think there is some work on seeing in simplified settings, can we show how humor relates to violations of predictions of expectations a little bit?
It's really pretty inadequate.
But what if instead of a program, it's just not going to speak to the subjective experience.
But what are the kind of computations, right, at the level of inputs and outputs?
That's right.
You can relate these things to actual computations that guide behavior in a mathematical way, I would say.
For humor, you can find some rules.
But then to try to create humor using those rules is where it hits the story.
There's a catastrophe where he modeled humor, which actually works pretty well.
There's a disruption in fact that the theory is a while, in the argument, where pettiliology, and I think that is something that humans, we have reasons for doing things that so far have not been built into sort of computational models.
Oh, no, no, you can model that, absolutely.
You can model agents that have goals and have some relationship between their actions and their goals and their outcomes, and they learn from that.
But in the context of evolution, too, what's selected?
We also say that we have good evidence that there are times when we think we are motivated to do things, and that there's good evidence to suggest that we have told ourselves a story about wanting to do something that we were doing for a completely other reason.
And habits that are not different.
Anishia.
So introduce yourself.
What was that?
Oh, no, I'm Anishia. I work with Cheryl. I'm a neurologist. So from my perspective, there has to be sort of an answer to all of this.
So I guess my question is, you know, one of the limitations I see with models and computers is that they have to be created by humans, right?
So is it conceivable that perhaps the reason some of their limitations are because we as humans are not smart enough, at least now, to really create these models and perhaps with evolution or with human learning, we could learn that we could be able to do things with humans.
And then we could learn to create these models and computers that could account for more complex psychiatric functions.
Well, from the point of view of the history of science, the history of science is kind of on your side, because there were all kinds of things that people said will never be explainable by science, including urea, right?
Right, the production of urea in the human body was something that people thought couldn't be replicated.
So the history of science is sort of pushes to that, but I would say that the human brain is the final frontier, and we don't know whether our historical experience with science being able to progress will be able to do that.
So that would be a limitation of us in our ability to create the model as opposed to a limitation to models in general.
Couldn't you argue that one of the ways of thinking about artificial intelligence is that it is teaching a machine to create new models?
I could imagine, certainly, and maybe this is already happening, building a machine that builds new models that we ourselves as humans couldn't build.
No, it has to appreciate art and tell jokes, and it has to be human. That's a directive.
I wouldn't argue with that.
There's some intrinsic limitation to how complicated a thing humans can create.
It's just a matter of just the whole way science has been built up. You've got to understand some things, and then you build on that, and then you build on that, and then you build on that.
We're ways from getting there, but I don't think there's any intrinsic limit to how far we can go.
Humans are stupid, but humanity is smart.
Humans can be stupid, but humanity is smart.
That's a quote of a word.
When you mentioned the word philosophy, and then before you wanted a definition of the word math, I thought of the confrontation between the analytical philosophers and the continental.
The logical positivist, Witton Stein and Bertrand Russell thought math was the answer. Logic was the answer. Could this be a little bit of what we're dancing around here?
Yeah, Fragan was in there. I would say, yeah, I would say that, and again, Andrew and I have had a number of conversations about this about what are some of the...
What, in conversations like this, what are some of the fundamental things? And Russell had a famous quote about the difference between mind and matter, right?
And he said, what is mind, not matter, what is matter, never mind.
So the mind-body problem underlies all this.
The use of folk psychological language to describe scientific psychology are problems like this.
And I think that those go to the positivist, questions of the positivist about whether you could ultimately come up with a set of definitions and a set of non-falsifiable statements,
whether you could do that or not.
Science hasn't, while philosophy has moved past that and rejected that, I think working scientists have never fully, have never rejected the logical positivist position.
And your question to me was implicit that, is this just kind of skirting around logical positivism as opposed to what else should we perhaps be bringing in and considering? That's the implicit part of your question.
I think, what was the problem with the quote? If we can't, we can't really get to it.
Yeah.
And this will be our last question. Thank you. Please, not too long.
This is seems to us to have gap, abysm between psychology and philosophy because it depends on where we turn our attention and our focus of attention.
Because this, I think this gap is artificial because in order to, I'll give you some example, in order to aware that every experience requires awareness,
requires consciousness, hidden in a way.
For example, Freud and Jung built his theory about unconscious from the point of view, not of unconscious, from the point of view conscious.
Therefore, did you see some animal to write book about biology? No.
Men who is higher ontological creature write book about biology. I wish to only to say that they are not only the, say, I'm a psychiatrist, a baris
not only our science.
So we can ask a question so we can respond.
Excuse me, sir. I didn't wrote so many books in order to only ask questions.
I wish to say some missing great point of contemporary physics, especially in physics because computation upon physics.
Still genes is the massive genes. He tried to deviate this general intention of thought that a universe is not computed.
The universe is a mind because ever mathematics needs of mathematicians.
What presents itself a mathematical equation without interpretation?
Okay. This is not my question.
My question, my team was to say something I think very important.
Now we are aware that the whole science meets time, temporality, because see, every, all the computers and all the living systems process information in time.
Time, substitute the, time is like work.
We are not actually.
So you don't want to listen to the, why sir?
Sir, do you have some esteem?
Yes. I have to stop now unfortunately.
I did, I did, because the time went out. So I must. I'm sorry. I apologize.
Do we have the panel responder or do you want to just, okay, then sit down and let's hear what the response we get, please.
Sir, afterwards you'll be able to ask the panelists independently.
I told you all the living systems information in time.
Okay. Let me ask the question.
The human brain is all the process time into the flow of information.
Okay.
You make something version. It's very important.
Do you have now read to, to.
Yes. I'll stop you now.
It is actually an interesting point.
If you have a response then they will not have knowledge and function.
Okay.
Because to be cautious that means double status.
I'll say it's time. It's all time plus the 50 days.
And the future takes them together.
Okay. Now it happens that your comment, that one of the-
My comment, concern about peak time.
Thank you.
Thank you.
Thank you.
Now one of the people that I, that we reference in the description of today's talk was on Ray Bergson,
who did supply that similar sort of analysis to making a connection between the mathematics and, and subjective experience.
So in that sense, you're in a good company.
Thank you very much.
And thank you everyone else here today for a really wonderful round table.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
It's a good opportunity.
I see that.
Yeah.
Thank you.
Thank you.
Thank you.
Thank you.
Oh, thank you.
Yeah.
Thank you.
