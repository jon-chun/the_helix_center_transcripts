 My name is Beth Haus. I'm a psychiatrist in private practice and a member of the executive committee for the Helix Center. And I've been asked to moderate this a little bit last minute. So bear with me. It's not my area. But we're here today to talk about secrecy, privacy, transparency, openness, and related concepts. Since Freud's early twin psychopathology stemmed from secrets that one part of the mind kept from another to win a cots idea for the development of self and to allow the child to overcome shame and narcissistic humiliation, psychoanalysis has always been interested in secrets. And Western literature also has been interested in secrets from medipists to Prometheus Bound, where the main character spends the entire play resisting the attempt of one character after another to get a secret out from him. So the secret and its gradual revelation serves many, many literary and psychoanalytic functions. And liberal political thought is obviously predicated on the autonomy of individual selves and the maintenance of secrets as an aspect of selfhood. So we're here to talk about these ideas today and an age of NSA surveillance and prison access to our Google and Facebook and Yahoo records, drones, big data, and the internet creation of secret and revealed selves. And we will look to our wonderful panelists to help us open up these concepts of secrecy and transparency and their current relevance. So I'm going to introduce the panelists now. We are pleased to have here with us today. Alex Abdo on the far left here. Alex is a staff attorney for the ACLU and for their national security project. He is the current counsel to the ACLU's challenge to the NSA's phone records program and has been involved in the litigation of cases concerning the Patriot Act and the Foreign Intelligence Surveillance Act, the International Emergency Economic Powers Act, and the treatment of detainees at Guantanamo and elsewhere. Alex is a graduate of Yale University and Harvard Law School, and prior to working at the ACLU clerked for several different judges. And he recently participated in a panel at the University of Pennsylvania, which was called on the very idea of secret laws, transparency and publicity, and deliberative democracy. So welcome, Alex. Next, we have Jack Braddich over here, who is Associate Professor and Chair of the Journalism and Media Studies Department at Rutgers University. His work applies autonomous social theory to popular culture and social movement media. He is the author of Conspiracy Panics, Political Rationality in Popular Culture in 2008. And his most recent publications include Adventures in the Public Secrets Sphere, Police, Sovereign Networks, and Communications Warfare in Cultural Studies, Critical Methodologies. Is that right? OK. He's also a Zion librarian at the ABC in Nel Rio and has co-taught courses at Blue Stocking's Bookstore in New York City. So welcome, Anna. Welcome. Our next panelist is Ted Jacobs. Ted is a psychiatrist and psychoanalyst at Albert Einstein College of Medicine in the NYU School of Medicine. He's also a training and supervising analyst for adults and children, both here at Nipsey and at four other psychoanalytic institutes around the country. And the editor of at least four analytic journals. Dr. Jacobs has published over 60 papers and book reviews, and among them are Secrets, Alliances, and Family Fictions, Psychoanalytic Observations, and Notes on the Unknowable, Analytic Secrets, and the Transfer Ensnorosis. He has two new books out for 2013, neither of which have much to do with Secrets. One is The Year of Du Roche, a novel about the turmoil created when the manager of the Brooklyn Dodgers moved to a different team, the New York Giants, in 1948, and the possible profession, the analytic process of change. So welcome. And finally, we have Michael Lewis. Michael is a university distinguished professor of pediatrics in psychiatry and director of the Institute for the Study of Child Development at Rutgers Robert Wood Johnson School. His research has focused on normal and deviant emotional and intellectual development. And among his books are Lies and Deception in Everyday Life, which he has brought with us here, and a handbook of emotional development, which was awarded the Critics' Choice Award. Most recently, his latest book, which he also has with him, is The Rise of Consciousness and the Development Devotion, Emotional Life, which is after 2014. And he's also working on a new book, My Life as Development. So these are our panelists. I hope that they will help us get access to the psychology and national psychology of secrecy and transparency. I wanted to start out just with a quote from JFK. The word secrecy is repugnant and free and open society. And we as a people are inherently and historically opposed to secret societies, secret oaths, and secret proceedings. It seems like JFK was not particularly up to date, but I would start out with the question related to that. What is our modern conception of secrecy, privacy, transparency, and openness? And is there something uniquely American about the way that we approach it? So leave it to you guys to open that. Well, I will be talking just before we came up. And many of you will remember that Eisenhower was going to meet with the Russian Premier. It was a bridge level. It was Khrushchev. I don't remember. Must have been Khrushchev. And right before they were to meet a YouTube plane with powers flew over Russia taking pictures. And they shot the plane down. And so they had us. Eisenhower was asked, did you have knowledge of this? He said yes. That terminated the first meeting since Yolta or Otslan between American President, Russian Premier. Because in diplomacy, it is recognized that indeed if you tell the truth, that's an insult. Have he said, I didn't know if I have this as you do this large government and all sorts of things happen, Khrushchev would have, the meeting would have taken place. That he chose Eisenhower, the all-American, chose to tell the truth, which from a diplomatic point of view was not the thing to do to have that meeting take place. So I guess I'm going to start off as sort of the other side of the view. I think that secrecy, deception, and lying have a very important place in human life. And I spend my time at as legal or helping folks with their problems, media issues. I study development. I study infants and their development. And one of the extraordinary things is how early children lie. By two years of age, children have pretend plague, which is a kind of self-deception. They lie to spare the feelings of others, and they lie not to get punished for transgressions. So and we are not unique. This goes on. We studied in Japan. We studied in Europe. This is all children as best we could say. So extraordinary early in life, secrecy, deception is part of human psyche. I'll stop. I agree with you that there is a very important place for secrecy and deception in our private lives. But I think in America, we've always had a double standard when it comes to secrecy. We expect to maintain our privacy fears, but we expect that the government will not maintain a significant privacy fear. We expect that the government will, to the extent possible, I think, be open and transparent. Although you're right, that there's obviously even there in a very important role for secrecy to play. Diplomacy doesn't work in the open generally. Many national security policies can't function if entirely open. But there's always been a deep-seated hostility, I think, toward excessive secrecy in government. And the question that, when we were discussing a moment ago, that we at the ACLU are concerned about is the question of when excessive government makes democratic self-governance difficult. And maybe another way of thinking about it, though, is just to take it on the terms that you've started us out with. If secrecy is so important for private development and private life, which I agree with you, it is, you can think of surveillance, government surveillance, as being what undoes private secrecy, what unmasks self-deception. It gets behind the veil that we construct for ourselves in maintaining a private and dignified life. And so there's a question as to what extent should we allow that surveillance. And obviously, we have decided there should be some of it. And to what extent should we allow secrecy about the extent of that surveillance, which is another interrelated question? Yeah, I've been following up on that, too. Around democracy, I really like the figure of Eisenhower. So he could have said, as you said, he could have said, yes, we have secrets, but I didn't know about this one. It's an acknowledgment. But he said, yes, we have secrets, and I know about them. So I mean, those are two different ways of revealing one's knowledge about secrecy. And I think it's that tactical approach to revelation that interests me as part of US history, so around democracy. So you think about the emergence of the American Revolution. So much of it was also hatched in things like lodges, and free Masonic lodges, and secret societies. So here's this fundamental moment of the foundation of democracy itself that's also partially hatched. In some people saying, well, there's a certain kind of secrecy that we don't like, monarchical secrecy. But we're going to start plotting some things in secret, because we have to do that, because it's a revolution. So there are moments that, to me, the issue is who gets to decide when secrecy and transparency are allowable. So to me, is the interest around sovereignty. Is there something, a difference between, say, a popular secrecy and something more like state secrecy? Can we think about something about secrets that belong to a population that's part of democracy and not just antithetical to democracy? In some sense, secrets, just like I think who it was who said that all politics is local. So it relates to the community, and even for its national politics, people tend to experience it in terms of their own community, their own private lives. Secrets also are always, in some deep sense, always personal, in the sense that they resonate with our own experience with the secrets and the deepest part of ourselves. As you've said, Dr. Lewis, that secrets are always a part of development and a necessary, can you imagine if a child didn't have any secrets that the parents knew everything about the child? There'd be no sense of separateness, no sense of development. And the larger question that Alex raises is when does this necessary aspect of secret become intolerable, and he says, well, a certain amount of state secrets are necessary for any government to exist? If the Germans knew where we were going to land and D-day, we would have lost thousands of more troops, or maybe even the war. But at what point does the individual right to privacy conflict with the national interest in, let's say, discovering secret plots that may go on? If the government had been able to discover the secrets of the 9-11 bombers as they were preparing their plans, we would have been saved a great deal. So let me ask Alex, in your work that you've been doing, have you been able to define at all that borderline between the necessary and the intrusive and immoral aspects of secrets? Let me, yeah. I think let's some agreement between having them and how much is a good thing. So I think that's a lot of progress, really, and just as an opening, because we could have folks sitting here as panelists who would say that secrets aren't good. So for example, there's a very famous philosopher, a boy who talks about lying, as I said, secrets as a first-door-no-moral failure. No, one could argue with that. What I think might concern us is what has changed for those of us who have lived longer than in terms of what is public and what was not public. So how many of us have not experienced walking down the street and having someone in full voice in a conversation on the phone with someone to which we could listen in to or go to the movies where people talk and the idea of private versus public behavior? So I think there's been a real transformation in this move toward public behavior, that private behavior. And I think it's part of this movement that is probably at least 50 to 70 years old in this society in which we are not supposed to have secrets, that good relationships don't involve privacy. If you go to a dinner party and it wasn't a good dinner or pleasant company, and you can say something about it, instead of what we used to do was write, remember we actually wrote things, and we sent the thank you note for inviting us to their home and so on. So I think there's an enormous change. And I think there's a lot of pathology that goes on with both the society at large, which will mean government, will be communicative, and individuals. I think that we're supposed to not have a secret. If you get a present that you don't like from your grandmother, who has netted you with arthritic fingers, a sweater, you're supposed to say you like it. But people chafe with that idea. You're not being honest with your grandmother. You should tell your grandmother the truth. So I think there's a strange thing going on in our society. In this domain of public private, which, of course, is some sense what we're talking about. As you were saying, private, we have to have private. But this idea is we're not supposed to. My wife comes home with a jacket that I don't like, and I'm supposed to tell her I don't like it. So all sorts of things are going on. And I think at multiple levels. And I think that we have to understand them in that context. I don't know historically whether in this country there was ever a period of time when the government didn't have secrets. I mean, it's inconceivable to me that you could have a government in the same way that they would say you can have a person, a child, who didn't have secrets. Any functionally organization has to have secret handshake, secret code, secret language, in fact. I don't know that I disagree with your kind of description of how a society has changed over the last 50 or 60 years. I'm not sure I know enough to agree or disagree. But one of the questions that concerns us so much is to what extent the government gets to capitalize on those changes. So if you look back at the late 1700s, one of the reasons that the early Americans rebelled was actually about secrecy. One of the last straws was the fact that King George insisted on using similar authority that was being used in England, what were known as general warrants in the colonies as well. And these were issued by courts and they gave constables the authority to enter homes at will to search for tax evaders and people who were evading import taxes. And that was the foundation of the Fourth Amendment. That was where our right to privacy came from, was a notion that unregulated government access to our secret lives is wrong. But then for the next 200 years, the primary protector of secrecy was not actually legal. The primary protector of secrecy in the country was practical. The government couldn't record all of the information that was being spread around in public and maintain it in that basis. And I think the real governmental shift over the last 15 years is that, you know, and this is actually a really kind of fundamental shift in the way intelligence gathering takes place, is that it is now possible for the government to keep a record of all of these conversations that are spoken in public or to keep track of all of the digital trails we leave whenever we interact with an internet service. Because those things are, in a sense, made public. We share them with Google, we share them with Yahoo. But now the government can keep track of them, can keep them forever. And that search first, you know, search first suspicion later approach to surveillance is really, you know, a revolution in the way our agencies conduct intelligence gathering. And so the question is, is that okay? And if it's not, why isn't it? If you're right that this is information that we're just volunteering anyway, why do we care if the government keeps a repository? And, you know, one answer is that, you know, when you, and this is a phrase I heard recently, when you calcify the present, you might say to yourself, suppose you had the world's best detective and he were always able to reconstruct the past. Would that be a bad thing? You know, maybe that's a great thing. Maybe you want a police officer who's always able to reconstruct the investigative path. And a lot, you know, one logical leap from that is, well, why not preserve the path now so you don't have to rely on the superhuman investigator. And then you can just give the government access to these databases of information. And the answer to that question I think is that when you calcify the present in that way, when you get rid of the practical protection for secrecy we had for 200 years, you also encumber the present. Every current decision is encumbered by the possibility of future liability, not necessarily legal liability, but the possibility that in 20 years something you said will be uncovered in a way that never existed, that there was in essence a right to be forgotten for most of our country's history, and that is being practically threatened. You know, we now live in a world where virtually everything we do is digitally tracked in some way or other. And we have to wrestle with the question of whether we want to preserve this practical ability to have those actions forgotten or not. Well, I don't want to want to talk about the government, but you don't object to governments having secrets, we object to them knowing about our secrets, that is knowing about our private life. Is that the argument? Are governments allowed to have secrets? Because I don't see how they could function. I think they have a question they can have secrets. The question is what level of secrecy is allowable in a democracy? And how about recoverable? Recoverable? Well, in the sense that you know what they know about you, freedom of information, act, and so on. There was an attempt there. The government makes records, takes, gets information about people, and you have a right to know what they know. Is that a safe gone? I think it is, but it's kind of telling in our country that that's a statutory right and not a constitutional one. You would think in a democracy that the Constitution would protect access to information about government. But in fact, the Supreme Court has held it doesn't. There's not actually a constitutional right to that information. And the statutory right, and as someone who litigates a lot under the Freedom of Information Act, I can tell you is a weak one. And so the question, if you went back to the 70s, which is when the Foreign Intelligence Surveillance Act was passed, and this is the main law that the government has used for national security intelligence gathering for the last quarter century, 35 years, you could have made an argument that in 1978, that statute itself should have been secret, that our prospects in the Cold War would have been better, had the KGB not been able to read the law that governed the intelligence activities of the NSA. But we rejected that. We didn't, because there was a recognition that certain things should be public. And so I agree, the government's need secrets. The very difficult question is when the secret becomes illegitimate. And to take the modern day example, you have Edward Snowden who leaked the existence of a program in which every phone record, every single day, is being captured by the NSA. The phone call that you're talking about made on the streets of New York City, by tomorrow morning, will be in an NSA database. Is that a secret that the government should be allowed to keep? And I think that's a difficult question in a democracy. We have a strong view of what the answer is. But not everyone agrees with us. And it's a difficult question. At the same time that there has been a kind of maybe defanging of FOIA, has there also been an increase, my understanding, is an increase in classification of certain kinds of domains of government activity. So at the same moment that public is disempowered, increasing disempowered from accessing things, more and more things are becoming inaccessible. Is that a kind of characterization of the recent? Every government official to have left government in the past 30 years has complained about overclassification, but even more of late. And they're now, I think, I forgot what the exact number is, but millions of people who have security clearances to access this trove of information that is growing exponentially. Particularly in the digital age, things are now born classified, they say, because they're derivative of other digital documents. You email something around internally on a classified network, and all of a sudden you have a whole new classified chain of information. So yeah, you're right. To me, some of the changes I think that are happening in the political environment include, precisely what you've been talking about, an expansion of a national security state, specifically in the last dozen years or so around terror war, right? And a kind of war context and a war environment that makes every question about freedom, democracy suddenly tied to security. And the security suddenly becomes the most important kind of value through which all these others have to be run through. So that kind of discursive environment is something I think that's changed over the last 15 years. The other thing that I think has changed a bit, which is my interest, is how does the do get revealed take place in a public sphere, and it almost doesn't matter, right? So one of the things I look at is the early Bush years, and some of the things that did get revealed, and all the books that came out around, you know, Bush is a liar, Bush is this and that, and then it made no difference for the election in 2004. Because it's almost like there's a belief somehow in American belief that if you expose secrets that leads to action, and I think that is the connection that I'm interested in, how do we move from information to action, and does exposure and revelation actually lead to action, or is there something else going on that might prevent that from happening? So that's sort of my interest. And my favorite figure during that time period is one of the masters of revealing secrets, and that was Donald Rumsfeld, right, who was this, I mean, just listen to these press conferences, and he's almost a wizard at this, where he says things like, remember that list of the known and the unknown that he brought up, but there are these known knowns, then there are the known unknowns about Iraq, where these are justifications, the unknown unknowns. Right, what he forgot though, he only mentioned three, right, and then that two by two mono hybrid, there's a fourth, right, which is the unknown knowns. Is that right? Yeah, right. So he didn't mention that one. Okay, well, what is that one about? And so that for me is the interesting moment of things that we know are happening, but we forget, right, or we deny, or we repress. So things like Abu Ghraib, I mean, it was a revelation of particular activities that were being done, but atrocities during warfare are something that we almost have to forget in order to engage in it as a society. So these moments of things that get revealed at the same time other things get concealed at the very same moment, I was sort of tracking that as a cultural media phenomenon. And I think a lot of that has changed too. So we get revelations. I like before the panel started, the roundtable panel on the screen we had, my friend Trevor Paglin was up there, the artist who studies government secrets and tries to map them and visualize them. He's collected the patches of units in the military and such that are secret units, right, and he finds their patches and he's collected them. He did some work on Area 51 before it was acknowledged that it existed, right, which just happened in the last year or two, right, before that Area 51 never existed. So he wouldn't try to give tours of it. Great artists, performance artists around this. Anyway, so that kind of question too, like what, you know, even if things get revealed, what happens? What happens now that Area 51 is revealed or, you know, more documents about the Kennedy assassination system start coming out, right? I mean, what is the action component that to me is the crucial part of democracy, not just the things that we know about the government, but the things that we can do about it. And I think that's one of the things that's so frightening about the NSA leaks, is that people have this feeling now that they're releasing this massive amount of information and anonymity, and that someday in the future it's going to come back and bite them, but it's very hard for them to conceptually keep it in mind as to when would that be. Let's take this back down to interpersonal, to sort of get it back, and I think Ted and I represent more that perspective. So it is not possible for a parent to go on the computer of their child and find out things about their child. So let's talk about parents and kids and the technology that allows parents to find out things about their kids and what we might feel about that. Because you couldn't do that before. Now, since you would open mail and so on, but it is now possible with computers in the home to do that. Then I think there would be more argument about whether that was a good thing or a bad thing, or how to regulate that and so on. I don't have an answer to that. I'm just sort of trying to bring your point about new technology, changing the complexity of the problem we have to making it now and to personally. I mean, we could even do it not therapeutically, but now with brain imaging and all this kind of work that is leading to find out what is going on in someone's head without asking them or without interacting with them. So what we have is a technology that is allowing all sorts of challenges to this idea of privacy or secrecy, whether it be at the level of the individual to the government or the level of the person to themselves, to the therapist, to parents and so on. That technology is changing that. The people have responded so much to this idea of the government listening in on phone calls, listening, being able to obtain private messages that people send to one another. It's a sense of violation that goes back to early childhood. I mean, that child is entitled to have some privacy. The parent who is looking at the diary, looking at the computer is violating something very essential in the child's development. But it's an interesting question, Alex. Let's just say, for argument's sake, that there are some people in this country sent by some foreign power and they're planning another attack of a major kind, a 9-11. And I think most people would say if we can identify those individuals or have some suspicion, we're entitled to tap their phones, get whatever information we can to avoid this massive disaster. And what if the government says, well, but we can't actually do this without listening to everybody, because maybe they have some contacts here with private citizens or US citizens that we won't know about unless we listen to everybody. Is that justified on the basis of a clear and present danger? Or should we say, no, you can't do that regardless, even if there's a danger, because that's just too invasive of an individual's rights. You know, I would dispute the factual premise of the question, which is that you actually would ever need to listen to everyone's communications in order to conduct a targeted investigation. But even if it were the case, you could prevent an extraordinary amount of crime in this country. If you gave police officers authority to open up houses without warrants, to install video cameras in houses, and then only access them later on if a need arose, you know, maybe through judicial authorization, maybe through an automated scan of what's going on in the house, so it's just a computer looking, it's not a human. And I think that, you know, there are a lot of people who kind of observe very provocatively that the optimal level of crime in a society is not zero, because the only way you can achieve zero crime in a society is to become a surveillance state, and that we've rejected that path, and that's a weird cost-benefit way of looking at it, that we tolerate a certain amount of civil disobedience or crime in order to not to sacrifice every bit of freedom that we have. And that question becomes a lot more difficult when you ratchet up the one side, when you make it about, you know, a terrorist attack in the country. But, you know, I spent a lot of time listening to people who conduct these investigations, and I've looked at all of the examples that the government has made public in any event about how these programs are used, and there's not really a convincing case that pervasive surveillance is necessary in a strong sense. It's, of course, useful. It makes the job easier sometimes. It's always easier if you don't have to go to a judge to get a warrant and why trouble the police officers. But that inefficiency has a purpose, and it's to protect the private sphere from, you know, unjustified invasion. And to get back to the question of when do we accept that invasion? And, you know, the balance that was originally drawn in the 1700s, you know, with the ratification of the Fourth Amendment was with cause. And the question always is what's sufficient cause, and we can have that debate. But with cause means something. It means that you don't accept pervasive surveillance at the outset. You don't accept dragnet surveillance. You know, that's what the founding was, a rejection of, you know, of King George's dragnet surveillance. You know, I used to do a lot of, most of my early work at the ACLU was relating to mistreatment of detainees. And so we heard the same argument there, which was, well, maybe torture does work. Maybe in that one situation, the ticking time bomb scenario, you'd want to use torture. And, you know, the kind of civil society groups that work on these issues are divided over whether to engage in that hypothetical. Because torture is immoral no matter what is the argument. I mean, we shouldn't engage on this practical question. But they always, you know, at the end of the day you want to convince people that it doesn't actually work. And even if it did, this ticking time bomb scenario is actually just a hypothetical. It doesn't actually exist. Those situations never really do exist. So I don't think we'll find ourselves in a situation where the but for limit, on cracking a terrorist attack, is collecting every American's communication. But if we did, I think our principles would reject pervasive surveillance to accomplish that result. Why do you think pervasive surveillance is going on now since there doesn't seem to be a clear and present danger? But it's still going on. You know, there's been a shift in the way the NSA conceives of its role. It really is switched from an agency that used to be targeted in its investigations to one that tries to collect everything at the outset to preserve for later searching. And that technological shift has just happened to happen, you know, occurred over the last 20 years. The war of terrorism, they've redefined so that there's always a threat. And given there's always a threat, you always can be in this mode of trying to prevent it, which then allows us to move. Great, it allows them to do this. There was another, and we were talking about it briefly earlier, which is the role of people in the society to uncover what in fact the secrets or what the government is doing. And there, we were talking about investigating, reporting. Well, that is all but disappeared, given the state that the print media is in now. Now, hopefully, the new technology, the Internet blogging will pick up this, but we get in our home items every day, and it says, then, all the news that's fit to print, well, that's silly. Clearly, we know that they selectively don't tell things as they've admitted, but investigated for reporting has, for the most part, disappeared. And now what we have are individuals who take it upon themselves to reveal some of these secrets that are going on. Of course, they'll label this traitors, and they have to flee the country and so on. But I have a concern that given that there has to be a certain tension between the public and private always, one of the regulators of that is investigative reporting. And there is much, I think, much less of that. It's not much less of it, in sense, it isn't happening. But, you know, I read Mother Jones, well, Mother Jones, I don't know if it has 50,000 subscribers or the nation where things break much earlier than, or I have stone in another generation, where, in fact, there were people who took up the reporters, the media who took it upon themselves to, in fact, report, and to try to regulate this private, public kind of activity. And I'm really placing, and I understand the position of preventing the government, I see it as a broader issue between a public and a private, what is private and what is public. And I think we're in trouble with this. There is much too much private behavior that's public now. For some of us, we're uncomfortable with it. We don't really want to hear the conversation, the regulation of conversation in restaurants. For those of us who are New Yorkers, come on, I mean, we can't go in, the noise level is so high, and it's because people don't modulate their voices any longer. And so, but investigative reporting, what's happened to that? You know better than I, how many people get their news from, you know, from television? How many get it from newspaper or from the internet? In fact, we know how little people know about what's going on in the world, our citizens. I've forgotten the figures, but I said I could name who the vice president is, and probably 90 couldn't name who was the last vice president. So, is something happening in this balance now that needs writing? Interesting legal ACLU, such organizations attempt to try to maintain this balance, but it's a lonely place to be. And you would pay much more help, right? And if there are a lot of people out there who could spot in their job reveal these things and, you know, confront some of these issues. I mean, this last event with, I remember his name at the moment, but, you know, had to reveal what Ennis, the NSA, what's doing, and then he had to certainly leave the country. So, that's kind of investigative reporting, but then you get classified as a traitor. So, I don't know, I don't even know how, I mean, from a legal point of view, obviously it has to be fought to regulate it. No one could argue with that, but I think if we take a broader perspective of, and maybe it is, what happens when technology changes? And indeed, it's only going to get more amazing with this balance between public and private. It clearly is, we're in the midst of change, which in a single lifetime we can witness, sometimes it's quite scary. I think the right to privacy has been based on the idea of habeas corpus, typically, right? And there's been these metaphors of the body or the home or, like, concrete things that are in violet that you have ownership over, and I was curious what are the rights to information that we have now, and what is considered to be owned by the person. I mean, in terms of language or data or things like that, what are the legal principles behind ownership in that way? One of the people that I talked to for this panel is starting a company where you would actually own your data and could monetize bits of information that are used. Because that is something that belongs to you. You know, Vick can find, start that once you put something in language, it no longer belongs to you. So, you know, how is that sort of tension being played out between people? As a legal matter, I think it's difficult to answer this question of what preserves our ownership of information, but as a practical matter, it's a lot easier to describe it, which is that, you know, if you think of your relationships with various internet companies, if you're not paying for the service, chances are that you're not the customer. That's the adage that's been cropping up these days, that if you're not paying for it, you're actually the product. And that's true for a lot of the companies that monetize the information. If you're a Gmail user, you're only a customer in a very attenuated sense, because what funds your use of that service is actually the information that you volunteer to Google, that they then scrape to create their ad-based business model. And so, I think this is part of what Dr. Lewis is getting at, which is that people more and more these days are volunteering this information. But, you know, there's a way in which we've always done that. It's just now we have an internet to facilitate the exchange of the information, and so by necessity, so much of it resides with someone else. You know, we used to keep journals, now we just keep them in the cloud. And what does that say about who owns that information? Should technology change what we think of the ownership of that information? I don't think so. You know, right now the government takes the position throughout much of the country that it doesn't need a warrant to open email. But all of a sudden when we move to the digital analog, they don't. And that's a bizarre conception of privacy. The follow up with that too, about the kind of corporate surveillance and data gathering that happens when people do this. So one way is to, yeah, we used to write journals and put them in the cloud and we make it in a bit concerning sense open in public, right? And it's no longer ours. But what's happening with corporate surveillance is we give it over to another private entity, right? It then captures and re-organizes the data. And we do that when we sign those, we check mark those boxes, right? The terms of service agreements and user licensing agreements, the things that people tend to just like, yeah, I've got to get to my mail or I've got to get to this. I want to start this platform. But that's when this sort of, it's almost like the last bastion of this true, like, older form of sovereignty, where you give up your rights to your data because you've told them, you know, whatever you want to take from here, you can. And then some of the battles that are happening both legally but also culturally around how platforms like Facebook have to then respond to its users that say, well, you might want to alter those terms of service agreements before, you know, unless you want to alienate a lot of people. So there is a cultural dimension, I think, there too, as well as legal. Information has become a sellable item. So, you know, on your, if you write a check, I mean, there are so many public things we do. That get us into the private domain. I mean, Social Security secret is probably the most secret thing we have. I mean, if you have a package sent to you, they have your address, they have your zip code and commercial thinking of commercial. I mean, there's enormous you go on and buy something online. So people are harvesting bits of information which are now extraordinarily valuable, supposedly. Now, there's something interesting about it which is that the algorithms to analyze these bits are very primitive. And what really scares me is when they develop really good algorithms. And that's of course where a lot of our tax dollars are going as they try to figure out how to take in every phone message, every internet message and try to get information that's useful for whatever their purpose might be. It's not easy. There's an awful lot of information out there. And one of the things that may save us in some sense is that there's so much of it that's going to take a long time. They can't analyze sentences and phrases. And they can't really analyze emotional tone. They can't analyze words. So if you say president and you say the murder, the simple algorithm can put that together in a sentence and bring it up to some other level. So, but it would be nice to go back to the beginning when privacy was greater. But I think we're losing that. And while it would be nice to go back to the end of the 18th century, I don't think we can anymore. I think we have to confront that bits, these bits which make a part of our lives are just available. They're in the clouds. And there's no way around that except if we go back to writing letters and they can't open the letters. Of course, they can't probably. I don't tell us. So it just seems to me, you know, here's another etiquette. There used to be rules of behavior. You could keep your private, but you can act appropriately. Well, there's, you know, the 60s will let it all hang out. What does that mean? And simply mean that you don't have to have a private. If you didn't like something, you could say it instead of saying, which you could call a lie or deception. Thank you very much for the gift. In fact, you didn't like the gift at all. So I think lots of things are happening. Motion and expression. Pride. If you look at any sports, and by the way, it's all over the world, when people used to succeed in a sport, then baseball, they tipped their hat if they hit a home run with the bases loaded. Now you see the full display of the pride response as if it's perfectly okay to express yourself. So this public private thing is shifting. And where private is less valued. And now you said that. I said it more from my perspective than yours. But it's true. It's less valued now. So what we're confronted with is in fact governments, which tell us we're always a threat. There's always an enemy there. And the war on terrorism is endless. We don't declare war anymore. We haven't had who was the last president, Roosevelt, I suspect, who went before Congress and asked for a declaration of war, which is a requirement. So I mean, not only are we, our secrets being a private being invaded, but certainly the rule that the president needed a Congressional Act to declare war has disappeared too. So I don't think the solution, I mean I hope you find the solution, but I don't think it's going to be going back to the end of the 18th century. We just live in a totally different world. I think that's right as a practical matter. We're not going to go back to the modes of communication of the H3, but I think the principles are worth thinking about anyway. But there's always been this tension between private and public and what you share. And if you want to live a meaningfully social life, you construct your private sphere and then you choose what to share with people. Every time you have a conversation, you're sharing of your private life. And that's what it means to engage. And I don't know that people now value their privacy less. It just might mean that they share their private information in a different way as part of their social engagements. But there's a way in which you can think about this from the governmental perspective, which is that private people share information to engage meaningfully. But government share information often with the public anyway to maintain credibility. And there's a certain amount of sharing you have to do as a government in order to maintain legitimacy. Otherwise, you're viewed as a repressive government. You're viewed as one that isn't democratic, isn't governed by the people. But that credibility is only at stake when there is kind of an adversity between the government and some other strong actor. It used to be as you were saying investigative journalists who would hold the government's feet to the fire when they didn't share enough. Now, large media organizations don't fulfill that role as well, perhaps as they used to. There's a flat or business model when it comes to media. But that essence of adversity needs to be there. There needs to be someone who has an adverse interest to the government to force the government to maintain his credibility by sharing information. I mean, I can't an individual decide that. We've had two examples. One of the WikiLeaks and this last recent one where someone exposed the... Yes, nothing I'd say. So can an individual decide, this is immoral, I'm going to expose this. It's a very interesting question because one may feel that they've done a service, and yet do they have a right to do that? Suppose they decided that some Democratic principle was entirely wrong and should be exposed. I mean, there is a whole interesting argument we made about all of this. Yeah, it's a hard question about who should be making the decision when it comes to government secrecy. And it's difficult to tell the director of the NSA that one of his employees should be the one making the decision about what should be public and what shouldn't be. I think an equally intolerable answer is that the executive alone should decide what should be secret and what shouldn't be. And the practical answer is, you know, our constitution is one that sets up a system of checks and balances. It pits... Two or two secrets, wasn't it? Yeah. One, that they were doing it. And two, they're doing it to us. And that's kind of interesting because in a certain sense, he exposed they were doing it, which then allows us to be prepared to act in a certain way to protect our privacy. So maybe what we need is not that they do it, but that we know that they do it because it would be pretty stupid if you were plotting... to overthrow the government to do it in an email, you know, to a list of your colleagues who were going to blow up something. I mean, they know that, okay, the Germans didn't know we... I mean, you know, the Germans didn't know we broke their code. So the secret was not only getting their secrets where they were going to bomb and where they were going to be, but it was the secret that we could find out this. So maybe what we need to do is something around finding out what the secrets are. Aren't we protected in a certain sense now? There's also a notion of the legitimacy of the relationship, right? I mean, that any situation where you give somebody authority over you, you're saying, I know something about this person, they've represented themselves fairly, and there's a legitimacy to the authority that I'm giving you. And I think when people feel that legitimacy has been undermined, that they've been tricked or it's in some way, that that's when they start to react against it and feel that they have the right then to reveal or leak or something like that. Well, if you wanted to tell someone that you didn't want the government to know, you wouldn't send an email, you wouldn't go on the phone, you'd probably meet them in some public place to exchange. So we have some protection by no, surprisingly, by knowing that they can invade us. And so in a certain sense, I think the revelation of that, rather than anything particular secret, but that secret is what so infuriates the government, because now it prevents them from doing the one thing they hoped to do. At least they say they hoped to do is to catch these bad folks doing the thing. Now, if you're a smart, bad folk, you're not going to do it in a way that the government would find out. I'm not sure the revelations changed that, though, for, you know, if I think we all knew the government had the technological capability to do what's been revealed. And if you were a terrorist, you would certainly expect that there would be no barrier to the government using that capability against you. Any system that requires cause, you know, suspected terrorists will pass that threshold. They will be targetable under any system. The biggest surprise, I think, from our perspective, anyway, was that it was so untargeted. And so the only people I think who have been, who have learned information that they didn't already assume was happening, you know, who learned that the former surveillance officer was going to be able to do it, who learned that the former surveillance was happening and didn't already assume was happening, were the ordinary public, you know, innocent Americans who are not plotting terrorist attacks, and so don't think daily about how to disguise their communications. And that's our concern. You know, that it's difficult to quantify the cost of an invasion of privacy. You know, you might say that for going a particular international call with a controversial colleague or for going visiting a particular website is not much of a harm in isolation. But in the aggregate, I think it is, I mean, I think it isn't in isolation, but in the aggregate it certainly is, that those hesitations add up. You know, in a sense, it allows the government to break down our ability to construct the private life that you started out this conversation by describing. You know, it takes away from the private citizen agency, the ability to manage his private affairs. You've written about this as a battleground, right? Yeah, lots of battles in the battleground. I'm trying to think about the pluck out. One thing is about going back to the 1700s, we shouldn't go back there. Yes, again, technically speaking, but in terms of technology, the principles of democracy and a nation's foundation were forged there, so it's important to go back for that reason. Otherwise, we go back to the 60s in which it was said during the Vietnam War, we had it destroyed in order to save it, right? And I think if that logic starts appearing as part of what we exist in now, then we have brought that kind of war to the homeland, right? And so that concerns me in terms of the freedom and the spaces of dissent. So if everyone, if there's a blanket notion that citizens are potentially connected, not they're not a potentially terrorist, they're just potentially connected to someone who might be connected to a terrorist. Then dissenters who've already been determined to be terrorists in different kinds of discourses, the FBI considers lots of different kinds of protests to be actually forms of terrorism, domestic terrorism. Then we may have already gutted the foundation under which people can have a democratic life as well as a rich, interior, personal life. And so that's the battleground that concerns me, is also where dissent can take place. Both through surveillance, the counter surveillance, I was thinking about cop watch, right? So instead of these sort of also grand figures like Snowden who do these international things, how about very local, while politics is local, very local things like cop watch that are tracking police abuse on the streets, and then the ways those people who are documenting that might be kind of investigative journalists are being preemptively arrested, their equipment confiscated, all this sort of NYPD techniques against Occupy Wall Street attempts to visualize what was going on by the police, especially during the clearing out of Zuccotti. I mean, these are ways that there's a prevention, a preemptive actually intervention into the forms of transparency that can happen from bottom up from the people on the streets. So that to me concerns me, that's why I think it's a battleground. And so think about it more in terms of warfare, in which case law is very important to find curbs and to be part of that. But when I think of at least the stories I've heard about the NYPD having built into their budgets, the fact that they're going to predict these lawsuits because of their extra legal detention, preemptive detention of protesters on the streets of New York, right? So they figure that they're going to do this, it's going to be illegal, they're going to lose in court, and they're going to have to pay out a civil case, right? So that's already built into the way that the strategy works to manage dissent, and that to me is where, when you think about who gets to be, who gets to produce a kind of transparency upon whom and under what conditions so. Who would it be interesting to, if there was someone among us who was a high tech person, who could tell us what we would have to do to counter now, they're Google and some of the others are saying that in fact, they're going to build devices that will prevent them from doing it. Now, I mean, clearly one way is to try to prevent them by arguing from principles of law and justice and so on. Another way, of course, is as an evolution, you know, or something evolves, and then those that survive have to evolve new things to the people who are going to do it. And then there are some things to do those old things, and so that there is this kind of balance, there's this kind of always tension that exists in life. So I can't imagine, I mean, I cannot imagine, but I cannot not imagine that there are high tech folks who are figuring out ways that you might be able to scramble phone messages in some way or internet, and so on, and maybe what we need to equalize some of this injustice because it's happening to us, but we don't have much lee except through the law to try to counter it. Maybe we need to develop a new technology that I attach it to my phone for any phone call that I don't want anyone to be able to decipher. It turns out it's relatively simple to disguise the content of your internet communications, your emails. Most people won't take the extra steps necessary, and Gmail has no incentive to facilitate it because their business model is based upon access to your email. But there are ways to encrypt those communications. What's much more difficult is to disguise your metadata, and it turns out, and the reason is because you generally need to expose your metadata so that your communication service knows where to send your information. If you're sending an email, the two line needs to be exposed so that the next computer knows where to send it. There's a lot of research that's gone into how to disguise that originally funded by the Navy, because the government wanted a way of securing its internal communications, and so they invested heavily in a system of what's called onion routing, where you would sequentially encrypt your communications through a series of hops with the idea that no one hop knows the full path, and it's very difficult to reconstruct. But these are difficult technologies to use for most people, and I think they're part of the solution, but they're not the full solution. But if we have to do something like that, what kind of society are we living in? And what is the implication of having to protect ourselves, and what's the implication of the government having the power to find out information about a private individual without regard to the, you might say, the basic rights of that person for privacy? I mean, what's the implication? Have we undermined really the whole sense of democracy and the sense of trusting government? It seems like the whole world is beginning to shift in terms of what are our values, what are we dealing with here? Well, some of it's not new. We use envelopes when we send a mail generally. Most people don't send truly private pieces of mail on postcards. They don't write something very sensitive on a postcard. They put it in an envelope. And it turns out that just the way the phone systems developed, they're all like postcards. When you are talking over the phone, there is nothing to prevent anyone who has access to the line anywhere along it from listening to the conversation. There's no protection. It's a postcard. And we have kind of a system of blind trust for the intermediaries, but it's a trust that we're now learning is undressified. The same has largely been true of email. Email for most of its history has been communicated entirely unencrypted. If you send, you know, give me an example, if you send a Gmail from a Gmail account to another Gmail account, that's generally encrypted internally to Gmail. But if you send a Gmail email to someone on Yahoo's account, the connection between Gmail and Yahoo's is not encrypted. So anyone, and not just our government and not just our government, but even a relatively unsophisticated hacker. Could intercept that communication. So some of it, I think, is just common sense. It's putting the envelope on your communication. But I agree that we shouldn't have to. It's a sad commentary that people in the tech community are now thinking of their products from the No Trust model. They're assuming that nothing can be trusted. The server can't be trusted because the NSA has access to it. The telecoms can't be trusted because they'll roll over and give up the information to less design a system that is secure, even if you can't trust the servers, which is possible. You know, but it's a sad commentary. Following up, why would somebody want to have, you can hear it, a private conversation on their phone in a public place? I'm sure we all have experience. People having fights on the phone and other kinds of things, which are really private. Now, we couldn't have done that before, at best. We could be in an oboe for the street, but usually you were in your office or home where you did those. So we now have a device which promotes it. And I believe promotes the idea that there is in private. That is, I don't only see it as the government. But I guess I'm trying to think it through with something not just the government and us, but something is happening. Commercial, you were mentioning. I mean, there are some incredible things on online dating. Now, you can fill out a form to begin with, and you say you really want, you're interested in dating brunettes. And so the pictures and the information they send you are brunettes, but they're not all brunettes. Now, the devices now can monitor if you start hitting a not-on brunettes, but on blondes, let's say, or black-haired people. And they will now switch. They will take your action rather than what you stated. So we now have to end. We know that in terms of buying things, these devices, these algorithms can come up and present you with things that you've done before. So even commercially, they're keeping track of your behavior. So it's endemic, I guess, is what I'm saying. We've always had to protect ourselves from our government and our constitution. Our initial struggle was to try to figure out how to do that for this country. But it's not only it's ourselves allowing ourselves less privacy, and it is our commerce in our commercial worlds and our everyday lives in which people are keeping track of what we do, what we're buying, and so on. So I guess, I mean, you read some of Scalia, you know, he would like us back to, you can't go into your house. Well, that's what it says, you know, fundamental interpretation. You can't need a warrant to come into your home. Well, talking on a phone is not your home. So they could argue we're not going to take technology into account. Then of course, the more progressive arguments are that indeed it's the idea of privacy and protection. But it just seems to me that we need a kind of a balance, a kind of protection, one in terms of understanding why we are giving up privacy. And two, mechanisms by which those of us who want could reestablish it, learning how to encode or getting the tech folks to give us really very simple algorithms to make an arm of encoding and encrypting the easier to do. I'm going to butt in here in the interest of time. I'm going to sum up and say that we're very trusting and we want to be close to people and be known and we're very curious and therefore very prying. And we'll have to grapple with that in the area of secrecy. We're now open for questions for the next 20 minutes. Please come to the microphone if you'd like to ask. You didn't really discuss, and I'm interested in this because it's got to do with human nature. I think the mechanism by which the NSA obtains the data. For instance, I suspect they don't really hack like you were saying. I don't think they hacked the lines and servers and stuff. I think it works like this. I'm guessing. They get a court order and you could help me here. They get a court order that says, okay, you can go to Google or AOL and present it to the President and say, we want your permission to tap into your memory, your servers, et cetera. And the President of AOL thinks and says, hey, what if I said no? What would the government do if I refused to obey the court order? So, I would like to know really the mechanism by which they're doing all this stuff. And maybe someone could tell me. Yeah, there are a couple ways, a number of ways they do it. The vast majority of the information the NSA collects is not through hacking. They do do some hacking. There are documented cases of the FBI seeking hacking orders in order to remotely turn on the video camera on someone's laptop without that person knowing. So, hacking happens. But the vast majority of what the NSA does is not through hacking. It's either through court orders directing companies to turn over information. So, for example, the very first document that Edward Snowden revealed to the world was an order from the Secret Foreign Intelligence Surveillance Court compelling Verizon Business Network services, which is a subsidiary of Verizon, to turn over on an ongoing daily basis records of every single call that came across the network that either started in or ended in the United States. So, that is an example. There are similar types of orders that allow programs of surveillance directed at Google, Yahoo, Microsoft, etc. And then there's a lot of surveillance that takes place outside the United States, either through alliances with other countries, with their intelligence services, or through picking up information off the wire, kind of physical hacking or tapping, or picking it up out of the air using satellite and radio wave surveillance, which happens. But the vast majority of it is not through hacking. And you're absolutely right about that. What happens when the companies are talking to you? No, they know. Well, they're compelled by court order. They can challenge those orders. They don't have a great incentive to. It's interesting, you know, this type of order, the one that was directed to Verizon, there have been similar ones to all the major companies, and they've been going to those companies every 90 days since 2006. So, each one of them has received dozens of orders. Not a single one of the telecoms has challenged that order. Even though on its face it's extraordinary. Every single record of every single call that comes across your network, whether it's related to a terrorist or not, hand over. And not a single one has challenged them, but they could challenge them. The reason they don't have an incentive is because, A, they have a very close working relationship with the government. They have a lot of government contracts, so they have a financial incentive not to. B, the statute immunizes them, so they're not. They don't suffer any legal liability for turning over your call records. You can't sue them. And C, they're compensated at fair market value by the statute for their cooperation. So they're getting paid. So they don't have much of an incentive. And on the other side, on the side of the service providers, the internet, the tech companies, as opposed to the telecoms, the tech companies have occasionally pushed back. The last major one was by Yahoo back in 2007. Haven't really been any major challenges from the tech companies since although they're starting to ramp up their efforts now and they're pushing back a little bit. But they have the same relationships with the government. They have the same immunity provided by the statute and they have the same provision for fair market compensation. Please introduce yourself. Greg Burke, this usually we've heard that there has to be a tacit kind of balance between individuals and institutions. I mean, maybe governments or societies or businesses, things like that over time where there's an understanding that there's a certain amount of less than a free discussion, I don't know between each other in terms of what information we've heard about being polite. And we all passively never believe anything that we see on television, for instance, in terms of advertisements and stuff like that. And it's been acceptable over the years. It's been a certain balance. Now we have this huge amount of technology that has shifted and shift the balance away from the individual towards institutions with regard to how to manipulate this interaction of the dance of social commerce. And particularly I'm concerned now with how is the individual as a responsible in the democratic society supposed to get the information from the government. It's supposed to get the information that is necessary to make decisions about voting. The issue here is believing what you hear from politicians, from people who are actually in the government. It seems to me that we have in our society now created a paranoia about terrorism that requires a lot of people to want to give up certain rights. And this is an opportunity to manipulate. And I just use your imbalance now because of people. I can't figure out what's true. I mean, how can you all on the panel here figure out what's true in terms of being able to make a little perform decision as a citizen to vote both from what the government is telling you on what you see on the news. I read wiki and that's how I found out about the prison program and how Google collaborated with the government with the week. So that's my source of the shh. This is not just happening to us. We are participating in this. And I guess that's been the psychological point I've been trying to understand is to what degree have we psychologically moved away from this idea of the private. And I think that one could find many, many examples of a shift during the same period and maybe even a longer to that makes it easier for the government to, in fact, do some of these things. The shift to telephone conversations in public. Just simply that. Now my wife and I were in Paris. We've just come back and shockingly, there are not many people on the phone walking the streets. We've been walking the difference in the two major cities in the world in this city. You can't go a block without someone talking and hearing them. And that's not the case in a week of walking in Paris. So I think there's something happening psychologically. And I think we can even find it in some of our theories and that suggests that privacy in terms of not expressing what you really think or not doing such. I'll be brief. In fact, changing us and making us more susceptible to it. Now it was interesting because you asked what we could do. I mean there is some outrage and it's going on for a while, but it's shocking how little there is. I'd be very curious if people don't use their phone as much or don't use email as much knowing that potentially someone could be listening in and gathering data. So it's happening to us, but I think some other things are happening. There's a psychology that is happening at the same time, which is playing into this. Can I just suggest one thing because we've had this conversation a little bit today, but is it possible that most of that shift is at the margins? Because I suspect that if you ask the person who's on their phone walking down New York having what is usually in a conversation with a mom or dad. It's not usually the most private conversation in the world, but suppose even if it is. If you ask that person, would you share with me your Gmail password? Tell me your social security number, allow me to install video equipment in your home. They'll say no to those things. So I think there's a core of privacy that persists even if there is a shift in the margins. But is it just at the margins? Well the question is, is it at the... Well do you mean margin in terms of people or not? I mean I've been in restaurants where a young woman is talking to her mother and having an argument about something in which I'm privy to. And she does not. She is not. This doesn't seem to bother her that a complete stranger is listening to this going on. Now does everyone do it? No of course not. Lots of people don't talk on their phones unless they really need to or just small exchange of information. So in some sense it's not everyone doing it. But I do think, for example, etiquette which disappeared in the 60s when the idea was no you let it all hang out. There's a struggle etiquette books disappeared there actually have reappeared which is kind of an interesting phenomena. But it now is you can't have a private for it. You'll have to make it public if someone asks you a question. Good interpersonal life was you gave them the answer. So I don't know how marginal it is. But I would be concerned in this struggle with this, with government which is what are major concerns here. I would be concerned that it's not them just doing it to us. And if they are doing it to us, that we are becoming more compliant psychologically to it. Time for a couple more questions I hope. I think people waiting are. I just want to ask what you guys think is the role of the psychology of fear in the way that the policies have been crafted. Because it seems to me that the way that the NSA's role has grown sort of comports with what millions of years of evolution have forged in us. There's the classical example of you have an animal in Savannah and here's the glass gras rustling behind it. And it can make two types of mistakes in that situation. We're worried that there's a threat and turn around and there's nothing, which is a mistake. Or it could assume that it was just the wind, but it's actually a predator and a dead. And so of course evolution pushes us in the direction of leaping at a threat that may not be present. And it seems that our reaction to one very significant but relatively isolated terrorist event has had a very profound effect. On our government policy and the way that we all sort of accepted changes in our own security. And so because this is such a deep-seated, strong, evolutionarily formed predisposition, I wonder if there's a real plausible way of fighting against it because it's such a strong urge. I'll just add before the human nature component of this, we'll just add that there's a whole layer of mediated repetition of the trauma that happens that reactivates that moment too. So the annual replaying of the images, the bushes, the security codes and the color codes and the constant reminding of people that we're at war. So I think regardless of whether this, what it touches in terms of the basic dimensions of being a human, the cultural mediated dimensions are very political in terms of that can be changed. There's no reason why we have to say, okay, well, this is a defining moment of our entire senses of self as Americans because we've been attacked. Which is something that other countries around the world go through on a daily basis. So this sort of American exceptionalism is something also I think that is a cultural dimension of this fear, that it's not just something that- We have been at war as a society. We haven't stopped from the Second World War. We have the Korean War. We have had an enemy. I mean, we could start looking at paranoia and judge on the stand or, or, or, or, or, or, we've had an enemy. For the last 75 years, there's all we spin in an enemy. That's true, but at the same time, the 9-11 acted like an acute trauma. In some sense was unexpected. I mean, we should have expected, but people didn't expect it because we've been fighting out there. We haven't had something hit us in quite this way. So it acts like a traumatic event to which it's almost like we're acting all of us in a post-traumatic neurosis. I mean, in the sense that we're always on guard against the repetition of the trauma, and that gets extended into policy and into the public arena in such a way as to cause a whole shift in our world. Since that happened, we've had a major shift in this country towards a long, a long signal reaction. And I don't think that's going to be easily reversed. I have a slightly different focus. I was struck by your analogy of the, the supernatural detective who could figure anything out retroactively. And the assumption of this broad data collection is essentially, I think, that if we have the data, somehow we can reconstruct the past and do so with great accuracy. Or it's sufficient accuracy. And I'm thinking immediately of a couple things. One is Google Books, where Google is going around scanning books. I don't know if any of you have ever had the experience of actually looking at these books. They're terrible. Nope, they scan them, but they don't proofread them. And I know, I mean, I've got downloaded some of these books. Some of them are unreadable. They're gobbledygook. I notice, for example, even here, we have to have technicians coming around constantly adjusting to get, I mean, this is open recording There's no secrecy about it. And yet it takes apparently a great deal of tending to make sure that you get a good recording. Great deal of data. Obviously, if we, if we record everybody's data, technically, if it were all listened to, it would mean that everybody would have to be working to listen to everybody's data. You know, there's a mathematical problem almost. The existence of the data, I think, often gives people the idea that somehow the data is knowledge, whereas often I think it's not data but interpretation. And I'm also responding to the personal experience of having been the subject of a government investigation many years ago for political activity during the Vietnam War. And I got a copy of the investigative report. And I wrote a response to it, which began with the sentiment that as a taxpayer, I was greatly disappointed in the low quality of the investigation. I mean, I'm not going to bother to go. But it was, it was, I was appalled. This is what they came up with. How much did they spend for this? So I think in part, what I'm saying here is, yeah, there's an issue about the collection of data, but there's also an issue, I think, about the perception of almost supernatural knowledge and so forth, which I think is very, very questionable. But it, you know, knowledge or the perception of knowledge also is power. So I don't know if anybody wants to comment on those comments, but those are some of my thoughts. I would say, right, I mean, that can be very politically disabling to think that there's nothing that can be done. All this data is out there. The government is perfectly efficient as we were talking about efficiency, like creating the algorithms that can detect all these things. So the notion of that actually shifts a kind of power dynamic that says we can't do anything about it, but it's also, it's just so perfectly done. I mean, when I study conspiracy theories, sometimes that's what they're saying. I think the idea is that the philosophy at the end of his Germany and the efforts to reconstruct and understand what people thought they knew, and also were to buy up, in many cases, with great sadness, who had been in the warming water. And the feeling of distrust and the inability to have a working democracy, basically, in an environment of such potential betrayal and distrust. The lesson of the 9-11 Commission Report was not that we didn't have enough information, but that we didn't analyze it properly. But the response was to collect more out of a fear that, or suspicion, I suppose, that if we just have more information, we'll solve it. And then, you know, data can lie, which is one of the reasons why the government relies more heavily on metadata, because metadata doesn't lie as easily, or it's more difficult to obscure, but I think that's a good point. I think the panel has covered a whole variety of different things, and it's hard to be focused. Which is rather than the issue of national security and spying, and the threat to civil liberties, or the restrictions of civil liberties that have always happened when those things have been threatened, and how much worse all of this could be down with and is with the explosion of information and the explosion of the technology and the accessibility of information. What interests me more, in no way to strike the importance of all that, but what interests me more is the information that we give away so, and willingly, and the implications of that. And that is, you know, all given the accessibility on the Internet of all the data, including our financial data, our medical data, our legal data, our personal lives, what we do and what we don't do, how we spend our money, et cetera. I wondered if the panel could comment more about this psychological, social, and even political ramifications of that, leaving out for the moment the special issue of national security and national safety versus. But the whole change in privacy, or the way in which, at least in America, and maybe in the rest of the world, we kind of willingly are, that's sort of gone or largely compromised. I'd like to start with that. So it's a question about the freely and willingly. I think there's Mauricio Lacerado who said, right, in the 60s, self-expression was a sign of freedom. Today, it's an obligation and a compulsion, which is not just a psychological one, but an economic one. It's an imperative that people create digital profiles. Young people do, right, in order to be able to get jobs, right? So that's one way. It's like this constant need to express oneself, to show oneself digitally, communicationally, in order to connect with the world. There's partially that. I think there's also, there is a change in what it means to share. I don't think it means people just, you know, produce everything without thinking about it. I mean, there are new words, I'd say, in our vocabulary. Sorry? Only adolescents texting to each other. Sorry, adolescents texting to each other? I mean, that's a particular form of communication. Let me text you. Sure. I'm also doing that too. Yeah. So I'm thinking about words that have entered the vocabulary, like oversharing and TMI, which young people also use. Too much information, right? So it's not as though it's unfiltered. I think the questions of etiquette, protocol, and what these filters are haven't been part of a discussion enough, but we're not also asking young people enough. How are they already managing this privacy? They don't want parents looking. They don't want employers looking at everything, right? They don't even want their partners, their romantic partners looking at all of their communication either. So I would just want to complicate the notion that it's sort of this flood that almost is coming from individuals rather than a social compulsion, again, around express yourself, or there's something questionable about you. If you don't express yourself, if you're not on call 24-7, says the family, says the job, says reality TV, right? You're hiding something. So I think that what we've lost is a notion that, yeah, that we might want to say that there's something worth hiding, which is a different one than just saying people are just giving freely and willingly, but what is it worth protecting? Not just its privacy, but its secrecy, which might be a little different too. And I also suggest that it's maybe more a difference in degree and not necessarily a difference in kind. You've always had to share extraordinarily personal information in order to obtain certain services. It is true now your medical records, for example, are often available online, but those medical records used to reside in your doctor's office. The digitization makes them more easily accessible and brings with it complicated questions about informational security and privacy. That's another con, though. Again, a new audience has more gray hair than the population at large, but clearly, I mean, you can go into a restaurant and someone's taking a picture of what they're eating to send to someone as they're eating it, or they're describing what they're doing in the here and now. And so these are another kind of information. But it's hard to compare that to what would have happened 50 years ago when the technology didn't exist. But the point is the technology allows for it, and I do believe there are social rules, psychological things that are changing in modern societies, which are undoing this, loneliness. I mean, silence, not having it light all the time, or being in the dark. We evolved with light and dark. We don't have to be in the dark anymore. We can go on and on. You can talk to someone in a continuous fashion. We're texting in cars as we're driving. I mean, there was a lot of insanity if you look at it from a cultural point of view that are going on. I mean, yes, you have a nice dinner and you talk about it. You say, gee, we went to this wonderful restaurant and you should go with it. We had this dish and you'd describe it if you're a foodie, but now you can take a picture of it. And not only show it later, but show it at the time you're eating. You're not going to show it later. That's the thing. So why not just think of it as temporality? I'm doing it now. I don't have to deal with it later. So it's a moment where it interrupts the present, but it just becomes a temporality. It takes it out of the private. It takes it out of eating the meal, at least either by yourself or with the person you're eating with. And now you make it a public eating. This dessert is now a public act. Now, if you think about it, okay, I mean, maybe that's a good thing. I don't know, but it sure as hell is a new thing. Well, it's always a public act. You're in a restaurant doing it. The question is how big the audience is. We're streaming this event, right? Or where it'll be streamed at some point. Has the role of privacy changed in child development and families? I think it has changed. It's evolving things no longer. Strict signs of demarcations that used to exist. That's a a subjective artifact. My father was not my friend. He was my father. And now fathers have to be friends. And what does friendship require? Well, friendship requires a reciprocality, which means giving up some of your privacy. I actually have been trying to understand that. I'm not sure it's a good thing. I'm just not sure that it isn't leading. Indeed, our parenting is not in fact leading a whole new set of generations. Almost two now to in fact not to just to know everything. And this is part of it. It's ongoing knowing everything. Now, that's a setup when you say there's danger out there and we're going to protect you. Because you used to it to begin with. And now you've got to they're giving you some kind of what seems like a good reason, which of course as you were saying isn't. One, you have to analyze this huge amount that you're collecting, which is not easy to do. But the fact is I think there is a psychological change. And I think we as older people in fact are not as susceptible to it. And I know as I the young and look at the public behavior, I mean others in the room look at therapeutic sense and a different kind of behavior. But in a public behavior, I see things which are just out of my experience. I think we have time for one more question. Two short ones. Okay. I'm a Lexi Kalaturak, a Summit Analyst here at New York Signaling. So I had I think going through a few of the things I'm here, closer sorry. Trust and mistrust, can you believe anything or can you know, certainly the governmental to private citizen level. But I think it also comes up in the use of the technology and families. I've been talking about child development. Sometimes I'll have parents in my office who will say, you know, my kids' new phone has GPS on it. I'll attract them. Well, maybe. And then hopefully we can get into a discussion of what would the purpose of tracking them be? What information would they gain from that? What would they do with that information? And then it doesn't become an easy yes or no answer at that point, which I think is good. So I think it can come up in other ways. You know, is the government benevolently listening to everything or are they really just looking for terrorists or, you know, one of the, I think Obama's not finest moments was basically telling us, don't worry about what the NSA is doing, right? But in a family, that might be okay. In a family, a teenager might come home with alcohol in his breath and a parent may think, should I say something? Well, that depends. Have you talked about this before? Is this the first time? Is this the tenth time? And hopefully what's there is a relationship in which you can maybe trust your teenager to a certain point, but not too much, but that it's established and that you can count on it in some way. Obviously, when we're talking about private citizens and the government, we can't do that. Some people feel you can't trust anything. They say some people feel, well, you know, they probably know what they're doing. So that's why we have rules and I'm very thankful we have people like you guarding our, but the balance of those things. But I think it comes up in other ways too. One other comment just on the issue of sort of groups and dissent. One of the times op-ed columnist from many years ago wrote a column saying, never use your credit card, always pay cash. It was the libertarian guy, I can't remember his name. And I thought, well, why? I mean, it's easy to use a credit card. It's convenient. Well, okay, but I'm not doing anything terribly embarrassing on my credit card or subversive. But if I were a little bit, then I would probably want to be able to pay cash and not worry about it and not have myself targeted. In some way. So I think with texting and with every email being possibly recorded, we may be making a white bread society where it's really dangerous to say anything that's a little too provocative. If you're a student who wants to go to college one day, God forbid somebody from the admissions office somewhere should see your Facebook where maybe you were holding a beer and you were underage, etc, etc. I would say that in the 1980s, they had an album called Give Me Convenience or Give Me Death. 40 years ago to today, it still works. Quick comment, I don't have a Facebook profile and I have experienced a certain amount of peer pressure to get one. I've had friends say to me, come on, it's fun. And I feel like an anomaly that I don't. But my quick question is, were you recommending that individuals encrypt their email correspondence? And if so, how do we get the information? I'm happy to talk to the technology effort, if you like. It turns out if you encrypt your emails, there are special rules that apply for the NSA's collection and they can collect and keep that information indefinitely under pretty much any one of their programs. So the more you try to protect your privacy, the more susceptible you are to NSA surveillance. Now they may not be able to decrypt it immediately, but they can keep it so long as they deem fit. I think this is really one of the fundamental paradoxes of the situation, the hackers are the people that are involved in protecting our privacy, these kinds of dichotomies. No, don't draw attention to yourself. And there are interesting questions about the role of attention and direction of attention in terms of constructing the self when you have all of this information equally available. The one thing that technology can do is make passive or pervasive or dragnet surveillance costly enough not to be effective. It can force the government to engage in targeted rather than dragnet surveillance. And the virtue of that is that the government then will use its limited resources where it should. And it turns out even if you encrypt your communications, it's very easy to encrypt your communications in transit. But it's very difficult to secure your endpoints. It's very difficult to secure your laptop or to secure your desktop. And that's because Windows and Mac and all these operating systems are fundamentally insecure because they're too complicated to make secure. And so if the NSA wants to get to you in a targeted way, they can. And there's nothing to stop them. And that might be a good thing because they're generally when they use their resources in a targeted way or focusing on the right people. And so technology can make untargeted surveillance difficult and force the government to engage in the type of targeted surveillance that should be engaging in. So if I could say yes to you and 350 million other people I would, but if it's just, yeah, we can talk about it. Thank you everybody for coming and for participating so thoroughly and thank our panelists very, very much.