 I'm Ed Nurekseion, the Director of the Center for Today's Roundtable on Transhumanism was proposed by Bill Grasse, whom I will introduce and then he will introduce the rest of the participants. Just two words about future programs. We have a program on boredom on April 22, I believe, and you'll get the notice from our mailing list and then on May 12, we have a program on the completeness of physics. Thank you. We're interested in this topic of transhumanism. For me, it started in 2000 when I was involved in a conference at the University of Pennsylvania on life extension technology and then I started meeting all these people. The science itself is really interesting, but the proponents of it are also very interesting. The whole question of who we are as humans is something that engages me philosophically and otherwise. This question of how we're changing raises all kinds of really important questions. That's how I got into it. My formal training is in comparative religion, religious studies, and of course death is a big issue in that as well. These days I call myself more a big historian. So I'm really interested in the big story that science is telling and how we understand and interpret it today. How about you, Lee Silver? Hi. I'm Lee Silver, professor Princeton. Training is in biophysics, molecular biology. In the 1990s I wrote a book called Remaking Eden which talks about the technological advances that allow genetic engineering and the potential that genetic engineering could be used on humans in the future. The biggest negative response I got was from other scientists who said what you're talking about is never going to happen. 20 years later, in fact, the technology is going faster than even I had predicted. So it's going to happen. We'll talk more. So I'm Father Sandelson. I'm from Arizona State University. I work on three areas. One is the relationship between philosophy and mysticism within the Jewish tradition. Another one is religion and ecology. And the third is religion science and technology. So my interest in transhumanism is through that angle. I actually got to know Billy Grassy through my work with the Templeton Foundation. So I've been in that conversation. I would say since 2003 but seriously since 2006. And I've been writing as a critic of transhumanism. So you're going to hear from me some of the criticism to the views that you're going to espouse. Hi everybody. I'm Francesca Rossi. I work at the IBM Research Center. I also have a professor of computer science at the University of Padawan, Italy. And I've been working in AI, artificial intelligence for many years. I think that my first conference was 30 years ago. So I've seen a lot of ups and downs in this technology. Now is a very high point for various reasons. And this also led me to being interested into the impact of this technology. Not on society or individuals or making us think of what we really want this technology to achieve by itself in autonomy or also together with us. So I think that that's what led me to being interested in the topic of this panel. Because I think that I'm optimistic that by understanding better how we want to shape the future of AI will also make us understand better what we have ourselves and how we want to relate to that technology. But having said that, I'm here I think much less expert than the other ones on the topic of the panel. So I'm here mostly to learn like everybody else. My name is Stephen Post. I direct the Center for Medical Humanities, Compassionate Care and Bioethics at Stony Brook University, Seattle Medicine. I've been there 10 years having migrated across Route 80 from Cleveland, Ohio in case med. I've been interested in pretty much all the great themes related to transhumanism. In the 1990s I was publishing a lot with Peter Whitehouse who had the patent on the colon S. race inhibitors in the treatment of Alzheimer's disease. And we were writing about cognitive enhancement using medications, not therapeutically, but actually to elevate certain kinds of fundamental capacities. I also went to that conference that Lee and Billy were at in 2000 at the University of Pennsylvania and we published a book called The Fountain of Youth which had every kind of scientific and philosophical and world religious and psychological perspective on the benefits and difficulties of anti-aging technologies. And that's certainly just rocketed now. I think way beyond whatever we thought might be possible. I've written a book, Why Good Things Happen to Good People, which is essentially a treat as on happiness. And thinking about whether certain forms of happiness can be technologically sustained, hedonic flow happiness, eudeministic happiness and so forth. Very interested in genetics and the perfect child over the many years in bioethics of course. So all of these aspects of transhumanism come together and they challenge us to think about how we want to recreate human nature going forward. So what do you think? Can we live forever? I don't know. It seems preposterous. But some of the... Lee, you're the biologist here. What are the technologies that are pushing us to the possibility of radical life extension? So when we say we, I assume you're talking about... The human species. And into the future. So I wrote a book that's 20 years ago talking about how technologies could be used to do everything basically that we could. Another DNA, it's not called genome editing because that sounds better than genetic engineering. And we could put in characteristics that would allow humans to avoid disease, live longer, be healthier. And what I've seen over the last 20 years in the field is that these technologies are happening faster than even anybody expected. It's going to happen. So I would say, I don't know, I mean, I don't believe in infinity, but will people be able to... will you be able to have children who live longer? Absolutely. I mean, will we already know how you could do that? Can you do it to yourself? That's not quite as easy. I don't have a response on that. So we're all familiar. Ray Kurzweil's book, The Singularity, it's what now, five, six, seven years old. He argues that there's all these exponential trends and we're moving towards this place where by 2045, we will pass a threshold in which we're going to be able to replenish the telomeres and our chromosomes, replace our organs with genetically cultivated organs out of pigs or other animals. And you know, it's, I guess, the natural human, maximum human lifespan is 125, somewhere around there. It's a current genome. Pardon, for the current genome, right. There are some species that live really long time. Turtles? Turtles. Anyway, that's only one aspect of the Transhumanist project. There's also the enhancement issues that are going on. You're jumping a little bit too much here. Okay, go ahead. You started with living, radical life extension is just one aspect. I would like to suggest that there's a difference between living longer and living forever. But over the gray and other proponents of radical life extension want is basically the postponement of death. There's a perpetual postponement of death. So the first task on the burden of proof is on you in this case to show us that this is a, doable, feasible, and b, is desirable. I would argue that it's definitely not desirable. I'm not a scientist. I cannot say if it's doable, but that's where the science should come in. So we can talk about radical life extension, but it's really one element in transhumanism that requires a lot more conversation and unpacking. Why is it not desirable? Okay, so, and what's the, you're playing into my field of that? Yeah, what's the option? So the option is, options, object, not desirable to who. Okay, fair enough. So let's talk about radical life extension. Why is it a good idea? And why is it not a good idea? So the argument is a title of the book suggests we all want to be young. I would first begin with a question, do we really, do I really want to be 20 years old? I definitely don't. Do I want to be a healthy person in my current stage? I mean my late 60s. Yes, I do. But between that and radical life extension, there's a big difference. So let's figure out what over the gray and other people who push for that agenda really want. They want, or reason. Everybody knows the name over the gray. No, you should know his work. He's a major proponent of radical, operate the gray. Radical life extension. He's a major prophet of that. What does he want? He wants us to be really living forever through perpetual remaking of the human body. The main metaphor is the car. The, the, yeah, well-built car. Are we really, is that a very good metaphor for a human? Not sure. I would argue that it's not. So, but you didn't say, I think, or I didn't hear why it's not there's arable. I mean, nobody wants to go back to being unexperienced, you know, like when we were 18 or so. But moving forward with more experience, more. And so does that. So can we avoid the degrade of our body so that not, not, I mean, so that, you know, we can. But with aging with some, some kind of you lose some, some capacity, yes, indeed. No, but they're not. What's wrong with that? What's wrong with being able to do that? Even though I don't know. There's nothing going on with my life. We will be healthier. The healthier we are, the better it is. But that's not what over is all about. And all the radical life extension project, as well as cryonics, don't forget that. That's also part of the story. What this is about is really immortality now. I would question the logic and the wisdom of this idea of immortality as they understand it in a very materialistic and especially machine based kind of approach to immortality. That's my art. But what would be the problem of it? So let's talk about the, okay. What would be the problem? Number one, what would people do if they live to be 500 years old? Learn, continuously learn. Learn the development. New science. I would make most people's worries. And what exactly would they do? And would the world as we know this planet, a very vulnerable planet can support all those billions of people who are going to live here forever? We can be doing planetary. So then we're going to space the colonization. So space colonization is the extension of radical life extension. That's exactly what's going on. So what's wrong with this debate? Is ancient, of course, and when Francis Bacon wrote, the New Atlantis, there were the waters of paradise, basically a fountain of youth. A hundred years later, when Jonathan Swift wrote Gulliver's Travels, Gulliver comes among a people called the Leagnagians and unusually, occasionally Leagnagians are born who are called Strollbrugs. That is to say, Immortals. And at first, Gulliver is excited about this. But then the chief of the Leagnagians tells him that they become forgetful, deeply forgetful, in their eighth decade of life and can no longer remember the words that were said immediately prior to the moment. And eventually, everyone hates them because they're incapable of communication. So he says to Gulliver, take a few of these Immortals back to your own people and tell them not to fear death. So there's always been the utopian and the dystopian aspect to this. And you bring it right up to the 20th century and you have JBS Haldane and then the reaction of Tolkien whose elves were immortal unless they were killed by a physical blow or in war. But there was a kind of malaise, a kind of listlessness about them, a kind of lack of intensity and purpose. Again, mortality being the mother of creativity, if you will. And so this debate- The mortality is good according to that, the way just back it's- Well, so that's well for Tolkien, for C.S. Lewis, for many others, mortality is a virtue. And Erwin, who is the great figure, gives up her immortality to marry Aragorn because she has a vision of a son. And she realizes that she can live a more fulfilled, eudaministic life by embracing a son as a mother than being an eternal elf. So it seems to me that this notion of mortality is good. When we were at this conference in 2000, Leon Katz, and there was another philosopher, the pro-death camp, is what I call them. And they were arguing against- No, it's a pro-life. I would say it's a pro-life. It's not pro-death. It's life and death at two sides of the same coin. So I mean, I think there's a religious component to this. It was, you know, until the 20th century. There was nothing we could do to expand, you know, make life longer. And it goes along the same lines with disease. There was nothing we could do to prevent most diseases. And so the religious response was, well, it's good to suffer. It sort of, you know, improves your soul in some way. And I think that's, I mean, I don't believe that nonsense. But I also think there's a difference between immortality versus life expansion, you know, in units, you know? Okay. So the human life, some people lived to 120. I think that's probably the maximum right now. And it goes up to 150, 200. I don't see the problem. I mean, the population is not a problem. The Japan, which has the longest lifespan is going down in population. I mean, they're very, very worried. They're not community people left because the women aren't having babies. But of their 120 million people, 14% of them have probable Alzheimer's disease because age is the main predictor. So the whole thing of life extension to me, I don't have an issue with it. And life extension, I mean, life span is the longest at any single representative of a species is known to have lived. Life expectancy is the average life, length of life in a given population in time. Japanese have an 88 year life expectancy. Huge problems with now, if you were to get to a point where we had people living longer, and I actually don't object to it terribly because I think aging is a disease, at least it's a syndrome. Okay? Our cluster of symptoms, it doesn't feel good to me. You have to include in that the compression of morbidity. So if you didn't have the compression of morbidity, for example, the eradication of these chronic diseases of old age, then you would have Swift's worst case scenario, which is extended life, but incredible dysfunction. Yeah, I don't think anybody wants that. For the purpose of what? That's the main issue that we need to put on the table. What's the purpose of being a human being? What do you want to accomplish? So tell us more, transhumanism gives us a purpose, a telos, the telos is posthumanism. So how do they envision the purpose of the whole operation? Ultimately, it's really the mechanization of the human. It's the total immersion and infusion and it's not an interface between the human and the machine. So if we ask, what is it all about? Why are we to live longer? It's ultimately in order to become a super intelligent machine. So that's the difference between transhumanism and posthumanism. Transhumanism is the process of enhancement of all the things that we are doing right now already. We are in a sense in a transhumanist position already or status already, but that's not where we're going to end. What it's all about? It's posthumanism. The total fusion between humans and computers. Are you for that? Are you for that? I'm definitely not for that. So I mean, we are already with technology and science and we are already, our capabilities are already extended by many technological things. And we also have the responsibility to critique what's happening. There's no doubt that transhumanism has impacted each and every aspect of human life today. No doubt about that. That's why I think it needs to be taken very seriously and not dismissed just a full-hardy thing. Some people have done in the beginning of the conversation. When I started working on these 15 years ago, people said, why are you spending time of that? It's all nonsense. I said, no, it's not nonsense. This is where we're going. We've got to critique it. We've got to look at it carefully. I think we're already there there. I think consulting is actually... It's actually better to... I'm back in the late 80s, a really unique thinker. We're Donna Haraway wrote a famous essay called Cyborg Manifesto. And I thought, wow, that's kind of cool. And it's true. And in some sense, we need to think about our technology as part of who we are and it changes who we are. And it's not just the glasses or the computers. Cars are part of nature. It's just a very complicated sex life that uses us as symbionts in their replication. And so... I'm saying this from an environmental perspective or what? I'm saying it in the sense that rather than think of our identity ending with our epidermis, sometimes it's inside our epidermis too, when we have transplants and so on and so forth. But rather than think of it that way, I think we should think of all these prosthetic devices as things that change who we are. And so whether you call us cyborgs or whether you call us transhumanists or when you have a different understanding of posthumanists, I think we're already radically changed species. And we don't experience this so much partly as individuals, but it's primarily a collective expression of who we are as a species and how we're evolving. And if you say, all right, so we're already post-homing, we're already transhumanists. That sort of takes away some of the utopic and dystopic dimensions of it. It's just a big muddle. And it's good things and bad things are both happening at the same time. I think it's great if we can improve health. I think it's great if we can improve longevity. I think it's very unlikely we're going to cure death. And I'll come back to that. I think it's unlikely that we're going to have the runaway artificial intelligence, which is going to take over the human species. But it is very likely and it's already happening that AI will augment all our capabilities. That's more likely than immortality. But the question is whether it's you welcoming it. You're not going to try to create friendly AI. Just before we turn it over to you, I just want to point out that there are people, Elon Musk, I mean Elon Musk, for instance, who thinks that the greatest danger that humanity faces is runaway artificial intelligence that's going to take over the planet and find us dispensable. And so I just want to point it out. And then do you think that's a realistic scenario or something to worry about? Some people worry about yes. Whether I think it's a realistic scenario. Usually it's a question that I don't work on a lot because I think that whether that's going to be realistic or not, I can be better prepared for whatever and whenever that moment will be. If I think about more current issues in augmenting our humanity with AI right now, there are issues to be considered right now. And there are very powerful algorithms and techniques even right now, even if we don't have general artificial intelligence, a very narrow one for the specific task. But still it is super intelligent on that task. So there are issues to be considered right now to work on, to find solutions, to guide these human intelligent augmentation via technology in a way that we can welcome this. Yes, I would like to welcome that. But not that you're asking if I welcome this fusion. If it's a fusion without even thinking about the implications and without thinking about the issues without working on that, maybe not. But if it's a fusion that is done day by day, improving and thinking about the issues and finding collective solutions and guiding it, then yes, I do welcome it. And you didn't tell me why I should not welcome it. Okay. So what I find problematic about the whole AI operation, we are obviously not talking the same language because you're talking about something very specific in the practice of artificial intelligence. I'm talking about transhumanism as basically as the way it should be understood, which is a social imaginary. It's a story. It's a story about humanity, about the destiny of humanity and what we need to do. And I critique it on that level. I critique it from a point of view of a political thinker and intellectually story and so forth. Okay. So we are not really talking the same language. Related. Yeah, definitely related. So my problem is, yes, we are going to live, we are living with machine next to machines, but I don't want to become a machine. I want them to understand. I want people like Nick Bostrom, the idea logs of transhumanism. I want them to understand why becoming a super intelligent machine is a problematic idea. I'll give you these three arguments. Number one, I'm first and foremost a body. I'm not just a pattern that is going to be instantiated in Silicon. I'm an embodied person and this embodied entity has mental cognitive as well as physical, emotional and all the rest. And I want to keep that integrity intact. But if you are going to upload me onto a computer, I'm not going to be the embodied thing that I am right now. I would call it an organism. I will use the organism element once I become instantiated in a computer. Okay, that's point number one. Point number two, the embodied aspect is very crucial because it has something to do with sex and with gender. The one thing that gets lost in this entire conversation is the gender dimension as if it doesn't exist, as if there is no sexuality, there is no reproduction, there is none of that exists. Why? Because all this business was created by men, excuse me. They are all AI operations. But anyway, I would like to protect embodiment. Okay, so that's a very important thing. Also the environmental dimension is very important to me. I don't think that what's going to happen with this AI taking over is good for the planet from environmental perspective. Unless you prove otherwise, let them prove otherwise. Right now, I think that they... What ways are not good for the planet? For example, extracting all those metals that you need in order to do what you're doing. Has anybody talked about what happens? Where do you get all these material from? It comes from the earth and some form... How are they more efficient than human beings? Yeah. So we co-sold from... So we co-sold from... How do you measure efficiency? As energy, human body consumes about 100 watts. Yeah, yeah, of course. I mean, out of being in our brain, it's about 20 watts. When the Europeans proposed some years ago to build a computer simulation of a brain, it was going to take nuclear power plants to do what... Yes, to just to run the computers. So, but then if you take out this uploading of whatever, so the disappearance of the embodiment, which is not something that I'm considering at all, but I mean, if you take those... That's true, that's fine. It's fine. So, I don't have to agree with everybody. But, yeah, there's one more. That's the third element. The real thing that bugs me is the reduction of the human to a pattern. You're dealing with patterns, right? When you're... You turn us into an algorithm. No, I'm trying to use algorithm to augment our capabilities. That's not a reduction to a pattern. Why don't you tell us a little bit about what your research is and what's going on in IBM once? Yeah, but I mean, not just in IBM. I mean, everywhere. I mean, so there are many people in AI that think that the purpose of AI is to augment our intelligence. When are called? So, that's why at IBM at some point, they didn't want to use artificial intelligence because it was kind of misleading as if you were creating another thing by itself and so on. So, at some point, they called it AI, but it was augmented intelligence. And now they said, okay, let's call it AI artificial intelligence, but what we mean is augmenting human intelligence. So, we have our own form of intelligence which brings intuition, asking the right questions, judgment, you know, and the AI has other things that you can do much better than us. So, this complementarity can bring the things together, but with the goal of not making us a machine, but using the machines to help us being better humans, whatever we want. We can define that. We're not going to disappear. We are going to be enhanced. So, I have this optimistic view. Of course, you have to be careful in doing this teaming, AI and humans. You have to be careful in the issues that can come out. You have to be careful in making the machines understand what humans want and not vice versa. You have to be careful in making the machine speak the language that we speak and not the opposite. And so, it really has to be an enhancement of ourselves and not us having to come to terms with the machines desire things. Do they want things to happen? If you tell, I mean, the machine has a goal. The question is, we know that natural selection is a natural process. So, this sounds very science-fiction-y and I wouldn't have thought, I mean, ten years ago, I would have thought this is a total nonsense. But machines that can learn how to replicate themselves or not the machines as much as the algorithm, the programs, if they can learn how to replicate themselves in the world, then natural selection takes over. Kevin Kelly, one of the founders of Wired Magazine wrote a book, What Technology Wants. And it's the old adage, you know, if all you have is a hammer, then every problem looks like a nail. And so, there is a way that, you know, the machines in our lives, whether it's a car, whether it's a computer or, you know, somewhat direct our behavior. Well, that's the autonomous technology thesis and it's certainly the case in medicine. The machinery becomes more elaborate. It takes a lot of effort, but it can be done to get a control over the utilization of those machines. I think, I mean, we keep talking about we as if that means something. Because I don't... You'll mind to... Well, but we're all individuals, right? There's a lot of individuals. I'm not going to, you know, leave my body and go into a machine. I'm not going to let somebody else make me into a machine. But people think that way, then, who is the we that's going to do it? So that's... So now we're on the same page here. I'm saying, and you seem to agree with that, that we need to look at those proposals and be critical of them. We shouldn't just add on this, kind of buy into it without any critical analysis. Let me remind all of us that when Nick Bostum started the whole conversation at least 15 years ago, nobody spoke about the dangers of AI. In his most recent book, 2015, Super Intelligent Machines, only there he even he begins to doubt or begins to admit that there may be some things that we don't want to happen with artificial intelligence. But 15 years ago, he did not even entertain the possibility that there may be some malicious AI. So now they're busy doing friendly AI. If you read The New York Times just a few days ago, there is an essay precisely on that topic. I have it here. And just where is it? Yes, how to make a human friendly? So my problem is, why didn't they listen to the critics 15 years ago? Because 15 years ago, AI was not so pervasive. It was not so impactful on our life and society 15 years ago, we didn't have enough computing power and enough data to make AI learn and be aware of the environment and be used in the uncertainty of the world. So there was no issue because AI was not really giving was only used in very controlled environments. Now, instead, it's different. So that's why people think about these issues. Are we too late? So 15 years ago, I wrote an essay in which I said, our official intelligence that could drive a car across town and park it in the parking lot would pass the Turing test. That would be for me proof of its intelligence and the way that even more than the traditional Turing test. Of course, now that's doable. So one of the things that interests me is the limits, and I've written about this as well, the limits of computation and the possible limits of the genetic engineering as well, that these are complex systems. And the more complex the system gets, the more you start pushing against nonlinear dynamics and unpredictability. And so the genome, I understand to be a bureaucracy, not a bunch of all-off switches. And within computer science, I'm not an expert in this, there are problems that can't be solved. There are problems that, because you can't write an algorithm for it, and there are other problems that are just too hard to solve. And I just wonder whether in these two domains, we might be running up against a complexity horizon. And these two domains are joining. And the brain as well, I would say, is also another potentially. Yes, and those three domains are joining forces. I mean, deep learning now, nobody knows how these algorithms work. Well, that's not exactly true. I mean, nobody knows. No. There's a bit of a black box, but somebody had to set up the black box to work and they have data into it, and they have to... Yeah, but if you ask why you did something, why you made the second decision, which is still a bit opaque. I mean, in some cases, you can go back to the kind of training data that allowed to make that decision, but it's still a bit opaque, much more opaque than traditional logic-based AI systems, which however, which were much less accurate than deep learning. And now there's a reproducibility problem in some of the AI. Yeah. And there should be. Okay, why? I mean, well, first of all, if you're talking about deep learning, and there's many, many hidden layers in the process of the machine learning how to recognize things. So you've given a lot of data and you give it some algorithms and... Yeah, but you know, but it's... Do people know how deep learning works? There is a... Go ahead, play it. No, I mean, it's very simple. I mean, it's not in the details of the algorithm, but it's very, very simple. So if you want an algorithm that can recognize whether in a picture that is a cat or a dog, okay? So you give it a picture and you want this algorithm to say whether it's a cat or a dog, okay? So what you do, you start with an algorithm that is behaving very randomly, okay? It doesn't know anything. And you start giving a lot of examples. What is one example? An example is one picture and the information that I give to the algorithm that I say whether in that picture there is a cat or a dog, okay? So I say, there's a picture, there's a cat, there's a picture, there's a dog, there's a picture, there's a cat. And I give a lot of these examples. And then the algorithm, by looking at one example after the other one in sequence, the beginning is kind of random and then it starts tuning its parameters in a way that it learns this relationship between pictures and whether there is a cat or a dog there. At the end of this, that we call the training phase, you have an algorithm that has some parameters tuned in a certain way that hopefully has learned the relationship between pictures and these two animals and the can able, is able to generalize it to picture that he has never seen before. So now you give it another picture, you don't tell if it's a cat or a dog and possibly the algorithm will be able to recognize whether there is a cat or a dog. And usually with this algorithm, you give it enough data, but not just enough data. If you give it data which is diverse enough, inclusive enough of all the possible situation, then the algorithm is able to generalize. And many deep learning approaches to, for example, automatic vision, like recognizing what is in a picture. Right now a very small percentage of error. An error is always there, but the percentage value is very, very small. So they are very, very good at generalizing. But you need a lot of data for training these examples and you need a lot of computing power because of this amount of data that you have to deal with. So the idea is very simple. You learn by example, which by the way, is something that AI people are trying to move forward from that. Because if you learn only from examples, the relationship between input and output, then if you give it another task, which is very similar to that, but not exactly the same, you have to start this whole process from scratch. Because the algorithm is actually not lamp general idea what is a cat or what is a dog. But it's just lamp this input-output relation. We're just still stupid. Yeah. Of course a two-year-old could do that. Yeah. So what's the utility? And why should we be worried that that's going to take over the world? That's not going to take over the world. That's just got to stop. So basically, this is analogous to the genome. The genome, each of us came from a single cell. And that single cell had information equivalent to 6 billion bits of digital data. That's it. Well, that cell with 6 billion bits of information grew into each human being. Can you change some of those bits and become a mouse, not a human being? And that's an algorithm. We don't know how that works. Evolution created this thing. In a sense, machine learning, the process, there are lots of hidden layers that are not telling the machine how to learn. It's just learning from what you're giving it. And what's happening with the genome and what's going to happen is using the computational tools to be able to see perturbations, how perturbations in the genome affect the output, the final output. How many human genetic diseases have been identified? Simple genetic diseases? Well, you could do 6,000. Well, diseases are not a good categorization. I mean, there are hundreds of thousands of mutations that can cause various diseases. Least started a company called Gene Peake. Gene Peake. Gene Peake. That does pre-pregnancy screening to identify what would be a good match. How reliable, how many traits are you screening for and how reliably. So, you know, I know this is used extensively in acidic Orthodox Jewish communities for certain recessive diseases. But tell us a little bit about where this is leading. The technology has exploded. So just a couple of years ago, you could look at, you know, 20 diseases first, 100. We now look at 7,000. And we look at, we create, we take a presumptive mother and people want to be a mother and a father, we take their DNA, it's digital information, then we create virtual babies, virtual genomes. You don't really know who's contributing the genes. It's 50, 50. Well, we create lots of virtual babies from a couple. And what do the virtual babies look like? Well, so we see whether they have disease right now. But the question is, okay, are there any limits? I'm talking primarily about ethical limits to this kind of screening. Wow. So in my view, people should be able to do what they want with their own data. But what's the goal of this analysis? So you take two people, the DNA of two people, you understand what are most of the many possibilities that are offspring. And then they can, if they want, they can use that information to avoid disease by picking an embryo. If you can embryo that doesn't have the genes causing disease, those in vitro fertilization, they start with a bunch of embryos. So you generate these offsprings, not just virtually, not just on a computer saying, this is the DNA that can come out, but as embryos, that's for them to decide. We give them the information so they can do that. How do you encounter this in hospitals today, Steven? Actually, there is a counter-cultural critique of the perfect baby notion, which is subjectively defined. And that's really the disability model. So people like Adrian Ash, for example, but many others have claimed that with our constant urge to enhance the lives and the lifespans that we bring into the world, that we eliminate the virtue of tolerance, of inclusion of a common or a shared humanity. And we begin as a culture to select certain traits which become definitive of a human being, having any kind of moral considerably. It becomes, if you will, sort of neo-ugenic. Now, that may not be the case, but that's the disability critique is that we benefit when we have, quote unquote, imperfection in the world because it teaches us to be more inclusive and to be understanding that in fact there are deeper things in community than hypercognitive values, hypercognitive achievements, and so forth. So the first thing I think it's very important to point out is that the perfect baby is fiction. There's no such thing as a perfect baby. My mom thought I was. I mean, that's not what people are doing right now. What they're trying to do is, you know, prevent a disease or, you know, provide resistance to a disease. I mean, that's not perfection. And I think it's really, I think people who are against the technology, they use this and it's a red herring. I mean, it's not what we're doing and there never will be a perfect baby. So can I comment on this though that so I actually agree with what you just said because in my view, I don't really engage in the transhumanist conversation at high philosophical levels. To me, it's all incremental. So we're going to have successful anti-aging. I was looking at a remarkable piece of work going on now as of, well, 2016 at the Mayo Clinic and its scripts where they're using an agent which combines chemotherapy and a plant dye, believe it or not. And they're actually eliminating senile cells from the kidneys of individuals with failing kidneys. They've been incredibly successful in mice. Now, this is therapeutic. We're doing things therapeutically but then we'll look pretty good as generalized enhancements. We'll all want to keep our organs from becoming senile, if you will. And similarly, the National Institute on Aging is devoting 55% right now but it's budget strictly to the science of anti-aging. Now that's why because they've given up, frankly, on finding solutions to many of the chronic illnesses, the main precipitating or risk factor for which is age itself. I mean, a hundred years ago, people got dementia because of syphilis, right? Now that they're living into their 70s and 80s, it's age itself and of course Alzheimer himself wasn't sure if he discovered a disease. He actually thought that he discovered a natural part of human senile aging. So because we've got to this kind of midway point where we're all living longer on average, we're so much more subject to these many diseases of old age, including cancer and so forth, that maybe the solution so the NIA thinks is to actually figure out, you know, telemirrically and in other ways what the process of senescence is. And if we can turn that around, okay, maybe we'll be living to be on average 112 years old or maybe 110 depending on who you talk with, you know, people do discuss these things. But if we can compress morbidity and we can get rid of these chronic illnesses, that would become an enhancement but a valuable enhancement. So in many of these areas, genetics, anti-aging, even psychiatry and so forth, I think that we start trying with the attempt to address a therapeutic need and then it just spills over because it's a good thing. I don't know if that makes any sense. No, it makes sense. That's a lot of sense. But usually the boundary between therapy and enhancement is very blurred and it's very fluid. It is. You're saying that it's kind of a natural growth that once we figure out the therapeutic stuff, it becomes enhancement. I don't think that that's where it comes to attention. It tends to. Well, maybe. But a lot of time it's this enhancement that I would call it an ideology. It's ideological thrust. It's kind of, we've got to be enhanced. If you're not enhanced, there's something wrong with you. And don't you dare stand in the process. I'm quoting actually Hugo DeGarris, the Australian transhumanist who said, don't you stand in the middle of this process of becoming perfect? So they use the concept of perfection. That's what they want. But they're just idiots. They're just idiots. I mean, Aubrey's degrade. You know, by the way, it doesn't have a position. He's not even a scientist. He's just a guy who hangs out in coffee shops in Cambridge. He's never met him. No, he's in the United States and he's now funded by the Metuzela. Well, that's true. But I mean, I won't say anything more about Aubrey. I mean, I don't know him too. I've encountered him a number of times. I think these people are sort of, what should I say? They're like adolescents in a science class at age 14 and some crazy idea comes along. And they think, oh my God, that's it. And they have no connection with the narrative of the human experience to be able to think critically about it, which is your point. So just to develop this conversation one more bit here, I wrote the other day to a friend of mine, Francisco Cardeso Comes de Matos, who's the world's leading south. He's a linguist. He's incredibly well known. And I asked him to reflect on France's humanism. Here's what he wrote back in an email. This is from Ressif Brazil. Human health enhancing question mark. Human dignity elevating question mark. Human mind expanding question mark. You know, jobs slept on my floor at Reed College, and he never let his kids play with computers growing up. Human spirituality probing question mark. Human creativity amplifying question mark. You should take a look at Delaney Rustin's great video screenagers, the movie, about how we're struggling with creativity and somatic learning and memory and knowledge and so forth. It's very interesting. With peaceful nature strengthening, human interaction facilitating, human science is integrating. So those are just reflections from someone down in the south. Yeah, but what does this question mark? Yes, it's what does it mean? Well, he's asking me to think about that. Well, the questions that you're asking, Hana, that we need to think carefully about these possibilities. But are those things that are, you know, that would be welcome or not? Well, he's wanting us to question them. Well, I think the implication is that those would all be positive. Yeah. And the question is, does transhumanism work? Right. Well, he's raising an ideology or his actual technology. He's raising many doubts about the transhumanist ideology because he doesn't think that it's attending necessarily. Now I'm not ruling it out, but he's saying his sense is that it's not attending to the most important elements of, shall we say, human enhancement in human, if you will, perfect ability, which has to do with character traits, dignity, empathy. You know, I have a close friend. He's in intelligence. Right. Well, let me just say that I have a close friend who's 90 years old and she was my dorm mother at a high school in New Hampshire. She lives in Martha's Vineyard. She's got one grandson. His son's 12 years old, he was literally raised on screens, okay, unfortunately. And she took her daughter and her grandson to the Swiss Alps for a vacation. And she came back and she called me just this December and she was in tears because she said her grandson has absolutely no empathic qualities. Cannot interact. Cannot even make eye contact. And she was so frustrated. She said it was the worst nightmare of her entire life. But that's why. So that's what we're asking is whatever it is, is it dignity and enhancing? Now some of these things, including, you know, by the way, some of the genetic ideas, are not contrary to human dignity by any means. I don't want to say they are. But these are the deeper questions that you need to be asking. Yeah. The point is, I think the discussion is at many levels and I'm not clear because we talk about increasing lifespan, which is one thing, creating immortality, it's another thing. Becoming all of us just computers and algorithms is yet another thing. But the thing that you are talking about, Francesca, has to do more with AI and the dangers of AI. It's specifically... I'm not the dangers. I will not put it that way. But I will put AI helping us to enhance our own traits and all those things with the question marks. I will say, yes, we can do that. If you are careful enough, we can do all of those. But what helps really? And they should be welcome. But I thought what works. Because with our creativity, enhance our traits and answer, we can do much more scientific discoveries. And discover fewer for money more diseases. No, we know that. But what you were saying also, I thought, was that we need to be aware of the potential problems and dangers in order to not end up in a place we don't want to end up. The fact is that the grandson of your friend has already ended up there. So there was no way to prevent it. And part of the issue seems to me in trying to say we can, in fact, figure out what the problems would be, we may not be able to figure out, just as we didn't know what the effect of social media on us would be, what the effect of the iPhone or the telephone would be on us. So only after the fact we are saying. So it's retrospective. And now people are saying, well, maybe we shouldn't buy into the MacArthur ideology of doing away with teachers in the grade schools and just having people on iPads. Maybe we should be more thoughtful about it. The American Journal of Pediatrics had an entire volume devoted in December to the problem of raising children and getting them into basic social skills. And so now the suggestion is, well, maybe we should hold off until they're 10 or 11 before they're. Look at this. Now we are going to have driverless cars. It seems to be from everything I hear around the corner. So to be. What are going to be the consequences of having driverless cars? What is going to be the consequence on our ability to drive or on our ability to do other physical things? What is going to be the consequence in terms of traffic situations? What is going to be the consequence economically? What's going to be the consequence in terms of insurance companies? And some of these things you can think ahead. But it seems to me that really parts of it, you cannot think until you're dealing with it already. That's too late. Well, it's not too late, but you can't think about it until you have some experience. But the whole conversation has various themes or strengths in it. And it's very hard to really differentiate between them. And it's very hard also to debate with transhumanists because when I asked, you know, I attacked them on one issue and said, oh, no, I didn't say, hey, I actually believe in B. So, okay, you go to B, oh, I don't believe in B, I believe in C. So it's kind of a moving target. It's very, very hard to pin down what's going on. In other words. They don't really take ownership of the consequences that will come about if they're dream, if that social imaginary will come to be a reality. I don't know. I mean, there is this book I was talking to, and I mentioned to you and I was talking to Francesca, but by Max Tech Markets focused on how we can prevent. Life 3.0. Yeah. How we can prevent some of the complications. So, I mean, there is an effort to think about it. And I think there is more of a focus. But you're right that people now think a lot about these issues and how to resolve them because there have been issues that have been shown in some examples. So it was like a trial and, you know, and you were right. Maybe one should have thought that at the beginning, but it was impossible to predict or very, very difficult. So, we saw some issues and I was like, oh, okay. So, let's rethink from scratch. You know, how are we going to develop AI? How are we going to design the AI and embed in the design itself, not just at the end and check how it behaves. And yeah, but embed, since the design phase, these issues that it should not be by as they should be fair, they should be explainable that they should all these things that you want the AI to have in order to not have these collateral negative aspects. But remember, the people who raised those critiques where dismissed as bio-conservatives way back at least 15 years ago, you were bio-conficertives. How can you raise those problems? All the people who spoke about the perils of technology were dismissed off-end. Now it turns out that they were closer to the truth probably than they were. And then they all, it's a tough balance because you don't want to say, okay, no more technology, no more advancement. We are happy the way it is. Let's stay here. On the other hand, there are things that are constant improvements, what you were talking about and what they're doing now, for example, in psychiatry where somebody gives blood and you can tell from the blood what medications will be working properly or better than others, what they would metabolize better than others, so that these are useful. But there is, however, the issue that I think you were alluding to is are there other things that could be dangerous and is it possible to prevent those? And I think some may be so and some may be hard to tell. But I think that now we are in a better position than 15 years ago because 15 years ago, the silos of different disciplines were much more well-defined. You know, technologies to one side, sociologists on the other side, economists on the other side, and they were rarely talking to each other. Now I regularly work and organize events with all these people. And the high people together with psychologists, sociologists, you know, and see all of these. How many humanists do you include in the interdisciplinary conversation? Maybe we should have more. So what I'm saying is that I really see a change in that. And that's what makes me optimistic that we can solve because the high people can find maybe technical solutions to issues, but the definition and the understanding and identification of the issues should be done together with everybody else. Okay, so if you bring the humanist perspective into, and I'm very happy to hear what you just said, but if you bring the humanist perspective, the humanist scholar into this conversation, into the mix, and the humanist would say, you know what? There is a dimension which is nonmeasurable, non-allegrizable, non-reductionable or nonreducable. What do you do with that? Are you saying to this guy, you know what? This is nonsense. Or are you saying, no, I really have to take you seriously. Let me figure out how the non-observable, the non-reducable, how do I fit it into my analysis? That's a challenge. Go ahead and tell us what you think that is. Yeah, one example. Well, you wrote a book called that by whatever names, right? So, I'm happy to talk about a soul as an emergent phenomenon. Okay, so talk about the soul. That's fine. I don't know how you call it. You can call it soul. You can call it psyche. You can call it all sorts of things, which will be problematic for the people who are doing this kind of work. And all I'm saying that I would like to see these people at least admit the possibility of the nonreducable dimension. The non-materialistic, the non-allegory ziable, the non-mathematical. You cannot mathesize that. Why are you saying non-mat of the non-mathematical. You see that there's no contribution. One book on AI today, almost. Yeah, I believe you. So this particular book, he's arguing that the AI project has been mistaken because it was basically based on mind-body dualism. And what he's telling us that we need to go back from a platonic position which under Giro did the entire project to a Aristotelian position that takes the body into account from the very beginning. In other words, the AI, the artificial intelligence has to think through the body or like the body thinks, not like the mind thinks as we think the mind thinks, but as the body thinks. It's a very interesting argument. But if that's the case, it goes against what transhumanism is trying to accomplish. Two things I want to say. Next is that what AI was conceived of 30 or 40 years ago was the AI project, as you call it. I think it's different than what signed. I mean, scientists are just basically, it doesn't matter if the artificial intelligence algorithms match what actually happens in the brain. It's whatever works to be able to solve problems. Problem solving, that's all it is. The typical analogy that is at the beginning of every AI textbook is that planes fly, but they don't fly like bears fly. They don't fall fair. But still, they do fly. So, it's not necessary to have some form of intelligence or to be able to help ourselves to be monitored that they have to replicate our way of doing it. I think the point is, we use AI now. We're not trying to replicate and challenge, to solve problems. The second thing I wanted to come back to is the transhumanism. And just the notion of what Billy said that we're always transitioning human-wise. I mean, 100,000 years ago, people didn't have writing yet. They didn't have the brains that were able to produce novels or anything like that. I mean, they didn't wear clothes until 70 or 80,000 years ago. And this evolution took place. And so, humans have been transitioning. The difference is that transhumanism is for what they call a directed evolution. It's not evolution. It's directed evolution. It's controlled evolution. It's actually accelerated evolution. That's the whole point of evolution. The question is, who's directing it? So, I have a question. Tenshu read the books by Tenshu, if you know Tenshu's work. And he's going to create what he calls Kobe's. Kobe's art. But I think it's really critical to ask the question when you say it's directed evolution. I think directed by a society, like in the... Actually, that's... Well, I would say it's directed by those who take control of the process of engineering. It's the engineer. Those who will engineer the process, they will be in the position of directing it. So, I want to take a big history perspective on this. The sun is going to be a reliable partner on... For complexity on Earth for about 2 billion years. And that's a really big future. There's no reason, based on what we know about the past, to think that our species unchanged will be here forever. I mean, we might be here for... Our descendants might be here for 2 billion years. They have a possibility of living on this planet without science fiction traveling late years with technology that we don't have. And they never have. So the planet is a pretty amazing place. And it's already had a really amazing journey in our species, but it's problems. But what... I mean, isn't it just take it for granted that we're going to evolve into something different? And they may or may not call themselves humans. We're already a domesticated species compared to 100,000 years ago. And how it happens, even if it's... It's still has to work. It has to be selected. It has to have function. A certain amount of dysfunction will be in there too, for sure. And there'll be unintended consequences. But I don't want to see it through the lens of utopia or dystopia, because I think those are dangerous tropes to get into. But the point is that, of course, we're going to evolve. But there's a difference. Evolution is a process. It's a very slow process. It's a process that... Nobody knows really what's going on, but they claim that they can control the process. I don't want them to control. No, but that's not a really professional. It's totally a crucial, more generally. The process is based on reproduction. Who controls reproduction? The women will reproduce, right? As long as the women have the freedom to reproduce. That could be true. It's not the engineers. I mean, I'm in this field, right? I know it's women controlling. If they want to give their child a gene which prevents disease, or they want to avoid... It means the women are doing it. Now, that's one way, right? So, you know, directed evolution could be each individual woman or couple. Culture has been directing human mating for a long time. Yeah, but I think you're talking about... You're talking about a societal... But on this point, I mean, just because this is a great immediate segue and then please go on, but that's where Leon Cass and Hans Jonas come in. Because they would tell you that... I mean, Leon Cass wrote an interesting book. I don't agree. I was his TA for a while, but it's called Toward a More Natural Science. And his argument is that all of the things we really think matter in the quality of our human experience at the family and at the level of community, all of it somehow has to do with the evolution of empathy. As Aldous Huxley said at the end of his life, when someone asked him for some advice for the younger generation, he said, well, it's a little embarrassing because I've written so many books, but I would say try to be a little kinder. His compassion, empathy, attentive listening, all these kinds of virtues are really critical. And where do they emerge from? Well, evolutionary biologists and evolutionary psychologists will spin this a little differently, but fundamentally from the fact that we are a reproductive species, that humans invest greatly in their offspring, who are dependent for very protracted periods of time compared to any other species. And so a lot of these things that we view, you know, altruism and so forth, all the noble aspects of the human endeavor really emerge from this kind of turning over of the generations. So if you move, he would say, toward something that is strongly anti-aging. For example, in Japan, by the way, they are living really long, but they're not reproducing much. Well, that's why the population is going to be opposite of what people thought. Yeah, and so the investment, correct? But because of that? Well, parental investment, well, I won't go. That's not quite the question. I mean, the issue is that so much of this is what Tolkien pointed out. This is why, you know, Erwin separates herself from the immortality of the elves so that she can experience the love of a child and so forth. So that's really important. That's a natural evolutionary dimension. It's not, and for Cass and for Hans Jonas, that dimension is something that is imperiled by anti-aging technologies, which would be humanly directed. Now, I'm not a, but understand, I'm so concerned about these chronic illnesses associated with old age, that I can actually tolerate a little transhumanism. I see that you're going with it, but you forget what they really want. Let's go back to the telos. The telos is, I'll put it very bluntly, it's to make the human biological species obsolete. That's what it's about. It's about the planned obsolescence of the human species. What it is for Ted Shoe, for Giulio Prisco, for Nick Bostrom, for all the people who write in that genre. You can say, okay, they don't really matter because they don't really do the science. They just popularize a certain kind of myth. What difference does it make? It makes a lot of difference because it affects the culture. Even if ideologies are true. It makes a lot of difference. I don't read those people. I have to say, I know that these forces were made out of. Why? Why do you think? I don't read those people. Why do you think humans as currently defined? Why do you think it's so essential that we stay the way that we live? That's a bad idea. But why does the species have to stay the way that we open up for questions? Then we open up for questions. Here is, I guess, it depends kind of where you come from. I come from the Jewish tradition. In the Jewish tradition, as well as in the Islamic and the Christian traditions, we do talk about creation in the image of God. One argument you can dismiss it, you can say, who cares about what religions say. But if you do care about what religions say, you can say, well, there's something really precious about being human. Being human comes with all those vulnerabilities and limitations and kind of words and all. We are not perfect. It's not about perfection. We never will be perfect. Thank God we are not going to be perfect. We should aspire for that kind of perfection. We should aspire more to perfection along the lines that Steve proposed, which is the tradition of Aristotelian and religious tradition. Talk about virtue, talk about character, talk about morality. In that sense, there's an offering. There's a way religion has always been against the kind of progress that we have. No, that's absolutely not true. Not in the middle ages, for sure. I will have to take issue with you here. Actually, many of the people who were doing the forefront of science in the 13th and 14th century were all religious people. How were they handled? I know they were religious, but how were they accepted? The most fantastic thing. Yes, how was Gaggilio? And he was doing the same thing. My manna is the same thing. It's not the case that the religious person was always dismissed by... No, no, no. But that was before Darwin. That was before Darwin. Fair enough, Darwinism is an important turning point. The realization that 100,000 years ago, the human species was different than it is today. That didn't come in... Notion did not come to existence. What I was saying, by the way, doesn't have much to do with religion. I remember looking back now, 30 years, when my wife and I had our first child, we went home. My older sister observed me for a while. A couple of days into this, she said, you know, Stevie, I never really liked you. Until you became a father. Which is a great compliment. But what she saw was that somehow my being had expanded in the care of a child. And there was a growth. Now I don't think that's everybody's journey by any means. Don't get me wrong. But simply stated, many of the key assets that we feel make a human life meaningful and not narcissistic, not I-it, but I-vow, are related to the natural evolutionary trajectory. Now when you get an Aldous Huxley talking about a brave new world, where you sort of engineered that it is dystopian out of the picture, then what do you have left? And that was the question. So again, but I don't want to go any further with it, but I do think it doesn't hang on a religious argument. Let's take some questions from the audience. Wonderful. I'll go around. I'm going to start on this side. I ask you to be brief. If you're going to make a comment, make it short. If you're going to make a question. And then I'll go-yes, I'm sorry. Go ahead, please. That's right. Go ahead, Steve. Go ahead, Steve. I'll post your name. Stuart Danbrought. Just brief background. Brief. Research Fellow at the Artificial General Intelligence Society Research Fellow at Brain Machine Interface Consortium. I do work with autonomous systems at IEEE. I'm ridiculously interdisciplinary and I also focus a lot on ethics. So it's kind of a basic question, really, because we don't have time to go into the technical details. But if, for example, Haba, you had a young person in your family or someone who was still in utero and it was known that they were going to express with, let's say, a fatal heart condition. But CRISPR-Cas9 could be used to prevent that. Would that be something you'd be comfortable with? Yeah, actually I'm going to speak precisely on that issue. Okay, so now how is that different when writ large of the transhumanism discussion we're having? Yeah. It's already been done, a paper about two months ago in utero child had a genetic anomaly that was going to express with heart failure. At some point in his or her, I forget the sex of the fetus, young life. So why is that not extensible to the major objections that you've been raising in this discussion? That goes back to the issue of the separation or at least raising the awareness. There's a difference between therapy and enhancement. So by the way, from the Jewish perspective, Jewish perspective is very pro biotechnology, very pro-crispuh, including the very orthodox and even ultra orthodox. They're very much for using gene editing or genome editing in order to solve that particular kind of problem. I think there's still a difference between that and enhancement, the way that Nick Bostrom and the rest of them speak about. So let me ask, so I... So but there must be a threshold, I mean, because otherwise if you say, oh, we are human also because our vulnerabilities are limits and so on, then you will not even cure any disease because it's part of you. So there must be a threshold that where do you put that threshold? Well, so here's the problem. The problem is that, you know, taking off of this crisper, it may be possible to change the genes of a human being such that a child would be born with a heart that was stronger and longer lasting than a normal human heart. Same thing with every other organ. Now that's enhancement, right? So that, I agree with you that it's tricky here. But I don't have a clear thing, but I don't like is the narrative, the enhancement narrative, the myth that we've been fed by those shall we say, prophets of transhumanism as if that would be the solution to all the problems. That's all, I'll say, we have to go much more, I'll try an error and much more one at a time. Here's an example of something that, yes, the position would be positive. The unbelievable. Right. And we could prevent it. We could change that. Yeah. Yeah. But, but, you know, Nick Prostam used to say, let's try to self-stoip it in the end. We have about six or seven hands up to working, moving. Yes. Stand up. My name is Todd Esig. I'm a psychoanalyst here in the city. And I really appreciated the comments about incrementalism and making things work. And I want to bring up an issue of the fact that every enhancement always has a downside. It's impossible to have a technological advance that doesn't have a loss as well as a gain. And that one of the front lines for seeing the losses of technologies are our practices. And for example, I see many people who are using Adderall for enhancement purposes and their careers and relationships are being destroyed. Like your grandson, we see many people who are having their communications kind of enhanced by communications technology and their capacity for intimacy is being destroyed. So I'd like the people who are kind of involved in the technological front lines to comment on how we can better communicate with you. So much of what medical ethics has been about, you know, there was a time when it was a horrible idea to think that someone didn't have to die with a tube in every orifice, natural and unnatural. And now 70% of people in hospitals die after treatment has been tried and withdrawn. And so we make progress and we have committees and we do case consultations. And so you begin to get a handle through experience and no, nobody can anticipate all of these possibilities coming on down the truck, the track. But as you deal with them as an active agent, you can make successes. But certainly, I mean, I really recommend Delaney Rustin's movie Screenagers, which has been all over the country, just helping families begin to deal process-wise and psychologically with the struggle of getting some control over the kid's screen time, you know, which I guess was a problem when I was a boy because we wanted to watch TV all the time. Right. So throw in a comment, a lot of this stuff, the profit that drives it, is designed to appeal to like our brain stem, our hunter-gatherer brain. It's meant to be addictive intentionally. And so it's partly in the design and the profit motive of Google or Facebook or whatever, to make these devices and their utilities. That's Ken's son of Brookhaven. He wanted to finish up one comment. Yeah, in the medical area, there are M&M conferences and processes are built in. I'm not so sure those processes are currently built into AI development, into genetics development. And so the question is how can those processes be built in with those of us on the front lines, being the downside of technology, be part of your creative process? Yeah. I agree that in all this multidisciplinary initiative that I'm involved, I didn't see much presence of those like you that see the fact, may see some effects of the technology. So definitely I think that that should be more present. And like we, for example, we have put together something which is called the partnership on AI that started from six companies, but now as more than 60 partners of which only 30 percent are companies. And then everybody else, you know, from various disciplines. But I don't think there is any initiative or entity or organization that has to do with SAC one analysis and the effect of the technology. So that definitely is something that should be there. And the goal is to build together best practices in designing and developing AI. So that, you know, these negative effects are not there. And drawing the right boundaries. Boundary creation is key. You know, I mean, the reason why positions have the highest suicide rate of any profession per capita in the country right now and why 50 percent of them respond from coast to coast to surveys about satisfaction saying they quit if they could afford to. I mean, this is serious stuff. You know, a lot of it is because, you know, let's take email, just take email, let alone electronic medical records. They're not connecting empathically with their patients so they lose meaning. It becomes depersonalized. And also they can't get away from it. The email is a machine, that's a machine. They're a human being. They need time away. They need to balance, but they can't get it. And so in that sense, boundary drawing in all these different areas is what's really important and we're not very good at it sometimes. First, I'm going to remove the other side. One thing I'm surprised that I didn't get into is the coming deep integration of DNA from among different organisms, which is already happening. You know, chimeric organisms are already here. But we're now getting to the point where we're going to have deeper integration of human DNA with that of other, you know, not just pigs in order to grow kidneys, which Bob Langer is doing up at MIT, but also, you know, we're going to get to the creation of new beings, the integration of human DNA with that of other non-humans. And we will begin to see things that haven't existed before that have various characteristics good and bad. So sort of curious. That goes back to their environmental argument that I made. Right? So environmentalist are really against that kind of, that's a whole debate about GMOs, right? So from environmental perspective, at least it's, I would go against it. So I mean, I think there's a species to reference there. I mean, if you look, actually look at chimpanzee DNA, most genes are identical to human genes. They're not human DNA. I think it's still 1% or what's a hunch? Chimpanzees. In the genes, less than 0.1% difference. And the conclusion, the philosophical... Well, I mean, what you said was what you're saying is we're going to take information. I mean, every organ is, every living species is connected to other species. So, so these I already showed that there's something wrong with a completely geneticist bottom-up approach because we're not, we're significantly different than chimpanzees. Ah, 0.1% just 3,000,000. But you know, I mean, if you go back to the new Atlantis, which is the definitive initial statement of the biological revolution, I mean, Bacon argued not only for fountains of youth, the waters of youth, but he argued for chimeras. And it's all there. It's all part of the vision. And I don't know that you can get... I think it's inevitable that we'll move in that direction personally. I think we're already incrementally halfway there, don't you? Oh, it's already happened. No. And if it can benefit, if it seems to be benefiting human beings, then mothers will do it. Oh, yeah, we'll do it. Thank you. Thank you very much. And it's a great conversation. Thank you very much for the one of the best here. And I just would like to point, I recently read an article about edging. Physics makes edging inevitable, not biology. It's in now tillus, a candidate that was published in, in, in, uh, laboratory. And on a scale, thermal physics guarantees our decline, no matter how many diseases we cure. It's not my opinion. So that are the, are the article in St. David's, you're a comedian about fake shortages. They, they, um, um, um, make people see and tell them they put, for example, a stand in the heart. And these actually make them as good as people with stance with real state stance. So even surgeries could help like, see, but if so, and, and so our integrations with machines also very questionable in this matter. And even, um, hip replacement also exercises and weight loss. In many experiments had much more effect and much, but effect there's hip replacement. And, and yes, and about AI and about our integration, migration about it. We don't discuss problem with, uh, phantom pain, for example, when people get those legs, then still have pain. Or do you, uh, understand when we, uh, we, uh, it's a question about embodiment, uh, when we get out our voice, uploaded some machine and we want to eat, we want to have sex or we want not just something to see. Don't you think that it will be the perfect reason when we can upload someone there and force leave them forever? Okay. Uh, the honest is on you. There are some cognitive, uh, capabilities that we don't have. So if you surround somebody with an incredible amount of data, our brain cannot handle that. Our brain, as we said, is very efficient, you know, but cannot handle that. So if you have to make a decision and you have a lot of data available to you, but you cannot handle it, you're going to make a decision with just a very small subset of, of information. And so that you're going to make a decision, but probably will not be as good or whatever good means in that context as if you could find patterns and information and knowledge from all that information. So that's something that is not placebo, I think, is something that cannot be replaced by something that we can do by ourselves. We have time now. Okay. I'm Giro, neuroscientist by training. Um, so in the face of the inevitability of the evolution of technology and the evolution of our species, which I think is a fact, um, I do see three major problem with the transhumanist movement, which is that overall it is rooted in low complexity thinking. And by low complexity thinking, I'm saying two things. First, it is reducing human reality to its biological component and its cognitive component, ignoring everything else. Which is really considering very little about what we are. The second also is like it's really classically, uh, offering simple, uh, causalities. And it's having a really bad time to understand every, every single action in a much more complex environment, which means that in the end, we have always this like, uh, conversation about what are the consequences of the thing you, you think is so great. And the step thing is that it's completely ignoring the own emotional development of human beings. And if you have, you know, average human beings, all they want is to be stronger to have a, uh, a body that's going to attract more mates, to have a bigger penis, bigger, bigger boobs. So we know human beings, right? We know what the kind of things we like when we want to be enhanced. So my question, my question is this. Is that is there any hope of, of sort of like, uh, a neo trans, you managed movement that would, yeah, yeah, whatever I said, um, that would actually do the things that it took you 15 years to understand, which is that you cannot, and I'm really not taking it personally, right? It's not, um, which is that we know that any, uh, technological improvement at that scale is going to have negative impact. So let's put together a transdisciplinary approach where we have like philosophers and psychologists and everything, but is that okay? Okay. So maybe you're going to say, yeah, it's a good idea, but do you think there is a real commitment in the world for that? Not just like a good intention in this room. But, I mean, there is commitment because there are initiatives like the one, like the partnership where, yeah, it's one, but there are many initiatives when there in the last two years, I think I've seen, I don't know, at least 10 or 20 Institute centers that are multidisciplinary and they study exactly this, you know, um, the fact that AI can, uh, has this goal you say of enhancing just our cognitive abilities and our, um, um, physical abilities. I mean, that's, that's, I mean, you are, you are speaking as if AI is what has been done for the last 50 years. And now it's done. It's not done. It's a, it continues revolving technology. Uh, after all is only 50 years old and it's really evolving and trying to understand how better and better and we're considering the consequences as well can help us. So I'm not, uh, it could be that the emphasis right until now was into announcing, uh, physical and cognitive capabilities, but I don't think that that's, uh, that the AI people would say, oh, we only want to help that, you know, that that's more and the more you are multidisciplinary, the more you understand these other dimensions. And then the AI people can also understand how to, you know, relate to those other dimensions, I think. So I think somebody like you engage Ben Gertzel, one of the major transhumanist AI who works in. I will engage with anybody. Yes. Yeah. But not the preclude. Yeah. But I want this into this. I saw with Nick bus from to, to events all the time and they speak with him all the time. So, so get him. Yeah, the move in your direction and we'll be in better shape. So I would just have a real quick, um, response in terms of actual transhumanism in terms of our species, um, evolving. Uh, it's, it seems to me that we can't, we can't stop it or let it go. We have no idea where it's going to go. I mean, do I disagree with this notion of directed evolution? No, but nobody's going to direct the evolution of the human species. It's just going to happen on our hands. I mean, I'm into that, but just tell this to Julia Pritzko, who has a whole conversation against what you do. They have no power to, they're, they're, they're like utilitarian somewhere. Correct. It's, you know, creating some sort of idea that does not apply to reality in a democratic society. I'm sorry. If you want to minimize their impact, go ahead and write against them. That's exactly what I've been doing. So we're running out of time. I'm going to ask that the last show of hands, one, two, three, four, that's not going to get it right there. Sorry. I just want to ask you each to make it really quick and you guys hold your, hold yours so you can write notes or whatever. Put it out there and then we'll give you one last chance to respond. So very quickly, please. My name is Bernard Starr. I'm a recovering academic. Several, several months ago, I published an article titled on the verge of immortality or are we stuck with death based on a, I'd say a four hour interview with a cellular biologist, Leonard Haeflick. Oh yeah. I'm sure many of you know. Yeah. Known for the Haeflick limit who set lifespan at about 120 years. And he has a radically different position. He's more or less a naysayer on the prospects of extensive life, life span. And it's a position that I haven't heard discussed here today. He believes that more than believes, he asserts that we know virtually zero about cellular aging and that most of the gains in longevity aside from public health measures that were introduced in the turn of the last century are based primarily on the cure of diseases. And he says, well, that's welcome and most of the funding is in that direction because that's what people demand and that's what the NIH and other funding agencies tend to fund that virtually nothing is spent on cellular aging at all. And that although we talk about diseases of old age, nobody really seriously addresses the question of why do cells age? That he believes that there's a common factor at the cellular level that would lead to a cure of all the diseases. All your comments, we're going to get all the questions out there. Please. My name is Moshe. I'm a psychologist. I'm trying to build on the point that Jill mentioned about the idea of artificial intelligence, technology and basically happiness. It's hard to imagine, we're just the beginning of that technology and expansion if it's cyber technology inside, outside and realizing how much of the people around us because of technology become addicted, anxiety exposed to that and so on and so forth, all the problems. And it has a spirit in itself, by the way, that's so hard to control and to imagine what is going to be, especially with the old stewards of singularity. I'm just curious to know about your perspective about that future that it almost has a spirit in itself that how is that going to impact us if it's at all impossible to predict about our own happiness or maybe spirituality? Thank you. And there was one over two. Very Paul, physics teacher, I was wondering, there was a artificial intelligence program that detected an exoplanet and the way it worked was that this exoplanet had been missed by humans. But we had lots of examples of planets that had been detected by humans and so the program was taught to recognize the planet and it recognized the planet better than humans could. So obviously that's a good thing. But I was wondering how can we defend against artificial intelligence when it might encroach on our privacy and be able to find, let's say it's some kind of disability, say somebody has a disability that isn't really something that is, you know, we should hold against them. And yet this artificial intelligence would be able to detect that. How do we defend against that? My name is Domisio Coutinho. I'm from Brazil. And I'd like to have a few questions, so if it's more common to what I heard, I really understand that it's possible and really admirable in there that it's able to have, you know, looking for artificial intelligence and no question about it, something desirable. But the question is, is there anything other than these that we should look for? We have from Plato a very important saying, nor should you yourself get to know yourself, nor is it an option. Do you know ourself enough? We know you're made from about 70 billions atoms in our body. Everything he has said about the importance of this extraordinary element in our life. Everything that moves, everything that's visible, everything that's around here is made and composed by atoms. What are these little ants, little ants in ourself? They see the potential opportunities made us here to be what we are. They taught us everything we are, how to walk, how to talk, how to speak, how to speak. When we try to improve ourself, improve humanity, do we have to look for somebody else, any place else, other than those who are responsible, or are existence youngers. And then if you do that, sister of the great-to-rate in rooms, you say, who is going to benefit our audience first? The regular human being, the street staff is going to benefit from artificial intelligence primarily, it's up to us to answer that question. However, I will say that these... There's a lot of things that we... I'm an ex-marathon runner. Before I run 1,000 miles, I learned how to run 100 miles. If you had to try to get artificial intelligence, I would ask you, do you know how to deal with the cancer? Do you know how to extinguish your fire that every year starts, thousands of thousands of miles, billions of billions of miles, are out of the United States? And do you cross the army and do not think about it? How about this storm? Thank you very much. Thank you. So, last round for everybody here. You can pick up on any of those pieces. So, I'd like to respond to the hay flick effect. And that idea that there was a limit to the number of cell divisions, and so there was this limit and cells couldn't go beyond the limit and they died and that consequence is that it would mean that there's a limit to human life. Sorry? Right. Now, the several problems with that, that was all done before the realization of what genetic engineering could do. And genetic engineering can make cells, I mean, you don't even need genetic engineering, just cancer. Cancer cells, they go dividing and dividing and dividing forever. We understand how telomeres are lengthened. And the important thing to think about is that if you look at my cells, it goes back in a continuous line back for 4 billion years. I mean, so, you know, it's, the organisms have figured out how to maintain continuity of life, even if the individual organism dies. And I think, I mean, I think hay flick is just, you know, he's of the generation prior to genetic engineering. I think you didn't know the power that was actually possible with that. I tend to agree with that assessment, but I think that's part of the way it is. Well, the second law of thermodynamics doesn't work because, I mean, there's a, there's a energy input, right? I mean, a single thermodynamics, everything's going to degrade if there's no energy input. For next 2 billion years, there's plenty of energy input and, and... At least on this planet. Yeah. Yeah. Okay. So, since there were a lot of questions about the AI, so maybe I'll try to respond to some of them. So, I remember, okay, the last one was about, you know, who is going to benefit for AI, you know, if the people in the street are going to benefit and so on. And I think that actually, you know, the, we can make, for example, healthcare is one obvious and current sector where AI is being used or trying to be used to, and to help doctors to find better cures, diagnosis, therapies and so on. And of course, this will improve the quality of healthcare in our first world, the country, world. But, you know, the main impact will be in developing countries where doctors do not see as many cases, they do not have, you know, the same education and kind of experience. So that's really what the impact is being done, actually. And more generally from that, I mean, again, the multidisciplinary is important because AI people and people in that know the problems that our planet has, like for example, the UN are regularly getting together and studying our AI can help towards the 17 sustainable development goals. For each one of them, what are the issues? What are the problems? How they can be framed and solved by AI in part or totally or whatever. So really, there is an emphasis on the represent the communities developing countries, you know, and what AI can do for that and not just for our first world world. The second one is about happiness and well-being. Again, I think that there are efforts in that direction, you know, to understand how to use AI not just to make us more efficient, but also to improve our well-being. So one example is that IEEE, which is the World Wide Association for Engineers, has put together a very interesting document, more than 200 pages, is called EthicaliAligned Design, which is about all the issues, ethics, issues that can come up when you are developing and deploying AI into the real world and for each one of them possible solutions. And one chapter of this big book is about well-being. So that is something to go. Another thing is that I, for example, am discussing with people that know about well-being and maybe they don't know about it, yeah, to understand really what it means for AI to help improve our well-being, whether it's an individual or a collective well-being and so on. So for example, there is a person, the venerable Tenzin Priyadarshi that I work with. He is an MIT, he is the Director of the Ethics Institute at MIT, and he is an expert of well-being, empathy, and these topics. And he is interested in really working to understand how technology and AI specifically can make us not less profitable, less efficient, but more, you know, and enhancing our well-being and empathy and these traits that are typical than we might want to maintain and even enhance. So I see a lot of things going on, but you have to understand that things are not, I mean, we are not at the point that, you know, everything is concluded and then you can judge AI right now. You know, things are evolving. People are understanding more and more and by talking to each other, especially in a place like this with people that have different point of view, different experience, you know. And then this brings along, you know, a better understanding of what to do. I'm doing it. Well, did you want to? I just want to take a moment. I'm smacked by how much things have changed in our lifetime. We should just be blown. I mean, we live day to day and we get used to this stuff very quickly, but these little devices here and the way we live today, the flying around the world, and we should just sort of take a moment and take a deep breath and say, my, how things have changed in a very short period of time. And remember that they could stop changing or could plateau or it could continue. And if it continues at the pace that it has been, then I think we will be a much transformed species on a very transformed planet for better and for ill. That's how I would frame it. So I think we could stop on that, Douglas. Yeah, that sounds good. I would also say on that little device in front of you, a certain point 20 years ago, very few people had them. Now everybody does. And so every technological development begins with a certain kind of, if you will, an imbalancer and injustice. And if we took that as our sole determinant, then we would have no technological development whatsoever. So I will try to have the last word here by saying that as long as we keep the critical perspective on those developments and not take them as inevitable and as necessary and as determined, then very good shape. But if we buy into the transhumanist myth that it has to happen the way, let's say, tells us it's going to happen, then we have a problem. Thank you. Thank you, Douglas. Good. I'm excited. I'm not going to get the problem. I'm afraid.