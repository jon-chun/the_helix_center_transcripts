WEBVTT

00:00.000 --> 00:24.800
Good afternoon, everyone.

00:24.800 --> 00:31.080
I'm Gerald Horowitz. I'm the Associate Director of Helix Center and I apologize for the delay

00:31.080 --> 00:36.480
in our getting started. One of our participants due to a family emergency is unable to make

00:36.480 --> 00:46.680
this talk on misinformation, coding and misinformation, and the birth of NFTs. And I'll say a word

00:46.680 --> 00:51.120
or two about what we're thinking this topic will be about, but the participants are going

00:51.120 --> 00:55.600
to be the ones who really help decide, and you'll decide among yourselves whether they're

00:55.600 --> 01:01.240
telling you the truth or not. Let me say something first about Laura Edelson, who's not here,

01:01.240 --> 01:07.400
unfortunately, but I'll give a brief description. She is a post-doc researcher at NYU with

01:07.400 --> 01:13.280
the Cybersecurity for Democracy Project, which she co-directs with Damon McCoy. There she

01:13.280 --> 01:19.800
leads the observatory and the ob-observer projects, which aim to increase public transparency

01:19.800 --> 01:26.120
of digital advertising, particularly during elections.

01:26.120 --> 01:32.480
We have here with us today, Susanna Martinez-Khande. Is that the way to say it? Isn't that good?

01:32.480 --> 01:38.600
She is an award-winning neuroscientist, author and a professor at the State University of

01:38.600 --> 01:44.760
New York, Downstate Health Sciences University. She is the founder and executive director

01:44.760 --> 01:51.760
of the annual Best Illusion of the Year contest, which inspired her most recent book, Champions

01:51.760 --> 01:57.160
of Illusion, published by Ferro Strauss and Jerome. Her first book, The International Best

01:57.160 --> 02:02.680
Seller, Sleight of Hands, Sleight of Mind, What the Neuroscience of Magic reveals about

02:02.680 --> 02:09.400
our everyday deceptions was published by Holt and won the Prisma Prize for Best Science

02:09.400 --> 02:14.520
Book of the Year. Martinez-Khande is one of the premier science communicators in the United

02:14.520 --> 02:20.560
States and has made television appearances on the National Geographic's channels, redesigned

02:20.560 --> 02:28.560
my brain, discovery channels, head games, the daily planet, PBS' Nova, Star Talk, CBS,

02:28.560 --> 02:35.600
Sunday Morning and the World According to Jeff Goldblum.

02:35.600 --> 02:41.680
Sidney Gess is an assistant professor of politics and public affairs at Princeton University.

02:41.680 --> 02:46.840
His research and teaching interests lie at the intersection of political communication,

02:46.840 --> 02:52.800
public opinion and political behavior. Via a combination of experimental methods, large

02:52.800 --> 02:58.200
datasets, machine learning and innovative measurement, he studies how people choose,

02:58.200 --> 03:03.880
process, spread and respond to information about politics. Recent work investigates the

03:03.880 --> 03:11.320
extent to which online Americans, news habits are polarized. The popular echo chamber hypothesis

03:11.320 --> 03:16.200
patterns in the consumption and spread of online misinformation and the effectiveness

03:16.200 --> 03:22.560
of efforts to counteract misperceptions encountered on social media.

03:22.560 --> 03:30.280
Yotem up here. Is that, did I get to? Yeah, good. He's saying good enough. Thank you.

03:30.280 --> 03:35.480
He's an assistant professor of communication at the University of Buffalo. His work combines

03:35.480 --> 03:43.080
computational methods for text mining, network analysis, experiments and surveys to study

03:43.080 --> 03:48.720
media content and effects in the areas of political science and health communication.

03:48.720 --> 03:55.080
Dr. O'Pyr authored and co-authored more than 300 peer reviewed academic papers published

03:55.080 --> 04:00.360
in journals such as the American Journal of Public Health, Health Security, Tobacco Regulatory

04:00.360 --> 04:06.720
Science, Risk Analysis, plus one Journal of Communication, Communication Research, Public

04:06.720 --> 04:11.480
Understanding of Science, Journal of Public Health at Health Communication, Communications

04:11.480 --> 04:26.000
Methods and Measures and more. So with that, we're going to get started. I'll after I

04:26.000 --> 04:32.080
take my seat. Okay, so I'm interested in getting things underway and I invite any of

04:32.080 --> 04:37.760
the three of you to jump in and express at least some sort of ideas about what you're

04:37.760 --> 04:43.400
seeing, what everyone of us, I think, is seeing in our culture about misinformation, polarization,

04:43.400 --> 04:51.480
etc. And obviously because the conference is on coding, we're interested in sort of how

04:51.480 --> 04:59.320
digitalization of information may be playing a role in this. So who wants to start?

04:59.320 --> 05:06.040
Okay, I'll offer a sort of starting idea and you'll feel free to sort of revise that

05:06.040 --> 05:10.160
or throw it away later, but just to get things started. I think part of what's happening

05:10.160 --> 05:16.440
or what has been happening is that we have incredible digital communication technologies

05:16.440 --> 05:21.680
that have enabled many people who previously were not able to express themselves at the

05:21.680 --> 05:26.000
sort of ease and scale that they can now. And this created a lot of opportunities for

05:26.000 --> 05:32.240
different people, different perspectives in different groups to express themselves in

05:32.240 --> 05:38.000
society and also to engage with society and participate in society in new ways that I

05:38.000 --> 05:45.600
think have sort of cut against the usual kinds of inequalities. However, what that also means,

05:45.600 --> 05:49.400
another way of saying that is that sort of traditional gatekeepers, including gatekeepers

05:49.400 --> 05:56.480
of information, have lost their kind of received power. And so kind of a flip side of that

05:56.480 --> 06:03.240
potentially is that gatekeepers who exist to kind of maintain hierarchies but also to

06:03.240 --> 06:08.480
vet information for better or for worse, have lost some other additional power. And so one

06:08.480 --> 06:15.880
of the big questions today is sort of who or what, including technologies, is replacing

06:15.880 --> 06:23.720
these kind of standard gatekeepers that have been in place for, let's say, 100 years.

06:23.720 --> 06:27.080
And how do we as society sort of adapt to this new reality?

06:27.080 --> 06:38.560
And I can add to that from a neuroscientific perspective, our brains are not wired to

06:38.560 --> 06:44.080
multitask. It's the opposite. We're wired to pay attention to one thing and one thing

06:44.080 --> 06:50.520
only and suppress everything else. What happens is that when we are pulled in all directions,

06:50.520 --> 06:57.760
we cannot really pay attention to more than one thing at once and arrive to any type of

06:57.760 --> 07:03.720
quality judgment or performance. This is something that happens in magic shows, actually magicians

07:03.720 --> 07:09.200
get us to multitask in a magic show, they split our attention, and that's how they get

07:09.200 --> 07:17.480
away with magical murder. What happens this day is that with all this digital content

07:17.480 --> 07:24.520
and social media, this is really pushing our capabilities to pay attention to the limit.

07:24.520 --> 07:35.280
And so we are, it's very taxing to be able to determine what actual data, what's misinformation,

07:35.280 --> 07:42.440
because everything seems to have the same priority and we are not focusing and analyzing

07:42.440 --> 07:47.720
in any depth for any length of time.

07:47.720 --> 07:54.480
I mean one of the big questions that I think are on my mind recently, is are we really in

07:54.480 --> 07:59.200
a new era of post truth? I mean, because you hear it everywhere, right? That we move to

07:59.200 --> 08:05.440
a different time in human history, but it's not clear to me based on the empirical work

08:05.440 --> 08:14.560
that we've been conducting and based on reviews of previous eras that really crossed a rubric

08:14.560 --> 08:22.360
on to a different time in terms of relationship between humans and truth or humans and information.

08:22.360 --> 08:29.640
I'm wondering in recent years why is everybody so preoccupied with misinformation now? It

08:29.640 --> 08:35.360
wasn't like that 10 years ago, right? When I started, I'm relatively, this guy is new

08:35.360 --> 08:42.120
in the area, but when I started in 2010 to look into misinformation was kind of a niche

08:42.120 --> 08:50.560
topic in social sciences. I wonder if something really changed in the way we communicate with

08:50.560 --> 08:57.480
one another or some external events happen that kind of pushed us to look for explanations.

08:57.480 --> 09:02.320
In other words, are we sitting here because something really changed in how we use media

09:02.320 --> 09:07.520
or are we sitting here because we're still trying to explain to ourselves the 2016 election?

09:07.520 --> 09:12.040
Yeah, what is going on? Well, this reminds me of, I think there's sort of two general

09:12.040 --> 09:19.320
classes of commentators on what's going on with us. So the one class says, oh my God,

09:19.320 --> 09:24.520
this is completely different. We're really in trouble. And then I'm sure you've all seen

09:24.520 --> 09:31.480
other articles that suggested, oh no, back in 1820, there was just as much politicization.

09:31.480 --> 09:38.320
Maybe there was more people were fist fighting in the Capitol building, et cetera. If it's

09:38.320 --> 09:43.960
true that there was an earlier period where there was more of this sort of fermentation

09:43.960 --> 09:50.760
of politicization, can we see anything in common then from now? Is it possible to draw a line

09:50.760 --> 10:02.080
between those two processes? Yeah, I mean, yeah, I know it could please go ahead.

10:02.080 --> 10:07.560
I think they work fundamentally the same people that we were a couple of hundred years ago

10:07.560 --> 10:15.160
and even much earlier. And we are, actually we have the capability and even you could

10:15.160 --> 10:23.480
save the drive to lie and to deceive the brain is the great story better. And we try to make

10:23.480 --> 10:29.800
sense of reality by telling stories about what's happening to others as well as to ourselves

10:29.800 --> 10:36.280
and that we make incorrect connections between cause and effect that has always happened.

10:36.280 --> 10:46.000
And even if something as easy as trying to trick somebody into thinking that we're interested

10:46.000 --> 10:53.240
in something that we're not or the other way around, we are able as primates, we are able

10:53.240 --> 10:59.240
to pay attention to something that we're not looking at for will intend to deceive for

10:59.240 --> 11:04.720
the primates to do this as well. But not every species is able to do it to dissociate what

11:04.720 --> 11:10.920
they're looking at from the place that they're actually paying attention to. So we have these

11:10.920 --> 11:17.400
mechanisms that are inherent to our brains that we have always lied to one another. I

11:17.400 --> 11:25.040
think what's different now is the tools that we have accessible to us. And I think that

11:25.040 --> 11:32.640
it used to be much easier if you don't know is this true or is this a false hood and you

11:32.640 --> 11:39.720
go and you try different sources and you can arrive to the veracity or particular issue,

11:39.720 --> 11:49.080
I think much more in a much more reliable way. I mean, even today you see an image, you see

11:49.080 --> 11:55.800
a video or an audio record. You cannot really tell if this is manipulated or not. This did

11:55.800 --> 11:58.160
not used to be the case.

11:58.160 --> 12:06.800
And I guess misinformation has always been there. It's not a new phenomenon. The only

12:06.800 --> 12:16.560
thing that seems to me is new is more people have access to internet and so on, which allows

12:16.560 --> 12:23.680
them to express their opinions, which before they had no access. So if, let's say, you

12:23.680 --> 12:30.800
were organizing a coup in a foreign country, you gave a story about what was happening

12:30.800 --> 12:36.800
that was in the papers and everybody accepted and nobody said, and if you knew information

12:36.800 --> 12:42.360
that countered the motives that were expressed, you couldn't make it public because there

12:42.360 --> 12:51.600
was no outlet. Now you have questions about, I don't know, whatever political issue, you

12:51.600 --> 12:57.040
immediately put it on the internet and you have an opinion and then other people follow

12:57.040 --> 13:04.440
you. And of course, part of the problem is the more you claim to have some kind of conspiracy

13:04.440 --> 13:11.040
behind it, the more excited you make people get and the more you have tension.

13:11.040 --> 13:15.960
Yeah, I think, I mean, one way of kind of restating a part of what you said is that

13:15.960 --> 13:22.280
propaganda has always been with us. It's traditionally been the domain of elites and

13:22.280 --> 13:27.760
today, the ability to produce propaganda, like a lot of things, has been democratized.

13:27.760 --> 13:32.840
So now anyone can sort of make up their own stories and they can have it disseminated

13:32.840 --> 13:39.000
instantaneously at great and unprecedented scale. So that's one thing that has changed.

13:39.000 --> 13:43.400
Right. And there are positive aspects to it because, like you said, there used to be

13:43.400 --> 13:50.440
like a one version of the truth and there was no questioning and that I'm thinking,

13:50.440 --> 13:55.640
well, something that I'm afraid about is the flu of 1918, what we call the Spanish flu,

13:55.640 --> 14:00.280
when it turns out it did not originate in Spain, actually it's still debated, were it

14:00.280 --> 14:10.760
actually? China, right. Sorry. Start a new rumor. Exactly. So, but the point is that

14:10.760 --> 14:16.400
apparently it is the case that the Spanish newspapers were the ones that were not lying

14:16.400 --> 14:22.280
about the numbers, other places were suppressing that information. So that's how it became

14:22.280 --> 14:28.680
to be known as the Spanish flu. But so that was like, I kind of like a worldwide misinformation

14:28.680 --> 14:35.360
back then, 100 years ago. Right. There may have been this sort of also this movement

14:35.360 --> 14:41.880
going back to their early 19th century where one of the pieces of propaganda was that our

14:41.880 --> 14:48.040
elected officials were dependable, reliable, they were reliable elitists and they were

14:48.040 --> 14:53.520
going to tell you the truth. And that was a useful bit of propaganda to a degree. I mean,

14:53.520 --> 14:57.480
you know, I don't want to sound too cynical about it, but that was a story and narrative

14:57.480 --> 15:02.480
that many people in the United States accepted true or false, but they accepted it, but it

15:02.480 --> 15:07.160
may have done some good because people said, well, I can look to this authority to establish

15:07.160 --> 15:14.000
the truth or falseness. Now we have politicians in this article this morning in New York Times

15:14.000 --> 15:20.040
that shows the number of Republican candidates who deny the results of the 2020 election.

15:20.040 --> 15:29.120
The majority of them deny the results. We're, it's interesting, fake news was is the claim

15:29.120 --> 15:34.200
of the people who've been creating a lot of the fake news, right? So they're not only

15:34.200 --> 15:39.640
producing fake news, but they're undermining everyone's faith in any authority to set

15:39.640 --> 15:44.880
the strength. The term fake news has come to me in something different that it used to

15:44.880 --> 15:51.240
mean some years ago, but it is true. I mean, something that it is not just trusting politicians

15:51.240 --> 15:59.960
and trusting governments, but I believe in trusting in scientists actually, we just published

15:59.960 --> 16:10.840
a paper in which we found in an international sample that the willingness to be vaccinated

16:10.840 --> 16:18.920
for COVID-19, the parameter that was mostly related to with one's willingness to be vaccinated

16:18.920 --> 16:26.920
was trust in scientists. And when this trust in scientists is not there anymore, then you

16:26.920 --> 16:32.680
have people who are thinking, well, why should I be vaccinated? I can do my own research.

16:32.680 --> 16:36.560
And I think that that's what we're seeing also that anybody can do their own research.

16:36.560 --> 16:41.160
And everybody can be an expert. There is no separation between expert opinion and the

16:41.160 --> 16:46.520
opinion that basically anybody could have in any field.

16:46.520 --> 16:53.320
I think if there's one thing, political scientists in my field of political science,

16:53.320 --> 16:59.520
it's the one thing that we have found time and time again is that trust is this core

16:59.520 --> 17:06.040
ingredient in making democracy work. And it's trust in institutions, trust in scientists.

17:06.040 --> 17:14.400
I would add maybe trust in the news media, trust in some basic quality sources of information

17:14.400 --> 17:21.880
about society, just trust is the thing that makes things run more smoothly. And when you

17:21.880 --> 17:29.680
lose that, things can come apart. And so this conversation is making me ask, on the one

17:29.680 --> 17:37.160
hand, trust is good. It has a lot of beneficial properties. But does trust also come with a

17:37.160 --> 17:42.440
cost? So what are we giving up in order to maintain high levels of trust? I think you

17:42.440 --> 17:47.800
suggested one, which is that if we sit on one extreme blind trust, you could blindly

17:47.800 --> 17:53.960
trust the government, you could blindly trust what the news tells you. And we've just seen

17:53.960 --> 18:02.520
through history that that too can have its pitfalls. And so maybe just I don't really

18:02.520 --> 18:07.840
have an answer to this, just to pose it as a dilemma. But I might suggest that there

18:07.840 --> 18:13.320
are perhaps different sort of equilibria that might work. So you could have a high trust

18:13.320 --> 18:21.680
equilibrium where there are perhaps more established gatekeepers, there are more transparent institutions

18:21.680 --> 18:26.920
and people understand how that works. And then we're in the process of moving to another

18:26.920 --> 18:32.280
equilibrium and we haven't quite figured out what that looks like, but it's a destabilizing

18:32.280 --> 18:33.280
period.

18:33.280 --> 18:38.080
And I think that perhaps, I mean, we're trying, I feel like the conversation that we're having

18:38.080 --> 18:46.480
is that it's top down. What can we do to achieve a balance or what should we do that so that

18:46.480 --> 18:54.320
society has a diversity of sources of information, but maybe not too much diversity or maybe

18:54.320 --> 19:00.000
another everybody's opinion should be way the same. I think that perhaps it's a, I don't

19:00.000 --> 19:07.280
have an answer, but maybe we can, there are certainly positives in having accessibility,

19:07.280 --> 19:18.440
having access to all of these kinds of forms of information, even fake news. But what we

19:18.440 --> 19:24.360
are lacking is education. And I think that what we, some of the things that we need to

19:24.360 --> 19:31.080
as a society is to empower individuals and that in the educational systems, I feel like

19:31.080 --> 19:38.120
even today children are not giving the tools to develop critical thinking to be able to

19:38.120 --> 19:44.760
face and evaluate all of these alternative and competing sources of information. So that's

19:44.760 --> 19:47.360
a serious lack.

19:47.360 --> 19:55.000
I want to build on something that Andy said, I think it's a healthy thing to be skeptical.

19:55.000 --> 20:00.080
We are scientists. That's what we do. That's our job, right? I mean, our job is to be skeptical

20:00.080 --> 20:05.720
to a healthy degree to question knowledge even after it's been established and so on. But

20:05.720 --> 20:11.160
what we've, what we're seeing in recent years is kind of a shift that I see as dangerous

20:11.160 --> 20:18.280
from skepticism to cynicism. And I think it has a lot to do with this erosion interest

20:18.280 --> 20:26.160
in institutions of knowledge that's actually predates the internet and social media. I

20:26.160 --> 20:30.240
mean, you can choose a lot of random points to kind of start the discussion of it, but

20:30.240 --> 20:41.640
I'll choose for now the early 90s where conservative talk radio shows like Rush Limbaugh and a

20:41.640 --> 20:50.800
few years later Fox News were launching these campaigns against the institution of knowledge

20:50.800 --> 20:56.960
if it's the mainstream media, if it's the scientific community, basically a populist

20:56.960 --> 21:02.240
argument that elites are lying to you and they're not working for you. I think this

21:02.240 --> 21:09.360
is where you start to see the beginning of the process that we're in the middle of right

21:09.360 --> 21:16.600
now. In the last six years or so, I believe that the Trump presidency pushed it even

21:16.600 --> 21:26.160
farther by not so much spreading specific lies, but challenging the epistemology of

21:26.160 --> 21:30.800
knowledge. I mean, what does it even mean to know something? Who should we trust and

21:30.800 --> 21:35.320
who shouldn't we trust? If you look at Trump's making arguments, for example, and I'm sorry

21:35.320 --> 21:41.000
that I'm making it about Trump a bit too tempting, but all those, all those sayings

21:41.000 --> 21:45.440
that people are saying, right? I mean, Trump says people are saying that the elections

21:45.440 --> 21:51.840
were stolen and now we should accept that as a source of knowledge. The whole perception

21:51.840 --> 21:57.520
that there is no reliable source of knowledge, that everything is subjective and everything

21:57.520 --> 22:05.360
is an attempt to push in the agenda of sorts, is I think kind of the cause of where we are

22:05.360 --> 22:06.360
right now.

22:06.360 --> 22:13.360
In our first panel this morning, Jorgi Bizaki was mentioning how so many of the facts that

22:13.360 --> 22:19.840
we think we know that we ascribe to, we don't know firsthand. We get them from our parents

22:19.840 --> 22:24.600
or from other authorities and we don't have the time to go and validate everyone, every

22:24.600 --> 22:30.080
one of them. If the world's in a state of chaos and it's making everyone anxious and

22:30.080 --> 22:34.960
I think rightfully it's making many people anxious, one thing to say is, well, one thing

22:34.960 --> 22:39.200
to hope for is that you have a great leader who's going to help communicate to you why

22:39.200 --> 22:45.920
you need to stay calm and carry on. And the other thing that can happen is leaders could

22:45.920 --> 22:50.680
say, no, you're right to be anxious, the elites are screwing you and there's a conspiracy

22:50.680 --> 23:00.080
going on. And weirdly enough, that conspiracy thinking, I think puts some of their minds

23:00.080 --> 23:05.280
partially at ease because I think, well, now I have an explanation for why this is going

23:05.280 --> 23:10.360
on rather than having anything more meaningful. I just want to say one other thing, I'm a

23:10.360 --> 23:15.880
physician and I treat a lot of, I'm a psychiatrist and many patients will come to me and complain

23:15.880 --> 23:20.360
about their doctors, their non psychiatric doctors, their primary care doctor or their

23:20.360 --> 23:25.000
cardiologist, whatever. Can you believe he didn't do this or say this or do this test

23:25.000 --> 23:32.080
or she didn't do this or? And I'm skeptical about the quality that some of these patients

23:32.080 --> 23:36.520
may get from time to time. Some of it's excellent, but some of it's not so good. But I always

23:36.520 --> 23:41.480
say to these patients, like, listen, if you want to go with the numbers, go toward the

23:41.480 --> 23:46.680
doctor and do what they tell you, okay, because, you know, it's not perfect, but it's better

23:46.680 --> 23:50.600
than you staying away and thinking you're going to figure this out on your own, right?

23:50.600 --> 23:56.920
So maybe that's a weak argument in favor of trusting authority. You say, look, you're

23:56.920 --> 24:02.560
better off of just imagining them to be honest and fair to you. It's pretty difficult with

24:02.560 --> 24:05.040
what's being advertised these days, right?

24:05.040 --> 24:09.720
And it's true that we need to develop some sort of algorithms for what you should trust

24:09.720 --> 24:15.640
and what you should. Because nobody has the time or the resources to question everything.

24:15.640 --> 24:24.680
And it seems that from regular skepticism about the particular sense of claims, we have a

24:24.680 --> 24:31.560
right-to-situation in which everything is set for questioning. It is different to question.

24:31.560 --> 24:39.560
I believe two vaccines cause autism, right? That has been debunked many times. But from

24:39.560 --> 24:45.480
there, we shouldn't, you know, go on and question whether the Earth maybe is flat and that there's

24:45.480 --> 24:53.080
actually a flat Earth society. I don't know how serious they are. But yeah, I think that

24:53.080 --> 25:02.120
goes again, I think, to the issue of like the expertise. Do we even rely or do we even trust

25:02.120 --> 25:08.120
to recognize that there is an actual thing as an expertise and who gets to be an expert

25:08.120 --> 25:14.080
and who gets to have an opinion that should be valued?

25:14.080 --> 25:20.000
There was this movement that's going on now for many years now. I think it's a high-frequency

25:20.000 --> 25:26.280
trading in the stock market, right? Where these transactions are occurring way faster than

25:26.280 --> 25:31.200
human beings can involve. And I mention that because apparently it does have an impact

25:31.200 --> 25:38.160
that the speed of these transactions has an impact on the dynamics of the market. So I'm

25:38.160 --> 25:43.440
wondering about, because this is a talk after all about coding and digitalization and such,

25:43.440 --> 25:49.760
we are getting a much faster feedback by the social media outlets that are tailoring the

25:49.760 --> 25:56.200
news items we get in a much higher rate. I wonder what you all think about that as a

25:56.200 --> 25:59.200
phenomenon.

25:59.200 --> 26:05.280
I mean, I think you're absolutely right that the velocity, the sheer velocity of information

26:05.280 --> 26:12.320
is increasing. And, you know, I think the most common response to this that I've seen

26:12.320 --> 26:19.040
is that people become overwhelmed and just tune out. So news avoidance is now like a

26:19.040 --> 26:23.120
term for it. There's a phenomenon of news avoidance. People just turn it off. They pay

26:23.120 --> 26:29.040
less attention. The flip side of that is people who actually do want to inject the information

26:29.040 --> 26:35.040
into their veins can do so at the most extreme rate that was never before possible. And so

26:35.040 --> 26:42.240
you have super engaged people who want to consume every little bit of content and are

26:42.240 --> 26:49.080
sort of mainlining like Twitter or TikTok or whatever it is. And then you have everyone

26:49.080 --> 26:54.000
else who's sort of not as engaged. And, you know, that creates a whole set of new problems

26:54.000 --> 26:59.280
for itself, because then you have, imagine the feedback, you have, you know, you have

26:59.280 --> 27:04.040
content producers, you have information sources that are now catering, whether they're fully

27:04.040 --> 27:09.000
aware of it or not to these like most hyper engaged consumers whose interests may or may

27:09.000 --> 27:14.880
not reflect those of the rest of society. And we don't consume all information equally

27:14.880 --> 27:22.040
because we are all subjective to cognitive biases, you know, confirmation bias. We hear

27:22.040 --> 27:27.560
what we want to hear and that this piece of information that is supporting my prior view,

27:27.560 --> 27:37.160
I'm going to really go deep into it and I'm going to process it in high detail with high

27:37.160 --> 27:41.920
focus and that this other piece of information that goes against my views, I'm just going

27:41.920 --> 27:49.520
to ignore, keep scrolling. So, and I think that the fact that we have so many source

27:49.520 --> 27:56.400
information coming at us with high speed and high amount, this only serves to exacerbate

27:56.400 --> 28:01.920
the cognitive biases that we already have because we're overwhelmed all the time and

28:01.920 --> 28:08.560
just defaulting to these ingrained ways of thinking. So, I think it is harder to change

28:08.560 --> 28:11.320
minds today than it used to be.

28:11.320 --> 28:16.320
I know in magic, one of the things they'll do is they'll get you to look here and you

28:16.320 --> 28:22.080
look there and they're getting you to confirm some false belief quickly, right? One, two,

28:22.080 --> 28:26.480
three, and then the trick goes, that takes place, right? And that's a little bit of what's

28:26.480 --> 28:32.800
going on with this, I think, right? There's all this sort of false and it's at least emotionally

28:32.800 --> 28:34.800
stirs you up.

28:34.800 --> 28:40.160
Yeah, absolutely. There's probably a paper about what the psychology and neuroscience

28:40.160 --> 28:45.400
of magic tell us about misinformation because there are so many parallels.

28:45.400 --> 28:52.440
I think the word emotional is key here because when you talk about polarization and the way

28:52.440 --> 28:57.280
the algorithms are maybe pushing us towards our own views, it's important to remember

28:57.280 --> 29:03.360
that most people don't care about politics or don't understand politics at all. I feel

29:03.360 --> 29:09.200
like what we do see right now is a lot of emotionality, a lot of affective polarization,

29:09.200 --> 29:14.040
right? I mean, I hate conservatives or I hate liberals. I mean, I just can't stand them

29:14.040 --> 29:24.000
and what they represent, this kind of sentiment is more driving people than actual understanding

29:24.000 --> 29:30.840
of policy or, you know, deep ideological views. Most people don't care about politics at all

29:30.840 --> 29:37.400
or I understand very little about it. But it seems like more and more we are occupied

29:37.400 --> 29:44.360
with feeling about the other side. That's what I see. I don't think we are more politically

29:44.360 --> 29:46.520
sophisticated now than 10 years ago.

29:46.520 --> 29:48.360
More and more we are.

29:48.360 --> 29:49.360
Say again, sorry?

29:49.360 --> 29:55.800
You said it's not so much that we are actually interested but we are more and more kind of

29:55.800 --> 29:58.000
preoccupied by it.

29:58.000 --> 30:07.360
I think we are more and more identifying emotionally with one side of the cultural divide that

30:07.360 --> 30:13.000
we have in this country and the more we see ourselves as part of one group and not the

30:13.000 --> 30:19.840
other, the more we seem to hate the other group more than we care about the actual policies

30:19.840 --> 30:22.400
that they are trying to promote.

30:22.400 --> 30:26.800
I think one example of how it's not always just about politics either. I mean, the way

30:26.800 --> 30:33.600
we might or might not be manipulated. One is I'm an infrequent user of Instagram and

30:33.600 --> 30:38.200
I don't use TikTok but I understand Instagram says hey, we have to get more of what TikTok

30:38.200 --> 30:40.400
is doing. So we are going to show little videos.

30:40.400 --> 30:45.280
So they show those ridiculously appealing videos of dogs and cats.

30:45.280 --> 30:50.760
And the next thing I'm going with, before I'm able to break away and that's just plucking

30:50.760 --> 30:55.840
in my emotions. There's nothing typically political. It was the one with the bulldog

30:55.840 --> 31:01.880
with the Trump hat on but aside from that it was just emotionally engaging and they are

31:01.880 --> 31:06.760
very good at it. I was like Doritos. You want to have another one and another one and you

31:06.760 --> 31:08.040
keep going.

31:08.040 --> 31:12.720
But the other topic which is again not really political, maybe it is a little bit, but it's

31:12.720 --> 31:18.320
this article today in the paper about this new finding about Chaucer. I mentioned this

31:18.320 --> 31:27.920
earlier today. So Chaucer has been accused by certain literary experts of having raped

31:27.920 --> 31:34.240
somebody. And in any way being a misogynist and a lot of feminist literary scholars have

31:34.240 --> 31:41.680
been applying feminist analysis to Chaucer as the father of English literature so to speak.

31:41.680 --> 31:45.920
Anyway, someone came up with this wonderful, it seemed to be wonderful and it may not be

31:45.920 --> 31:51.400
because we have to be checked. But the interpretation of these legal documents may mean that it

31:51.400 --> 32:00.600
wasn't the word, it wasn't rape. Anyways, this is a special term they use. They seem

32:00.600 --> 32:09.080
to demonstrate that this was basically, the woman was basically defending herself against

32:09.080 --> 32:15.280
the accusations she left her previous employer too quickly and was taking to Chaucer's and

32:15.280 --> 32:19.720
both of them were in defense of this lawsuit. Anyway, I'm sorry if this is confusing to

32:19.720 --> 32:25.520
her. My point is it may have changed the worldview of many of these people. So I'm thinking,

32:25.520 --> 32:30.640
gee, I wonder how some of these feminist scholars are going to react. And I was really pleased

32:30.640 --> 32:35.480
to see that the ones that were quoted in the New York Times anyway had a really good and

32:35.480 --> 32:39.800
measured response to it. You know, like, well, this doesn't mean that everything we do about

32:39.800 --> 32:45.160
feminist scholarship is now invalidated whether or not this is, whatever this, however this

32:45.160 --> 32:50.280
gets determined. But I knew I was thinking to myself, people are invested in a particular

32:50.280 --> 32:55.880
view, you know, and they almost resist the idea of changing. Like, they will disbelieve

32:55.880 --> 32:59.520
they're a little bit more skeptical of the new finding, let's say, because they want

32:59.520 --> 33:04.480
to hold on to their view of the way things are. And I think that's fascinating because

33:04.480 --> 33:09.680
that's, again, it's not exactly a political case.

33:09.680 --> 33:11.640
Isn't that rational that what you just described?

33:11.640 --> 33:16.480
How do you mean? I mean, like, I've lived, you know, I've lived a number of years, like,

33:16.480 --> 33:20.400
I've educated myself about a topic and I've like developed what I consider to be informed

33:20.400 --> 33:25.120
views about things. Find counter a piece of information that like, maybe challenges some

33:25.120 --> 33:29.440
part of my existing belief structure, like, sure, like, you know, I might be skeptical

33:29.440 --> 33:34.280
of it because it contradicts, like, it contradicts my worldview, which I've rationally, you know,

33:34.280 --> 33:39.880
constructed, of course. But like, it would be very strange from a rational perspective

33:39.880 --> 33:43.800
I were doing counter one piece of information that contradicts what I think and then so totally

33:43.800 --> 33:45.800
changed my opinion, right?

33:45.800 --> 33:51.240
But wouldn't you take pride in thinking that you're open-minded to changing your point

33:51.240 --> 33:56.800
of view? And whether I've changed it, you might say, oh, good.

33:56.800 --> 34:01.720
Yeah, yeah, yeah, but I think open-mindedness doesn't necessarily mean that you are just

34:01.720 --> 34:05.200
like, your opinions are being swayed by every piece of information that you encounter.

34:05.200 --> 34:10.280
And I think sometimes that's the idea that people have when the term sort of open-minded

34:10.280 --> 34:14.520
is used. And I think I actually think that would be irrational and totally unworkable

34:14.520 --> 34:18.960
if people went around the world just totally changing their views based on the last piece

34:18.960 --> 34:24.000
of information that they encounter. I'm caricaturing what you just said, but we have people here

34:24.000 --> 34:28.240
with more expertise who could probably speak to what I'm trying to say. But I guess, you

34:28.240 --> 34:31.080
know, often these kinds of patterns where people say, like, oh, you're resisting this

34:31.080 --> 34:35.840
information. Well, yeah, I mean, of course, people are resisting information that like

34:35.840 --> 34:40.240
challenges their worldview. Like, why would we expect anything otherwise? Scientists do

34:40.240 --> 34:41.800
that all the time.

34:41.800 --> 34:52.400
I guess I'm thinking there's a value in believing in your intellectual indifference to the outcome.

34:52.400 --> 34:57.320
I'm not saying you are going to do that. You're a human being and that's natural, it is natural.

34:57.320 --> 35:02.600
But if you say about people, oh, it's only natural, you're going to be in a camp. That's

35:02.600 --> 35:09.960
the camp you're in. And if you say, well, there's a real value in ascribing to some impartiality.

35:09.960 --> 35:14.840
And I think that we've lost a little bit of that, that there's... Trump made some comments

35:14.840 --> 35:19.000
some time ago that, oh, of course, someone made that decision because they're a democratic

35:19.000 --> 35:26.440
judge. And Justice Roberts said, nothing like democratic judges and Republican judges.

35:26.440 --> 35:33.080
Well, I think this is fascinating because I have to say, I don't know anyone in my circle

35:33.080 --> 35:38.400
who, most of those people do not like Trump whatsoever. I think they all go, yeah, he's

35:38.400 --> 35:46.040
right. Okay. Now, see, to me, that comment of Roberts was prescriptive, not so much descriptive.

35:46.040 --> 35:51.960
Like, it's sort of, yes, we should be able to believe in the indifference of our jurists

35:51.960 --> 35:57.520
because that's really the ideal. You say, well, in a real world, it doesn't work that way.

35:57.520 --> 36:00.760
You're being a fool. You're being naive. But you see, instead of saying, oh, good for

36:00.760 --> 36:05.240
you for supporting the idea of impartiality, you're sort of looked at like you're some

36:05.240 --> 36:12.800
kind of knife, right? I think that's unfortunate. I mean, why not believe impartiality as an

36:12.800 --> 36:13.800
ideal?

36:13.800 --> 36:18.640
Well, I think as long as it's clear that this is aspirational rather than descriptive.

36:18.640 --> 36:25.640
I think impartiality is good, but it depends on what it is about. There are certain things

36:25.640 --> 36:32.400
that you can't be impartial about. So if they told you the best treatment for depression

36:32.400 --> 36:42.560
is to hang yourself, you can't be impartial about such a thing. But I think part of the

36:42.560 --> 36:52.000
issue is to be somewhat somewhat, it's said that skeptical and have a certain more balanced

36:52.000 --> 36:58.560
view is that it helps with anxiety. You can see that in your office, if you have a couple

36:58.560 --> 37:04.200
and one of them doesn't trust the other one, the lack of trust becomes a major preoccupation

37:04.200 --> 37:08.560
going around and around. Next thing you know, they're checking each other's cell phones,

37:08.560 --> 37:14.680
they're doing this. So trust is very important and I think what's happening with all this

37:14.680 --> 37:21.680
misinformation is that you end up diminishing people's trust and therefore you get the kind

37:21.680 --> 37:26.840
of agitation that we've seen, especially in this country a couple years ago where everybody

37:26.840 --> 37:31.880
is so agitated, you have patients who are waking up at two o'clock, three o'clock, four o'clock

37:31.880 --> 37:36.440
in the morning. I say patience because that's my sorts of information, but I'm sure some

37:36.440 --> 37:46.200
of my friends were doing that to check the news. And so that kind of thing is psychologically

37:46.200 --> 37:56.480
damaging. So there is a limit to how much misinformation can actually affect people's

37:56.480 --> 38:03.680
mental health and I think it does and to develop skepticism about all the information is a

38:03.680 --> 38:09.360
positive look. I think you're both getting on something important in terms of you mentioned

38:09.360 --> 38:15.280
something about presenting a balanced view and what is a balanced view because hanging

38:15.280 --> 38:20.240
yourself is not a good treatment for depression and you shouldn't be given the same way as

38:20.240 --> 38:31.600
some actual forms of therapy. But this is something that the news media has struggled

38:31.600 --> 38:39.440
with and that leading to the Trump election used to be in a newspaper recording that a

38:39.440 --> 38:45.840
new person two sides of an issue and that's supposed to be balanced. But I think that

38:45.840 --> 38:51.280
reports today they have come to still struggling with this but they're coming to the realization

38:51.280 --> 38:58.320
that I just giving equal time and equal work come to two issues. That's not necessarily

38:58.320 --> 39:08.480
a balanced view or if you're talking about having a TV show with interviews about a panel

39:08.480 --> 39:16.200
about climate change and you have a climate scientist and a climate denier that's not

39:16.200 --> 39:22.840
a balanced view because in one case you have the exception view of a specific issue and

39:22.840 --> 39:30.080
the other case you have somebody who represents thousands of climate scientists so it's not

39:30.080 --> 39:36.840
that's not balanced that would be in balance but I do not think that we have arrived to

39:36.840 --> 39:45.160
the right formula or 100% different size of an issue with appropriate weight.

39:45.160 --> 39:54.760
Well you and Tim you mentioned the cynicism before and you know for me the issue of cynicism

39:54.760 --> 40:04.160
as I was saying in my thesis just a moment ago that if people are considered to be somehow

40:04.160 --> 40:12.200
stupid or naive to be open to some you know consensus opinion or some authority and that

40:12.200 --> 40:18.880
or if they're made fun of for thinking or believing in impartiality that doesn't breed

40:18.880 --> 40:23.560
that doesn't breed trust it just won't you know you're wrong for being for having any

40:23.560 --> 40:29.400
trust in an impartial decision you're just a fool and I'm afraid that's a meme in our

40:29.400 --> 40:36.480
society right now it's keeping us away from forming establishing some kind of legitimate

40:36.480 --> 40:43.160
sources of authority for many of these topics and there seem to be a change in how we react

40:43.160 --> 40:50.280
to evidence I think evidence is maybe a key word here on one hand we have more and more

40:50.280 --> 40:57.120
segments of the population who just reject evidence as irrelevant and on the other let

40:57.120 --> 41:02.920
me take for example you know what the the January 6 hearings right now there is a I

41:02.920 --> 41:08.560
think kind of a feeling that no matter how much evidence the committee will accumulate

41:08.560 --> 41:13.200
some people will not be persuaded by it right maybe because they distrust the source of

41:13.200 --> 41:18.680
the evidence or maybe because they just don't it doesn't change our mind at the same time

41:18.680 --> 41:26.160
where evidence is losing its meaning for many people you now have a new kind of brand of

41:26.160 --> 41:32.720
conspiracies and that doesn't rely on any of it and it's at all I mean I take the they

41:32.720 --> 41:39.440
QAnon conspiracy for example people are willing to believe in in outrageous arguments based

41:39.440 --> 41:47.400
on very little it's it's different even from the conspiracy theories of let's say 2001

41:47.400 --> 41:53.560
where truther is around the 9 11 attacks were trying to collect every bead of information

41:53.560 --> 41:59.120
they could you know they would try to I mean it was of course inaccurate and wrong but

41:59.120 --> 42:03.760
at least it wasn't attempt to kind of find some information that can support their side

42:03.760 --> 42:09.680
I remember all the you know attempts to calculate the heat levels of the metal and what not

42:09.680 --> 42:16.360
these days the new conspiracies are just arguments being thrown around people are willing to

42:16.360 --> 42:23.160
at least spread them without any support whatsoever and at the same time they're willing to reject

42:23.160 --> 42:30.640
the scientific community that that is working around around facts and evidence right and

42:30.640 --> 42:34.840
I think that part of the problem and one of the reasons not necessarily the main reason

42:34.840 --> 42:41.120
but one of the reasons that we don't have trust and that misinformation continues and

42:41.120 --> 42:46.560
impeded is that we have a lack of accountability I don't think that we can have trust without

42:46.560 --> 42:55.160
accountability and I think that perhaps there are some there's a there's a sea change or

42:55.160 --> 43:02.720
the beginnings of a sea change I mean we just had the Alex Jones trial for spreading this

43:02.720 --> 43:11.120
misinformation with the with the with the families of the Sunday Sunday hook victims but

43:11.120 --> 43:18.480
for for a very long time for over a decade he was able to spread this misinformation and

43:18.480 --> 43:25.120
making a lot of money out of it without without any consequence.

43:25.120 --> 43:32.160
I mean just to throw out one other ingredient in this yeah I'm I thought your take on the

43:32.160 --> 43:37.040
sort of objectivity and you know the extent to which sort of whether something is truly

43:37.040 --> 43:43.760
objective say in journalism has been challenged you know I think the you know what's going

43:43.760 --> 43:49.120
up part of what's going on here is that we have claims by kind of established players

43:49.120 --> 43:55.200
so like journalists like judges who are you know they're claiming some sort of objectivity

43:55.200 --> 44:00.800
or neutrality but people you know have they're taking some other evidence like whether it's

44:00.800 --> 44:04.800
their experience or they're feeling that there's no accountability or being able to point to

44:04.800 --> 44:11.120
outcomes that contradict this this assertion of objectivity and they're saying what you're

44:11.120 --> 44:14.800
saying isn't true or you know I don't believe what you're telling us because we have this

44:14.800 --> 44:20.040
other evidence that you know you're obviously biased towards this outcome and it's easier

44:20.040 --> 44:26.520
than ever to obtain that independent evidence that at least challenges these traditional

44:26.520 --> 44:31.920
claims to objectivity and lack of bias and you know one thing that's making that easier

44:31.920 --> 44:37.440
is transparency or just you know the ability to actually collect your own your own data

44:37.440 --> 44:42.200
and make that available for other people traditionally you know most information that people would

44:42.200 --> 44:47.280
use to make these kinds of assessments was channeled through these kinds of gatekeepers

44:47.280 --> 44:53.280
but but today you know whether it's through literally laws that allow people to just request

44:53.280 --> 44:57.920
documents from from government authorities or social media which can take very obscure

44:57.920 --> 45:03.680
pieces of information and suddenly put them in before millions of people suddenly you

45:03.680 --> 45:07.920
know there is other evidence that people can use to challenge these claims to authority

45:07.920 --> 45:15.720
which are based on you know neutrality or objectivity and that can't withstand that kind of scrutiny

45:15.720 --> 45:21.480
you know if people are willing to believe that that the claims are not fully fully based

45:21.480 --> 45:26.560
on yeah like on a solid foundation.

45:26.560 --> 45:33.160
Even the efforts have been to try to police or regulate the messages in social media

45:33.160 --> 45:37.760
and then that that's a fraud to some degree fraud right.

45:37.760 --> 45:45.120
I think people don't understand how unregulated social media is part of it is intentional

45:45.120 --> 45:50.800
I mean we decided to put social media under section 230 which means that we read them

45:50.800 --> 45:55.680
as the technology industry and not a media industry right.

45:55.680 --> 46:01.800
I don't think people understand how arbitrary the process of moderating information on social

46:01.800 --> 46:12.200
media is it's basically still you know based on on those companies making decisions based

46:12.200 --> 46:20.800
on their on their financial kind of benefit they are not legally bound to remove misinformation

46:20.800 --> 46:26.360
there are no clear rules about what's considered misinformation or not this is the wild west

46:26.360 --> 46:27.360
of information.

46:27.360 --> 46:33.840
Why is misinformation bothering us more than that because we have more access to it.

46:33.840 --> 46:34.920
Because what sorry.

46:34.920 --> 46:39.680
Because we have more of it or more access to misinformation why are we so bothered about

46:39.680 --> 46:40.680
it.

46:40.680 --> 46:42.120
I mean we knew it was always there.

46:42.120 --> 46:50.240
I think that what's new about misinformation in the digital era is that we are communicating

46:50.240 --> 46:56.240
now in an environment that prioritized the algorithms that you talked about earlier.

46:56.240 --> 47:02.040
I think for a long time we were worried that the algorithms are pushing us toward information

47:02.040 --> 47:03.560
we already believe in.

47:03.560 --> 47:08.880
So there was a lot of discussion of filter bubbles and echo chambers and all those ideas

47:08.880 --> 47:15.560
but I think these days it seems more evident that the environment that we communicate in

47:15.560 --> 47:21.440
prioritizes engagement I mean at the end of the day it's a financial decision the social

47:21.440 --> 47:26.120
media companies like Facebook and TikTok and YouTube are free meaning they need to make

47:26.120 --> 47:31.560
money somehow when they do that by keeping us engaged for as long as possible collecting

47:31.560 --> 47:35.920
our data and tailoring advertisements to us right.

47:35.920 --> 47:40.880
In order to do that they need to give us information that that's going to keep us interested.

47:40.880 --> 47:45.280
This information just fits the bill better than facts.

47:45.280 --> 47:50.520
I think the information environment that we are working in and almost living in these

47:50.520 --> 47:57.120
days just prioritizes misinformation more than before more than the mass media or mainstream

47:57.120 --> 48:03.760
media era that was more bound to some objective norms of objectivity.

48:03.760 --> 48:09.800
It's something that I think should bother us is about the access and vulnerability that

48:09.800 --> 48:13.200
young people have to misinformation.

48:13.200 --> 48:20.320
This is no and I have three children there 11, 12 and 15 and I noticed especially during

48:20.320 --> 48:27.560
the pandemic during Zoom school and my two all this kids were a couple of years older

48:27.560 --> 48:35.560
at the time I guess 13 and 11 and I learned a little bit too late and that we've better

48:35.560 --> 48:41.480
best to remedy it but they have been subjected to a vast amount of misinformation online

48:41.480 --> 48:48.400
and we have a number of conversations and I have not even been aware of this and that

48:48.400 --> 48:56.040
even with misinformation being kind of like my field in a sense but this was basically

48:56.040 --> 49:02.360
happening in front of me and I wasn't seeing it and young people they have access but they

49:02.360 --> 49:07.080
don't have the tools it's difficult to have the tools as even as informing as informed

49:07.080 --> 49:14.720
adults but in some of these misinformation is specifically targeting children and young

49:14.720 --> 49:20.080
people and yeah I think it's a big problem and it's a no problem.

49:20.080 --> 49:27.480
Well if it's true that it's way less regulated and never in the past would that mean how

49:27.480 --> 49:33.520
would it be regulated now is that something you're in favor of?

49:33.520 --> 49:39.600
I mean it's I mean if you're talking about things that are targeted to children I mean

49:39.600 --> 49:44.400
that seems like a pretty ripe area for regulation that seems like yeah that seems like that's

49:44.400 --> 49:51.040
a pretty pretty uncontroversial statement so let's start there.

49:51.040 --> 49:56.080
Yeah are we skipping a right are we going to regulation now?

49:56.080 --> 50:01.240
I mean I was interested in actually peaking off something else that you said so I mean

50:01.240 --> 50:06.120
you've been talking a little bit about sort of learning basically like training and teaching

50:06.120 --> 50:14.400
people how to basically sift through the information that they encounter and there's been a lot

50:14.400 --> 50:21.120
of talk about you know trying to improve educational efforts both you know in children and even

50:21.120 --> 50:26.040
later in life so I've been very interested for example in things like digital data.

50:26.040 --> 50:31.040
Media literacy you know trying to come up with ways of improving people's digital literacy

50:31.040 --> 50:39.920
skills as a potential solution for people's susceptibility to misinformation and so I'm

50:39.920 --> 50:44.360
curious if you've like you know ever kind of thought about that or if you've encountered

50:44.360 --> 50:49.400
these kinds of issues if you are optimistic about these kinds of approaches for helping

50:49.400 --> 50:51.680
to solve this problem.

50:51.680 --> 50:58.160
Well optimistic I don't think this is the only solution but I think it's an integral

50:58.160 --> 51:10.640
part of the solution and because I mean to be able to sift through all of this information

51:10.640 --> 51:17.680
and decide what to keep what to discard you first need to be aware of your own vulnerability

51:17.680 --> 51:21.360
so you have to be aware that there are all of these various sources of information.

51:21.360 --> 51:28.960
I think also there's lack of awareness of our own just neurological susceptibility

51:28.960 --> 51:36.960
such as human beings with the nervous systems that we have how we can folkry to all sorts

51:36.960 --> 51:38.760
of perceptual cognitive biases.

51:38.760 --> 51:44.920
I don't think that this is really well understood or accepted you think okay I'm going to be

51:44.920 --> 51:51.080
able to I know that there is misinformation out there but I know myself I know that I

51:51.080 --> 51:56.080
can make a good decision and you can convince yourself that you can be a good judge and

51:56.080 --> 52:02.000
but fundamentally you have to realize that you have to keep questioning yourself because

52:02.000 --> 52:07.600
you are vulnerable in ways that are not going to be apparent to you.

52:07.600 --> 52:12.320
I want to go back to regulation for a second it's a really tough topic and all of us are

52:12.320 --> 52:14.840
struggling to answer those questions.

52:14.840 --> 52:19.160
I think there are two parts or two components that we need to consider.

52:19.160 --> 52:25.640
First is what do we regulate and the second is who is supposed to do that.

52:25.640 --> 52:29.640
So the first one is hard I mean both of them are hard but the first one is really really

52:29.640 --> 52:34.720
hard because the amount of misinformation right now is so big that we cannot regulate

52:34.720 --> 52:39.720
all of it right so we need to make a decision on where to draw the line in the sand.

52:39.720 --> 52:46.720
For me for example I mean it's still vague but my kind of border line will be where people

52:46.720 --> 52:55.560
live or well being are put at risk right so maybe we wouldn't regulate any misstated

52:55.560 --> 53:00.040
argument on the internet but if something is for example the conspiracy is putting a

53:00.040 --> 53:06.600
complete full racial group at risk for example maybe that's the place where you want to intervene.

53:06.600 --> 53:10.760
So first of all we need to decide what to regulate and what not I mean what kind of

53:10.760 --> 53:13.200
lies to take down and what not.

53:13.200 --> 53:19.880
The second problem of course is who's going to do it and both options are pretty bad.

53:19.880 --> 53:24.360
One option is to let the government do that and we know that in the past governments

53:24.360 --> 53:27.200
had abused this power.

53:27.200 --> 53:33.360
The Chinese government for example right now is regulating TikTok in a way that removes

53:33.360 --> 53:42.040
let's say information that's favorable to the Hong Kong and Taiwanese side right.

53:42.040 --> 53:46.560
We can think of other examples from the history when governments use their power to regulate

53:46.560 --> 53:50.200
information to detrimental effects.

53:50.200 --> 53:55.640
The other option is to let the companies themselves do that and that once again is problematic.

53:55.640 --> 53:59.440
Do we trust Twitter to decide what's truth and what's false.

53:59.440 --> 54:03.600
Do we trust YouTube to be the arbitrators of truth.

54:03.600 --> 54:05.000
The answer is of course not.

54:05.000 --> 54:08.960
They are first and foremost business people.

54:08.960 --> 54:17.380
Their concern is with the bottom line of their companies and they don't have a motivation

54:17.380 --> 54:20.680
really to keep the information environment clean.

54:20.680 --> 54:25.480
Now between these two if I had to choose I would still go with the government because

54:25.480 --> 54:28.520
at least the government is being elected by the people.

54:28.520 --> 54:34.160
I mean nobody elected Mark Zuckerberg to have so much power over information.

54:34.160 --> 54:35.480
Politicians are not perfect.

54:35.480 --> 54:49.320
But at least as citizens we have some authority over selecting them or monitoring their behaviors.

54:49.320 --> 54:56.240
So no solution is perfect but I think we need to start talking about government regulation.

54:56.240 --> 54:58.040
It happens in other countries.

54:58.040 --> 55:03.080
I mean in the United States it sounds like a big deal to ask the government to interfere

55:03.080 --> 55:09.560
with information but take Germany or Austria for example where it is illegal to deny the

55:09.560 --> 55:10.560
Holocaust.

55:10.560 --> 55:16.360
I mean there are laws in place and again how do you decide what to make into a law where

55:16.360 --> 55:23.520
something is becoming an existential threat to people's safety.

55:23.520 --> 55:26.920
So maybe it's time to start seriously thinking about regulation.

55:26.920 --> 55:29.040
I wasn't actually necessary.

55:29.040 --> 55:32.720
I didn't want you to get the idea that I was in favor of regulation although I know there

55:32.720 --> 55:35.840
aren't that many obvious solutions to it.

55:35.840 --> 55:43.160
I also agree with the idea of educating people more to try to become more skeptical.

55:43.160 --> 55:48.840
I'm a little bit pessimistic about educating people basically because of what your original

55:48.840 --> 55:54.400
premises which is we're really prone to these sorts of trickery.

55:54.400 --> 55:58.040
We just are as human beings.

55:58.040 --> 56:02.120
And then there's this sort of general idea that there's a, you know it's interesting

56:02.120 --> 56:07.560
that there's so much skepticism about truth started on the left.

56:07.560 --> 56:15.640
There's a lot of critics of skepticism and the relativism of truth started on the left

56:15.640 --> 56:20.120
and then it's sort of really been appropriated by the right now.

56:20.120 --> 56:25.240
And so we have both camps have become relativist which is difficult.

56:25.240 --> 56:31.320
Right, as people say well I don't think the government on the one hand should be the ones

56:31.320 --> 56:34.680
who decide what's true or what's not true.

56:34.680 --> 56:38.720
And then the other people say we should be free to say whatever we want.

56:38.720 --> 56:40.280
We want the First Amendment rights.

56:40.280 --> 56:43.200
Everything's turned upside down.

56:43.200 --> 56:48.120
But maybe the idea might be also, you know, first of all I think when folks say well for

56:48.120 --> 56:57.080
example Holocaust denying is illegal in Germany I don't think about their legal system around

56:57.080 --> 57:01.880
that but I imagine if you've been cited for claiming the Holocaust wasn't real you might

57:01.880 --> 57:07.440
have some ways to address that legally to try to, no I didn't do it or was it work of

57:07.440 --> 57:10.040
art or whatever, you know something of that nature.

57:10.040 --> 57:12.400
I would think maybe that would be something that would happen here.

57:12.400 --> 57:16.040
The other is you can get together these businesses and say look you have to come together with

57:16.040 --> 57:18.760
to some consensus of what's legitimate.

57:18.760 --> 57:24.360
Let the companies do it as a group and let them know that otherwise it's going to be

57:24.360 --> 57:27.280
the government's going to step in.

57:27.280 --> 57:32.200
It's interesting that a lot of, I mean you were mentioning where the groups being oppressed

57:32.200 --> 57:37.320
because of false information I think Alex Jones was a good example but one of the things

57:37.320 --> 57:42.280
that came up with Alex Jones and I know we've all heard about this in other context is that

57:42.280 --> 57:46.000
there are people getting threatening phone calls and you can imagine that that's something

57:46.000 --> 57:53.200
you could keep a record of and it could be something used as a trigger point for there's

57:53.200 --> 57:54.680
something has to be done about this.

57:54.680 --> 57:56.240
This is leading to a lot of threats.

57:56.240 --> 57:59.440
I don't know what you all think of that as a possible.

57:59.440 --> 58:03.200
Yeah I mean that's something that would probably be illegal you know offline with a telephone

58:03.200 --> 58:08.440
so why would that be legal if you're doing it through Twitter or through Facebook.

58:08.440 --> 58:13.080
I will say I thought the way you framed that was very good.

58:13.080 --> 58:16.640
You know personally in terms of regulation I feel like we actually had a pretty good workable

58:16.640 --> 58:18.600
solution for a while.

58:18.600 --> 58:23.040
This section 230 idea which is we're going to let there be a flourishing of different

58:23.040 --> 58:24.040
platforms.

58:24.040 --> 58:27.240
They can all figure out their rules and people can sort of go to the platform whose rules

58:27.240 --> 58:28.680
that they like.

58:28.680 --> 58:34.480
Problem is that was not designed for a world in which we have like two or three huge platforms

58:34.480 --> 58:39.320
that have come to somehow dominate our kind of public sphere or that's what it seems

58:39.320 --> 58:40.640
like anyway.

58:40.640 --> 58:44.080
It was for a world in which there was like AOL and copy serve and all these little dial

58:44.080 --> 58:47.920
up services and the stakes just don't seem so high.

58:47.920 --> 58:51.960
And so you know the question to me is is there a way to sort of adapt this kind of like middle

58:51.960 --> 58:58.320
path to our present day reality which just does not reflect the reality in which the

58:58.320 --> 59:00.720
original regulations were drawn.

59:00.720 --> 59:04.400
So I did included.

59:04.400 --> 59:09.920
I'll just say the idea bearing section 230 was that if you're a technology company that

59:09.920 --> 59:15.760
produces let's say a phone you can't be held responsible for what people say on the phone.

59:15.760 --> 59:18.400
But with Facebook and Twitter that's not the case anymore.

59:18.400 --> 59:24.200
Their algorithms are determining which information will be more permanent which information will

59:24.200 --> 59:26.280
be more obscure.

59:26.280 --> 59:31.600
Meaning they are beginning to hold not beginning they are holding editorial role of what's

59:31.600 --> 59:35.560
being said on their platforms and maybe they're not a technology company anymore.

59:35.560 --> 59:39.720
Maybe they are media companies at this point and if they are we need to regulate them just

59:39.720 --> 59:45.160
like we did for cable TV and newspapers and all the media that came before.

59:45.160 --> 59:50.240
Yeah I think the question really does come down to the extent to which there is some

59:50.240 --> 59:52.080
sort of editorial discretion.

59:52.080 --> 59:56.720
It's like literally this is literally what some of the court cases now are hinging on.

59:56.720 --> 59:59.280
So it actually isn't the case that there aren't regulations or laws.

59:59.280 --> 01:00:01.160
There actually are regulations or laws.

01:00:01.160 --> 01:00:06.920
They're going to be made by one actor or another whether it's a court right or some sort of

01:00:06.920 --> 01:00:12.320
de facto rule by a company and so I think what we should try to figure out is whether

01:00:12.320 --> 01:00:18.520
the public can sort of play a role in determining what the rules are going to look like because

01:00:18.520 --> 01:00:22.400
the rules are going to be set one way or another.

01:00:22.400 --> 01:00:29.000
I included the reference NFTs which are a little bit have receded a little bit in the

01:00:29.000 --> 01:00:33.760
media coverage of LA but I saw it as a being an effort.

01:00:33.760 --> 01:00:39.400
I mentioned this to you earlier, Rotem, it's like an effort to reestablish authenticity

01:00:39.400 --> 01:00:46.400
in some way because these are ways in which these things are supposedly indelible and

01:00:46.400 --> 01:00:54.400
not open to dispute and similarly Bitcoin which have a relationship in the cryptocurrencies

01:00:54.400 --> 01:00:58.160
the idea that okay we don't want to trust the Fed anymore with the way our money is being

01:00:58.160 --> 01:01:03.480
managed we're going to find this sort of democratized way of making sure our money is

01:01:03.480 --> 01:01:09.080
transactions are I don't want to ledger that's indelible how quickly that sort of what do

01:01:09.080 --> 01:01:13.080
you think about the fact that how quickly this is sort of it was like a little bit of

01:01:13.080 --> 01:01:16.840
a fat and it seems to be I don't know if it's going to receive forever but it has receded

01:01:16.840 --> 01:01:21.760
a little bit.

01:01:21.760 --> 01:01:27.200
One thing that interests me about NFTs is that we perceive them as less authentic as

01:01:27.200 --> 01:01:33.440
you said than money but for me it's kind of ironic because money was always.

01:01:33.440 --> 01:01:34.440
Fictional.

01:01:34.440 --> 01:01:36.160
I mean right, I mean what is money?

01:01:36.160 --> 01:01:41.640
What does it mean that I give you a piece of grain paper that has no value at all you

01:01:41.640 --> 01:01:44.880
cannot wear it you cannot turn it into a tent or anything you know.

01:01:44.880 --> 01:01:46.160
It depends on trust.

01:01:46.160 --> 01:01:50.840
It depends on trust right I mean the only reason money works is that I can give you this piece

01:01:50.840 --> 01:01:55.560
of paper and both of us know that you can take this piece of paper to a genet by the

01:01:55.560 --> 01:01:58.520
share with it right.

01:01:58.520 --> 01:02:04.200
I think the NFTs are just another iteration of the same old idea of imagining a financial

01:02:04.200 --> 01:02:10.440
system and making up rules to play by but yeah it seems like these days it's kind of

01:02:10.440 --> 01:02:12.200
collapsing I don't know.

01:02:12.200 --> 01:02:16.240
I'm not an expert on NFT but it seems that the.

01:02:16.240 --> 01:02:25.480
In the NFTs there is no country behind the NFT it's between the buyer and the seller

01:02:25.480 --> 01:02:30.960
but with the let's say the owner you have the United States treasured guaranteed that

01:02:30.960 --> 01:02:36.400
what's guaranteed the NFTs was.

01:02:36.400 --> 01:02:44.480
Just trust in the other or in the market.

01:02:44.480 --> 01:02:50.280
In a way it connects to the previous point you started talking a little bit about kind

01:02:50.280 --> 01:02:56.400
of libertarian models of communication what if we just let people be and hope that they

01:02:56.400 --> 01:02:59.600
are going to do the best with it.

01:02:59.600 --> 01:03:04.480
We seem to put a lot of hopes into that and it's true for NFTs but it's also true for

01:03:04.480 --> 01:03:07.480
social media and discussion.

01:03:07.480 --> 01:03:14.400
We built this utopian perception of media environments like the internet where if we

01:03:14.400 --> 01:03:19.120
just let people be themselves if we don't tell them what to you know what to read or

01:03:19.120 --> 01:03:24.560
what to think or what to say the best content will always prevail and it doesn't seem to

01:03:24.560 --> 01:03:25.560
hold water.

01:03:25.560 --> 01:03:30.760
When push comes to shove it seems like we're not always looking for the best content.

01:03:30.760 --> 01:03:36.080
We're not always trying to spread the most accurate information.

01:03:36.080 --> 01:03:41.760
It's nice to kind of dream about the libertarian world where you can just leave people through

01:03:41.760 --> 01:03:44.880
their own devices and they're going to do the best.

01:03:44.880 --> 01:03:47.040
It doesn't seem to work.

01:03:47.040 --> 01:03:52.560
Do you think this concern about misinformation is going to diminish over the years since

01:03:52.560 --> 01:03:57.200
there's so much of it and people will then start thinking well I'm reading all this but

01:03:57.200 --> 01:04:07.600
it's misinformation so that they develop a sense of skepticism of a degree that unless

01:04:07.600 --> 01:04:13.360
they find real evidence in something they just dismiss it.

01:04:13.360 --> 01:04:15.240
I think arguably it's already diminishing.

01:04:15.240 --> 01:04:19.880
I think it's being replaced with other concerns.

01:04:19.880 --> 01:04:29.560
For example you hear a lot about other kinds of consequences of social media like harassment,

01:04:29.560 --> 01:04:34.720
hate speech, even things like incidility, things that just also make things unpleasant,

01:04:34.720 --> 01:04:38.480
have a lot of harmful effects but don't necessarily hinge on the question of whether something

01:04:38.480 --> 01:04:42.200
is factually accurate or not.

01:04:42.200 --> 01:04:47.120
I guess my prediction would be the next time that there's a new big technological shift

01:04:47.120 --> 01:04:54.120
in mass communication that raises worries about whether people will be manipulated in some

01:04:54.120 --> 01:04:58.000
way we'll hear again about misinformation.

01:04:58.000 --> 01:05:04.000
Now I think the conversation has sort of moved on a little bit and misinformation is I think

01:05:04.000 --> 01:05:10.080
a potential harmful effect of social media but there are lots of others and I think it's

01:05:10.080 --> 01:05:14.240
perhaps healthy that we're kind of making some room for some of these other things as

01:05:14.240 --> 01:05:15.240
well.

01:05:15.240 --> 01:05:21.760
And I think it will be unlikely that people will just, anything that I read, anything

01:05:21.760 --> 01:05:26.800
that I see on the web I'm going to discharge.

01:05:26.800 --> 01:05:33.600
I think it's going to keep, it's being curated currently it's going to be even more so that

01:05:33.600 --> 01:05:40.040
it links to the polarization issue but I think that people will always have some particular

01:05:40.040 --> 01:05:46.720
sources of information that they trust implicitly and they'll be seeking that kind of content

01:05:46.720 --> 01:05:49.760
that they already predisposed to trust.

01:05:49.760 --> 01:05:56.120
So I don't think that there will be like a widespread skepticism about any sort of

01:05:56.120 --> 01:06:00.640
information but perhaps more polarization, heaven.

01:06:00.640 --> 01:06:10.000
I think the idea behind NFTs and cryptocurrencies was an effort to sort of codify a form of

01:06:10.000 --> 01:06:12.800
authenticity and it fails.

01:06:12.800 --> 01:06:16.040
It does fails because what people need is more trust.

01:06:16.040 --> 01:06:22.280
And you know you like to think well if I codify it I make it absolutely unassailable yes

01:06:22.280 --> 01:06:26.120
or no that that's not replacing trust between human beings.

01:06:26.120 --> 01:06:28.280
It's really an interesting, right?

01:06:28.280 --> 01:06:31.280
That isn't a good point.

01:06:31.280 --> 01:06:37.480
I agree that that's potentially a cautionary tale but I'm not sure, I guess I don't know

01:06:37.480 --> 01:06:39.080
if that's universally the case.

01:06:39.080 --> 01:06:44.440
So here we have a situation in kind of financial markets, right?

01:06:44.440 --> 01:06:52.360
So maybe like we really need trust to sustain a healthy market.

01:06:52.360 --> 01:06:56.960
But I see some more things going on with our previous discussion about how do you know

01:06:56.960 --> 01:06:59.880
which sources of information to trust.

01:06:59.880 --> 01:07:02.800
Can we replace that kind of trust with authenticity?

01:07:02.800 --> 01:07:05.640
Well I think that's happening too, right?

01:07:05.640 --> 01:07:10.200
If you look at where, I mean when I just talk to my students, you know, they don't even

01:07:10.200 --> 01:07:12.840
think about information in terms of trust.

01:07:12.840 --> 01:07:16.760
They think about influences that they follow.

01:07:16.760 --> 01:07:23.280
They think about broadcasters who they find authentic or real.

01:07:23.280 --> 01:07:29.040
So people are already using authenticity as a sort of a metric for where they should

01:07:29.040 --> 01:07:31.480
get information.

01:07:31.480 --> 01:07:36.360
And so it is a question to me as to whether that sort of replacing trust with authenticity.

01:07:36.360 --> 01:07:43.120
But is that cause or effect like do you trust some influencer because they're authentic

01:07:43.120 --> 01:07:44.760
or they seem authentic, will you trust?

01:07:44.760 --> 01:07:46.360
Really, I know it's a good question.

01:07:46.360 --> 01:07:48.160
It's a good question.

01:07:48.160 --> 01:07:49.600
Yeah, yeah.

01:07:49.600 --> 01:07:52.960
But I guess like one way that you could think about this, I don't know if this is accurate

01:07:52.960 --> 01:07:58.120
but you know as trust is sort of declined across the board in a number of spaces.

01:07:58.120 --> 01:08:04.520
People still need something that can just simply solve the problem of like where do

01:08:04.520 --> 01:08:05.520
I turn to?

01:08:05.520 --> 01:08:06.520
People will always find shortcuts.

01:08:06.520 --> 01:08:07.520
Yeah.

01:08:07.520 --> 01:08:09.000
What shortcuts do I use?

01:08:09.000 --> 01:08:14.560
And maybe I'm just using these words interchangeably or something but it's like there is something

01:08:14.560 --> 01:08:19.520
about the authenticity of the messenger now that seems different than this kind of traditional

01:08:19.520 --> 01:08:20.520
notion of the problem.

01:08:20.520 --> 01:08:21.520
But I don't...

01:08:21.520 --> 01:08:23.520
The apparent of this.

01:08:23.520 --> 01:08:25.160
The apparent, yes, exactly.

01:08:25.160 --> 01:08:27.640
I'm all in favor of authenticity and I agree with everything you said.

01:08:27.640 --> 01:08:32.040
And I'm just saying that thinking you're going to find it by having it digitalized that

01:08:32.040 --> 01:08:37.560
the other thing, this is going to be vouch safe by the digital, the code is not going

01:08:37.560 --> 01:08:38.560
to happen.

01:08:38.560 --> 01:08:42.080
If Bitcoin and other cryptocurrencies ever take off, it's not going to be because they

01:08:42.080 --> 01:08:43.080
have...

01:08:43.080 --> 01:08:47.880
Because of the tech, their blockchain technology, it's going to be because people start to put

01:08:47.880 --> 01:08:49.880
trust into it.

01:08:49.880 --> 01:08:53.000
It's not going to be because of the technology is what I'm saying.

01:08:53.000 --> 01:08:56.000
Well, it's like something that inherently can't be hard coded.

01:08:56.000 --> 01:08:59.320
Like, well, at the point where you have to sign a contract with someone, it's like,

01:08:59.320 --> 01:09:00.800
well, you're not relying on trust anymore.

01:09:00.800 --> 01:09:02.240
Like, you know, right?

01:09:02.240 --> 01:09:03.240
So...

01:09:03.240 --> 01:09:08.400
Well, should we open up the floor to some questions?

01:09:08.400 --> 01:09:09.400
Does anyone...

01:09:09.400 --> 01:09:10.400
Does anyone here have any questions?

01:09:10.400 --> 01:09:11.400
Why don't you come over here?

01:09:11.400 --> 01:09:14.400
No, please, because one of them...

01:09:14.400 --> 01:09:21.680
Pick up a demike.

01:09:21.680 --> 01:09:27.560
So I'm curious, with so many different views of reality and everything you guys have been

01:09:27.560 --> 01:09:33.360
talking about, how will history be written about our time?

01:09:33.360 --> 01:09:35.440
Will it be in parallel tracks?

01:09:35.440 --> 01:09:40.240
Will there be a history that is true history of what was real?

01:09:40.240 --> 01:09:42.240
What was fact-based?

01:09:42.240 --> 01:09:44.640
We never had true history.

01:09:44.640 --> 01:09:45.640
Yeah.

01:09:45.640 --> 01:09:51.640
Well, maybe, but it seems like it's more at risk now than possibly it's been.

01:09:51.640 --> 01:10:02.200
I mean, there's a book by Vargas Losa that came out last year about the events in Guatemala

01:10:02.200 --> 01:10:07.560
and the U.S. role in whatever it was that happened in Guatemala.

01:10:07.560 --> 01:10:18.280
Well, that only is something that came up in a more consistent and coherent way with Vargas

01:10:18.280 --> 01:10:19.800
Losa's book.

01:10:19.800 --> 01:10:26.080
So what is the accurate history of what happened in Guatemala until that point?

01:10:26.080 --> 01:10:30.080
No, I know what's the problem.

01:10:30.080 --> 01:10:35.720
History's written through the eyes of the historians.

01:10:35.720 --> 01:10:40.160
But this seems even more fraught with conflict about what reason did that.

01:10:40.160 --> 01:10:42.160
I think I'm not that I'm an historian, but I have a little bit more faith.

01:10:42.160 --> 01:10:46.760
There's going to be a consensus that will be built over time.

01:10:46.760 --> 01:10:52.480
Right now, historians just agree about the way things went and they reinterpret parts

01:10:52.480 --> 01:10:57.600
of history still to this day and not always in a highly polarized Democrat versus Republican

01:10:57.600 --> 01:11:02.560
way, but just because they're honest disagreements among historians about how things go.

01:11:02.560 --> 01:11:05.440
I mentioned a story about Chaucer today is a good example.

01:11:05.440 --> 01:11:07.560
That may be debated.

01:11:07.560 --> 01:11:15.520
I think among academic historians, there will be enough of a consensus about what's...

01:11:15.520 --> 01:11:23.600
Actually, I am more optimistic about the future historians than I am, but what's happening

01:11:23.600 --> 01:11:24.600
today.

01:11:24.600 --> 01:11:34.000
Because I do think that the access to information and to spreading information, there are so

01:11:34.000 --> 01:11:37.040
many people today, like anybody has a voice.

01:11:37.040 --> 01:11:43.760
And so future historians will have access not just to establish experts, governments,

01:11:43.760 --> 01:11:51.680
borders, but we don't know how the everyday person used to think about in the Middle Ages.

01:11:51.680 --> 01:11:55.080
They didn't have a voice that we have been able to recover today.

01:11:55.080 --> 01:12:01.760
So I think that future historians will have to shift through content, but they will have

01:12:01.760 --> 01:12:08.400
a lot more to work with than we have today about the arrest passed.

01:12:08.400 --> 01:12:10.000
But that itself is going to pose...

01:12:10.000 --> 01:12:15.000
It's going to be this challenge of abundance versus...

01:12:15.000 --> 01:12:18.000
What is the scientist that I will say?

01:12:18.000 --> 01:12:20.000
Do you have too much data?

01:12:20.000 --> 01:12:21.000
I agree.

01:12:21.000 --> 01:12:23.000
Which is like a practical matter.

01:12:23.000 --> 01:12:27.000
I've tried to reconstruct what people have said on Twitter last week.

01:12:27.000 --> 01:12:28.000
And you should try it sometime.

01:12:28.000 --> 01:12:34.640
It's really hard because people are responding to other people directly and indirectly.

01:12:34.640 --> 01:12:43.200
People are making vague references to things that are not always obvious after the fact.

01:12:43.200 --> 01:12:48.520
Reconstructing the context, I think is going to be increasingly difficult because it's

01:12:48.520 --> 01:12:54.720
told through memes and references that are constantly evolving.

01:12:54.720 --> 01:12:58.320
And it's going to be trying to decipher hieroglyphics in a way.

01:12:58.320 --> 01:12:59.320
Perhaps so.

01:12:59.320 --> 01:13:03.280
And will that information be preserved in forms that are accessible?

01:13:03.280 --> 01:13:06.280
Well, yeah, just because it's digital doesn't mean it doesn't decay.

01:13:06.280 --> 01:13:07.280
Exactly.

01:13:07.280 --> 01:13:08.280
Yeah.

01:13:08.280 --> 01:13:11.680
Well, hopefully there will be people who are academics who are motivated to do that work

01:13:11.680 --> 01:13:13.280
on the hieroglyphics.

01:13:13.280 --> 01:13:14.920
I like to think there is.

01:13:14.920 --> 01:13:22.720
A lot of people who have written about history, books about historical developments are not

01:13:22.720 --> 01:13:24.760
always exactly historians either.

01:13:24.760 --> 01:13:30.240
And we can think of economists who have written pretty divergent views, Hayek and Keynes,

01:13:30.240 --> 01:13:35.200
and pretty divergent views about how history is going to economic history, but also general

01:13:35.200 --> 01:13:36.200
history.

01:13:36.200 --> 01:13:37.400
And we've survived with that.

01:13:37.400 --> 01:13:42.640
So I'm reasonably hopeful about that.

01:13:42.640 --> 01:13:43.640
Anybody else?

01:13:43.640 --> 01:13:47.600
Oh, please step up to the mic.

01:13:47.600 --> 01:13:49.680
Okay.

01:13:49.680 --> 01:14:00.200
So since we have some political scientists here, the first thing I want to ask this concept

01:14:00.200 --> 01:14:04.440
is a little tangential, but it comes back political science.

01:14:04.440 --> 01:14:10.720
My understanding is science is you observe the world, you make theories, you test those

01:14:10.720 --> 01:14:15.280
theories through experiment, and then you see if your theories were correct.

01:14:15.280 --> 01:14:25.640
Now, if we want to guide this in the context of today's topic, misinformation and algorithms,

01:14:25.640 --> 01:14:32.920
would a political scientist be able to conduct an experiment on this topic and make predictions

01:14:32.920 --> 01:14:34.000
in theories?

01:14:34.000 --> 01:14:40.440
And is that something they would do, or even more generally would do, political scientists

01:14:40.440 --> 01:14:43.720
just make predictions but don't run experiments?

01:14:43.720 --> 01:14:46.240
Can you comment on that a little bit?

01:14:46.240 --> 01:14:48.080
That's a great question.

01:14:48.080 --> 01:14:49.080
Yeah, you're right.

01:14:49.080 --> 01:14:56.320
And as sort of social scientists, we want to be able to make and test hypotheses, which

01:14:56.320 --> 01:14:59.600
often means you're testing predictions.

01:14:59.600 --> 01:15:05.280
So certainly, speaking for myself and my own research, everything that I try to do fits

01:15:05.280 --> 01:15:07.320
the framework that you just described.

01:15:07.320 --> 01:15:10.960
When you're talking about misinformation, things become difficult because there are ethical

01:15:10.960 --> 01:15:11.960
issues involved.

01:15:11.960 --> 01:15:17.520
So if I could think of the ideal experiment that I would like to run, it would involve

01:15:17.520 --> 01:15:21.600
exposing people to a ton of misinformation and see what happens.

01:15:21.600 --> 01:15:23.440
Well, that doesn't seem ethical to me.

01:15:23.440 --> 01:15:25.240
And so I can't run that.

01:15:25.240 --> 01:15:26.240
You can't rat.

01:15:26.240 --> 01:15:27.240
Sorry?

01:15:27.240 --> 01:15:28.240
You can rat.

01:15:28.240 --> 01:15:29.240
Exactly.

01:15:29.240 --> 01:15:29.920
So you can do it in rats.

01:15:29.920 --> 01:15:38.080
And so part of the creative challenge of doing this kind of research is trying to explore

01:15:38.080 --> 01:15:43.480
ways of studying these questions in ways that don't require you to be a mad scientist,

01:15:43.480 --> 01:15:44.480
basically.

01:15:44.480 --> 01:15:49.560
It involves natural experiments, so have platforms changed the way that they've operated.

01:15:49.560 --> 01:15:55.320
And so does this speak to this particular hypothesis about, say, the effects of misinformation?

01:15:55.320 --> 01:15:58.120
The other thing is that a lot of the most interesting research that's happening right

01:15:58.120 --> 01:16:03.880
now, both by political scientists but also people in psychology and other fields, and

01:16:03.880 --> 01:16:11.920
in communication, is trying to test the effectiveness of different kinds of solutions for misinformation.

01:16:11.920 --> 01:16:13.560
So take it as a given.

01:16:13.560 --> 01:16:19.040
How can we do to reduce people's belief in misinformation in ways that don't infringe

01:16:19.040 --> 01:16:21.960
on other kinds of values, like free expression?

01:16:21.960 --> 01:16:25.240
So I think this is all a very active area of research.

01:16:25.240 --> 01:16:30.520
But I agree that we want to take this sort of scientific empiricist path to understanding

01:16:30.520 --> 01:16:31.520
these questions.

01:16:31.520 --> 01:16:41.600
Can you give a performance for us to give some sort of experience with, well, not on a sometimes

01:16:41.600 --> 01:16:48.040
sort of misinformation, we have the number of experiments with misdirection, as you might

01:16:48.040 --> 01:16:50.800
have, in a magic show.

01:16:50.800 --> 01:16:58.120
We actually study magic tricks directly to investigate various kinds of cognitive biases.

01:16:58.120 --> 01:17:02.360
So you can do these kinds of things.

01:17:02.360 --> 01:17:06.440
It's a bit less of an ethical concern where you're investigating magic tricks, but you

01:17:06.440 --> 01:17:09.680
can get similar kinds of issues.

01:17:09.680 --> 01:17:15.200
I'll just add, oh, I'm so sorry.

01:17:15.200 --> 01:17:21.720
I'll just add that, first of all, there ain't one approach to scientific inquiry of political

01:17:21.720 --> 01:17:22.720
science.

01:17:22.720 --> 01:17:29.040
Both Andy and me are more quantitative and, I guess, post-postivistic in nature, but some

01:17:29.040 --> 01:17:34.600
people don't accept that as the only way to understand the world.

01:17:34.600 --> 01:17:39.960
In the area of misinformation, specifically, I think that in both your field of political

01:17:39.960 --> 01:17:45.880
science and in my field of communication, we are getting very good at building microtheories

01:17:45.880 --> 01:17:53.360
of misinformation, which can be tested experimentally in the lab or in controlled environments.

01:17:53.360 --> 01:17:59.680
What we are not able to do is to use scientific methods to answer those big questions.

01:17:59.680 --> 01:18:03.160
Like, how does misinformation influence our society?

01:18:03.160 --> 01:18:07.280
That's something you cannot put into a lab or you cannot create two societies that are

01:18:07.280 --> 01:18:12.160
equal on everything except for the presence of misinformation.

01:18:12.160 --> 01:18:16.200
So I think we're spending a lot of our time on the micro level of just understanding the

01:18:16.200 --> 01:18:18.840
psychological processes.

01:18:18.840 --> 01:18:24.200
And in their regard, we are taking a very, an approach that's very similar to the hard

01:18:24.200 --> 01:18:28.440
science as much as possible within the creation of movements.

01:18:28.440 --> 01:18:29.440
That's such.

01:18:29.440 --> 01:18:33.920
Well, first of all, thank you for this wonderful discussion.

01:18:33.920 --> 01:18:40.800
And a few years ago, a study made at MIT Media Lab.

01:18:40.800 --> 01:18:50.200
The question was, do fake news spread faster and more than real news or truthful news?

01:18:50.200 --> 01:18:53.040
And the answer was yes.

01:18:53.040 --> 01:19:01.280
So the problem is why and one may think well because of bots and new technology that can

01:19:01.280 --> 01:19:03.560
multiply the diffusion.

01:19:03.560 --> 01:19:08.400
But the result of the study tells something different.

01:19:08.400 --> 01:19:17.280
Apparently, fake news spread faster because of human beings, because of the emotional

01:19:17.280 --> 01:19:21.600
reaction they evoke.

01:19:21.600 --> 01:19:27.560
So my question is, when we are discussing the impact of new technologies, the temptation

01:19:27.560 --> 01:19:31.240
to be apocalyptic is already at hand.

01:19:31.240 --> 01:19:34.480
But shouldn't we go back to the human factor?

01:19:34.480 --> 01:19:37.480
Because as you said, we are basically the same.

01:19:37.480 --> 01:19:48.000
So confirmation bias, you said that reassurance, conformism, the feeling of being part of a

01:19:48.000 --> 01:19:52.360
community of people who share the same belief are always the same.

01:19:52.360 --> 01:19:57.120
So I think the human factor probably has to be more investigative than interface.

01:19:57.120 --> 01:19:58.120
There's too much emphasis.

01:19:58.120 --> 01:20:01.000
Don't you think there's too much emphasis on the technology?

01:20:01.000 --> 01:20:02.000
Thank you.

01:20:02.000 --> 01:20:07.280
I do think that emotions are a critical component.

01:20:07.280 --> 01:20:13.840
And we know from a neuroscientific perspective and that in studies of attention, that emotions

01:20:13.840 --> 01:20:15.480
prioritize attention.

01:20:15.480 --> 01:20:20.280
That's actually a lot of the reasons that magicians take advantage of this.

01:20:20.280 --> 01:20:27.600
Magicians actually make us laugh at critical points where they need to misdirect us.

01:20:27.600 --> 01:20:37.120
So you can use emotion almost surgically in a magic show, also in social media and in

01:20:37.120 --> 01:20:38.560
the spread of fake news.

01:20:38.560 --> 01:20:46.880
And we used to think, I mean, many years ago, the thinking in science communication was

01:20:46.880 --> 01:20:51.840
that, well, you need to put out the correct information out there and you need to give

01:20:51.840 --> 01:20:55.440
more detail and you need to communicate it more.

01:20:55.440 --> 01:20:59.080
And so people are going to extract the right conclusion.

01:20:59.080 --> 01:21:03.680
It's just they are arriving to the wrong conclusion because they don't have all the information.

01:21:03.680 --> 01:21:05.040
So let's give more information.

01:21:05.040 --> 01:21:06.800
Let's make it more accessible.

01:21:06.800 --> 01:21:12.480
That doesn't fix the problem because you're ignoring the emotional components.

01:21:12.480 --> 01:21:15.400
Can I add something?

01:21:15.400 --> 01:21:17.680
I thought that was a great question too.

01:21:17.680 --> 01:21:21.920
I also, as a social scientist too, I think humans are always going to be at the center

01:21:21.920 --> 01:21:24.160
of what I think is important.

01:21:24.160 --> 01:21:29.400
But as a political scientist, I think human behavior is structured by institutions.

01:21:29.400 --> 01:21:35.600
And so kind of another way of saying that, how that applies to this topic is that I think

01:21:35.600 --> 01:21:41.040
social media platforms have different affordances or different features which can bring out or

01:21:41.040 --> 01:21:43.840
suppress tendencies that exist in humans.

01:21:43.840 --> 01:21:45.560
And so that's the thing that's really important.

01:21:45.560 --> 01:21:51.880
There's nothing inherent to, I think there's nothing inherent to social media in the abstract

01:21:51.880 --> 01:21:58.240
that means that it's going to incentivize engagement with misinformation.

01:21:58.240 --> 01:22:02.600
But it is baked into some platforms today and that the way that they set up the incentives

01:22:02.600 --> 01:22:03.920
within the platform.

01:22:03.920 --> 01:22:10.360
And so I think that redesigning social media, how they're designed, the kinds of behaviors

01:22:10.360 --> 01:22:15.200
that they facilitate for people, the kinds of behavior that they encourage from people

01:22:15.200 --> 01:22:17.680
is something that we should be thinking very seriously about.

01:22:17.680 --> 01:22:18.680
Because yeah, it's true.

01:22:18.680 --> 01:22:22.520
Humans have a tendency to think of ourselves as part of a group.

01:22:22.520 --> 01:22:27.280
But that can be emphasized or de-emphasized.

01:22:27.280 --> 01:22:30.880
And what the group is, right, that's not hardwired either.

01:22:30.880 --> 01:22:35.520
And so these are things that can be brought out through features of social media, including

01:22:35.520 --> 01:22:39.200
things like algorithms or not.

01:22:39.200 --> 01:22:44.120
There's been a movement I know and I'll know much about it, but I do know that some groups,

01:22:44.120 --> 01:22:49.920
organizations will have people go out together and live camp out or solve problems.

01:22:49.920 --> 01:22:53.680
And the whole idea is here they're identifying with each other, yeah, they're cooperating

01:22:53.680 --> 01:22:58.000
with each other towards certain goals which is different just saying, well, I'm a liberal

01:22:58.000 --> 01:22:59.600
or I'm a conservative, right?

01:22:59.600 --> 01:23:03.960
They're actually targeting some goals and that seems to foster a little bit more of

01:23:03.960 --> 01:23:05.600
a sense of community.

01:23:05.600 --> 01:23:06.600
Yes.

01:23:06.600 --> 01:23:11.120
Thank you very much for a very stimulating discussion.

01:23:11.120 --> 01:23:19.800
I cannot help but remember that it goes to time in human history where the heliocentric

01:23:19.800 --> 01:23:22.880
system was considered misinformation.

01:23:22.880 --> 01:23:30.680
And the geocentric system was considered human to be the truth.

01:23:30.680 --> 01:23:37.760
And people were actually tried, they were put on the fire for challenging the so-called

01:23:37.760 --> 01:23:40.040
truth by spreading misinformation.

01:23:40.040 --> 01:23:46.520
Okay, so my question is, is there such a thing as information?

01:23:46.520 --> 01:23:50.480
Because if there is misinformation, it means that the information is what's true and the

01:23:50.480 --> 01:23:52.480
misinformation is what's wrong.

01:23:52.480 --> 01:23:55.440
Now is there such a thing as information?

01:23:55.440 --> 01:24:00.360
And even if there is, what's wrong with challenging it?

01:24:00.360 --> 01:24:12.120
And so the last thing I'm going to say is science is very limited in what objective,

01:24:12.120 --> 01:24:28.680
let's say, is like physics, I mean, more than 95% of medical, biomedical published research,

01:24:28.680 --> 01:24:36.120
which we consider science, cannot be replicated.

01:24:36.120 --> 01:24:43.800
That tells you how hard establishing what information is at least in the scientific context where

01:24:43.800 --> 01:24:49.320
you can have objective methodology let alone in the social sciences.

01:24:49.320 --> 01:24:50.800
That's what the problem is.

01:24:50.800 --> 01:24:59.040
So should we err on the side of allowing misinformation because that makes the dialectic process which

01:24:59.040 --> 01:25:07.280
allows us to filter and synthesize and refuse and accept that should we allow misinformation?

01:25:07.280 --> 01:25:09.760
Should we err on the side of allowing misinformation?

01:25:09.760 --> 01:25:16.200
Or should we err on the side of imposing quote-unquote information which actually may turn out in

01:25:16.200 --> 01:25:20.280
maybe the next decade or the next century to be false?

01:25:20.280 --> 01:25:22.640
Thank you.

01:25:22.640 --> 01:25:29.800
My feeling, I think that these are different issues I've played here.

01:25:29.800 --> 01:25:37.120
And I think one issue pertains to the science enterprise itself and that it is true that

01:25:37.120 --> 01:25:46.520
we do have a replicability crisis or problem more in some areas than in others.

01:25:46.520 --> 01:25:51.960
But and I think that there's a lot of fundamental problems with the structure of science, how

01:25:51.960 --> 01:25:59.200
it's done this day, the kinds of science that gets incentivized, the pressure to publish.

01:25:59.200 --> 01:26:07.080
There are a lot of problematic issues and certainly sometimes we're playing it a bit

01:26:07.080 --> 01:26:15.800
too safe in the sense of the research that gets resources to be performed.

01:26:15.800 --> 01:26:25.880
I think that's a different problem from misinformation itself and in the spirit of misinformation,

01:26:25.880 --> 01:26:35.680
I think that by individuals, not necessarily scientists, I think that's a different domain

01:26:35.680 --> 01:26:42.600
from a science than the best way it could be done.

01:26:42.600 --> 01:26:51.760
So to me, those are different issues and yes, in terms of the science, the other thing

01:26:51.760 --> 01:26:57.200
I think that's important to keep in mind in terms of the science because it was mentioned

01:26:57.200 --> 01:26:59.080
something about truth.

01:26:59.080 --> 01:27:05.720
And I would say that scientists don't try to get at the truth or they should not try

01:27:05.720 --> 01:27:06.720
to get at the truth.

01:27:06.720 --> 01:27:11.840
The truth in science is always aspirational and that's why we talk about validating hypothesis,

01:27:11.840 --> 01:27:18.120
not verifying a hypothesis and the hypothesis is correct until it's proven otherwise.

01:27:18.120 --> 01:27:24.440
So as scientists, at least the way that I was taught to the science and the way that

01:27:24.440 --> 01:27:33.680
I teach my trainees is that you try to eliminate hypothesis that are incorrect and hopefully

01:27:33.680 --> 01:27:37.200
you get to narrow down more and more the actual answer.

01:27:37.200 --> 01:27:44.200
But as a scientist, you have to be always in the mind frame that you need to be questioning

01:27:44.200 --> 01:27:49.920
your own results and there's also others of course, but all the time you're supposed

01:27:49.920 --> 01:27:55.560
to be revising your framework in light of no evidence.

01:27:55.560 --> 01:27:58.000
Yeah I absolutely love this question.

01:27:58.000 --> 01:28:02.560
We can spend two more hours just answering this, right?

01:28:02.560 --> 01:28:07.000
You asked what is information, forget about misinformation, what is information and that

01:28:07.000 --> 01:28:12.680
bothered every thinker since we learned how to put our mind into words, right?

01:28:12.680 --> 01:28:17.040
I mean that's Greek philosophy that's played out thinking about the people in the cave

01:28:17.040 --> 01:28:22.760
trying to figure out if they are really seeing the world or not.

01:28:22.760 --> 01:28:28.800
I'll kind of get inspiration from all the statues of someone Freud in this building and

01:28:28.800 --> 01:28:33.440
go to another Austrian philosopher of science which is Karl Popper, right?

01:28:33.440 --> 01:28:41.640
And I'm a very strong, a very strong, a properian person and I think he reminded us that science

01:28:41.640 --> 01:28:45.960
is about, as you said, science is not the search for information.

01:28:45.960 --> 01:28:50.160
It's the systematic rejection of misinformation.

01:28:50.160 --> 01:28:56.640
We would never be able to prove with certainty that anything that we see in studies is true,

01:28:56.640 --> 01:28:57.640
right?

01:28:57.640 --> 01:29:02.720
The best we can do is to reject hypotheses that are wrong.

01:29:02.720 --> 01:29:08.160
We are able logically to reject some ideas and then at any given moment we need to take

01:29:08.160 --> 01:29:13.960
the actions that are most suitable to the current state of knowledge that we have at

01:29:13.960 --> 01:29:15.260
that point.

01:29:15.260 --> 01:29:19.480
Take vaccines, for example, that you talked about before.

01:29:19.480 --> 01:29:24.200
Can we say for certain that vaccines have no negative impact?

01:29:24.200 --> 01:29:25.320
Of course not.

01:29:25.320 --> 01:29:26.320
We can't.

01:29:26.320 --> 01:29:27.320
Certainly we can't.

01:29:27.320 --> 01:29:34.120
We can just reject the hypothesis that people who take the vaccines are more likely than

01:29:34.120 --> 01:29:36.280
others to have autism, for example.

01:29:36.280 --> 01:29:41.960
We can reject this hypothesis but we cannot say for sure that vaccines will never have

01:29:41.960 --> 01:29:44.800
a negative influence.

01:29:44.800 --> 01:29:53.280
So yes, science is kind of, as if it's working in this regard, we will never get to the truth

01:29:53.280 --> 01:30:00.800
but I think we are able to gather enough consensus on what's wrong to direct policy and behavior

01:30:00.800 --> 01:30:03.160
that's more educated.

01:30:03.160 --> 01:30:09.320
I wanted to make a real quick response to this too.

01:30:09.320 --> 01:30:15.680
There are different sorts of misinformation and when the consequence of misinformation

01:30:15.680 --> 01:30:20.960
could be dangerous, of course, we want to figure out a way to get around that.

01:30:20.960 --> 01:30:26.520
A famous director now, sort of infamous director had this wonderful little bit where he was

01:30:26.520 --> 01:30:32.280
his neurotic child version of himself was being reprimanded by his mother who said,

01:30:32.280 --> 01:30:36.400
what's at your business if the universe is expanding?

01:30:36.400 --> 01:30:40.800
So the idea is, okay, you know what, if the universe is expanding or not, we don't need

01:30:40.800 --> 01:30:41.800
to get to the bottom of that.

01:30:41.800 --> 01:30:44.880
It's okay with us if you don't accept authority on that.

01:30:44.880 --> 01:30:50.920
But if you go to your doctor and you have a, God forbid you have a cancer and the treatment

01:30:50.920 --> 01:30:53.880
that's going to be offered for you and oftentimes if they're experimental treatments, they'll

01:30:53.880 --> 01:30:55.720
even tell you in advance.

01:30:55.720 --> 01:31:01.160
I can't even say this is going to be good or safe for you but you have to make a decision.

01:31:01.160 --> 01:31:03.480
You know, that's where the rubber meets the road.

01:31:03.480 --> 01:31:07.920
You then, I think, you're best off putting your trust into the doctor and in return,

01:31:07.920 --> 01:31:13.320
the doctor has to have in his or her mind the idea that I don't want to let my patient

01:31:13.320 --> 01:31:18.120
down because this is almost like a sacred trust that's being placed on me.

01:31:18.120 --> 01:31:25.320
So that means we have to go back and make sure that this treatment is good and valid.

01:31:25.320 --> 01:31:28.760
Sometimes you don't know in any particular point in time but trust is another, again,

01:31:28.760 --> 01:31:34.000
comes up as another important feature separating information from misinformation.

01:31:34.000 --> 01:31:37.400
And not always making a clear demarcation, right?

01:31:37.400 --> 01:31:41.480
Then there cannot be, which is part of, I think, what your question entails.

01:31:41.480 --> 01:31:43.240
Yeah, thank you.

01:31:43.240 --> 01:31:45.240
Yes, please.

01:31:45.240 --> 01:31:54.480
Actually, that response was very closely related to the question I wanted to ask because, so,

01:31:54.480 --> 01:31:58.880
there's an implication to certain kinds of misinformation.

01:31:58.880 --> 01:32:02.920
And so, we touched on regulation before.

01:32:02.920 --> 01:32:08.720
My question's about are there other kinds of regulatory capacity in sort of societies

01:32:08.720 --> 01:32:11.960
that exist today or that we can build into our societies?

01:32:11.960 --> 01:32:16.560
Because if certain kinds of misinformation might imply certain kinds of harm to specific

01:32:16.560 --> 01:32:18.840
people and they're endowed with certain kinds of voices.

01:32:18.840 --> 01:32:26.080
So my question is, is it possible to think of how can that create the potential harm

01:32:26.080 --> 01:32:31.640
of misinformation, how can that create feedback loops to like a repair capacity?

01:32:31.640 --> 01:32:34.120
Is it possible?

01:32:34.120 --> 01:32:41.720
I mean, I think this raises, I mean, I think this is an interesting question that raises

01:32:41.720 --> 01:32:52.280
the challenge as to how we sort of build sort of responsive mechanisms of accountability

01:32:52.280 --> 01:32:56.560
for any kind of regulatory regime that we end up wanting to have.

01:32:56.560 --> 01:33:02.280
So what are the rules of the road for content moderation and platform governance?

01:33:02.280 --> 01:33:06.200
And who gets the decide, who gets a voice and how these rules are determined?

01:33:06.200 --> 01:33:11.240
I think there's a strong case to be made that whether this is being channeled through

01:33:11.240 --> 01:33:16.200
like legislatures or some other citizens' bodies, those bodies should be representative

01:33:16.200 --> 01:33:18.920
of the diversity of interest in society.

01:33:18.920 --> 01:33:25.920
Very much including people who are the victims of, I mean, not only misinformation, but harassment

01:33:25.920 --> 01:33:32.320
and hateful speech that can deal legitimized people, deal with legitimized groups and make

01:33:32.320 --> 01:33:36.440
it more difficult to participate as citizens.

01:33:36.440 --> 01:33:40.160
When we say regulation, we usually think of content moderation, right?

01:33:40.160 --> 01:33:44.040
Having information that is wrong or adding some disclaimers and so on.

01:33:44.040 --> 01:33:50.080
But recently some scholars raised some more creative approaches to regulation.

01:33:50.080 --> 01:33:57.000
And one that I found really interesting is the one suggested by Victor Picard from the

01:33:57.000 --> 01:33:58.160
University of Pennsylvania.

01:33:58.160 --> 01:34:06.800
He says, instead of focusing on moderation of content, let's take taxes from social media

01:34:06.800 --> 01:34:07.800
companies.

01:34:07.800 --> 01:34:10.800
There's a lot of money from that misinformation, right?

01:34:10.800 --> 01:34:16.600
Let's take some taxes back and use it to fund high quality journalism.

01:34:16.600 --> 01:34:23.840
You can create a fund that kind of builds on the money that being made from our misinformation

01:34:23.840 --> 01:34:26.880
and build more reliable institutions of knowledge with it.

01:34:26.880 --> 01:34:32.680
So maybe there are more solutions that we're not thinking about, but they're more creative

01:34:32.680 --> 01:34:38.240
than just running after the next mistake and trying to correct it all the time.

01:34:38.240 --> 01:34:39.240
I think that's wonderful.

01:34:39.240 --> 01:34:41.480
It's a great point to high point to end on.

01:34:41.480 --> 01:34:42.480
It's not my idea.

01:34:42.480 --> 01:34:44.280
But it's a great comment.

01:34:44.280 --> 01:34:50.600
And I'm really pleased to hear all the different efforts to sort of come up with some, you

01:34:50.600 --> 01:34:54.040
know, handle some solution on this issue.

01:34:54.040 --> 01:34:58.520
And I want to thank you all three of you for contributing the way you did.

01:34:58.520 --> 01:34:59.520
Thank you.

01:34:59.520 --> 01:35:00.520
Great.

01:35:00.520 --> 01:35:03.880
I appreciate that.

01:35:03.880 --> 01:35:04.900
Congratulations.

01:35:04.900 --> 01:35:13.320
A lot of talk sharing.

01:35:13.320 --> 01:35:16.100
Thank you.

01:35:16.100 --> 01:35:17.600
That's all we're going to do, right?

