WEBVTT

00:00.000 --> 00:04.000
I'm Ed Nersesian, the Director of the Center.

00:04.000 --> 00:08.000
Today's program, Mind Matters,

00:08.000 --> 00:12.000
Past, Present and Future, and the

00:12.000 --> 00:16.000
participants are, please raise your hand when I call your name.

00:16.000 --> 00:20.000
John Krakower, who is Professor of

00:20.000 --> 00:24.000
Neurology at Neuroscience at Johns Hopkins University.

00:24.000 --> 00:28.000
Jonathan Kramnick,

00:28.000 --> 00:32.000
who is Maynard Mack, Professor of English at Yale University.

00:32.000 --> 00:36.000
George McCarry, who is Director of the

00:36.000 --> 00:40.000
Wheat Wallace Institute for the History of Psychiatry and Professor at

00:40.000 --> 00:44.000
Wile Cornell, Ken Miller, Professor of Neuroscience at

00:44.000 --> 00:48.000
Columbia University, and Barbara Montero,

00:48.000 --> 00:52.000
Professor of Philosophy at the University of New York.

00:52.000 --> 00:56.000
They are aware that they just start spontaneously

00:56.000 --> 01:00.000
with a conversation and we'll see where they end up.

01:00.000 --> 01:04.000
Thank you. Sorry. Maybe we could just begin by saying something about the perspective that

01:04.000 --> 01:08.000
we bring to the question. One of the interesting and

01:08.000 --> 01:12.000
attractive features of this afternoon, for me at least, is that

01:12.000 --> 01:16.000
I am sitting with people who are bringing

01:16.000 --> 01:20.000
expertise from a variety of different disciplines

01:20.000 --> 01:24.000
and none of them my own. So I'd be curious to know

01:24.000 --> 01:28.000
simply how you all approach this issue, which is for me a literary

01:28.000 --> 01:32.000
and cultural question, though I'm always excited to

01:32.000 --> 01:36.000
think about questions of mind, consciousness, and mental life from

01:36.000 --> 01:40.000
an interdisciplinary perspective and bringing into account

01:40.000 --> 01:44.000
developments in neuroscience, cognitive science, and philosophy.

01:44.000 --> 01:48.000
So now I will pass the torch off to someone else.

01:48.000 --> 01:52.000
So, in understanding the mind, are you looking

01:52.000 --> 01:56.000
at literature? Are you looking at

01:56.000 --> 02:02.000
does this literary story reveal the nature of the mind?

02:02.000 --> 02:06.000
Or does the author of the literary story have insight?

02:06.000 --> 02:10.000
Or who's inside are you

02:10.000 --> 02:14.000
benefiting from in that project?

02:14.000 --> 02:18.000
Well, I'm probably the authors, but I kind of focus on questions

02:18.000 --> 02:22.000
of the representation of mental life and work to literature.

02:22.000 --> 02:26.000
Yeah. And how it's changed, I guess.

02:26.000 --> 02:29.000
How it's changed or how it took shape in a particular moment in time. And one of the

02:29.000 --> 02:33.000
exciting things about working in my particular historical field, which is the 18th

02:33.000 --> 02:37.000
century, is that at that moment in time,

02:37.000 --> 02:41.000
literary writers were in pretty close dialogue with scientists and philosophers.

02:41.000 --> 02:45.000
It's part of the emergence of empiricism and all kinds of work into

02:45.000 --> 02:49.000
the nature of cognition and the nature of representation, perception,

02:49.000 --> 02:53.000
and other kinds of questions in and around mental life that have

02:53.000 --> 02:57.000
posed problems that people are still interested in addressing.

02:57.000 --> 03:01.000
Sounds interesting.

03:01.000 --> 03:05.000
And so to me, that side of it is simple.

03:05.000 --> 03:09.000
I think how consciousness arises from me is not

03:09.000 --> 03:14.000
simple, and in fact I don't even see how you can approach that as a question.

03:14.000 --> 03:19.000
But it's obvious to me that this piece of meat that evolved is

03:19.000 --> 03:24.000
the basis of our mind.

03:24.000 --> 03:31.000
I guess I approached it from two vantage points, which is that I'm a working

03:31.000 --> 03:36.000
psychiatrist, and that does no doubt in form of some of my perspective.

03:36.000 --> 03:41.000
But my work has been in the history of ideas, so I would really take often away from

03:41.000 --> 03:46.000
your point of view and say one of the things that intrigued me and

03:46.000 --> 03:51.000
made me write my last book was the notion that we've been living with this problem

03:51.000 --> 03:57.000
for many, many years, with centuries, and that to think of it as an inside of a problem

03:57.000 --> 04:03.000
was fine, but not as interesting as a problem that in a way had its own history,

04:03.000 --> 04:07.000
had political history, had a scientific history, had a philosophic history,

04:07.000 --> 04:12.000
that impacted us as we couldn't solve it, and moved forward to different iterations

04:12.000 --> 04:14.000
of ways of thinking about it.

04:14.000 --> 04:18.000
So I really look at it in a way much like you do.

04:18.000 --> 04:22.000
I was interested in what happens once we take the, let's say, I don't think it's quite

04:22.000 --> 04:27.000
innocent to say it comes from the meat, but then all the difficult problems, as you say,

04:27.000 --> 04:29.000
come after the meat.

04:29.000 --> 04:31.000
I guess it comes with a dessert.

04:31.000 --> 04:33.000
We don't know what makes it dessert.

04:33.000 --> 04:38.000
I think it's a mad story and we've got to go through the lens of history of ideas.

04:38.000 --> 04:39.000
Sean, please.

04:39.000 --> 04:41.000
Oh, gosh.

04:41.000 --> 04:46.000
Yeah, I always try to think to myself how I feel being an audience, and I think topics

04:46.000 --> 04:53.000
like this are so amorphous and abstract that, so how does one get some

04:53.000 --> 05:04.000
concreteness on it?

05:04.000 --> 05:10.000
That's what people think of me by mind.

05:10.000 --> 05:15.000
I mean, it's a slightly human, self-absorbed idea that that's what's making us create

05:15.000 --> 05:18.000
all the specialties that we represent.

05:18.000 --> 05:24.000
And then that's what Ken just said, which is he's a neuroscientist.

05:24.000 --> 05:27.000
In neuroscience, we don't talk about the mind.

05:27.000 --> 05:29.000
We talk about the brain.

05:29.000 --> 05:33.000
So the mind is what psychologists and cognitive certain neuroscientists talk about,

05:33.000 --> 05:37.000
and it's what we all consider, as I said, the creator of all the things we care about,

05:37.000 --> 05:41.000
and then the neuroscientists talk about brain, and then we get this tedious thing.

05:41.000 --> 05:44.000
How are we going to bridge the brain and the mind?

05:44.000 --> 05:49.000
And the answer to that is, we're not.

05:49.000 --> 05:52.000
And what do I mean by that?

05:52.000 --> 05:56.000
It means that, and I'll give you a tiny little anecdote.

05:56.000 --> 05:57.000
Ken probably knows this.

05:57.000 --> 06:01.000
Génelia, does everyone know what Génelia research campus is?

06:01.000 --> 06:06.000
It's a big campus for neuroscience, and they've just decided that they're going to switch

06:06.000 --> 06:11.000
directions and do something they call mechanistic cognitive neuroscience.

06:11.000 --> 06:19.000
Meaning that they're going to spend 15 years to do the bridge between the brain of a fruit fly

06:19.000 --> 06:21.000
and cognition.

06:21.000 --> 06:30.000
So they're going to try and operationally define what could possibly be the bridge between mind and brain.

06:30.000 --> 06:36.000
And the way they're going to do it is they're going to have to come up with some operational definition of cognition.

06:36.000 --> 06:43.000
So I think we can have a fruitful discussion here that we agree that we're going to talk about cognition.

06:43.000 --> 06:48.000
Thought, if we will, conscious of that, that's it.

06:48.000 --> 06:49.000
Cognition.

06:49.000 --> 06:57.000
Now, depending on how you operation define cognition, you can decide that we are going to have a scientific theory of the mind.

06:57.000 --> 07:03.000
That is neuroscientific, not psychological, and just the last point I want to make is that it's extremely important

07:03.000 --> 07:10.000
to say that all the interesting work on the mind to date, in my view, has been psychological, not neuroscientific.

07:10.000 --> 07:19.000
And in philosophy, we talk about functionalist explanations versus reductionist mechanistic explanations.

07:19.000 --> 07:26.000
If you say to somebody, why is that woman crying there in the corner, and you say it's because she's sad,

07:26.000 --> 07:31.000
because she lost a loved one, that is a perfectly adequate explanation.

07:31.000 --> 07:40.000
To say it's because circuits in her head are misfiring, or dopamine levels are low, is not an adequate explanation.

07:40.000 --> 07:46.000
Now, anyone who says, oh, and you know, and they're molecules of the moment, oxytocin is very big at the moment,

07:46.000 --> 07:55.000
dopamine was really big, and these molecules get this totemic meaning that we think are bridging, and they're not.

07:55.000 --> 08:05.000
So as soon as we move away from causal bridges between the brain and the mind, and decide the kind of work we want to do,

08:05.000 --> 08:12.000
I think you have to be perfectly happy with saying the woman is sad, and never talk about dopamine.

08:12.000 --> 08:21.000
And any attempt to think that you'll explain away the notion of sadness by some reduced circuit or molecular-based exclamation

08:21.000 --> 08:26.000
is a philosophical aporia. It's a non-place.

08:26.000 --> 08:29.000
And that, I think, is where we're going to happen.

08:29.000 --> 08:34.000
And I think many people in the audience really hope that the neuroscientists will solve the mind.

08:34.000 --> 08:37.000
It's a non-starting.

08:37.000 --> 08:43.000
Okay. Well, it's interesting for me to hear different perspectives on this.

08:43.000 --> 08:51.000
My work is very interdisciplinary, so I take into consideration literature.

08:51.000 --> 08:57.000
That's why I was interested in how you, you know, think about it, because I've looked at Shakespeare and said,

08:57.000 --> 09:05.000
well, you know, how did he understand the mind, which is different how the characters sometimes seem to see the springs of action.

09:05.000 --> 09:14.000
And so, and I look at neuroscience and psychology and common sense.

09:14.000 --> 09:18.000
I've even conducted an experiment.

09:18.000 --> 09:21.000
And then my own case, too, introspection.

09:21.000 --> 09:27.000
I use that too, and I mix it all together and see what comes out.

09:27.000 --> 09:37.000
So, well, so one thing Ken said was, certainly the brain is the basis of the mind.

09:37.000 --> 09:47.000
And, you know, one sense who wants to say, yeah, but one question I'm interested in what it means to be the basis of something else.

09:47.000 --> 10:07.000
So, because it seems to me from different perspectives, you can see different, you could say in a different context, someone might say our socialization is the basis of the mind,

10:07.000 --> 10:16.000
because that's what makes us who we are, or you could, in a different context, our DNA, or so, yeah,

10:16.000 --> 10:34.000
so there's a, so one thing, so my work tends to, like, focus on some very, well, I have a variety of areas of research, but in my most, like strictly focusing on the mind and the mind body problem,

10:34.000 --> 10:48.000
focuses on the meaning of that, what can we mean when we're looking for the basis, and also the question of, well, what is that base?

10:48.000 --> 10:54.000
So, we all want to be somehow materialist or physicalist, but what does that mean?

10:54.000 --> 11:17.000
And somehow is there, like, I mean, we think about the problem of reducing the mind to the brain, but, you know, we haven't reduced chemistry either to physics, so what is there something special about the mind, and its relation to the lower level features that it somehow emerges out of, or is based on, or is maybe

11:17.000 --> 11:34.000
reduced, so as opposed to other, the other stratifications of nature, or is it just, do we have the same problems throughout, or are they just different perspectives we take on reality, so, those are some of my thoughts.

11:34.000 --> 11:50.000
It's just that you're not, the question why is this woman crying, it's not asked, this is a question of, like, what people are interested in when they pose a question, what kind of answer they want, right?

11:50.000 --> 12:05.000
So, if you're in a religious office, maybe if someone's crying all the time, nonstop, maybe you need to figure that out, so it might be depending on your content.

12:05.000 --> 12:23.000
It's annoying, it's annoying, what I'm saying is, is that, you know, it's philosophy, explanation, and understanding, and causality have different meanings. Physicists have understood notions of emergence and aggregate behavior and complexity for ages.

12:23.000 --> 12:42.000
Neuroscientists in particular, and I say this, have a kind of philosophical, sophomoric way of speaking, right, where, because they're sophisticated with their tools and their techniques, they think by inheritance, they're also intelligent about talking about these things, and they're not.

12:42.000 --> 13:08.000
Okay, and what I'm saying is that it's not, lots of people have dealt with these problems of levels of analysis, you know, as you said, physics, chemistry, biology, phase, transitions in science, complexity, I mean, you know, I think it gets down to you, you know, the book that we're writing, I think the title I'm using right now is, what does neuroscience want to know?

13:08.000 --> 13:13.000
And I think members of the audience are asking, why is that woman sad?

13:13.000 --> 13:18.000
But what the answer to sound like something like dopamine?

13:18.000 --> 13:34.000
And what I'm saying is, as long as you're in that track where you're asking a question that's never going to yield the kind of answer you feel like, it's like the number 42, I mentioned that in Hitchhiker's Guide to the Larrazie, what's the meaning of the universe?

13:34.000 --> 13:38.000
Well, that's my face, I want something that felt like my question.

13:38.000 --> 13:49.000
The problem is, is that we have a feeling when we ask our question and we demand that the answer have the same feel as the question, and it will not.

13:49.000 --> 14:00.000
And as long as we accept that, we're fine, you can do causal neurology, yes, you can do cheat Parkinson's in depression and stroke, that's causal work, that's where the levels matter.

14:00.000 --> 14:04.000
But if you're asking, understanding explanation, why is this person a good cook?

14:04.000 --> 14:10.000
It's because they salt well, it's because they read recipes well, it's because they have a knack.

14:10.000 --> 14:17.000
And notice that those explanations for why a cook is good, all on the Daniel Dennett's intentional level of cooking.

14:17.000 --> 14:22.000
If you said they're good cook, they've got really good spatial working memory, right?

14:22.000 --> 14:25.000
Or they have good selective spatial attention.

14:25.000 --> 14:37.000
You're no longer explaining why they're a good cook, all you're doing is talking about the, perhaps, necessary but not sufficient cognitive capacities that you require to be a good composer as well.

14:37.000 --> 14:47.000
So, to me, it's all a bit of a non-question that we like, because we all would like the feeling of an answer that we're never going to get.

14:47.000 --> 14:56.000
I completely agree with you, but I'm much more curious rather than bored by the question, because in fact, the non-question becomes a culture.

14:56.000 --> 15:02.000
As you know, the NIMH now demands that studies about sadness have biomarkers.

15:02.000 --> 15:06.000
You cannot get a grant at the National Institute of Mental Health.

15:06.000 --> 15:14.000
And so these problems, we have this capacity to sometimes manage better, in the 19th century, Hughlings Jackson said exactly what you said.

15:14.000 --> 15:21.000
We're going to basically defer psychic causality, and we're going to look for neural causality, and we're going to start to do the same thing with psychology.

15:21.000 --> 15:27.000
Everyone is mixing mind and brain in a mash of nonsense.

15:27.000 --> 15:29.000
He said we're just going to look for psychological causality.

15:29.000 --> 15:37.000
The problem is some fields and some people, like psychiatrists and their patients, walk into a situation where they're demanded.

15:37.000 --> 15:43.000
It seems like there is a great deal of pressure to think on both sides and to prematurely integrate.

15:43.000 --> 15:46.000
Those integrations have been usually disastrous.

15:46.000 --> 15:56.000
And presently, I think we're in the midst of another chapter in that with the recent NIMH demand that everyone's going to have to make up a biomarker for every study they do.

15:56.000 --> 15:59.000
You will not be able to do a clinical study on sadness.

15:59.000 --> 16:01.000
Yeah, so that sounds right to me.

16:01.000 --> 16:10.000
And also, I think there's something that's been historically perplexing about the relationship between physical matter and cognition or the mind in the brain over long spans of time.

16:10.000 --> 16:20.000
So there's something, at least in the curiosity or the fad or the fetish that you're describing, John, that has cultural significance, if not also political significance.

16:20.000 --> 16:31.000
And there's a reason why we started off in this vein, even though with the possible exception of Ken, it seems like no one here really is committed to a kind of program of reduction.

16:31.000 --> 16:40.000
And yet, it's what bugs you, even though none of us really actually are committed to explaining in the way that you're afraid of.

16:40.000 --> 16:43.000
Well, as I said, that's not true of NIMH.

16:43.000 --> 16:44.000
Well, no, exactly.

16:44.000 --> 16:45.000
Do you need the neuroscience?

16:45.000 --> 16:46.000
Yes, right.

16:46.000 --> 16:57.000
Genuinely believe that if you can understand heading direction through a ring attractor, a fly's brain, that you will then be able to extrapolate from that other forms of cognition.

16:57.000 --> 16:59.000
They really do believe that.

16:59.000 --> 17:01.000
Right?

17:01.000 --> 17:08.000
And it's now, look, if they could explain in an argument, you know, Ken just said, I believe one day you will.

17:08.000 --> 17:10.000
That's the religion, as far as I understand.

17:10.000 --> 17:11.000
Right?

17:11.000 --> 17:19.000
But if you're going to come up with a framework as to how that extrapolate, I mean, if you were to say, look, here's an ant.

17:19.000 --> 17:20.000
Yeah.

17:20.000 --> 17:21.000
One little ant.

17:21.000 --> 17:29.000
And I'm going to be so intelligent that I will actually infer ant colonies and termite mounts from that one ant.

17:29.000 --> 17:30.000
Good luck.

17:30.000 --> 17:31.000
You never would.

17:31.000 --> 17:32.000
Yeah.

17:32.000 --> 17:34.000
I'm going to agree with everything you're saying.

17:34.000 --> 17:38.000
And unfortunately, neuroscience, we study the ant because we've got great tools.

17:38.000 --> 17:40.000
We can go deep into the ant's brain.

17:40.000 --> 17:46.000
We will infer termite mounts, which is what cognition would be in an ant colony, as present in the present.

17:46.000 --> 17:47.000
Right, right.

17:47.000 --> 17:49.000
It's an emergent behavior when you have thousands of ants.

17:49.000 --> 17:50.000
Correct.

17:50.000 --> 17:54.000
But somehow we're going to work out how that thousands of ants work.

17:54.000 --> 18:04.000
And there are coarse grain descriptions of complex systems like ant colonies that are very explanatory, but they're not single ants.

18:04.000 --> 18:05.000
Right?

18:05.000 --> 18:07.000
And you substitute ants for neurons and you can see the problem.

18:07.000 --> 18:08.000
Yeah.

18:08.000 --> 18:09.000
Right?

18:09.000 --> 18:18.000
And yet neuroscientists hate this kind of argument because they're deeply in love with the reductionist work.

18:18.000 --> 18:20.000
And it's good work, by the way.

18:20.000 --> 18:22.000
I think at the level of the work, ants are interesting.

18:22.000 --> 18:23.000
Neurons are interesting.

18:23.000 --> 18:24.000
Right.

18:24.000 --> 18:26.000
Parts of neurons are interesting.

18:26.000 --> 18:27.000
Right?

18:27.000 --> 18:34.000
But the idea that if you study and study and study and study and make some magical nonlinear extrapolatory moment, you'll have this new thing.

18:34.000 --> 18:35.000
It's never happened.

18:35.000 --> 18:36.000
I've never seen it.

18:36.000 --> 18:37.000
Yeah.

18:37.000 --> 18:38.000
That's the problem.

18:38.000 --> 18:39.000
Right.

18:39.000 --> 18:47.000
I don't agree that it's an insoluble, in principle, separation between the physical and the mental.

18:47.000 --> 18:49.000
That will never get there.

18:49.000 --> 19:06.000
And just as one simple example that John would know very well, but we have the experience that to see this cup and to reach for this cup and to know it's a cup and to be able to reach for it is the same thing.

19:06.000 --> 19:10.000
Well, from study of the brain, we now know it's not the same.

19:10.000 --> 19:18.000
That there's one system that I use to say that's a cup and it's a sort of round in a cylinder and to describe its shape.

19:18.000 --> 19:24.000
And there's a completely different system that I use to form my hands to reach for it, know where to reach it and be able to pick it up.

19:24.000 --> 19:26.000
And those are two separable systems.

19:26.000 --> 19:28.000
You can lead in one or lead in the other separately.

19:28.000 --> 19:37.000
So that's a very tiny example of where knowing something about the brain gives us some new insight into the mind that we just wouldn't get by introspection.

19:37.000 --> 19:52.000
And I think that doesn't go very far into our daily life, but it's an example of how understanding how the real thing works is going to piece by piece little by little over a very, very long time going to revise our understanding of our mind works.

19:52.000 --> 20:05.000
Well, actually, let me ask you though, what have we learned about the mind by knowing that the action of reaching for a cup and of gazing at a cup are served by two different systems?

20:05.000 --> 20:11.000
We've learned about the underlying neural architecture of each and how they're distinct from each other.

20:11.000 --> 20:13.000
Well, you mentioned that they're separate processes.

20:13.000 --> 20:15.000
Right, but they're separate and neural.

20:15.000 --> 20:16.000
Unified.

20:16.000 --> 20:20.000
No, no, just to defend, I mean, just to be, this is the crux of matter to be clear.

20:20.000 --> 20:21.000
Yeah.

20:21.000 --> 20:24.000
What Ken is talking about is a form of modularity of process.

20:24.000 --> 20:25.000
Right, exactly.

20:25.000 --> 20:26.000
Okay.

20:26.000 --> 20:37.000
Now, psychologists, Sternberg and many others who have worried about the decomposition into components of what seems like the unified brain.

20:37.000 --> 20:42.000
So that's not implementational level work.

20:42.000 --> 20:53.000
In other words, showing that there's dissociation of modules, showing that the seemingly unified brain mind is actually made up of these competing subsystems.

20:53.000 --> 20:54.000
Right.

20:54.000 --> 20:57.000
It's incredibly interesting, but that's psychology.

20:57.000 --> 20:58.000
Right.

20:58.000 --> 21:01.000
And then cognitive neuroscience is sort of psychology, but imaging.

21:01.000 --> 21:02.000
Right.

21:02.000 --> 21:03.000
But.

21:03.000 --> 21:09.000
But I think for the benefit of the audience, actually, we might want to clarify that what we're talking about here is still actually below any level of consciousness.

21:09.000 --> 21:10.000
Yes.

21:10.000 --> 21:20.000
So this is about a mental process, a cognitive process in which these two modules are distinct from each other, but one can't's introspect on that at all.

21:20.000 --> 21:35.000
So that this is in some sense what I was asking. I think many people in the audience, when they hear questions of mind are interested in something that is available to introspection is consciously experienced.

21:35.000 --> 21:39.000
Right. And I think it's very important. I'm sure Ken and I would take the view.

21:39.000 --> 21:47.000
I think that, and I think Dan Dennett, I was using the point to introspection.

21:47.000 --> 21:52.000
Yes, in certain circumstances, self-report is useful in psychology.

21:52.000 --> 21:53.000
Right.

21:53.000 --> 22:04.000
But it's a dangerous thing to base science on, whether it's cognitive neuroscience with its computational modules, or whether it's neuroscience where you actually talk about implementation circuits.

22:04.000 --> 22:05.000
Right.

22:05.000 --> 22:11.000
I think they're both ways to study the brain. I think the bridge, as I said, between the brain and mind is the notion of cognition.

22:11.000 --> 22:19.000
The best way to go after cognition, I think, is psychological experiments. Sometimes there's psychological experiments benefit from some self-report.

22:19.000 --> 22:34.000
But I think it's very important that I do not take the view that the introspective route alone, even I think members of the audience who care about free will, consciousness, thinking would, I think, prefer cognitive neuroscience to introspection.

22:34.000 --> 22:35.000
Okay.

22:35.000 --> 22:42.000
And I would... The one thing I disagree is, this isn't... The dissociative... I just talked about it's not just psychology.

22:42.000 --> 22:50.000
Without... We discovered that by understanding how two separate brain systems process things and how when you're lesion one of them, you lose one faculty.

22:50.000 --> 22:52.000
That's neuropsychology. Neuropsychology.

22:52.000 --> 22:53.000
Neuropsychology.

22:53.000 --> 22:59.000
No, right. I'm just saying that if you had area A and area B and they dissociated, it's fascinating.

22:59.000 --> 23:06.000
But unless you care that it was dorsal stream versus ventral stream, it could have been occipital cortex, could have been temporal cortex.

23:06.000 --> 23:12.000
It's the dissociation that's interesting, not the exact anatomical location of it at the current time.

23:12.000 --> 23:14.000
I agree with that.

23:14.000 --> 23:15.000
Yes.

23:15.000 --> 23:22.000
Wouldn't you have the cognitive dissociation be at some level of explanatory removed from the neural...

23:22.000 --> 23:29.000
Why would it occur in different forms of neural location?

23:29.000 --> 23:31.000
Well, the point is we discover it by studying the brain.

23:31.000 --> 23:34.000
We don't discover it by studying the mind without studying the brain.

23:34.000 --> 23:35.000
Right.

23:35.000 --> 23:36.000
It's a leading...

23:36.000 --> 23:37.000
Yes, you know, I understand.

23:37.000 --> 23:45.000
It seems to me that on the one hand, we have the limits epistemologically of neural reductionism, which you made the case for very clearly.

23:45.000 --> 23:50.000
And on the other, we do have the limits of self-report, which are obvious.

23:50.000 --> 23:56.000
For the people who are in the lab doing this, do we not need a new model of science to understand the mind?

23:56.000 --> 23:59.000
Are we not stuck between bad models?

23:59.000 --> 24:01.000
I think...

24:01.000 --> 24:07.000
Well, one thing I've found recently, and I've just...

24:07.000 --> 24:15.000
A recent project, but I've been writing about the fact that we seem to forget the sensation of pain.

24:15.000 --> 24:21.000
And there's quite a large psychology and some neuroscience on this.

24:21.000 --> 24:30.000
And looking at it, it's interesting how so much of the neuroscience is still in...

24:30.000 --> 24:35.000
Really, I mean, because what else can we do, but maybe there's a way to think about moving forward into something else,

24:35.000 --> 24:39.000
but has to speak in terms in behavioral terms.

24:39.000 --> 24:42.000
So about the two components of pain.

24:42.000 --> 24:50.000
There is a distinction and maybe a dissociation, though it's not clear that there's ever been a full dissociation

24:50.000 --> 24:54.000
between the feeling of pain and your emotional reaction.

24:54.000 --> 24:59.000
But both are described in terms of behavior. They're identified in behavior.

24:59.000 --> 25:01.000
So it's very difficult.

25:01.000 --> 25:11.000
Just, I think, to get... It would be nice in my paper, I suggest, you know, that the literature on memory of pain

25:11.000 --> 25:18.000
is also very confusing because it is hard to identify this sensory component outside of behavioral terms.

25:18.000 --> 25:25.000
So it would be nice, I think, for the science to move forward, for the neuroscience to move forward,

25:25.000 --> 25:38.000
to allow for neuroscientists to feel a little bit more free about not needing to identify everything behaviorally.

25:38.000 --> 25:44.000
Now, how do you do the study? You know, you have to find some thing that goes on.

25:44.000 --> 25:51.000
But... And this is where, I think, maybe first introspection and the neuroscience, the fMRI,

25:51.000 --> 25:57.000
it's going to have to work hand in hand because maybe, okay, we're not going to be able to see some behavior

25:57.000 --> 26:04.000
that a subject in a study is going to events, but we're going to have to take their word for it

26:04.000 --> 26:12.000
that they are remembering a sensation. But it's... And we'll look at what's going on in the brain at that point.

26:12.000 --> 26:22.000
So I feel that in moving forward, and then just in looking at that research, I wanted to suggest that it would be nice

26:22.000 --> 26:31.000
to have a way to get subjects to identify a conscious component of what's going on.

26:31.000 --> 26:38.000
Versus, well, what I found in the literature was a distinction between remembered pain and known pain.

26:38.000 --> 26:44.000
But the poor subjects in these studies, there's like a 500-word description of making this distinction,

26:44.000 --> 26:49.000
and I'm sure that's very difficult for any subject to read and really understand.

26:49.000 --> 26:54.000
So I thought... Here I thought it was a place where philosophers who like to think a lot about this subjectivity

26:54.000 --> 27:04.000
and what they call qualia and consciousness could help out in trying to create a protocol to offer to subjects

27:04.000 --> 27:14.000
and studies for them to try to identify different conscious aspects of their mind, the consciousness.

27:14.000 --> 27:21.000
So in looking at what's the core, you know, what we see is correlated with activity in the brain.

27:21.000 --> 27:25.000
I mean, that seemed to be clear in the pain.

27:25.000 --> 27:30.000
But even in the end, you're just going to have correlations, which are not explanations.

27:30.000 --> 27:31.000
Oh, right.

27:31.000 --> 27:36.000
Just to get to your question, right, I mean, there's the meteorological fallacy.

27:36.000 --> 27:42.000
You know, PMS, Hackler, Wittgenstein, he talked about, you know, wings don't fly, birds do.

27:42.000 --> 27:48.000
Okay, the amygdala does not feel pain, people do.

27:48.000 --> 27:54.000
All right, so soon, now lots of, again, neuroscientists don't understand that logical fallacy.

27:54.000 --> 27:59.000
Right, they think that parts feel rather than the... Yeah.

27:59.000 --> 28:01.000
...the glagration of the path.

28:01.000 --> 28:07.000
So there, you could say we don't need the difference, because there's a philosophical misunderstanding.

28:07.000 --> 28:08.000
Okay.

28:08.000 --> 28:13.000
But on the other hand, we do lack, in complexity science, a bridging hypothesis.

28:13.000 --> 28:21.000
It is true that it's difficult to come up with, if I were to ask you, do you understand New York City?

28:21.000 --> 28:23.000
I could ask everyone in this room.

28:23.000 --> 28:27.000
What does that question mean? Do I understand New York City?

28:27.000 --> 28:32.000
So to understand the mind is as stupid as that question, right?

28:32.000 --> 28:35.000
Right? Do you understand New York City?

28:35.000 --> 28:37.000
You can utter that sentence, right?

28:37.000 --> 28:38.000
But I beg to differ.

28:38.000 --> 28:42.000
Now, what's ever asked me that question before, I've been asked the question if I understand the mind a million times.

28:42.000 --> 28:43.000
Right.

28:43.000 --> 28:44.000
Why?

28:44.000 --> 28:45.000
I'm just saying it's the same in times.

28:45.000 --> 28:46.000
No, but let me finish.

28:46.000 --> 28:48.000
Why do neuroscientists keep making the same mistake?

28:48.000 --> 28:50.000
It's not because they don't understand the problems.

28:50.000 --> 28:53.000
It's because there's a great deal of pressure on them.

28:53.000 --> 28:55.000
Social, political, human, bless you.

28:55.000 --> 28:57.000
Make that leap.

28:57.000 --> 29:01.000
And so for 150 years, they keep going off the same cliff.

29:01.000 --> 29:06.000
People keep asking them, but what about the thing that I think organizes my day every day?

29:06.000 --> 29:11.000
And that's got to be related to these gray matters that you're talking about in these neurons.

29:11.000 --> 29:13.000
But how is it related?

29:13.000 --> 29:16.000
And again and again, the pressure of answering that question.

29:16.000 --> 29:17.000
Exactly what I'm saying is...

29:17.000 --> 29:18.000
It's a seduction.

29:18.000 --> 29:19.000
I know, it's a seduction.

29:19.000 --> 29:21.000
But why don't we just get over it?

29:21.000 --> 29:26.000
In other words, what I'm saying is we can have very important causal connections made.

29:26.000 --> 29:29.000
Causality matters, right?

29:29.000 --> 29:37.000
But just like explaining ant colonies and weather and cities, you can't do it.

29:37.000 --> 29:39.000
I completely agree with you, but I'll tell you the answer.

29:39.000 --> 29:40.000
Let's just get over this.

29:40.000 --> 29:42.000
The reason we don't get over it is you won't get grants.

29:42.000 --> 29:44.000
Yeah, but that's why you won't get over it.

29:44.000 --> 29:47.000
But that's not a very intellectual position to take.

29:47.000 --> 29:50.000
I can tell my friends that they're laughing.

29:50.000 --> 29:55.000
I would say I'm not going to be always not interrupted, just because I'm a woman.

29:55.000 --> 29:57.000
So I'm going to interrupt a little bit.

29:57.000 --> 30:03.000
And also I want to bring up somewhere where I think Jonathan can add, okay, I would say

30:03.000 --> 30:10.000
things are even worse or maybe more complicated than John has just pointed out with explanation.

30:10.000 --> 30:21.000
I mean, I would say it's partly a sociological linguistic fact that we say people think

30:21.000 --> 30:23.000
instead of the brain.

30:23.000 --> 30:26.000
And I think it could, I mean, we could change.

30:26.000 --> 30:31.000
I'm very always influenced by Chomsky on his thoughts about this.

30:31.000 --> 30:38.000
And he often points out, well, you know, in English we say birds fly and airplanes fly.

30:38.000 --> 30:41.000
But you know, in some other languages, airplanes don't fly.

30:41.000 --> 30:47.000
No, you know, so it's, you know, well in English and maybe today in most languages we talk about

30:47.000 --> 30:50.000
people as thinking and not the brain.

30:50.000 --> 30:52.000
But you know, that could change.

30:52.000 --> 30:57.000
I mean, it's interesting you see also, I mean, I noticed in my writing, I don't want an

30:57.000 --> 30:58.000
argument to state something.

30:58.000 --> 31:02.000
But a lot of people say, you know, so maybe arguments are now state.

31:02.000 --> 31:08.000
So it might be somehow also just a social fact also.

31:08.000 --> 31:09.000
I'm not sure.

31:09.000 --> 31:16.000
I mean, I'm willing to say there's some flexibility in what we take as a fact of the matter in this case.

31:16.000 --> 31:18.000
Well, I would agree entirely.

31:18.000 --> 31:19.000
I think it is.

31:19.000 --> 31:20.000
I knew you know.

31:20.000 --> 31:23.000
I think it's very much a social fact.

31:23.000 --> 31:27.000
But also with an interesting history, I mean the mind-body problem goes, you know, it goes

31:27.000 --> 31:28.000
all the way back.

31:28.000 --> 31:32.000
And people have written interesting things about it for a very long time.

31:32.000 --> 31:38.000
And it has affected our culture in recent years in ways that are, you know, I guess good and bad.

31:38.000 --> 31:42.000
And certainly our arts in ways that are interesting.

31:42.000 --> 31:49.000
There's good novels have been written about, you know, brain-based accounts of behavior and psychology.

31:49.000 --> 31:51.000
E.M.E.Q. and Saturdays, lovely novel.

31:51.000 --> 31:53.000
The science is wrong.

31:53.000 --> 31:54.000
No doubt.

31:54.000 --> 32:02.000
But it's preoccupied with, you know, the problem of reducing the experience to the brain.

32:02.000 --> 32:09.000
But also actually I think even in everyday speech, again, going way back, you will pick up phrases

32:09.000 --> 32:14.000
like, you know, my brain hurts or something like that when you're talking about having to think really hard about a problem.

32:14.000 --> 32:20.000
The notion that the brain is the seat of the mind and is involved in cognition has been, you know,

32:20.000 --> 32:24.000
obvious in one way or another for people for a very long time.

32:24.000 --> 32:30.000
And there's all sorts of kind of like folk cultural ways of making the connections pretty quick.

32:30.000 --> 32:35.000
And none of that I think poses any problems for your fundamental irritation with your own discipline,

32:35.000 --> 32:36.000
though.

32:36.000 --> 32:38.000
I think that it's actually quite compatible with it.

32:38.000 --> 32:41.000
There's in the sense that they're not doing any explanatory work.

32:41.000 --> 32:49.000
But it's part of the culture in which people will refer to the brain as a kind of chunky way of talking about, you know, the mind.

32:49.000 --> 32:59.000
Yeah, I mean, if you're just, you know, in an article last year, you know, involved in cognition, that word involved, doesn't know work.

32:59.000 --> 33:05.000
It's just a correlation or that are causal link, which none of them doubt.

33:05.000 --> 33:06.000
Right.

33:06.000 --> 33:11.000
In other words, if you're doing causal work, manipulative, interventional work, that's great science.

33:11.000 --> 33:12.000
Right.

33:12.000 --> 33:21.000
And we do, you know, but it's going to be more difficult when you say, hey, how does the brain lead to the mind?

33:21.000 --> 33:23.000
And I'm going to go, you really go, oh, thank you.

33:23.000 --> 33:25.000
I'm not going to have to worry about that again.

33:25.000 --> 33:26.000
I've had my aha moment.

33:26.000 --> 33:27.000
Yeah.

33:27.000 --> 33:30.000
It's a nice compressed sentence has been uttered.

33:30.000 --> 33:31.000
Yeah.

33:31.000 --> 33:35.000
I've understood just the way you say how does a car engine work.

33:35.000 --> 33:37.000
I think I know how a car engine works.

33:37.000 --> 33:40.000
I want there to be a way to say how the brain leads to the mind.

33:40.000 --> 33:46.000
When I'm saying it is not going to ever sound like the way you're being told how a car engine works.

33:46.000 --> 33:47.000
Yeah.

33:47.000 --> 33:50.000
And you just have to look at that.

33:50.000 --> 33:51.000
Yeah, no, no.

33:51.000 --> 33:58.000
And I'm just saying that most people, I think, intuited better than the reductionist scientists.

33:58.000 --> 33:59.000
Again, I agree entirely with that.

33:59.000 --> 34:00.000
Yeah.

34:00.000 --> 34:05.000
I also think that there are cultural reasons and political reasons along the lines of which

34:05.000 --> 34:12.000
order is suggesting as to why this conversation now in 2018 seems so pressing.

34:12.000 --> 34:19.000
At least in my experience over the last decade, universities and funding agencies and everything

34:19.000 --> 34:26.000
else, I've been preoccupied with two things in particular, neurological reduction and

34:26.000 --> 34:30.000
what you might call kind of data or computational reduction.

34:30.000 --> 34:37.000
So the money is in either kind of information systems or studying, using computers to sort

34:37.000 --> 34:43.000
of provide numbers for things or it is, as you suggested, George, in putting a squiggly F

34:43.000 --> 34:46.000
in front of something or just generally using the word neuron.

34:46.000 --> 34:48.000
And that's an interesting sociological question.

34:48.000 --> 34:53.000
Yeah, there's a wonderful book of anyone interested called Neuro published by Princeton University Press.

34:53.000 --> 35:01.000
Think about five years ago by two writers where they very, very beautifully outline the sociology

35:01.000 --> 35:03.000
of the neuro fad.

35:03.000 --> 35:04.000
Right.

35:04.000 --> 35:09.000
And they very much link it to what they call the neuromolecular view of the mind, which

35:09.000 --> 35:12.000
very much came on the heels of molecular biology and molecular genetics.

35:12.000 --> 35:18.000
So the hubris was that we told DNA makes RNA, makes protein.

35:18.000 --> 35:20.000
We're going to do this for neurosar.

35:20.000 --> 35:22.000
Complete failure, obviously.

35:22.000 --> 35:25.000
But nevertheless, it was very compelling.

35:25.000 --> 35:30.000
The Caltech story, Mary McKay wrote a history of Caltech.

35:30.000 --> 35:34.000
And how Linus Pauli said that we studied proteins, we would extrapolate from proteins.

35:34.000 --> 35:39.000
So this has happened over and over again, this sort of extrapolation hubris.

35:39.000 --> 35:40.000
Right.

35:40.000 --> 35:45.000
And now the current one isn't neurons, it's not genes, it's circuits.

35:45.000 --> 35:46.000
Yeah, exactly.

35:46.000 --> 35:49.000
This nauseating word that you hear over and over again.

35:49.000 --> 35:52.000
Now it's not again, it's not that it isn't used to work.

35:52.000 --> 35:54.000
Which is also kind of a neuro term as well.

35:54.000 --> 35:58.000
Yeah, it's just that there's underline this good work.

35:58.000 --> 36:06.000
There's this additional strange totemic view that this will be what gets us to the promised

36:06.000 --> 36:07.000
land.

36:07.000 --> 36:08.000
Right.

36:08.000 --> 36:09.000
And it's bizarre.

36:09.000 --> 36:13.000
So I get to where I don't quite know what we're talking about.

36:13.000 --> 36:18.500
Well, I think it's what people really wanted to know whether the things that we talk about

36:18.500 --> 36:22.840
as mind will ever be sub explained.

36:22.840 --> 36:23.840
And okay, so to address.

36:23.840 --> 36:24.840
That's what it's about.

36:24.840 --> 36:31.000
So I'm saying not at the level of neural circuits.

36:31.000 --> 36:33.840
So there's different things there.

36:33.840 --> 36:40.040
So for example, I mean to understand New York City in its totality.

36:40.040 --> 36:41.040
Yeah.

36:41.040 --> 36:45.760
No, but we can understand a lot and we can understand more and more and we can understand

36:45.760 --> 36:49.440
why, you know, why are the traffic patterns the way they are.

36:49.440 --> 36:51.440
We can understand the forces that lead to that.

36:51.440 --> 36:56.000
We can, there's a lot you can understand without saying that you ever grasp the whole thing.

36:56.000 --> 36:57.000
But the word, right.

36:57.000 --> 36:58.000
It seems to me you're saying if we can't.

36:58.000 --> 37:00.840
No, no, no, no, no, no, it's more subtle than that.

37:00.840 --> 37:04.120
When you look at work on cities, for example, Jeffrey West, the former president of Santa

37:04.120 --> 37:08.680
V Institute, has written a wonderful book which I highly recommend called Scale, where he talks

37:08.680 --> 37:12.760
about how the complexity of cities arises.

37:12.760 --> 37:21.520
Any science does have ways of producing explanations about aggregate behavior, but it is non-reductionist

37:21.520 --> 37:22.520
science.

37:22.520 --> 37:28.320
What I'm saying is when you talk about complexity, you can find reduced forms of explanation

37:28.320 --> 37:30.760
to discuss complex systems.

37:30.760 --> 37:31.760
Okay.

37:31.760 --> 37:37.080
But no one's going to talk about galaxy formation by talking about particle physics, right.

37:37.080 --> 37:38.760
It's a different discipline.

37:38.760 --> 37:43.200
But all I'm saying is, of course you can study cities.

37:43.200 --> 37:47.440
The Santa Fe Institute has been studying cities for ages, but what they wouldn't say is to

37:47.440 --> 37:51.000
understand cities to study one family.

37:51.000 --> 37:57.840
Look, of course there's many, many levels and the very bottom level doesn't give a good

37:57.840 --> 37:59.560
explanation of the top level.

37:59.560 --> 38:01.280
But that's what neuroscientists think.

38:01.280 --> 38:02.920
I don't think so.

38:02.920 --> 38:05.000
I don't see that myself.

38:05.000 --> 38:07.920
I think in popular culture and popular writing, there's a lot of that.

38:07.920 --> 38:12.920
I don't see it really in neuroscientists myself.

38:12.920 --> 38:18.240
But just to say another thing, so you were talking about what people want to know is

38:18.240 --> 38:22.120
the mind they experience, their consciousness.

38:22.120 --> 38:26.000
From my point of view, that's literally the tip of the iceberg.

38:26.000 --> 38:30.480
And the iceberg being all the stuff that goes on in the brain.

38:30.480 --> 38:32.480
It's not literally the tip of the iceberg though.

38:32.480 --> 38:44.400
As the English professor, I'm constantly thinking, I'm going to be guilty.

38:44.400 --> 38:50.400
And the reason why that matters is because what we experience has a lot of structure

38:50.400 --> 38:55.280
that we don't understand, that we try to get at by introspection, by meditation, by all

38:55.280 --> 38:56.800
kinds of means.

38:56.800 --> 39:00.720
But a lot of that structure comes from all the stuff that's beneath the surface and not

39:00.720 --> 39:03.440
conscious.

39:03.440 --> 39:10.480
So to me, to understand the mind, to understand the conscious mind is a tiny piece of that.

39:10.480 --> 39:14.640
And it's not the central question really, although for ourselves personally, that's

39:14.640 --> 39:17.280
what we'd like to know because that's what we experience.

39:17.280 --> 39:21.400
But we're not going to understand that without understanding this huge amount of substructure

39:21.400 --> 39:24.520
and all the many, many levels from the bottom of the top.

39:24.520 --> 39:26.000
That's a very, very long project.

39:26.000 --> 39:28.440
But it's not that we're never going to get any insight.

39:28.440 --> 39:32.720
I mean, the one thing that I would agree with, or maybe I don't know if you're saying this,

39:32.720 --> 39:41.120
John, but I don't think we're ever going to have a scientific explanation of why the

39:41.120 --> 39:46.240
operations of the brain and the mind and all of their structure that leads us to act in

39:46.240 --> 39:50.640
the way that we act, why that's accompanied by subjective experience.

39:50.640 --> 39:55.320
Why we have a conscious experience, why we're not zombies, that whole thing of a question.

39:55.320 --> 39:57.040
I don't think that's a scientific question.

39:57.040 --> 39:59.040
I don't think we're ever going to answer that.

39:59.040 --> 40:03.000
We experience that when our mind does these things, they enter consciousness.

40:03.000 --> 40:04.880
We have a subjective awareness of them.

40:04.880 --> 40:10.360
But if you take away the subjective awareness part and just take all of the processing,

40:10.360 --> 40:17.840
all of the things that go on by which our brain is associating ideas and understand

40:17.840 --> 40:22.720
anything about the world and leading us to act in certain ways, then I don't see why

40:22.720 --> 40:26.800
we can't ultimately understand that in terms of the brain.

40:26.800 --> 40:31.280
For example, the problem is we're at such an early stage.

40:31.280 --> 40:35.720
At the time of Aristotle, if you wanted to understand why water felt wet, you really

40:35.720 --> 40:36.960
didn't have the means.

40:36.960 --> 40:40.120
Somebody could say, we're never going to understand that in physical terms.

40:40.120 --> 40:45.440
Now, any way you can describe the property of wetness, we have an explanation in terms

40:45.440 --> 40:48.480
of quantum mechanics and atoms and hydrogen bonds.

40:48.480 --> 40:51.920
We have explanations of why it has all the properties of wetness.

40:51.920 --> 40:54.840
In Aristotle's time, that was totally out of reach, but it didn't mean it was out of

40:54.840 --> 40:55.840
reach and principle.

40:55.840 --> 40:58.200
I think we're in Aristotle's time in terms of neurosis.

40:58.200 --> 40:59.600
No, just one...

40:59.600 --> 41:03.960
I don't agree actually about the subjective experience, but I actually feel that's a

41:03.960 --> 41:04.960
red herring.

41:04.960 --> 41:08.320
I think as it can shine again pointed out, it's amazing that you decide to move your

41:08.320 --> 41:09.320
arm and it goes up.

41:09.320 --> 41:11.160
It's amazing that you get touched and you feel it.

41:11.160 --> 41:15.880
So I actually think, like Nicholas Humphrey has written, that actually knowing where your

41:15.880 --> 41:21.920
limits in space when you close your eye is probably on the way to subjective conscious

41:21.920 --> 41:25.040
experience and you have a lovely argument of that kind.

41:25.040 --> 41:28.800
What I'm saying is that you keep using the word understand and what I'm saying can is

41:28.800 --> 41:33.840
you remove causal relations from that word.

41:33.840 --> 41:34.840
What does it mean?

41:34.840 --> 41:37.040
It means understanding the substance.

41:37.040 --> 41:39.040
No, don't use understanding to explain understanding.

41:39.040 --> 41:43.880
It means understanding the substructure that leads to the structure.

41:43.880 --> 41:45.680
Leads, but what does needs do?

41:45.680 --> 41:48.600
Is that causality?

41:48.600 --> 41:52.000
It's getting a deeper understanding of how the pieces are put together.

41:52.000 --> 41:53.360
You can't be going back to that word.

41:53.360 --> 41:55.360
What you're saying is what does it mean?

41:55.360 --> 41:57.360
What is causality?

41:57.360 --> 42:02.680
What I'm saying is that in the philosophy of science, in words explain and understand

42:02.680 --> 42:08.160
and cause are not the same thing or predict.

42:08.160 --> 42:12.360
When a sycamore leaf is dropped, we know the physics of the movement of a sycamore.

42:12.360 --> 42:15.360
It's extremely difficult to predict what its trajectory is going to be.

42:15.360 --> 42:20.480
Similarly, you can have converse situations where you can predict but not understand things.

42:20.480 --> 42:24.720
What I'm saying is the problem here is that you're using the word understanding.

42:24.720 --> 42:27.360
When you say, why is that woman crying?

42:27.360 --> 42:28.360
It's because she's sad.

42:28.360 --> 42:32.640
That's an explanation and you go, I now understand why she's crying.

42:32.640 --> 42:36.240
Causality is not in there in the scientific sense.

42:36.240 --> 42:41.040
What I'm saying is understanding isn't synonymous with causality.

42:41.040 --> 42:47.200
As soon as one goes after a scientist, like I'm going after you, to remove any causal sounding

42:47.200 --> 42:50.120
words from your sentences.

42:50.120 --> 42:52.840
Your left bereft.

42:52.840 --> 42:55.960
That's what I'm saying is what's so difficult about this.

42:55.960 --> 42:58.760
To me, it's a matter of these things.

42:58.760 --> 43:01.760
There's very, very complicated structure underlying it.

43:01.760 --> 43:08.040
The more you get insight, it's not a total understanding.

43:08.040 --> 43:12.760
You gain insight, the more you understand the structure underneath the surface.

43:12.760 --> 43:14.760
A body of correlations is not nothing.

43:14.760 --> 43:16.440
I think that's what you mean.

43:16.440 --> 43:19.120
You gain more and more and more correlations.

43:19.120 --> 43:20.120
They aren't causal.

43:20.120 --> 43:42.280
I think perhaps John

43:42.280 --> 43:55.800
has a question.

43:55.800 --> 44:00.520
You can also say that whatever event that this poor woman had in her life before she

44:00.520 --> 44:07.280
started crying had some causal relationship to her crying in a way that we could understand

44:07.280 --> 44:11.200
in some scientific fashion, perhaps though not just in terms of we wouldn't be in the

44:11.200 --> 44:12.200
language of neuroscience.

44:12.200 --> 44:17.440
In the language of psychology or sociology, events in one's life that have an effect

44:17.440 --> 44:18.960
on your emotions.

44:18.960 --> 44:21.600
That's not outside of science, I don't think.

44:21.600 --> 44:22.600
Is it?

44:22.600 --> 44:23.600
No, I'm just saying-

44:23.600 --> 44:25.320
It's just that science is not neuroscience.

44:25.320 --> 44:30.040
Right, I'm just saying that there are, as a general, intentional levels, there are words

44:30.040 --> 44:32.680
that do explain them that mean things.

44:32.680 --> 44:37.720
All I'm saying is that if you want it to sound like an explanation or understanding,

44:37.720 --> 44:43.760
by dropping down to what is doing good, correlational causal work and wanted to also give you,

44:43.760 --> 44:49.120
along with its correlational causal truth, the feeling of explanation and understanding,

44:49.120 --> 44:53.680
in addition when you subtract the way the correlational causality, we don't have a way

44:53.680 --> 44:54.680
of doing that.

44:54.680 --> 44:55.680
No, and I agree entirely.

44:55.680 --> 44:59.120
You could say that in some ways, there's just a dependency relationship between these

44:59.120 --> 45:00.680
levels of explanation.

45:00.680 --> 45:02.200
You can't have one without the other.

45:02.200 --> 45:06.400
We're not going to have crying people who have no brains.

45:06.400 --> 45:12.560
Nevertheless, the explanation that's going to satisfy the question of whether it was

45:12.560 --> 45:16.520
or someone crying is simply not going to be done at some lower level of dependency that

45:16.520 --> 45:20.880
needs to be there, but it doesn't do any explanatory causal work.

45:20.880 --> 45:22.880
It doesn't.

45:22.880 --> 45:25.080
And I don't have to- I don't claim any of the answer.

45:25.080 --> 45:31.120
I'm just saying that I don't think we should fool ourselves with these words and use them.

45:31.120 --> 45:36.240
Well philosophers of science have spent a lot of time arguing about what it means to be

45:36.240 --> 45:43.640
an explanation and to have understanding, and they've come to no answers on this or no

45:43.640 --> 45:44.640
understanding.

45:44.640 --> 45:49.000
But some of them, like Nathan Salmon, he did argue that an explanation is just providing

45:49.000 --> 45:50.000
a cause.

45:50.000 --> 45:57.800
Boss von Frostin, one of my favorite, he says an explanation is an answer to a Y question.

45:57.800 --> 46:03.040
So it's sort of a social thing also when we stop sort of asking the question, maybe we

46:03.040 --> 46:06.040
have the explanation.

46:06.040 --> 46:16.120
Now Ken, I wanted to say you're just really not being bold enough, I would say.

46:16.120 --> 46:23.120
I am another thing that boss von Frostin says that I like to quote quite often.

46:23.120 --> 46:26.280
So he says there are no science stoppers.

46:26.280 --> 46:27.440
And I really believe that.

46:27.440 --> 46:34.080
I mean, well yes, from our perspective now, consciousness, subjective experience that's

46:34.080 --> 46:39.240
beyond the Ken, but you know, why, who knows?

46:39.240 --> 46:46.120
I mean, how can we, at our point, really, I mean, there have been such major turnovers

46:46.120 --> 46:52.000
in science, but we couldn't have predicted at all in the past, maybe in the future, we

46:52.000 --> 46:57.760
will stop, you know, wondering why consciousness, why are we subjective, and it will just be

46:57.760 --> 47:05.000
something that seems, somehow we've come up with some psychologically satisfying answer

47:05.000 --> 47:06.000
to it.

47:06.000 --> 47:11.480
Now, of course, there is the other certain science stoppers do exist in terms of grant

47:11.480 --> 47:12.480
money.

47:12.480 --> 47:17.240
You know, maybe it's not reasonable to be giving a lot of money right now to the neuroscientists

47:17.240 --> 47:21.320
studying subjectivity because we're nowhere close enough.

47:21.320 --> 47:30.120
But in principle, why like sort of say, absolutely not, isn't it useful to leave open, except

47:30.120 --> 47:32.720
for maybe economic reasons?

47:32.720 --> 47:38.280
So, okay, I don't think it's really the most important question to worry about, but the

47:38.280 --> 47:45.960
reason I say that is what science does, I mean, we start with subjective experience

47:45.960 --> 47:47.560
of an objective world.

47:47.560 --> 47:52.520
What science does is it isolates the things that are objectively reproducible, objectively

47:52.520 --> 47:55.640
definable, operationally definable.

47:55.640 --> 48:01.440
And so you can, I believe consciousness, science, consciousness, neuroscience is a real field

48:01.440 --> 48:08.400
because what it has to do with understanding what brain processes and what brain systems

48:08.400 --> 48:13.640
are active, in what ways when you are versus are not conscious, when you do versus don't

48:13.640 --> 48:15.960
consciously perceive something.

48:15.960 --> 48:21.760
It's knowing, you know, ultimately, hopefully we will completely be able to say by observing,

48:21.760 --> 48:25.680
you know, the brain, whether someone was conscious of a certain thing or not.

48:25.680 --> 48:27.320
I think that's totally unreached.

48:27.320 --> 48:34.320
What I don't think is unreached is to say why there's a subjective experience associated

48:34.320 --> 48:38.520
with it because all that science can talk about is the objective processes underlying.

48:38.520 --> 48:42.920
Or how you get from these objective processes to this objective experience, not just why.

48:42.920 --> 48:47.720
I'm impressed that you know what science can do, maybe that's what it can do today.

48:47.720 --> 48:53.120
But come on, look at what Aristotle would have said, all this was what science can do.

48:53.120 --> 48:57.560
He would have really had a much different, none of what we are doing today would have

48:57.560 --> 48:58.560
he said.

48:58.560 --> 49:03.280
But I mean, prediction is difficult, especially about the future.

49:03.280 --> 49:08.800
I think someday you have an explanation that makes us satisfied and stop worrying about

49:08.800 --> 49:16.080
it, you know, so that to say when this subsystem of the brain acts in this way, it makes the

49:16.080 --> 49:20.440
brain imagine that it's experiencing something and that's consciousness.

49:20.440 --> 49:24.880
You know, and you could imagine that we will tell ourselves a story that will satisfy ourselves

49:24.880 --> 49:29.080
and will be 100% correlated with when you're conscious and when you're not.

49:29.080 --> 49:33.800
That's different from saying why dead matter has subjective experience.

49:33.800 --> 49:37.600
That's just that we can get a satisfying explanation, but that's a different issue.

49:37.600 --> 49:39.400
I think it's an important one though.

49:39.400 --> 49:43.680
I think it might seem termological and not that interesting, but what's happened over

49:43.680 --> 49:48.160
time was when neuroscience says that's not a scientific question and subjectivity and

49:48.160 --> 49:52.280
consciousness have gotten that treatment, it ends up flipping over into mysticism and

49:52.280 --> 49:53.280
religion.

49:53.280 --> 49:57.080
Usually there's a great deal of pressure for it to flip over into religion and mysticism.

49:57.080 --> 50:00.360
So I think it's easy to say this is part of the natural world.

50:00.360 --> 50:03.960
We probably need a different way of thinking about science and different technological

50:03.960 --> 50:09.560
kind of advances to be able to master this, but the problems don't go away.

50:09.560 --> 50:13.600
And one of the central problems subjectivity is if you think of it as an epiphenomena,

50:13.600 --> 50:15.000
it's not very interesting.

50:15.000 --> 50:21.320
But if you think of intention and top down regulation as critical to human behavior and

50:21.320 --> 50:25.920
to expand it outward to the ant in a colony, to political life, to life, liberty and the

50:25.920 --> 50:31.400
pursuit of happiness, if you think all of that is critical, then you don't want to walk

50:31.400 --> 50:36.280
away from it as potentially open to reliable and valid knowledge, AKA science.

50:36.280 --> 50:38.520
I don't want to look at any of that.

50:38.520 --> 50:43.360
It's only any objective process you must have to name on.

50:43.360 --> 50:45.320
Intentionality won't make me quite.

50:45.320 --> 50:48.920
Yeah, any objective process you can put a name on, I think we can investigate.

50:48.920 --> 50:57.160
It's just why that objective process is not, you know, look, when a computer program is

50:57.160 --> 51:02.160
complicated as we can make it today, I think we all feel confident does not have any subjective

51:02.160 --> 51:03.160
experience.

51:03.160 --> 51:06.960
A car engine, I think we all feel confident does not have any subjective experience.

51:06.960 --> 51:11.240
So you keep adding more and more and more complexity of the matter, and at some point

51:11.240 --> 51:13.200
the matter has subjective experience.

51:13.200 --> 51:16.600
I think we can talk about all the complexity of the matter, all the processing it does,

51:16.600 --> 51:19.880
we can talk about which of them are associated with subjective experience.

51:19.880 --> 51:27.020
But the fact that the dead meat requires subjective experience, how do you, there isn't a

51:27.020 --> 51:29.600
fact, that's a fact, it's a phenomenon.

51:29.600 --> 51:33.720
Well, I think I recognize that it's a paradox.

51:33.720 --> 51:35.880
How do we have an objective science of subjectivity?

51:35.880 --> 51:36.880
I honestly feel...

51:36.880 --> 51:38.880
It's a real problem.

51:38.880 --> 51:45.000
I mean, there's a lot more that's concerning about understanding the link between mind

51:45.000 --> 51:49.640
and brain than this old sore of subjectivity and consciousness.

51:49.640 --> 51:51.480
I think one of the...

51:51.480 --> 51:55.280
I think one has to distinguish.

51:55.280 --> 51:59.720
It's extremely important to distinguish between making statements about science never getting

51:59.720 --> 52:00.720
somewhere.

52:00.720 --> 52:01.720
I think you're totally right.

52:01.720 --> 52:08.840
And at no point was I trying to say that versus logical conceptual errors that are

52:08.840 --> 52:12.880
being made and being mistaken for lack of scientific progress.

52:12.880 --> 52:15.840
And all I'm saying is they're not the same.

52:15.840 --> 52:21.200
There's a lot of logical conceptual error in the way we think about these questions that

52:21.200 --> 52:27.040
is invariant to how far we are along in terms of our technologies and our techniques.

52:27.040 --> 52:28.320
Of course we don't know.

52:28.320 --> 52:33.080
And actually, when it comes to the subjectivity argument, that's actually what I don't think

52:33.080 --> 52:34.080
it's such a big deal.

52:34.080 --> 52:38.180
I think it's a big deal because of us posing it.

52:38.180 --> 52:42.760
We give special status to subjectivity over pain, over proprioception.

52:42.760 --> 52:44.560
But that's cultural.

52:44.560 --> 52:49.520
I actually think this obsession with consciousness subjectivity is a cultural bias, more than

52:49.520 --> 52:51.760
a difference in kind.

52:51.760 --> 52:52.760
And I just...

52:52.760 --> 53:03.080
I hope this is a complex discussion that understanding things like language, pain, movement, attention,

53:03.080 --> 53:07.960
all of those are difficult to know what the right level of analysis is.

53:07.960 --> 53:09.480
Do we do psychological modules?

53:09.480 --> 53:10.480
Do we do circuits?

53:10.480 --> 53:11.480
Do we do neural?

53:11.480 --> 53:15.880
I'm trying to say that all those areas that aren't the sexy area of consciousness of subjectivity

53:15.880 --> 53:22.000
are all still in play in terms of we're not sure what the level of granularity is to do

53:22.000 --> 53:24.280
the work.

53:24.280 --> 53:25.280
That's what I'm saying.

53:25.280 --> 53:30.120
It's true in all areas, even movement.

53:30.120 --> 53:35.400
And what I'm saying is that the moment in neuroscience we've got this reductionist turn

53:35.400 --> 53:39.960
where we feel like we can play God on small circuits, which we can.

53:39.960 --> 53:42.960
It's remarkable what we can do now on small circuits.

53:42.960 --> 53:46.360
We are like gods, right?

53:46.360 --> 53:53.400
Has led to a kind in my view premature belief that this is going to be extrapolated to be

53:53.400 --> 53:58.680
as good as what our current psychological functional explanations look like.

53:58.680 --> 54:00.680
So you see global points.

54:00.680 --> 54:01.680
Right.

54:01.680 --> 54:08.720
So if I understand what you're saying now, the complaint or the concern about reducing

54:08.720 --> 54:15.080
subjectivity is for you at least less of a concern or is a red herring in the way of

54:15.080 --> 54:22.280
actually what you're really worried about, which is reducing and being kind of a sort

54:22.280 --> 54:26.800
of neurological greediness at other levels of the mind, which aren't even conscious actually.

54:26.800 --> 54:27.800
That's correct.

54:27.800 --> 54:34.280
And what we're really dealing with is how are we going to do neuroscience versus psychology?

54:34.280 --> 54:36.240
One is functional, one is mechanistic.

54:36.240 --> 54:38.800
And that's a genuinely difficult bridging question.

54:38.800 --> 54:41.440
And that's true across the board.

54:41.440 --> 54:49.120
And I think that there's a tendency to believe that we will, even for complex cognitive phenomena,

54:49.120 --> 54:54.800
be able to explain away some of our functional designations with lower level ones.

54:54.800 --> 54:58.560
And at the current time, that has not succeeded.

54:58.560 --> 55:02.880
Now, whether there's some breakthrough, we shall see.

55:02.880 --> 55:07.400
But that's right, but that's so that we're agreeing because as I said, we're, you know,

55:07.400 --> 55:11.000
we're centuries or millennia away from those kinds of connections.

55:11.000 --> 55:14.080
But that's different from saying in principle, it can't be done, which is what I thought

55:14.080 --> 55:15.080
you were saying.

55:15.080 --> 55:16.080
No, I wasn't saying principle.

55:16.080 --> 55:20.840
I was saying I want to distinguish between what is still open to being discovered versus

55:20.840 --> 55:28.440
what is a illogical kind of framework to begin with that needs to just be dismantled a little

55:28.440 --> 55:29.440
bit.

55:29.440 --> 55:33.680
So that's saying one day we'll understand the ether, there is no ether.

55:33.680 --> 55:34.680
Right?

55:34.680 --> 55:39.840
And what I'm saying is we just, I want to say that there are lots of philosophical, logical

55:39.840 --> 55:48.320
mistakes at work today, which by the way, the neurological fallacy that Haka talks about,

55:48.320 --> 55:53.040
Aristotle was the one who first came up with that idea that it's not the idea that the

55:53.040 --> 55:55.560
part is doing what the whole is doing.

55:55.560 --> 56:00.440
Aristotle was the first one to point that out and he's correct up until this day.

56:00.440 --> 56:02.440
Wings don't fly, birds do.

56:02.440 --> 56:03.440
Right?

56:03.440 --> 56:04.440
In some language, yes, sir.

56:04.440 --> 56:06.440
The amygdala does not feel pain.

56:06.440 --> 56:07.440
Right?

56:07.440 --> 56:08.920
Well, yeah, I don't think...

56:08.920 --> 56:11.480
You could say the heart doesn't pump blood, a person does.

56:11.480 --> 56:14.560
No, I think we all feel comfortable saying the heart pumps blood.

56:14.560 --> 56:17.080
You could say, you know, the brain doesn't think the person does.

56:17.080 --> 56:20.680
Well, that's because we identify the person with what the brain does.

56:20.680 --> 56:23.600
So in that sense, we feel more comfortable saying the person thinks.

56:23.600 --> 56:25.840
It's just sensible to say the brain.

56:25.840 --> 56:27.840
Now, the amygdala, you wouldn't feel the pain.

56:27.840 --> 56:31.080
Yeah, but without pain sensors and your periphery, you wouldn't.

56:31.080 --> 56:33.520
So are they feeling pain in your skin?

56:33.520 --> 56:35.520
That's not the question.

56:35.520 --> 56:39.320
No, I'm saying we don't consider your skin as feeling pain.

56:39.320 --> 56:40.320
We don't.

56:40.320 --> 56:41.320
Right?

56:41.320 --> 56:44.160
Or you do when you burn your hand, your skin is moving.

56:44.160 --> 56:46.760
No, it's not your skin feeling pain.

56:46.760 --> 56:48.760
It's not your skin feeling pain.

56:48.760 --> 56:51.440
And then why do you say my skin hurts?

56:51.440 --> 56:56.680
No, because we're very subject to this neurological fallacy, which Aristotle first pointed out.

56:56.680 --> 56:57.680
Yes, right.

56:57.680 --> 57:01.520
There's an importance to that because we start with saying it's my...

57:01.520 --> 57:05.360
I just burnt my finger, my finger is there for hurting.

57:05.360 --> 57:11.000
And out of that observation comes a series of other development and progress that gets

57:11.000 --> 57:16.280
us to the point where you can say, this part, these circuits and this and that got us to

57:16.280 --> 57:18.080
the fact that now I'm perceiving this.

57:18.080 --> 57:19.080
But there's a causal...

57:19.080 --> 57:28.560
There is a... in terms of worrying about subjectivity and the consciousness, there is a gain at

57:28.560 --> 57:32.040
the end, just as there is a gain about understanding any of the...

57:32.040 --> 57:35.280
Interesting facts and causality that we gathered along the way.

57:35.280 --> 57:40.040
What I'm saying is the answers aren't of the form of the original question.

57:40.040 --> 57:43.960
Your five government interests in five governments.

57:43.960 --> 57:45.440
Can't hear you in.

57:45.440 --> 57:47.040
Why is the government interested in...

57:47.040 --> 57:51.640
Well, it's... well, there was a leader, Thomas O'Hil, who was the head of the NIMH and he

57:51.640 --> 57:53.600
had a very narrow view.

57:53.600 --> 57:59.960
I think he would have benefited from a conversation with you about the epistemologic problems of

57:59.960 --> 58:05.280
neuroscience and he felt that we were wasting our time looking for correlations, wasting

58:05.280 --> 58:09.720
our time doing clinical research that didn't have clear biomarkers or neural circuits.

58:09.720 --> 58:12.000
These are the two big terms.

58:12.000 --> 58:17.880
And so he mandated, kind of from the top down, that any grant that would be coming to the

58:17.880 --> 58:23.040
NIMH must make a claim about a biomarker or a neural circuit that was underlying it in

58:23.040 --> 58:24.720
a causal manner.

58:24.720 --> 58:28.480
Now in psychiatry, we have none.

58:28.480 --> 58:31.640
So that puts researchers in a rather strange position.

58:31.640 --> 58:33.760
They have to make something up.

58:33.760 --> 58:36.840
Mr. Ensel, a doctor Ensel, has gone to Google.

58:36.840 --> 58:38.680
We're no doubt he's doing very well.

58:38.680 --> 58:39.680
He left...

58:39.680 --> 58:40.680
He left Google already.

58:40.680 --> 58:42.760
He left the company now.

58:42.760 --> 58:46.360
Okay, but the NIMH to this date, we don't know, they have a new director.

58:46.360 --> 58:48.640
We'll see if they continue with this.

58:48.640 --> 58:58.720
Whether they do or not, it is a really made manifest the way science can become epistemologically

58:58.720 --> 59:03.320
unsound and ideological essentially.

59:03.320 --> 59:04.320
This was essentially ideology.

59:04.320 --> 59:06.640
It wasn't science.

59:06.640 --> 59:09.600
And it's really a hamper research.

59:09.600 --> 59:15.600
The irony was the great victory of Tom Ensel's NIMH came out as he was on his way out the

59:15.600 --> 59:16.600
door.

59:16.600 --> 59:21.680
It was a five-year study that showed that early intervention with young people who were psychotic,

59:21.680 --> 59:27.960
with psychotherapy and family support and medication led to better outcomes.

59:27.960 --> 59:32.400
It was a study that could not have been done with a biomarker or a neural circuit.

59:32.400 --> 59:38.240
So his greatest victory actually seemed to imply that he should not have made these

59:38.240 --> 59:41.720
decisions, but it's presently the law of the land at the NIMH.

59:41.720 --> 59:43.520
As far as I understand.

59:43.520 --> 59:47.880
Maybe I'll say if it's okay.

59:47.880 --> 59:55.600
Okay, I mean I also, in my research, I also, and I'm writing a book really why we need

59:55.600 --> 01:00:03.400
to move beyond this problem actually of just the subjectivity and consciousness actually.

01:00:03.400 --> 01:00:05.000
So mind without matter.

01:00:05.000 --> 01:00:08.920
We don't need to be thinking now about that relationship, but I just have to say something

01:00:08.920 --> 01:00:17.000
about this, still this idea that there's this insuperable problem about science's objective

01:00:17.000 --> 01:00:19.400
and the consciousness is subjective.

01:00:19.400 --> 01:00:25.920
Well, you know, no one else, as philosophers, no philosopher has been able to explain what

01:00:25.920 --> 01:00:28.560
that means to say science is objective.

01:00:28.560 --> 01:00:32.680
It's very difficult to say what that exactly means.

01:00:32.680 --> 01:00:38.560
So it's not, it sounds like there's a problem, but it's not clear what that problem is at

01:00:38.560 --> 01:00:41.160
all if there is a problem.

01:00:41.160 --> 01:00:47.080
So I wouldn't take that as a, okay, we're never going to get there because we have science

01:00:47.080 --> 01:00:51.080
as objective and if we don't really know what that means.

01:00:51.080 --> 01:00:56.720
I mean, just to defend Ken a little bit about, just so you don't think I'm anti-circuit.

01:00:56.720 --> 01:00:58.720
I mean, these are subtle issues.

01:00:58.720 --> 01:01:03.160
But if you look at the Sherryton's work on the stretch reflex, in other words, Shankton

01:01:03.160 --> 01:01:07.160
at the end of the 19th, early 20th century was very interested in the loop between the

01:01:07.160 --> 01:01:09.920
sensation and the reflex, you know, the nature that everyone says.

01:01:09.920 --> 01:01:16.720
And we do have a mechanistic understanding that goes beyond correlation or causation.

01:01:16.720 --> 01:01:21.840
I mean, when you talk about understanding in science, it's about this object, pushing

01:01:21.840 --> 01:01:24.000
on that object and moving it.

01:01:24.000 --> 01:01:26.160
It's about interaction between things.

01:01:26.160 --> 01:01:30.360
Although not in physics because they don't even talk about causality and physics.

01:01:30.360 --> 01:01:35.360
Well, well, I mean, quantum mechanics is a causal to degree, but that's not true at

01:01:35.360 --> 01:01:37.280
the meso level they do, right?

01:01:37.280 --> 01:01:41.040
So in other words, what I'm saying is, is you can say, and Sherryton did, that this is

01:01:41.040 --> 01:01:45.920
a stimulus, it hits the 1A apron, it goes and it makes a monosynaptic connection to the

01:01:45.920 --> 01:01:50.280
motor neuron, which then innovates the muscle, and that is really nice.

01:01:50.280 --> 01:01:52.760
It's just the kind of work that we like.

01:01:52.760 --> 01:01:56.520
And then you look at eye movement, so the very famous engineer at Hopkins called David

01:01:56.520 --> 01:02:01.480
Robinson, who beautifully integrated eye movements with the circuitry underlying them in the

01:02:01.480 --> 01:02:04.040
brainstem and a mathematical model.

01:02:04.040 --> 01:02:10.320
There was an isomorphic click between the model, the anatomy and the behavior.

01:02:10.320 --> 01:02:15.160
So there are beautiful successes in neuroscience where you do get the perfect link between

01:02:15.160 --> 01:02:18.200
the circuit, the behavior and a computational model.

01:02:18.200 --> 01:02:24.400
The problem is, is can we repeat that success when it comes to what we all call the mind

01:02:24.400 --> 01:02:25.680
or cognition?

01:02:25.680 --> 01:02:29.880
When I mentioned Janelia at the beginning of this session, they say, look, what if we

01:02:29.880 --> 01:02:35.840
find the cognitive primitive that is the equivalent of the stretch reflex or an eye movement,

01:02:35.840 --> 01:02:38.400
but it's not about the sensory motor, we'll move those out.

01:02:38.400 --> 01:02:41.000
It's about that decision in between, right?

01:02:41.000 --> 01:02:45.280
That it's the cognitive decision that is invariant to whether you decide to pick up

01:02:45.280 --> 01:02:48.320
the apple because you saw it, you smelled it, you can use your mouth, you can use your

01:02:48.320 --> 01:02:49.320
hand.

01:02:49.320 --> 01:02:54.520
The decision is invariant to the sensory stimulus and to the effector and if we could just understand

01:02:54.520 --> 01:03:00.720
the cognitive equivalent of the stretch reflex, we're on our way, right?

01:03:00.720 --> 01:03:03.920
And we have the technology now that Sherryton didn't have and David Robinson didn't have,

01:03:03.920 --> 01:03:06.440
we can move beyond the sensory motor.

01:03:06.440 --> 01:03:08.080
That's what's going on.

01:03:08.080 --> 01:03:13.120
And what I'm saying is, is there's a possibility, just like we're seeing with deep mind, we

01:03:13.120 --> 01:03:17.040
don't know what all those synaptic weights are doing, but when it gets to cognition of

01:03:17.040 --> 01:03:22.320
the form we're interested in, it won't be that cliquey little isomorphic feeling that

01:03:22.320 --> 01:03:26.240
eye movements and stretch reflex have.

01:03:26.240 --> 01:03:29.680
That's the big dilemma is will we be able to extrapolate, because even for the stretch

01:03:29.680 --> 01:03:32.720
reflex, we haven't been able to extrapolate to motor cortex, we still don't know what

01:03:32.720 --> 01:03:36.040
motor cortex does and we've had stretch reflex for 100 years.

01:03:36.040 --> 01:03:43.640
So I'm just voicing a little bit of skepticism about the simple version and then scaling it

01:03:43.640 --> 01:03:44.640
up.

01:03:44.640 --> 01:03:50.120
But again, it's, there's a question of in principle, is it impossible or is it, are

01:03:50.120 --> 01:03:52.400
we just way premature?

01:03:52.400 --> 01:03:56.600
And you know, just as another example, I mean, you know, memory.

01:03:56.600 --> 01:04:03.880
So we, that's a psychological process and from neuropsychology, but the neuro was critical.

01:04:03.880 --> 01:04:06.240
We've discovered it breaks up into pieces, right?

01:04:06.240 --> 01:04:10.760
There's the episodic memory and there's the short term working memory and there's the

01:04:10.760 --> 01:04:15.280
short term and long term episodic memory and the ways those that psychology that's neuro

01:04:15.280 --> 01:04:18.320
psychology, but we didn't and that's that I love that stuff.

01:04:18.320 --> 01:04:19.640
That separates from procedural memory.

01:04:19.640 --> 01:04:22.680
And there's not agreement that they don't have agreement about that.

01:04:22.680 --> 01:04:26.320
But we never knew any of those things separated until there was a jam, right?

01:04:26.320 --> 01:04:30.560
So until there was a guy who lost his ability to make new episodic memories.

01:04:30.560 --> 01:04:35.760
Well, that research though is though also I think we can't talk about that research

01:04:35.760 --> 01:04:40.160
after you have you read the journalist's book about the research on HM.

01:04:40.160 --> 01:04:42.120
I don't think it's, yeah.

01:04:42.120 --> 01:04:44.120
That's not going to happen anymore.

01:04:44.120 --> 01:04:45.120
Well done.

01:04:45.120 --> 01:04:49.000
It was like, no, I mean, you're talking about, you know, the ethics of how it was done.

01:04:49.000 --> 01:04:50.480
I'm just talking about the results.

01:04:50.480 --> 01:04:51.480
Right.

01:04:51.480 --> 01:04:53.480
I mean, we can maybe separate them.

01:04:53.480 --> 01:04:55.480
We'll leave them there.

01:04:55.480 --> 01:05:03.040
But my point was that a psychological process starts to break up into pieces we were not

01:05:03.040 --> 01:05:05.120
aware of that give us insight.

01:05:05.120 --> 01:05:06.120
Oh, I love that stuff.

01:05:06.120 --> 01:05:07.520
And that's never going to stop.

01:05:07.520 --> 01:05:11.240
We're never going to stop breaking it up into pieces that are we didn't know about and

01:05:11.240 --> 01:05:14.480
that are going to give us insight into how it works and give us more and more power to

01:05:14.480 --> 01:05:15.480
manipulate it.

01:05:15.480 --> 01:05:16.480
No, just agreement there.

01:05:16.480 --> 01:05:24.840
You know, neuropsychological decomposition into modules is not the same as circuit implementation

01:05:24.840 --> 01:05:25.840
in neuroscience.

01:05:25.840 --> 01:05:26.840
They're not there.

01:05:26.840 --> 01:05:27.840
They're related.

01:05:27.840 --> 01:05:28.840
Well, okay.

01:05:28.840 --> 01:05:29.840
But that's so a third cause.

01:05:29.840 --> 01:05:30.840
All right.

01:05:30.840 --> 01:05:33.840
I'm going to turn it on.

01:05:33.840 --> 01:05:40.840
Please come to the microphone for asking any questions that you may have.

01:05:40.840 --> 01:05:47.840
No, I don't want to worry in principle.

01:05:47.840 --> 01:05:50.840
Should there be limits to what we can know?

01:05:50.840 --> 01:05:52.640
I'm thinking of evolution.

01:05:52.640 --> 01:05:56.640
Obviously, you know, a monkey can't know answer these questions.

01:05:56.640 --> 01:06:01.640
And if you think of evolution, our brains have evolved to deal with everyday life.

01:06:01.640 --> 01:06:03.640
I'm assuming evolution hasn't stopped.

01:06:03.640 --> 01:06:08.480
Something species have come along with brains bigger than ours and can't figure out why

01:06:08.480 --> 01:06:10.360
we can't understand things.

01:06:10.360 --> 01:06:14.520
So why is it obvious to me that there are questions that we haven't ever answered?

01:06:14.520 --> 01:06:15.880
Well, that's a good question.

01:06:15.880 --> 01:06:21.640
I mean, I would say we shouldn't take there to be in principle science toppers.

01:06:21.640 --> 01:06:22.640
Why?

01:06:22.640 --> 01:06:23.720
Say you can't do it.

01:06:23.720 --> 01:06:28.960
It's not useful psychologically from a psychological perspective.

01:06:28.960 --> 01:06:31.720
Like since we don't know.

01:06:31.720 --> 01:06:35.920
We so, yes, of course our brains are a certain size.

01:06:35.920 --> 01:06:37.640
We have certain resources.

01:06:37.640 --> 01:06:39.440
They're going to be limits.

01:06:39.440 --> 01:06:44.800
But why say we can't right now, we're at a point where we can't because in the past

01:06:44.800 --> 01:06:50.320
we've seen so many times where scientists have said, oh, we've figured it all out now.

01:06:50.320 --> 01:06:53.560
This is something we can never figure out.

01:06:53.560 --> 01:06:55.280
And we have after time.

01:06:55.280 --> 01:06:56.280
Not these questions.

01:06:56.280 --> 01:06:59.520
So the thing that we're just spending your money should do where you think you can have

01:06:59.520 --> 01:07:00.520
the most chances of the things.

01:07:00.520 --> 01:07:04.640
Yes, so that's why there are practical reasons.

01:07:04.640 --> 01:07:10.880
So maybe, you know, this is why maybe it's an argument since some people want the money

01:07:10.880 --> 01:07:13.000
and they're trying to argue for it.

01:07:13.000 --> 01:07:14.960
So that's a reasonable argument.

01:07:14.960 --> 01:07:22.880
But I don't think we can predict the future well enough given how much science has changed

01:07:22.880 --> 01:07:23.880
in the past.

01:07:23.880 --> 01:07:24.880
It's going to change in the future too.

01:07:24.880 --> 01:07:31.800
I think to say this is one area where we're absolutely certain we'll not make progress.

01:07:31.800 --> 01:07:32.800
So yes.

01:07:32.800 --> 01:07:33.800
I don't think you know what I'm saying.

01:07:33.800 --> 01:07:34.800
I think there's another.

01:07:34.800 --> 01:07:35.800
No one said that.

01:07:35.800 --> 01:07:40.360
Yeah, there's another answer which is that this isn't just about pure science.

01:07:40.360 --> 01:07:42.320
It's about pragmatic problems.

01:07:42.320 --> 01:07:46.560
You know, as a psychiatrist, if someone comes to me and I take the epistemological standards

01:07:46.560 --> 01:07:49.680
that we've been talking about today, I say, I really have no idea.

01:07:49.680 --> 01:07:53.680
I have no idea about almost anything at this level of certainty and causal certainty.

01:07:53.680 --> 01:07:56.720
And yet, here is a person who needs help.

01:07:56.720 --> 01:08:02.040
So I have to try to think in a very dirty way from a scientific point of view about what's

01:08:02.040 --> 01:08:09.600
pragmatically and what's pragmatically effective, what kind of correlations exist, what things

01:08:09.600 --> 01:08:16.240
like my experience have shown me that give me some sort of dirty attempt to try to help

01:08:16.240 --> 01:08:17.240
this person.

01:08:17.240 --> 01:08:18.840
So I think that's just one experience.

01:08:18.840 --> 01:08:24.760
I think there's a whole array of other pragmatic reasons why saying this isn't unanswerable

01:08:24.760 --> 01:08:29.560
leads to, it doesn't have to lead to fake answers.

01:08:29.560 --> 01:08:35.120
It can lead to hypotheses that you know are not confirmed that are working in hypotheses

01:08:35.120 --> 01:08:37.400
that help you work through a problem.

01:08:37.400 --> 01:08:41.000
Well, I would someone study consciousness for instance.

01:08:41.000 --> 01:08:43.880
I don't think there's any sort of human knowledge benefit.

01:08:43.880 --> 01:08:47.400
And for me, that's obvious one where we're not going to have an answer.

01:08:47.400 --> 01:08:48.400
It's really one possible.

01:08:48.400 --> 01:08:55.000
Well again, we're going to have lots of answers about what neuroprocesses happen when you

01:08:55.000 --> 01:08:56.800
are and aren't conscious.

01:08:56.800 --> 01:08:59.120
But so those will have certain kinds of answers.

01:08:59.120 --> 01:09:00.360
I think, well, of course.

01:09:00.360 --> 01:09:02.960
And also, I mean, why study consciousness?

01:09:02.960 --> 01:09:06.600
I mean, there's several, there's different ways in which one can study consciousness.

01:09:06.600 --> 01:09:10.840
I mean, since consciousness is actually available for introspection, it is something we all

01:09:10.840 --> 01:09:14.600
experience because it is experience.

01:09:14.600 --> 01:09:19.920
It certainly is available for all kinds of investigation and explanation of a gist of

01:09:19.920 --> 01:09:25.480
a different sort than you might have with respect to its neural substructure.

01:09:25.480 --> 01:09:28.280
So then why do it?

01:09:28.280 --> 01:09:30.960
Well, because actually it's the world in which we all live.

01:09:30.960 --> 01:09:37.120
I mean, it was something that we all care deeply about because it's something we are

01:09:37.120 --> 01:09:41.000
intimately familiar with from waking up to going to sleep.

01:09:41.000 --> 01:09:46.320
So certain jetties and consciousnesses, if it's irrelevant, seems to basically leave

01:09:46.320 --> 01:09:48.920
behind the entire world.

01:09:48.920 --> 01:09:53.040
And who would want to do that?

01:09:53.040 --> 01:09:55.640
So like, you know, it could be out there with the science of correlations like you were

01:09:55.640 --> 01:10:02.440
describing, the whole neural-carlate program, which I think is underway for a while now,

01:10:02.440 --> 01:10:08.840
and or it could be some other form of phenomenological science where actually you really look hard

01:10:08.840 --> 01:10:14.360
on your own experiences and those are the reports of others.

01:10:14.360 --> 01:10:17.080
And also, you don't know what type of spin-offs it might have.

01:10:17.080 --> 01:10:21.520
With pure research now, we don't really know what these correlations would do.

01:10:21.520 --> 01:10:23.280
You don't know what type of...

01:10:23.280 --> 01:10:26.760
And if people are motivated, if there's some people that are interested, well then they'll

01:10:26.760 --> 01:10:31.600
probably work really hard and maybe do some good research.

01:10:31.600 --> 01:10:39.200
I have a wonderful scientist, MIT, Harvard, Emory Brown, who've done some fascinating

01:10:39.200 --> 01:10:45.440
work on the differences between being under anesthesia and versus being asleep, for example,

01:10:45.440 --> 01:10:48.560
and being sedated and doing what Ken was talking about.

01:10:48.560 --> 01:10:54.360
Very interesting differences in the sub-component neuroanatomy and physiological processes versus

01:10:54.360 --> 01:10:58.080
immuno-reuse sleep, sedated, or under anesthesia of different kinds.

01:10:58.080 --> 01:11:04.200
It says, wonderful, basic work being done in hospitals where patients are being put under

01:11:04.200 --> 01:11:05.200
anesthesia.

01:11:05.200 --> 01:11:09.200
In fact, Emory Brown's work to me is some of the nicest work showing how you can do in

01:11:09.200 --> 01:11:16.280
parallel mechanistic modular work and work that's going to be important for patients.

01:11:16.280 --> 01:11:19.680
The problem with translation, I mean, with a wonderful paper that came out last year by

01:11:19.680 --> 01:11:26.160
Unida Senjoyna at how little of what the NIH has funded has translated.

01:11:26.160 --> 01:11:31.320
And one of the reasons they put forward is because it's this horrible reductionist neuromolecular

01:11:31.320 --> 01:11:36.240
program that we're going to solve disease, one molecule at a time, one gene at a time.

01:11:36.240 --> 01:11:42.000
And actually, if you notice now, many people are considerably their sanguine now about

01:11:42.000 --> 01:11:47.080
what they think this is going to lead to, the former head of the NIH and Blanchion's name

01:11:47.080 --> 01:11:50.040
now, he was interviewed recently about Thomas Insol.

01:11:50.040 --> 01:11:54.800
No, I mean, he was saying, you know, we've got hundreds and hundreds of genes associated

01:11:54.800 --> 01:11:55.800
with all these things.

01:11:55.800 --> 01:11:59.960
We haven't got the slightest clue what to do about it.

01:11:59.960 --> 01:12:06.320
Now, when it comes to things like diabetes, hypertension, stroke, heart disease, and,

01:12:06.320 --> 01:12:11.960
you know, obesity, cigarette smoking, opioid addiction, you know, these chronic, low-end

01:12:11.960 --> 01:12:17.520
lifelong conditions that require behavioral intervention, we're very bad because we want

01:12:17.520 --> 01:12:22.680
a delta function, we want a pill or a surgery or a zap.

01:12:22.680 --> 01:12:27.400
The idea, and just so you understand the absurdity of it, if I had said to you, take this pill,

01:12:27.400 --> 01:12:33.400
sir, swallow it, and you'll be an expert pianist, right?

01:12:33.400 --> 01:12:36.960
Take this pill and you don't need to go to college, all four years of college, you've

01:12:36.960 --> 01:12:38.280
been compressed into this pill.

01:12:38.280 --> 01:12:42.240
You rightly go, there's something nonsensical about that.

01:12:42.240 --> 01:12:47.880
But once you get to medicine, switch you being healthy and taking a pill to be an expert,

01:12:47.880 --> 01:12:51.440
violinist or pianist, but take this pill and we'll cure your multiple sclerosis, your

01:12:51.440 --> 01:12:52.440
Alzheimer's.

01:12:52.440 --> 01:12:56.480
That suddenly makes more sense, right?

01:12:56.480 --> 01:12:57.480
Right.

01:12:57.480 --> 01:13:01.560
So what I'm saying is it's going to turn out that we're going to have to do a lot more

01:13:01.560 --> 01:13:07.080
human-behavioral modular work than mass models of Alzheimer's.

01:13:07.080 --> 01:13:08.080
I'm not against them.

01:13:08.080 --> 01:13:11.480
I do think there'll be pharmacological interventions.

01:13:11.480 --> 01:13:13.640
I do mouse studies.

01:13:13.640 --> 01:13:22.160
But again, you're totally correct that there is an equivalent fallacy in medicine of a

01:13:22.160 --> 01:13:27.160
reductionist kind, just like there is in neuroscience, right?

01:13:27.160 --> 01:13:32.280
That we're going to solve diseases, one drug, one molecule, one gene at a time.

01:13:32.280 --> 01:13:37.160
And if you look at these papers by Unidists and others, it's been for the most part of

01:13:37.160 --> 01:13:38.160
failure.

01:13:38.160 --> 01:13:41.360
Now, I'm going to get into lots of trouble saying that, but I'm just quoting them.

01:13:41.360 --> 01:13:42.360
Yeah.

01:13:42.360 --> 01:13:51.760
Well, the other sort of pie-in-the-sky translational outcome of studying consciousness through neuroscience,

01:13:51.760 --> 01:13:56.680
of course, would have to do with end-of-life issues, whether one of patients in a coma.

01:13:56.680 --> 01:14:02.240
So you need to, you know, I mean, it's a lot of complicated issues here.

01:14:02.240 --> 01:14:05.200
Do we, is this over?

01:14:05.200 --> 01:14:07.400
Is there anything worth living for?

01:14:07.400 --> 01:14:12.360
You know, is, is, if there is subject to consciousness, does that make life, you know,

01:14:12.360 --> 01:14:17.360
so it's a very complicated thing to think about that requires a lot of interdisciplinary

01:14:17.360 --> 01:14:18.360
thought.

01:14:18.360 --> 01:14:24.680
But that could be, you know, a principle, a possible translational issue.

01:14:24.680 --> 01:14:29.000
Hey, this is a question that Sam Harris addresses.

01:14:29.000 --> 01:14:34.280
I think in the book, Consciousness, but don't hold me to that.

01:14:34.280 --> 01:14:41.160
If we can never understand this subject, or if it's a long way off, you never say never,

01:14:41.160 --> 01:14:49.680
either way, pattern, you want to go by, how can we be responsible for our actions?

01:14:49.680 --> 01:14:55.240
Well, I'm not sure if I actually see the connection, to be honest.

01:14:55.240 --> 01:15:02.760
I mean, I'm, yeah, your question is the perfect question, because it's exactly the perfect

01:15:02.760 --> 01:15:08.680
question, because it's exactly the way not to think about these things.

01:15:08.680 --> 01:15:15.000
We're talking about a social psychological being, we call the you.

01:15:15.000 --> 01:15:21.960
When we talk about, you know, is the brain deterministic, or, you know, where, where does

01:15:21.960 --> 01:15:27.520
that choice live, nearly, that's a whole nother level that I don't think we have any good

01:15:27.520 --> 01:15:28.520
clear answers.

01:15:28.520 --> 01:15:32.640
But it doesn't, it doesn't, I mean, when we talk, it's a practical matter.

01:15:32.640 --> 01:15:38.400
We talk about people being responsible, in part, because we're either trying to, you

01:15:38.400 --> 01:15:42.680
know, cause interventions to change their behavior, or cause interventions to lock them

01:15:42.680 --> 01:15:47.880
away so they don't bother us again, or we're doing things in the human world on the basis

01:15:47.880 --> 01:15:50.600
of morality and responsibility.

01:15:50.600 --> 01:15:55.400
And the fact that things have physical causes is at a whole completely different level.

01:15:55.400 --> 01:15:59.520
And Jonathan, I'm sure, could talk about this far better, I mean, it's more 19th century

01:15:59.520 --> 01:16:09.320
than 18th century, but the sort of medicalization of, you know, behavioral states, I mean, you

01:16:09.320 --> 01:16:14.520
know, homosexuality, for example, it went from being a legal issue to being the most

01:16:14.520 --> 01:16:16.000
medicalized issue.

01:16:16.000 --> 01:16:18.800
Everyone had a theory about this, right?

01:16:18.800 --> 01:16:23.320
And I'm saying that the equivalent of this medicalization of things that shouldn't be

01:16:23.320 --> 01:16:30.760
medicalized, I think in a way, neuroscience is doing the same thing.

01:16:30.760 --> 01:16:35.160
It's walking over areas it should not be trespassing on.

01:16:35.160 --> 01:16:41.120
I would, okay, I need to say something, because I would say it's not the exact wrong question.

01:16:41.120 --> 01:16:42.960
I think there is an issue here.

01:16:42.960 --> 01:16:49.840
And I do think as society in courts of law, and it does, sometimes we do take away responsibility

01:16:49.840 --> 01:16:52.720
when we find an underlying physical cause.

01:16:52.720 --> 01:16:58.960
And I think this is something that it's a very, I mean, I think we're not going to always

01:16:58.960 --> 01:17:04.640
say it's just the person we always have free will, but it's a very delicate balance.

01:17:04.640 --> 01:17:12.840
And we have to think about it carefully, and just make sure that, I mean, yeah, sometimes

01:17:12.840 --> 01:17:13.840
we do take it away.

01:17:13.840 --> 01:17:14.840
But it's a mistake.

01:17:14.840 --> 01:17:16.840
I don't know if it's always a mistake.

01:17:16.840 --> 01:17:19.880
Well, but I mean, you know, it's not always a mistake.

01:17:19.880 --> 01:17:22.760
Sometimes it makes sense, I think, to take it away.

01:17:22.760 --> 01:17:28.360
It's no different in kind from the question of my responsible, if my childhood experience,

01:17:28.360 --> 01:17:29.840
you know, let me down this path.

01:17:29.840 --> 01:17:31.240
It's just, it's a difficult question.

01:17:31.240 --> 01:17:32.240
And it's a difficult question.

01:17:32.240 --> 01:17:35.440
There's, you have to take it to so many issues.

01:17:35.440 --> 01:17:40.960
Yeah, it's a similar, we don't have a solution, but one way or the other, it's complicated.

01:17:40.960 --> 01:17:46.560
It depends on part of, to go back to Baslan-Drasen's language, like what question you're asking.

01:17:46.560 --> 01:17:52.720
So there's a, like, for example, they just, sure, John and Ken read the article today,

01:17:52.720 --> 01:17:55.840
or yesterday's times, about the brain of the shooter in Las Vegas.

01:17:55.840 --> 01:17:56.840
Yeah, I see.

01:17:56.840 --> 01:17:58.960
They sliced it, diced it, looked at it.

01:17:58.960 --> 01:17:59.960
Interesting.

01:17:59.960 --> 01:18:01.600
You know, and they came up with it.

01:18:01.600 --> 01:18:05.360
No, we can't tell anything that's different about this brain, that would explain it.

01:18:05.360 --> 01:18:10.800
But I know it's, but even if they had, but my point in the end, I think it's a little

01:18:10.800 --> 01:18:15.200
bit of a, my point is both to kind of yet another example of neuromania, but also, but

01:18:15.200 --> 01:18:20.160
also because, because if you think about what they were asking, it was not if we actually

01:18:20.160 --> 01:18:26.160
found some sort of underlying, you know, abnormality that would explain the recent, you know,

01:18:26.160 --> 01:18:30.840
that would explain the atrocity that we then therefore excuse him for it in retrospect.

01:18:30.840 --> 01:18:35.200
It's more like, would this provide an account of the, you know, the change in behavior that

01:18:35.200 --> 01:18:39.960
led up to an atrocity that he would have he had survived, still be put in jail for?

01:18:39.960 --> 01:18:42.760
I think that's a reasonable question.

01:18:42.760 --> 01:18:45.960
That's a, it's a question different, however, from a legal question.

01:18:45.960 --> 01:18:48.120
And I think sometimes they often get confused.

01:18:48.120 --> 01:18:52.320
And I think that, then especially when you bring in something as, you know, as difficult

01:18:52.320 --> 01:18:55.720
as free will talk, it then just becomes a mess.

01:18:55.720 --> 01:18:56.720
Yeah.

01:18:56.720 --> 01:18:58.240
And we would love to keep them separate.

01:18:58.240 --> 01:19:03.880
It's much easier to say the moral, political, social world is dominated by notions of free

01:19:03.880 --> 01:19:04.880
will.

01:19:04.880 --> 01:19:05.880
We need to operate that way.

01:19:05.880 --> 01:19:11.200
If we work at the level of biological determinism, that doesn't really correspond to that.

01:19:11.200 --> 01:19:13.880
And so we'll, this will go over here and that'll go over there.

01:19:13.880 --> 01:19:18.560
But then if you want to think of a field, forensic psychiatry is when the two mix.

01:19:18.560 --> 01:19:23.360
And you know, the, someone is going to be making decisions about whether someone had

01:19:23.360 --> 01:19:29.200
intentionality and free will and, and civilized society since the 17th century have said,

01:19:29.200 --> 01:19:34.200
you know, if you're start raving mad and you commit a crime, that's going to be different

01:19:34.200 --> 01:19:36.200
than otherwise.

01:19:36.200 --> 01:19:40.040
You know, I think embarrassingly some of these studies are like, I mean, these people go

01:19:40.040 --> 01:19:42.120
to eat a Chinese restaurants too much.

01:19:42.120 --> 01:19:44.440
They think you open the brain, it's going to be like a fortune cookie and insights.

01:19:44.440 --> 01:19:48.800
I wanted to kill a lot of people, but they never find anything like that.

01:19:48.800 --> 01:19:55.840
And just to get to the notion of explanation so you can get some sense, you know, Fred

01:19:55.840 --> 01:19:58.600
is a teatotler.

01:19:58.600 --> 01:20:00.080
Why?

01:20:00.080 --> 01:20:02.040
His father was an alcoholic.

01:20:02.040 --> 01:20:04.040
Ah, yes.

01:20:04.040 --> 01:20:06.040
Do you see what I'm saying?

01:20:06.040 --> 01:20:07.040
Yeah.

01:20:07.040 --> 01:20:11.040
We can create these pseudo explanations right at any level, right?

01:20:11.040 --> 01:20:13.040
And it's very tempting.

01:20:13.040 --> 01:20:15.040
We live by them.

01:20:15.040 --> 01:20:33.040
And what I'm, and what I'm saying is, as I think I, and the demonstrate, they're not,

01:20:33.040 --> 01:20:34.040
right?

01:20:34.040 --> 01:20:38.320
But we, we like them.

01:20:38.320 --> 01:20:44.160
And we now have a new kind of nonsensical explanation like that, which is neuromania,

01:20:44.160 --> 01:20:45.160
right?

01:20:45.160 --> 01:20:52.160
We like to have this new addition to these pseudo explanations that as you say, we live

01:20:52.160 --> 01:20:53.160
by.

01:20:53.160 --> 01:20:59.000
You know, from, at least from the literary sort of history of science and philosophy perspective

01:20:59.000 --> 01:21:00.000
that I would have.

01:21:00.000 --> 01:21:04.200
I don't think I said anything like consciousness is in the brain.

01:21:04.200 --> 01:21:11.800
I think I would just, you know, would say that consciousness requires, for our species,

01:21:11.800 --> 01:21:17.760
requires a brain, but is embodied and is about, you know, interacting with the world.

01:21:17.760 --> 01:21:22.320
And in other kinds of creatures like, you know, the famous octopus, for example, it's

01:21:22.320 --> 01:21:25.120
a much more of a whole body phenomenon.

01:21:25.120 --> 01:21:30.000
And arguably is out there in the world too, if you take the kind of panpsychists take

01:21:30.000 --> 01:21:33.760
on the, on the heart problem, which I think is very attractive and interesting.

01:21:33.760 --> 01:21:35.760
So why not?

01:21:35.760 --> 01:21:42.800
I mean, you know, but as I look at this far as I understand it, I think professional

01:21:42.800 --> 01:21:46.560
it's taken saying that I just find it, something kind of cool about it.

01:21:46.560 --> 01:21:50.880
So, so yeah, so I, you know, at least for us, it's like it requires the brain.

01:21:50.880 --> 01:21:51.880
That's all I would say.

01:21:51.880 --> 01:21:53.600
But I'm sure these folks who disagree.

01:21:53.600 --> 01:21:59.080
I mean, brain is a particular organization of neurons and the nervous system.

01:21:59.080 --> 01:22:03.680
It's limo type of nervous system too, that, you know, and plants have certain kinds of

01:22:03.680 --> 01:22:08.760
memory and they have it through physical processes in their cells that, you know, don't correspond

01:22:08.760 --> 01:22:10.760
to neurons, but it's their own system.

01:22:10.760 --> 01:22:16.200
So there's lots of ways of building memories out of, out of cells and ours gets organized

01:22:16.200 --> 01:22:17.200
into brains.

01:22:17.200 --> 01:22:23.480
And embodiment is one of those very slippery, very cool subjects right now.

01:22:23.480 --> 01:22:28.520
I mean, Andy Klartz written famously about this, but I think one way to think about it

01:22:28.520 --> 01:22:33.840
is Dennis Noble talks about top-down causality when it comes to the heartbeat.

01:22:33.840 --> 01:22:38.760
So you can take a cardiac cell and it will start beating in the right medium.

01:22:38.760 --> 01:22:44.080
And then you say, what's the cause of the heartbeat?

01:22:44.080 --> 01:22:49.240
Now you can look at the ion channels in that myocardial cell and go, oh, look, those ion

01:22:49.240 --> 01:22:54.200
channels, it's through the flow of ions through those channels that needs to a change in the

01:22:54.200 --> 01:22:56.000
membrane of the heart cell.

01:22:56.000 --> 01:22:59.440
But then you have to go, well, if those ion channels were just floating around alone,

01:22:59.440 --> 01:23:00.960
there'd be no heartbeat.

01:23:00.960 --> 01:23:04.800
They have to be embedded in a heart cell.

01:23:04.800 --> 01:23:07.000
So then where do you point to the heartbeat?

01:23:07.000 --> 01:23:08.440
What's the cause of the heartbeat?

01:23:08.440 --> 01:23:11.600
The whole thing is the heartbeat.

01:23:11.600 --> 01:23:15.880
There is no thing that you can point at, which is more fundamental of the heartbeat.

01:23:15.880 --> 01:23:18.080
You need the whole thing, right?

01:23:18.080 --> 01:23:20.400
And that's what embodiment is.

01:23:20.400 --> 01:23:25.680
Is that you can't avoid being trans-level when you talk about the heartbeat.

01:23:25.680 --> 01:23:28.840
The membrane is not doing it alone, the ion channels are not doing it alone, the ions

01:23:28.840 --> 01:23:29.840
aren't doing it alone.

01:23:29.840 --> 01:23:30.840
It's the whole thing.

01:23:30.840 --> 01:23:35.640
So that's really what embodiment is, is that you need the whole thing in its organizational

01:23:35.640 --> 01:23:40.880
structure to do the thing that you're seeing in its totality, right?

01:23:40.880 --> 01:23:45.680
And that's, I think, the reasonable way of thinking about embodiment is ended up having

01:23:45.680 --> 01:23:52.720
a sort of hokey, slightly holistic thing that's attached to it, but that's separate.

01:23:52.720 --> 01:23:53.720
Okay.

01:23:53.720 --> 01:23:54.720
Thank you.

01:23:54.720 --> 01:23:55.720
Thank you.

01:23:55.720 --> 01:23:56.720
Thank you.

01:23:56.720 --> 01:23:57.720
Thank you.

01:23:57.720 --> 01:23:58.720
Thank you.

01:23:58.720 --> 01:23:59.720
Thank you.

01:23:59.720 --> 01:24:12.280
Thank you.

