WEBVTT

00:00.000 --> 00:01.040
My name is Beth Haus.

00:01.040 --> 00:02.760
I'm a psychiatrist in private practice

00:02.760 --> 00:04.640
and a member of the executive committee

00:04.640 --> 00:06.440
for the Helix Center.

00:06.440 --> 00:08.640
And I've been asked to moderate this a little bit last minute.

00:08.640 --> 00:10.320
So bear with me.

00:10.320 --> 00:11.200
It's not my area.

00:11.200 --> 00:13.600
But we're here today to talk about secrecy, privacy,

00:13.600 --> 00:17.240
transparency, openness, and related concepts.

00:17.240 --> 00:19.560
Since Freud's early twin psychopathology

00:19.560 --> 00:21.800
stemmed from secrets that one part of the mind kept

00:21.800 --> 00:26.040
from another to win a cots idea for the development of self

00:26.040 --> 00:27.760
and to allow the child to overcome shame

00:27.760 --> 00:29.920
and narcissistic humiliation, psychoanalysis

00:29.920 --> 00:32.000
has always been interested in secrets.

00:32.000 --> 00:33.400
And Western literature also has been

00:33.400 --> 00:36.720
interested in secrets from medipists to Prometheus Bound,

00:36.720 --> 00:39.240
where the main character spends the entire play resisting

00:39.240 --> 00:41.640
the attempt of one character after another

00:41.640 --> 00:43.440
to get a secret out from him.

00:43.440 --> 00:45.800
So the secret and its gradual revelation

00:45.800 --> 00:50.160
serves many, many literary and psychoanalytic functions.

00:50.160 --> 00:52.280
And liberal political thought is obviously

00:52.280 --> 00:55.360
predicated on the autonomy of individual selves

00:55.360 --> 00:58.320
and the maintenance of secrets as an aspect of selfhood.

00:58.320 --> 01:00.640
So we're here to talk about these ideas today

01:00.640 --> 01:03.200
and an age of NSA surveillance and prison access

01:03.200 --> 01:07.600
to our Google and Facebook and Yahoo records, drones, big data,

01:07.600 --> 01:10.400
and the internet creation of secret and revealed selves.

01:10.400 --> 01:12.040
And we will look to our wonderful panelists

01:12.040 --> 01:14.600
to help us open up these concepts of secrecy

01:14.600 --> 01:16.920
and transparency and their current relevance.

01:16.920 --> 01:18.760
So I'm going to introduce the panelists now.

01:18.760 --> 01:21.520
We are pleased to have here with us today.

01:21.520 --> 01:24.280
Alex Abdo on the far left here.

01:24.280 --> 01:26.760
Alex is a staff attorney for the ACLU

01:26.760 --> 01:29.160
and for their national security project.

01:29.160 --> 01:32.080
He is the current counsel to the ACLU's challenge

01:32.080 --> 01:35.280
to the NSA's phone records program

01:35.280 --> 01:37.880
and has been involved in the litigation of cases concerning

01:37.880 --> 01:41.560
the Patriot Act and the Foreign Intelligence Surveillance

01:41.560 --> 01:44.440
Act, the International Emergency Economic Powers

01:44.440 --> 01:47.200
Act, and the treatment of detainees at Guantanamo

01:47.200 --> 01:48.640
and elsewhere.

01:48.640 --> 01:50.840
Alex is a graduate of Yale University and Harvard Law

01:50.840 --> 01:53.720
School, and prior to working at the ACLU

01:53.720 --> 01:56.480
clerked for several different judges.

01:56.480 --> 01:58.200
And he recently participated in a panel

01:58.200 --> 02:00.440
at the University of Pennsylvania,

02:00.440 --> 02:03.640
which was called on the very idea of secret laws,

02:03.640 --> 02:07.280
transparency and publicity, and deliberative democracy.

02:07.280 --> 02:09.160
So welcome, Alex.

02:09.160 --> 02:10.840
Next, we have Jack Braddich over here,

02:10.840 --> 02:13.360
who is Associate Professor and Chair of the Journalism

02:13.360 --> 02:16.840
and Media Studies Department at Rutgers University.

02:16.840 --> 02:19.000
His work applies autonomous social theory

02:19.000 --> 02:22.680
to popular culture and social movement media.

02:22.680 --> 02:25.720
He is the author of Conspiracy Panics,

02:25.720 --> 02:29.960
Political Rationality in Popular Culture in 2008.

02:29.960 --> 02:33.120
And his most recent publications include Adventures

02:33.120 --> 02:35.560
in the Public Secrets Sphere, Police,

02:35.560 --> 02:38.760
Sovereign Networks, and Communications Warfare

02:38.760 --> 02:41.040
in Cultural Studies, Critical Methodologies.

02:41.040 --> 02:41.560
Is that right?

02:41.560 --> 02:42.840
OK.

02:42.840 --> 02:45.360
He's also a Zion librarian at the ABC in Nel Rio

02:45.360 --> 02:49.080
and has co-taught courses at Blue Stocking's Bookstore

02:49.080 --> 02:50.320
in New York City.

02:50.320 --> 02:51.040
So welcome, Anna.

02:51.040 --> 02:53.120
Welcome.

02:53.120 --> 02:55.760
Our next panelist is Ted Jacobs.

02:55.760 --> 02:57.640
Ted is a psychiatrist and psychoanalyst

02:57.640 --> 02:59.720
at Albert Einstein College of Medicine

02:59.720 --> 03:01.960
in the NYU School of Medicine.

03:01.960 --> 03:04.000
He's also a training and supervising analyst

03:04.000 --> 03:06.360
for adults and children, both here at Nipsey

03:06.360 --> 03:07.920
and at four other psychoanalytic

03:07.920 --> 03:09.760
institutes around the country.

03:09.760 --> 03:13.480
And the editor of at least four analytic journals.

03:13.480 --> 03:16.520
Dr. Jacobs has published over 60 papers and book reviews,

03:16.520 --> 03:21.000
and among them are Secrets, Alliances, and Family Fictions,

03:21.000 --> 03:25.280
Psychoanalytic Observations, and Notes on the Unknowable,

03:25.280 --> 03:28.560
Analytic Secrets, and the Transfer Ensnorosis.

03:28.560 --> 03:31.120
He has two new books out for 2013,

03:31.120 --> 03:32.760
neither of which have much to do with Secrets.

03:32.760 --> 03:35.360
One is The Year of Du Roche, a novel

03:35.360 --> 03:37.840
about the turmoil created when the manager of the Brooklyn

03:37.840 --> 03:40.840
Dodgers moved to a different team, the New York Giants,

03:40.840 --> 03:43.800
in 1948, and the possible profession,

03:43.800 --> 03:45.920
the analytic process of change.

03:45.920 --> 03:47.280
So welcome.

03:47.280 --> 03:48.960
And finally, we have Michael Lewis.

03:48.960 --> 03:51.280
Michael is a university distinguished professor

03:51.280 --> 03:53.800
of pediatrics in psychiatry and director

03:53.800 --> 03:56.080
of the Institute for the Study of Child Development

03:56.080 --> 03:58.680
at Rutgers Robert Wood Johnson School.

03:58.680 --> 04:01.240
His research has focused on normal and deviant

04:01.240 --> 04:04.520
emotional and intellectual development.

04:04.520 --> 04:07.840
And among his books are Lies and Deception in Everyday Life,

04:07.840 --> 04:10.080
which he has brought with us here,

04:10.080 --> 04:12.880
and a handbook of emotional development, which

04:12.880 --> 04:15.800
was awarded the Critics' Choice Award.

04:15.800 --> 04:18.360
Most recently, his latest book, which he also has with him,

04:18.360 --> 04:20.200
is The Rise of Consciousness and the Development

04:20.200 --> 04:23.520
Devotion, Emotional Life, which is after 2014.

04:23.520 --> 04:26.920
And he's also working on a new book, My Life as Development.

04:26.920 --> 04:27.800
So these are our panelists.

04:27.800 --> 04:29.280
I hope that they will help us get access

04:29.280 --> 04:31.760
to the psychology and national psychology of secrecy

04:31.760 --> 04:33.920
and transparency.

04:33.920 --> 04:36.840
I wanted to start out just with a quote from JFK.

04:36.840 --> 04:40.200
The word secrecy is repugnant and free and open society.

04:40.200 --> 04:42.440
And we as a people are inherently and historically

04:42.440 --> 04:45.200
opposed to secret societies, secret oaths,

04:45.200 --> 04:47.280
and secret proceedings.

04:47.280 --> 04:50.080
It seems like JFK was not particularly up to date,

04:50.080 --> 04:52.680
but I would start out with the question related to that.

04:52.680 --> 04:55.240
What is our modern conception of secrecy, privacy,

04:55.240 --> 04:56.600
transparency, and openness?

04:56.600 --> 04:58.840
And is there something uniquely American about the way

04:58.840 --> 04:59.640
that we approach it?

04:59.640 --> 05:04.000
So leave it to you guys to open that.

05:04.000 --> 05:09.880
Well, I will be talking just before we came up.

05:09.880 --> 05:16.440
And many of you will remember that Eisenhower was

05:16.440 --> 05:19.280
going to meet with the Russian Premier.

05:19.280 --> 05:21.720
It was a bridge level.

05:21.720 --> 05:22.520
It was Khrushchev.

05:22.520 --> 05:23.640
I don't remember.

05:23.640 --> 05:25.800
Must have been Khrushchev.

05:25.800 --> 05:32.760
And right before they were to meet a YouTube plane

05:32.760 --> 05:38.520
with powers flew over Russia taking pictures.

05:38.520 --> 05:41.280
And they shot the plane down.

05:41.280 --> 05:44.720
And so they had us.

05:44.720 --> 05:50.880
Eisenhower was asked, did you have knowledge of this?

05:50.880 --> 05:51.320
He said yes.

05:54.280 --> 06:01.520
That terminated the first meeting since Yolta or Otslan

06:01.520 --> 06:06.040
between American President, Russian Premier.

06:06.040 --> 06:13.120
Because in diplomacy, it is recognized

06:13.120 --> 06:20.080
that indeed if you tell the truth, that's an insult.

06:20.080 --> 06:26.240
Have he said, I didn't know if I have this as you do this large

06:26.240 --> 06:29.400
government and all sorts of things happen,

06:29.400 --> 06:34.680
Khrushchev would have, the meeting would have taken place.

06:34.680 --> 06:39.320
That he chose Eisenhower, the all-American,

06:39.320 --> 06:47.920
chose to tell the truth, which from a diplomatic point of view

06:47.920 --> 06:55.120
was not the thing to do to have that meeting take place.

06:55.120 --> 07:03.080
So I guess I'm going to start off as sort of the other side

07:03.080 --> 07:04.640
of the view.

07:04.640 --> 07:10.480
I think that secrecy, deception, and lying

07:10.480 --> 07:15.560
have a very important place in human life.

07:15.560 --> 07:23.760
And I spend my time at as legal or helping folks

07:23.760 --> 07:28.600
with their problems, media issues.

07:28.600 --> 07:30.440
I study development.

07:30.440 --> 07:34.360
I study infants and their development.

07:34.360 --> 07:36.640
And one of the extraordinary things

07:36.640 --> 07:40.680
is how early children lie.

07:44.280 --> 07:48.280
By two years of age, children have pretend

07:48.280 --> 07:51.920
plague, which is a kind of self-deception.

07:51.920 --> 07:56.440
They lie to spare the feelings of others,

07:56.440 --> 08:04.320
and they lie not to get punished for transgressions.

08:04.320 --> 08:08.480
So and we are not unique.

08:08.480 --> 08:09.480
This goes on.

08:09.480 --> 08:10.760
We studied in Japan.

08:10.760 --> 08:13.440
We studied in Europe.

08:13.440 --> 08:18.440
This is all children as best we could say.

08:18.440 --> 08:27.720
So extraordinary early in life, secrecy, deception

08:27.720 --> 08:31.000
is part of human psyche.

08:31.000 --> 08:33.200
I'll stop.

08:33.200 --> 08:37.120
I agree with you that there is a very important place

08:37.120 --> 08:40.480
for secrecy and deception in our private lives.

08:40.480 --> 08:42.720
But I think in America, we've always

08:42.720 --> 08:45.120
had a double standard when it comes to secrecy.

08:45.120 --> 08:49.400
We expect to maintain our privacy fears,

08:49.400 --> 08:50.920
but we expect that the government will not

08:50.920 --> 08:53.560
maintain a significant privacy fear.

08:53.560 --> 08:56.400
We expect that the government will, to the extent possible,

08:56.400 --> 08:58.040
I think, be open and transparent.

08:58.040 --> 09:00.200
Although you're right, that there's obviously even

09:00.200 --> 09:03.200
there in a very important role for secrecy to play.

09:03.200 --> 09:07.760
Diplomacy doesn't work in the open generally.

09:07.760 --> 09:12.600
Many national security policies can't function if entirely open.

09:12.600 --> 09:14.960
But there's always been a deep-seated hostility,

09:14.960 --> 09:17.680
I think, toward excessive secrecy in government.

09:17.680 --> 09:20.960
And the question that, when we were discussing a moment ago,

09:20.960 --> 09:22.800
that we at the ACLU are concerned about

09:22.800 --> 09:28.400
is the question of when excessive government

09:28.400 --> 09:30.960
makes democratic self-governance difficult.

09:30.960 --> 09:32.520
And maybe another way of thinking about it,

09:32.520 --> 09:34.400
though, is just to take it on the terms

09:34.400 --> 09:36.120
that you've started us out with.

09:36.120 --> 09:40.920
If secrecy is so important for private development

09:40.920 --> 09:43.320
and private life, which I agree with you, it is,

09:43.320 --> 09:46.240
you can think of surveillance, government surveillance,

09:46.240 --> 09:48.960
as being what undoes private secrecy,

09:48.960 --> 09:52.000
what unmasks self-deception.

09:52.000 --> 09:54.560
It gets behind the veil that we construct for ourselves

09:54.560 --> 09:57.480
in maintaining a private and dignified life.

09:57.480 --> 09:59.480
And so there's a question as to what extent

09:59.480 --> 10:00.680
should we allow that surveillance.

10:00.680 --> 10:03.680
And obviously, we have decided there should be some of it.

10:03.680 --> 10:05.480
And to what extent should we allow secrecy

10:05.480 --> 10:07.920
about the extent of that surveillance, which

10:07.920 --> 10:09.880
is another interrelated question?

10:12.520 --> 10:15.760
Yeah, I've been following up on that, too.

10:15.760 --> 10:20.040
Around democracy, I really like the figure of Eisenhower.

10:20.040 --> 10:21.920
So he could have said, as you said,

10:21.920 --> 10:23.760
he could have said, yes, we have secrets,

10:23.760 --> 10:25.680
but I didn't know about this one.

10:25.680 --> 10:26.800
It's an acknowledgment.

10:26.800 --> 10:29.680
But he said, yes, we have secrets, and I know about them.

10:29.680 --> 10:30.840
So I mean, those are two different ways

10:30.840 --> 10:33.600
of revealing one's knowledge about secrecy.

10:33.600 --> 10:38.400
And I think it's that tactical approach

10:38.400 --> 10:42.760
to revelation that interests me as part of US history,

10:42.760 --> 10:44.560
so around democracy.

10:44.560 --> 10:48.960
So you think about the emergence of the American Revolution.

10:48.960 --> 10:51.880
So much of it was also hatched in things like lodges,

10:51.880 --> 10:54.520
and free Masonic lodges, and secret societies.

10:54.520 --> 10:58.720
So here's this fundamental moment of the foundation

10:58.720 --> 11:01.400
of democracy itself that's also partially hatched.

11:01.400 --> 11:03.440
In some people saying, well, there's

11:03.440 --> 11:05.120
a certain kind of secrecy that we don't like,

11:05.120 --> 11:07.240
monarchical secrecy.

11:07.240 --> 11:09.640
But we're going to start plotting some things in secret,

11:09.640 --> 11:12.480
because we have to do that, because it's a revolution.

11:12.480 --> 11:17.080
So there are moments that, to me, the issue

11:17.080 --> 11:21.640
is who gets to decide when secrecy and transparency

11:21.640 --> 11:23.480
are allowable.

11:23.480 --> 11:26.920
So to me, is the interest around sovereignty.

11:26.920 --> 11:29.120
Is there something, a difference between,

11:29.120 --> 11:31.560
say, a popular secrecy and something

11:31.560 --> 11:32.720
more like state secrecy?

11:32.720 --> 11:34.120
Can we think about something about secrets

11:34.120 --> 11:37.680
that belong to a population that's part of democracy

11:37.680 --> 11:40.400
and not just antithetical to democracy?

11:43.040 --> 11:48.160
In some sense, secrets, just like I

11:48.160 --> 11:53.280
think who it was who said that all politics

11:53.280 --> 11:55.000
is local.

11:55.000 --> 11:58.680
So it relates to the community, and even

11:58.680 --> 12:01.400
for its national politics, people

12:01.400 --> 12:05.920
tend to experience it in terms of their own community,

12:05.920 --> 12:07.720
their own private lives.

12:07.720 --> 12:12.880
Secrets also are always, in some deep sense, always personal,

12:12.880 --> 12:17.120
in the sense that they resonate with our own experience

12:17.120 --> 12:20.560
with the secrets and the deepest part of ourselves.

12:20.560 --> 12:25.520
As you've said, Dr. Lewis, that secrets are always

12:25.520 --> 12:28.440
a part of development and a necessary,

12:28.440 --> 12:31.360
can you imagine if a child didn't have any secrets

12:31.360 --> 12:35.400
that the parents knew everything about the child?

12:35.400 --> 12:37.060
There'd be no sense of separateness,

12:37.060 --> 12:39.560
no sense of development.

12:39.560 --> 12:43.240
And the larger question that Alex raises

12:43.240 --> 12:47.040
is when does this necessary aspect of secret

12:47.040 --> 12:51.960
become intolerable, and he says, well,

12:51.960 --> 12:53.760
a certain amount of state secrets

12:53.760 --> 12:56.120
are necessary for any government to exist?

12:59.880 --> 13:04.600
If the Germans knew where we were going to land and D-day,

13:04.600 --> 13:07.760
we would have lost thousands of more troops,

13:07.760 --> 13:10.440
or maybe even the war.

13:10.440 --> 13:14.080
But at what point does the individual

13:14.080 --> 13:20.640
right to privacy conflict with the national interest

13:20.640 --> 13:27.360
in, let's say, discovering secret plots that may go on?

13:27.360 --> 13:33.440
If the government had been able to discover the secrets

13:33.440 --> 13:39.640
of the 9-11 bombers as they were preparing their plans,

13:39.640 --> 13:41.360
we would have been saved a great deal.

13:41.360 --> 13:47.160
So let me ask Alex, in your work that you've been doing,

13:47.160 --> 13:49.640
have you been able to define at all

13:49.640 --> 13:54.040
that borderline between the necessary and the intrusive

13:54.040 --> 13:57.520
and immoral aspects of secrets?

13:57.520 --> 13:58.520
Let me, yeah.

14:01.720 --> 14:11.040
I think let's some agreement between

14:11.040 --> 14:16.360
having them and how much is a good thing.

14:16.360 --> 14:21.280
So I think that's a lot of progress, really,

14:21.280 --> 14:24.640
and just as an opening, because we

14:24.640 --> 14:30.520
could have folks sitting here as panelists who

14:30.520 --> 14:34.280
would say that secrets aren't good.

14:34.280 --> 14:38.560
So for example, there's a very famous philosopher,

14:38.560 --> 14:43.440
a boy who talks about lying, as I said,

14:43.440 --> 14:48.840
secrets as a first-door-no-moral failure.

14:48.840 --> 14:52.800
No, one could argue with that.

14:52.800 --> 14:58.520
What I think might concern us is what

14:58.520 --> 15:01.320
has changed for those of us who have lived longer

15:01.320 --> 15:08.040
than in terms of what is public and what was not public.

15:08.040 --> 15:13.240
So how many of us have not experienced

15:13.240 --> 15:17.760
walking down the street and having someone in full voice

15:17.760 --> 15:22.880
in a conversation on the phone with someone to which we could

15:22.880 --> 15:27.760
listen in to or go to the movies where people talk

15:27.760 --> 15:33.120
and the idea of private versus public behavior?

15:33.120 --> 15:41.360
So I think there's been a real transformation in this move

15:41.360 --> 15:46.840
toward public behavior, that private behavior.

15:46.840 --> 15:49.640
And I think it's part of this movement

15:49.640 --> 15:56.880
that is probably at least 50 to 70 years old in this society

15:56.880 --> 16:03.120
in which we are not supposed to have secrets,

16:03.120 --> 16:06.960
that good relationships don't involve privacy.

16:09.840 --> 16:12.640
If you go to a dinner party and it

16:12.640 --> 16:17.520
wasn't a good dinner or pleasant company,

16:17.520 --> 16:23.560
and you can say something about it,

16:23.560 --> 16:26.040
instead of what we used to do was write,

16:26.040 --> 16:28.160
remember we actually wrote things,

16:28.160 --> 16:32.040
and we sent the thank you note for inviting us

16:32.040 --> 16:33.600
to their home and so on.

16:33.600 --> 16:36.760
So I think there's an enormous change.

16:36.760 --> 16:40.440
And I think there's a lot of pathology

16:40.440 --> 16:44.280
that goes on with both the society at large, which

16:44.280 --> 16:47.760
will mean government, will be communicative,

16:47.760 --> 16:49.720
and individuals.

16:49.720 --> 16:55.000
I think that we're supposed to not have a secret.

16:55.000 --> 16:56.760
If you get a present that you don't

16:56.760 --> 16:59.880
like from your grandmother, who has

16:59.880 --> 17:04.040
netted you with arthritic fingers, a sweater,

17:04.040 --> 17:07.320
you're supposed to say you like it.

17:07.320 --> 17:10.880
But people chafe with that idea.

17:10.880 --> 17:13.360
You're not being honest with your grandmother.

17:13.360 --> 17:17.120
You should tell your grandmother the truth.

17:17.120 --> 17:23.080
So I think there's a strange thing going on in our society.

17:23.080 --> 17:27.400
In this domain of public private, which, of course,

17:27.400 --> 17:30.560
is some sense what we're talking about.

17:30.560 --> 17:34.720
As you were saying, private, we have to have private.

17:34.720 --> 17:39.240
But this idea is we're not supposed to.

17:39.240 --> 17:45.240
My wife comes home with a jacket that I don't like,

17:45.240 --> 17:47.720
and I'm supposed to tell her I don't like it.

17:47.720 --> 17:52.720
So all sorts of things are going on.

17:52.720 --> 17:54.720
And I think at multiple levels.

17:58.720 --> 18:03.720
And I think that we have to understand them in that context.

18:03.720 --> 18:08.720
I don't know historically whether in this country there

18:08.720 --> 18:12.720
was ever a period of time when the government didn't have secrets.

18:12.720 --> 18:16.720
I mean, it's inconceivable to me that you could have a government

18:16.720 --> 18:20.720
in the same way that they would say you can have a person,

18:20.720 --> 18:23.720
a child, who didn't have secrets.

18:23.720 --> 18:30.720
Any functionally organization has to have secret handshake,

18:30.720 --> 18:38.720
secret code, secret language, in fact.

18:38.720 --> 18:43.720
I don't know that I disagree with your kind of description

18:43.720 --> 18:45.720
of how a society has changed over the last 50 or 60 years.

18:45.720 --> 18:48.720
I'm not sure I know enough to agree or disagree.

18:48.720 --> 18:51.720
But one of the questions that concerns us so much

18:51.720 --> 18:56.720
is to what extent the government gets to capitalize on those changes.

18:56.720 --> 19:00.720
So if you look back at the late 1700s,

19:00.720 --> 19:03.720
one of the reasons that the early Americans rebelled

19:03.720 --> 19:05.720
was actually about secrecy.

19:05.720 --> 19:09.720
One of the last straws was the fact that King George insisted

19:09.720 --> 19:13.720
on using similar authority that was being used in England,

19:13.720 --> 19:17.720
what were known as general warrants in the colonies as well.

19:17.720 --> 19:21.720
And these were issued by courts and they gave constables the authority

19:21.720 --> 19:25.720
to enter homes at will to search for tax evaders

19:25.720 --> 19:29.720
and people who were evading import taxes.

19:29.720 --> 19:33.720
And that was the foundation of the Fourth Amendment.

19:33.720 --> 19:35.720
That was where our right to privacy came from,

19:35.720 --> 19:42.720
was a notion that unregulated government access to our secret lives is wrong.

19:42.720 --> 19:45.720
But then for the next 200 years, the primary protector of secrecy

19:45.720 --> 19:47.720
was not actually legal.

19:47.720 --> 19:50.720
The primary protector of secrecy in the country was practical.

19:50.720 --> 19:54.720
The government couldn't record all of the information that was being spread around in public

19:54.720 --> 19:56.720
and maintain it in that basis.

19:56.720 --> 20:01.720
And I think the real governmental shift over the last 15 years

20:01.720 --> 20:05.720
is that, you know, and this is actually a really kind of fundamental shift

20:05.720 --> 20:07.720
in the way intelligence gathering takes place,

20:07.720 --> 20:11.720
is that it is now possible for the government to keep a record

20:11.720 --> 20:15.720
of all of these conversations that are spoken in public

20:15.720 --> 20:19.720
or to keep track of all of the digital trails we leave

20:19.720 --> 20:22.720
whenever we interact with an internet service.

20:22.720 --> 20:25.720
Because those things are, in a sense, made public.

20:25.720 --> 20:28.720
We share them with Google, we share them with Yahoo.

20:28.720 --> 20:31.720
But now the government can keep track of them, can keep them forever.

20:31.720 --> 20:36.720
And that search first, you know, search first suspicion later approach

20:36.720 --> 20:39.720
to surveillance is really, you know, a revolution

20:39.720 --> 20:42.720
in the way our agencies conduct intelligence gathering.

20:42.720 --> 20:45.720
And so the question is, is that okay?

20:45.720 --> 20:48.720
And if it's not, why isn't it?

20:48.720 --> 20:52.720
If you're right that this is information that we're just volunteering anyway,

20:52.720 --> 20:55.720
why do we care if the government keeps a repository?

20:55.720 --> 21:01.720
And, you know, one answer is that, you know, when you,

21:01.720 --> 21:06.720
and this is a phrase I heard recently, when you calcify the present,

21:06.720 --> 21:11.720
you might say to yourself, suppose you had the world's best detective

21:11.720 --> 21:14.720
and he were always able to reconstruct the past.

21:14.720 --> 21:15.720
Would that be a bad thing?

21:15.720 --> 21:16.720
You know, maybe that's a great thing.

21:16.720 --> 21:19.720
Maybe you want a police officer who's always able to reconstruct

21:19.720 --> 21:21.720
the investigative path.

21:21.720 --> 21:23.720
And a lot, you know, one logical leap from that is,

21:23.720 --> 21:26.720
well, why not preserve the path now so you don't have to rely

21:26.720 --> 21:28.720
on the superhuman investigator.

21:28.720 --> 21:31.720
And then you can just give the government access to these databases of information.

21:31.720 --> 21:34.720
And the answer to that question I think is that when you calcify the present

21:34.720 --> 21:43.720
in that way, when you get rid of the practical protection for secrecy we had for 200 years,

21:43.720 --> 21:45.720
you also encumber the present.

21:45.720 --> 21:50.720
Every current decision is encumbered by the possibility of future liability,

21:50.720 --> 21:56.720
not necessarily legal liability, but the possibility that in 20 years something you said

21:56.720 --> 22:02.720
will be uncovered in a way that never existed, that there was in essence a right to be forgotten

22:02.720 --> 22:07.720
for most of our country's history, and that is being practically threatened.

22:07.720 --> 22:14.720
You know, we now live in a world where virtually everything we do is digitally tracked in some way or other.

22:14.720 --> 22:19.720
And we have to wrestle with the question of whether we want to preserve this practical ability

22:19.720 --> 22:21.720
to have those actions forgotten or not.

22:21.720 --> 22:28.720
Well, I don't want to want to talk about the government,

22:28.720 --> 22:33.720
but you don't object to governments having secrets,

22:33.720 --> 22:39.720
we object to them knowing about our secrets, that is knowing about our private life.

22:39.720 --> 22:41.720
Is that the argument?

22:41.720 --> 22:43.720
Are governments allowed to have secrets?

22:43.720 --> 22:46.720
Because I don't see how they could function.

22:46.720 --> 22:48.720
I think they have a question they can have secrets.

22:48.720 --> 22:51.720
The question is what level of secrecy is allowable in a democracy?

22:51.720 --> 22:53.720
And how about recoverable?

22:53.720 --> 22:54.720
Recoverable?

22:54.720 --> 23:01.720
Well, in the sense that you know what they know about you, freedom of information, act, and so on.

23:01.720 --> 23:03.720
There was an attempt there.

23:03.720 --> 23:09.720
The government makes records, takes, gets information about people,

23:09.720 --> 23:12.720
and you have a right to know what they know.

23:12.720 --> 23:15.720
Is that a safe gone?

23:15.720 --> 23:20.720
I think it is, but it's kind of telling in our country that that's a statutory right and not a constitutional one.

23:20.720 --> 23:25.720
You would think in a democracy that the Constitution would protect access to information about government.

23:25.720 --> 23:28.720
But in fact, the Supreme Court has held it doesn't.

23:28.720 --> 23:31.720
There's not actually a constitutional right to that information.

23:31.720 --> 23:36.720
And the statutory right, and as someone who litigates a lot under the Freedom of Information Act,

23:36.720 --> 23:38.720
I can tell you is a weak one.

23:38.720 --> 23:44.720
And so the question, if you went back to the 70s,

23:44.720 --> 23:46.720
which is when the Foreign Intelligence Surveillance Act was passed,

23:46.720 --> 23:50.720
and this is the main law that the government has used for national security intelligence gathering

23:50.720 --> 23:56.720
for the last quarter century, 35 years, you could have made an argument that in 1978,

23:56.720 --> 24:04.720
that statute itself should have been secret, that our prospects in the Cold War would have been better,

24:04.720 --> 24:13.720
had the KGB not been able to read the law that governed the intelligence activities of the NSA.

24:13.720 --> 24:14.720
But we rejected that.

24:14.720 --> 24:18.720
We didn't, because there was a recognition that certain things should be public.

24:18.720 --> 24:22.720
And so I agree, the government's need secrets.

24:22.720 --> 24:27.720
The very difficult question is when the secret becomes illegitimate.

24:27.720 --> 24:33.720
And to take the modern day example, you have Edward Snowden who leaked the existence of a program

24:33.720 --> 24:37.720
in which every phone record, every single day, is being captured by the NSA.

24:37.720 --> 24:41.720
The phone call that you're talking about made on the streets of New York City,

24:41.720 --> 24:45.720
by tomorrow morning, will be in an NSA database.

24:45.720 --> 24:50.720
Is that a secret that the government should be allowed to keep?

24:50.720 --> 24:53.720
And I think that's a difficult question in a democracy.

24:53.720 --> 24:55.720
We have a strong view of what the answer is.

24:55.720 --> 24:59.720
But not everyone agrees with us. And it's a difficult question.

24:59.720 --> 25:05.720
At the same time that there has been a kind of maybe defanging of FOIA,

25:05.720 --> 25:08.720
has there also been an increase, my understanding,

25:08.720 --> 25:12.720
is an increase in classification of certain kinds of domains of government activity.

25:12.720 --> 25:16.720
So at the same moment that public is disempowered,

25:16.720 --> 25:21.720
increasing disempowered from accessing things, more and more things are becoming inaccessible.

25:21.720 --> 25:24.720
Is that a kind of characterization of the recent?

25:24.720 --> 25:30.720
Every government official to have left government in the past 30 years has complained about overclassification,

25:30.720 --> 25:31.720
but even more of late.

25:31.720 --> 25:35.720
And they're now, I think, I forgot what the exact number is,

25:35.720 --> 25:39.720
but millions of people who have security clearances to access this trove of information

25:39.720 --> 25:41.720
that is growing exponentially.

25:41.720 --> 25:45.720
Particularly in the digital age, things are now born classified, they say,

25:45.720 --> 25:48.720
because they're derivative of other digital documents.

25:48.720 --> 25:51.720
You email something around internally on a classified network,

25:51.720 --> 25:55.720
and all of a sudden you have a whole new classified chain of information.

25:55.720 --> 25:57.720
So yeah, you're right.

25:57.720 --> 26:01.720
To me, some of the changes I think that are happening in the political environment include,

26:01.720 --> 26:05.720
precisely what you've been talking about, an expansion of a national security state,

26:05.720 --> 26:09.720
specifically in the last dozen years or so around terror war, right?

26:09.720 --> 26:15.720
And a kind of war context and a war environment that makes every question about freedom,

26:15.720 --> 26:18.720
democracy suddenly tied to security.

26:18.720 --> 26:24.720
And the security suddenly becomes the most important kind of value through which all these others have to be run through.

26:24.720 --> 26:29.720
So that kind of discursive environment is something I think that's changed over the last 15 years.

26:29.720 --> 26:33.720
The other thing that I think has changed a bit, which is my interest,

26:33.720 --> 26:40.720
is how does the do get revealed take place in a public sphere, and it almost doesn't matter, right?

26:40.720 --> 26:47.720
So one of the things I look at is the early Bush years, and some of the things that did get revealed,

26:47.720 --> 26:50.720
and all the books that came out around, you know,

26:50.720 --> 26:55.720
Bush is a liar, Bush is this and that, and then it made no difference for the election in 2004.

26:55.720 --> 27:01.720
Because it's almost like there's a belief somehow in American belief that if you expose secrets that leads to action,

27:01.720 --> 27:05.720
and I think that is the connection that I'm interested in, how do we move from information to action,

27:05.720 --> 27:09.720
and does exposure and revelation actually lead to action,

27:09.720 --> 27:13.720
or is there something else going on that might prevent that from happening?

27:13.720 --> 27:14.720
So that's sort of my interest.

27:14.720 --> 27:19.720
And my favorite figure during that time period is one of the masters of revealing secrets,

27:19.720 --> 27:24.720
and that was Donald Rumsfeld, right, who was this, I mean, just listen to these press conferences,

27:24.720 --> 27:29.720
and he's almost a wizard at this, where he says things like,

27:29.720 --> 27:34.720
remember that list of the known and the unknown that he brought up,

27:34.720 --> 27:38.720
but there are these known knowns, then there are the known unknowns about Iraq,

27:38.720 --> 27:41.720
where these are justifications, the unknown unknowns.

27:41.720 --> 27:46.720
Right, what he forgot though, he only mentioned three, right, and then that two by two mono hybrid,

27:46.720 --> 27:50.720
there's a fourth, right, which is the unknown knowns.

27:50.720 --> 27:51.720
Is that right?

27:51.720 --> 27:52.720
Yeah, right.

27:52.720 --> 27:53.720
So he didn't mention that one.

27:53.720 --> 27:55.720
Okay, well, what is that one about?

27:55.720 --> 28:00.720
And so that for me is the interesting moment of things that we know are happening,

28:00.720 --> 28:03.720
but we forget, right, or we deny, or we repress.

28:03.720 --> 28:08.720
So things like Abu Ghraib, I mean, it was a revelation of particular activities that were being done,

28:08.720 --> 28:15.720
but atrocities during warfare are something that we almost have to forget in order to engage in it as a society.

28:15.720 --> 28:21.720
So these moments of things that get revealed at the same time other things get concealed at the very same moment,

28:21.720 --> 28:24.720
I was sort of tracking that as a cultural media phenomenon.

28:24.720 --> 28:26.720
And I think a lot of that has changed too.

28:26.720 --> 28:28.720
So we get revelations.

28:28.720 --> 28:32.720
I like before the panel started, the roundtable panel on the screen we had,

28:32.720 --> 28:40.720
my friend Trevor Paglin was up there, the artist who studies government secrets and tries to map them and visualize them.

28:40.720 --> 28:46.720
He's collected the patches of units in the military and such that are secret units, right,

28:46.720 --> 28:48.720
and he finds their patches and he's collected them.

28:48.720 --> 28:52.720
He did some work on Area 51 before it was acknowledged that it existed, right,

28:52.720 --> 28:57.720
which just happened in the last year or two, right, before that Area 51 never existed.

28:57.720 --> 28:59.720
So he wouldn't try to give tours of it.

28:59.720 --> 29:02.720
Great artists, performance artists around this.

29:02.720 --> 29:09.720
Anyway, so that kind of question too, like what, you know, even if things get revealed, what happens?

29:09.720 --> 29:15.720
What happens now that Area 51 is revealed or, you know, more documents about the Kennedy assassination system start coming out, right?

29:15.720 --> 29:19.720
I mean, what is the action component that to me is the crucial part of democracy,

29:19.720 --> 29:23.720
not just the things that we know about the government, but the things that we can do about it.

29:23.720 --> 29:27.720
And I think that's one of the things that's so frightening about the NSA leaks,

29:27.720 --> 29:32.720
is that people have this feeling now that they're releasing this massive amount of information and anonymity,

29:32.720 --> 29:34.720
and that someday in the future it's going to come back and bite them,

29:34.720 --> 29:38.720
but it's very hard for them to conceptually keep it in mind as to when would that be.

29:38.720 --> 29:48.720
Let's take this back down to interpersonal, to sort of get it back,

29:48.720 --> 29:55.720
and I think Ted and I represent more that perspective.

29:55.720 --> 30:07.720
So it is not possible for a parent to go on the computer of their child and find out things about their child.

30:07.720 --> 30:19.720
So let's talk about parents and kids and the technology that allows parents to find out things about their kids

30:19.720 --> 30:22.720
and what we might feel about that.

30:22.720 --> 30:24.720
Because you couldn't do that before.

30:24.720 --> 30:32.720
Now, since you would open mail and so on, but it is now possible with computers in the home to do that.

30:32.720 --> 30:39.720
Then I think there would be more argument about whether that was a good thing or a bad thing,

30:39.720 --> 30:42.720
or how to regulate that and so on.

30:42.720 --> 30:44.720
I don't have an answer to that.

30:44.720 --> 30:50.720
I'm just sort of trying to bring your point about new technology,

30:50.720 --> 30:57.720
changing the complexity of the problem we have to making it now and to personally.

30:57.720 --> 31:04.720
I mean, we could even do it not therapeutically, but now with brain imaging and all this kind of work

31:04.720 --> 31:15.720
that is leading to find out what is going on in someone's head without asking them or without interacting with them.

31:15.720 --> 31:27.720
So what we have is a technology that is allowing all sorts of challenges to this idea of privacy

31:27.720 --> 31:34.720
or secrecy, whether it be at the level of the individual to the government or the level of the person to themselves,

31:34.720 --> 31:38.720
to the therapist, to parents and so on.

31:38.720 --> 31:40.720
That technology is changing that.

31:40.720 --> 31:50.720
The people have responded so much to this idea of the government listening in on phone calls,

31:50.720 --> 31:57.720
listening, being able to obtain private messages that people send to one another.

31:57.720 --> 32:01.720
It's a sense of violation that goes back to early childhood.

32:01.720 --> 32:04.720
I mean, that child is entitled to have some privacy.

32:04.720 --> 32:13.720
The parent who is looking at the diary, looking at the computer is violating something very essential in the child's development.

32:13.720 --> 32:17.720
But it's an interesting question, Alex.

32:17.720 --> 32:28.720
Let's just say, for argument's sake, that there are some people in this country sent by some foreign power

32:28.720 --> 32:36.720
and they're planning another attack of a major kind, a 9-11.

32:36.720 --> 32:44.720
And I think most people would say if we can identify those individuals or have some suspicion,

32:44.720 --> 32:55.720
we're entitled to tap their phones, get whatever information we can to avoid this massive disaster.

32:55.720 --> 33:02.720
And what if the government says, well, but we can't actually do this without listening to everybody,

33:02.720 --> 33:08.720
because maybe they have some contacts here with private citizens or US citizens

33:08.720 --> 33:12.720
that we won't know about unless we listen to everybody.

33:12.720 --> 33:17.720
Is that justified on the basis of a clear and present danger?

33:17.720 --> 33:23.720
Or should we say, no, you can't do that regardless, even if there's a danger,

33:23.720 --> 33:28.720
because that's just too invasive of an individual's rights.

33:28.720 --> 33:33.720
You know, I would dispute the factual premise of the question,

33:33.720 --> 33:38.720
which is that you actually would ever need to listen to everyone's communications

33:38.720 --> 33:41.720
in order to conduct a targeted investigation.

33:41.720 --> 33:46.720
But even if it were the case, you could prevent an extraordinary amount of crime in this country.

33:46.720 --> 33:54.720
If you gave police officers authority to open up houses without warrants, to install video cameras in houses,

33:54.720 --> 34:00.720
and then only access them later on if a need arose, you know, maybe through judicial authorization,

34:00.720 --> 34:04.720
maybe through an automated scan of what's going on in the house,

34:04.720 --> 34:07.720
so it's just a computer looking, it's not a human.

34:07.720 --> 34:12.720
And I think that, you know, there are a lot of people who kind of observe very provocatively

34:12.720 --> 34:17.720
that the optimal level of crime in a society is not zero,

34:17.720 --> 34:22.720
because the only way you can achieve zero crime in a society is to become a surveillance state,

34:22.720 --> 34:27.720
and that we've rejected that path, and that's a weird cost-benefit way of looking at it,

34:27.720 --> 34:33.720
that we tolerate a certain amount of civil disobedience or crime

34:33.720 --> 34:38.720
in order to not to sacrifice every bit of freedom that we have.

34:38.720 --> 34:42.720
And that question becomes a lot more difficult when you ratchet up the one side,

34:42.720 --> 34:48.720
when you make it about, you know, a terrorist attack in the country.

34:48.720 --> 34:55.720
But, you know, I spent a lot of time listening to people who conduct these investigations,

34:55.720 --> 34:58.720
and I've looked at all of the examples that the government has made public in any event

34:58.720 --> 35:04.720
about how these programs are used, and there's not really a convincing case

35:04.720 --> 35:08.720
that pervasive surveillance is necessary in a strong sense.

35:08.720 --> 35:10.720
It's, of course, useful.

35:10.720 --> 35:12.720
It makes the job easier sometimes.

35:12.720 --> 35:15.720
It's always easier if you don't have to go to a judge to get a warrant

35:15.720 --> 35:17.720
and why trouble the police officers.

35:17.720 --> 35:26.720
But that inefficiency has a purpose, and it's to protect the private sphere from, you know,

35:26.720 --> 35:28.720
unjustified invasion.

35:28.720 --> 35:33.720
And to get back to the question of when do we accept that invasion?

35:33.720 --> 35:37.720
And, you know, the balance that was originally drawn in the 1700s,

35:37.720 --> 35:41.720
you know, with the ratification of the Fourth Amendment was with cause.

35:41.720 --> 35:46.720
And the question always is what's sufficient cause, and we can have that debate.

35:46.720 --> 35:48.720
But with cause means something.

35:48.720 --> 35:51.720
It means that you don't accept pervasive surveillance at the outset.

35:51.720 --> 35:54.720
You don't accept dragnet surveillance.

35:54.720 --> 35:57.720
You know, that's what the founding was, a rejection of, you know,

35:57.720 --> 36:00.720
of King George's dragnet surveillance.

36:00.720 --> 36:08.720
You know, I used to do a lot of, most of my early work at the ACLU was relating to mistreatment

36:08.720 --> 36:09.720
of detainees.

36:09.720 --> 36:13.720
And so we heard the same argument there, which was, well, maybe torture does work.

36:13.720 --> 36:18.720
Maybe in that one situation, the ticking time bomb scenario, you'd want to use torture.

36:18.720 --> 36:27.720
And, you know, the kind of civil society groups that work on these issues are divided

36:27.720 --> 36:30.720
over whether to engage in that hypothetical.

36:30.720 --> 36:34.720
Because torture is immoral no matter what is the argument.

36:34.720 --> 36:37.720
I mean, we shouldn't engage on this practical question.

36:37.720 --> 36:43.720
But they always, you know, at the end of the day you want to convince people that it doesn't actually work.

36:43.720 --> 36:47.720
And even if it did, this ticking time bomb scenario is actually just a hypothetical.

36:47.720 --> 36:49.720
It doesn't actually exist.

36:49.720 --> 36:51.720
Those situations never really do exist.

36:51.720 --> 36:56.720
So I don't think we'll find ourselves in a situation where the but for limit,

36:56.720 --> 37:04.720
on cracking a terrorist attack, is collecting every American's communication.

37:04.720 --> 37:12.720
But if we did, I think our principles would reject pervasive surveillance to accomplish that result.

37:12.720 --> 37:19.720
Why do you think pervasive surveillance is going on now since there doesn't seem to be a clear and present danger?

37:19.720 --> 37:21.720
But it's still going on.

37:21.720 --> 37:24.720
You know, there's been a shift in the way the NSA conceives of its role.

37:24.720 --> 37:31.720
It really is switched from an agency that used to be targeted in its investigations to one that tries to collect everything at the outset

37:31.720 --> 37:33.720
to preserve for later searching.

37:33.720 --> 37:38.720
And that technological shift has just happened to happen, you know, occurred over the last 20 years.

37:38.720 --> 37:44.720
The war of terrorism, they've redefined so that there's always a threat.

37:44.720 --> 37:53.720
And given there's always a threat, you always can be in this mode of trying to prevent it, which then allows us to move.

37:53.720 --> 38:00.720
Great, it allows them to do this.

38:00.720 --> 38:14.720
There was another, and we were talking about it briefly earlier, which is the role of people in the society to uncover what in fact the secrets

38:14.720 --> 38:16.720
or what the government is doing.

38:16.720 --> 38:21.720
And there, we were talking about investigating, reporting.

38:21.720 --> 38:30.720
Well, that is all but disappeared, given the state that the print media is in now.

38:30.720 --> 38:44.720
Now, hopefully, the new technology, the Internet blogging will pick up this, but we get in our home items every day,

38:44.720 --> 38:51.720
and it says, then, all the news that's fit to print, well, that's silly.

38:51.720 --> 39:06.720
Clearly, we know that they selectively don't tell things as they've admitted, but investigated for reporting has, for the most part, disappeared.

39:06.720 --> 39:16.720
And now what we have are individuals who take it upon themselves to reveal some of these secrets that are going on.

39:16.720 --> 39:22.720
Of course, they'll label this traitors, and they have to flee the country and so on.

39:22.720 --> 39:34.720
But I have a concern that given that there has to be a certain tension between the public and private always,

39:34.720 --> 39:42.720
one of the regulators of that is investigative reporting.

39:42.720 --> 39:46.720
And there is much, I think, much less of that.

39:46.720 --> 39:50.720
It's not much less of it, in sense, it isn't happening.

39:50.720 --> 40:03.720
But, you know, I read Mother Jones, well, Mother Jones, I don't know if it has 50,000 subscribers or the nation where things break much earlier than,

40:03.720 --> 40:16.720
or I have stone in another generation, where, in fact, there were people who took up the reporters, the media who took it upon themselves to, in fact, report,

40:16.720 --> 40:23.720
and to try to regulate this private, public kind of activity.

40:23.720 --> 40:32.720
And I'm really placing, and I understand the position of preventing the government,

40:32.720 --> 40:39.720
I see it as a broader issue between a public and a private, what is private and what is public.

40:39.720 --> 40:43.720
And I think we're in trouble with this.

40:43.720 --> 40:49.720
There is much too much private behavior that's public now.

40:49.720 --> 40:52.720
For some of us, we're uncomfortable with it.

40:52.720 --> 41:00.720
We don't really want to hear the conversation, the regulation of conversation in restaurants.

41:00.720 --> 41:13.720
For those of us who are New Yorkers, come on, I mean, we can't go in, the noise level is so high, and it's because people don't modulate their voices any longer.

41:13.720 --> 41:19.720
And so, but investigative reporting, what's happened to that?

41:19.720 --> 41:28.720
You know better than I, how many people get their news from, you know, from television?

41:28.720 --> 41:34.720
How many get it from newspaper or from the internet?

41:34.720 --> 41:42.720
In fact, we know how little people know about what's going on in the world, our citizens.

41:42.720 --> 41:52.720
I've forgotten the figures, but I said I could name who the vice president is, and probably 90 couldn't name who was the last vice president.

41:52.720 --> 42:03.720
So, is something happening in this balance now that needs writing?

42:03.720 --> 42:18.720
Interesting legal ACLU, such organizations attempt to try to maintain this balance, but it's a lonely place to be.

42:18.720 --> 42:21.720
And you would pay much more help, right?

42:21.720 --> 42:32.720
And if there are a lot of people out there who could spot in their job reveal these things and, you know, confront some of these issues.

42:32.720 --> 42:50.720
I mean, this last event with, I remember his name at the moment, but, you know, had to reveal what Ennis, the NSA, what's doing, and then he had to certainly leave the country.

42:50.720 --> 42:58.720
So, that's kind of investigative reporting, but then you get classified as a traitor.

42:58.720 --> 43:09.720
So, I don't know, I don't even know how, I mean, from a legal point of view, obviously it has to be fought to regulate it.

43:09.720 --> 43:19.720
No one could argue with that, but I think if we take a broader perspective of, and maybe it is, what happens when technology changes?

43:19.720 --> 43:29.720
And indeed, it's only going to get more amazing with this balance between public and private.

43:29.720 --> 43:41.720
It clearly is, we're in the midst of change, which in a single lifetime we can witness, sometimes it's quite scary.

43:41.720 --> 43:46.720
I think the right to privacy has been based on the idea of habeas corpus, typically, right?

43:46.720 --> 44:01.720
And there's been these metaphors of the body or the home or, like, concrete things that are in violet that you have ownership over, and I was curious what are the rights to information that we have now, and what is considered to be owned by the person.

44:01.720 --> 44:08.720
I mean, in terms of language or data or things like that, what are the legal principles behind ownership in that way?

44:08.720 --> 44:15.720
One of the people that I talked to for this panel is starting a company where you would actually own your data and could monetize bits of information that are used.

44:15.720 --> 44:18.720
Because that is something that belongs to you.

44:18.720 --> 44:22.720
You know, Vick can find, start that once you put something in language, it no longer belongs to you.

44:22.720 --> 44:26.720
So, you know, how is that sort of tension being played out between people?

44:26.720 --> 44:43.720
As a legal matter, I think it's difficult to answer this question of what preserves our ownership of information, but as a practical matter, it's a lot easier to describe it, which is that, you know, if you think of your relationships with various internet companies, if you're not paying for the service, chances are that you're not the customer.

44:43.720 --> 44:49.720
That's the adage that's been cropping up these days, that if you're not paying for it, you're actually the product.

44:49.720 --> 44:53.720
And that's true for a lot of the companies that monetize the information.

44:53.720 --> 45:10.720
If you're a Gmail user, you're only a customer in a very attenuated sense, because what funds your use of that service is actually the information that you volunteer to Google, that they then scrape to create their ad-based business model.

45:10.720 --> 45:21.720
And so, I think this is part of what Dr. Lewis is getting at, which is that people more and more these days are volunteering this information.

45:21.720 --> 45:24.720
But, you know, there's a way in which we've always done that.

45:24.720 --> 45:34.720
It's just now we have an internet to facilitate the exchange of the information, and so by necessity, so much of it resides with someone else.

45:34.720 --> 45:41.720
You know, we used to keep journals, now we just keep them in the cloud. And what does that say about who owns that information?

45:41.720 --> 45:47.720
Should technology change what we think of the ownership of that information? I don't think so.

45:47.720 --> 45:56.720
You know, right now the government takes the position throughout much of the country that it doesn't need a warrant to open email.

45:56.720 --> 46:09.720
But all of a sudden when we move to the digital analog, they don't. And that's a bizarre conception of privacy.

46:09.720 --> 46:16.720
The follow up with that too, about the kind of corporate surveillance and data gathering that happens when people do this.

46:16.720 --> 46:25.720
So one way is to, yeah, we used to write journals and put them in the cloud and we make it in a bit concerning sense open in public, right? And it's no longer ours.

46:25.720 --> 46:30.720
But what's happening with corporate surveillance is we give it over to another private entity, right?

46:30.720 --> 46:35.720
It then captures and re-organizes the data. And we do that when we sign those, we check mark those boxes, right?

46:35.720 --> 46:39.720
The terms of service agreements and user licensing agreements, the things that people tend to just like,

46:39.720 --> 46:50.720
yeah, I've got to get to my mail or I've got to get to this. I want to start this platform. But that's when this sort of, it's almost like the last bastion of this true, like, older form of sovereignty,

46:50.720 --> 46:57.720
where you give up your rights to your data because you've told them, you know, whatever you want to take from here, you can.

46:57.720 --> 47:07.720
And then some of the battles that are happening both legally but also culturally around how platforms like Facebook have to then respond to its users that say,

47:07.720 --> 47:14.720
well, you might want to alter those terms of service agreements before, you know, unless you want to alienate a lot of people.

47:14.720 --> 47:18.720
So there is a cultural dimension, I think, there too, as well as legal.

47:18.720 --> 47:36.720
Information has become a sellable item. So, you know, on your, if you write a check, I mean, there are so many public things we do.

47:36.720 --> 47:48.720
That get us into the private domain. I mean, Social Security secret is probably the most secret thing we have.

47:48.720 --> 47:56.720
I mean, if you have a package sent to you, they have your address, they have your zip code and commercial thinking of commercial.

47:56.720 --> 48:12.720
I mean, there's enormous you go on and buy something online. So people are harvesting bits of information which are now extraordinarily valuable, supposedly.

48:12.720 --> 48:22.720
Now, there's something interesting about it which is that the algorithms to analyze these bits are very primitive.

48:22.720 --> 48:28.720
And what really scares me is when they develop really good algorithms.

48:28.720 --> 48:46.720
And that's of course where a lot of our tax dollars are going as they try to figure out how to take in every phone message, every internet message and try to get information that's useful for whatever their purpose might be.

48:46.720 --> 48:52.720
It's not easy. There's an awful lot of information out there.

48:52.720 --> 49:01.720
And one of the things that may save us in some sense is that there's so much of it that's going to take a long time.

49:01.720 --> 49:08.720
They can't analyze sentences and phrases. And they can't really analyze emotional tone.

49:08.720 --> 49:24.720
They can't analyze words. So if you say president and you say the murder, the simple algorithm can put that together in a sentence and bring it up to some other level.

49:24.720 --> 49:39.720
So, but it would be nice to go back to the beginning when privacy was greater. But I think we're losing that.

49:39.720 --> 49:48.720
And while it would be nice to go back to the end of the 18th century, I don't think we can anymore.

49:48.720 --> 49:59.720
I think we have to confront that bits, these bits which make a part of our lives are just available. They're in the clouds.

49:59.720 --> 50:07.720
And there's no way around that except if we go back to writing letters and they can't open the letters.

50:07.720 --> 50:12.720
Of course, they can't probably. I don't tell us.

50:12.720 --> 50:26.720
So it just seems to me, you know, here's another etiquette. There used to be rules of behavior. You could keep your private, but you can act appropriately.

50:26.720 --> 50:36.720
Well, there's, you know, the 60s will let it all hang out. What does that mean? And simply mean that you don't have to have a private.

50:36.720 --> 50:46.720
If you didn't like something, you could say it instead of saying, which you could call a lie or deception. Thank you very much for the gift.

50:46.720 --> 50:55.720
In fact, you didn't like the gift at all. So I think lots of things are happening. Motion and expression.

50:55.720 --> 51:11.720
Pride. If you look at any sports, and by the way, it's all over the world, when people used to succeed in a sport, then baseball, they tipped their hat if they hit a home run with the bases loaded.

51:11.720 --> 51:27.720
Now you see the full display of the pride response as if it's perfectly okay to express yourself. So this public private thing is shifting.

51:27.720 --> 51:39.720
And where private is less valued. And now you said that. I said it more from my perspective than yours.

51:39.720 --> 51:51.720
But it's true. It's less valued now. So what we're confronted with is in fact governments, which tell us we're always a threat.

51:51.720 --> 51:59.720
There's always an enemy there. And the war on terrorism is endless. We don't declare war anymore.

51:59.720 --> 52:10.720
We haven't had who was the last president, Roosevelt, I suspect, who went before Congress and asked for a declaration of war, which is a requirement.

52:10.720 --> 52:27.720
So I mean, not only are we, our secrets being a private being invaded, but certainly the rule that the president needed a Congressional Act to declare war has disappeared too.

52:27.720 --> 52:42.720
So I don't think the solution, I mean I hope you find the solution, but I don't think it's going to be going back to the end of the 18th century.

52:42.720 --> 52:46.720
We just live in a totally different world.

52:46.720 --> 52:58.720
I think that's right as a practical matter. We're not going to go back to the modes of communication of the H3, but I think the principles are worth thinking about anyway.

52:58.720 --> 53:03.720
But there's always been this tension between private and public and what you share.

53:03.720 --> 53:09.720
And if you want to live a meaningfully social life, you construct your private sphere and then you choose what to share with people.

53:09.720 --> 53:14.720
Every time you have a conversation, you're sharing of your private life. And that's what it means to engage.

53:14.720 --> 53:20.720
And I don't know that people now value their privacy less.

53:20.720 --> 53:27.720
It just might mean that they share their private information in a different way as part of their social engagements.

53:27.720 --> 53:39.720
But there's a way in which you can think about this from the governmental perspective, which is that private people share information to engage meaningfully.

53:39.720 --> 53:44.720
But government share information often with the public anyway to maintain credibility.

53:44.720 --> 53:50.720
And there's a certain amount of sharing you have to do as a government in order to maintain legitimacy.

53:50.720 --> 53:58.720
Otherwise, you're viewed as a repressive government. You're viewed as one that isn't democratic, isn't governed by the people.

53:58.720 --> 54:06.720
But that credibility is only at stake when there is kind of an adversity between the government and some other strong actor.

54:06.720 --> 54:15.720
It used to be as you were saying investigative journalists who would hold the government's feet to the fire when they didn't share enough.

54:15.720 --> 54:21.720
Now, large media organizations don't fulfill that role as well, perhaps as they used to.

54:21.720 --> 54:25.720
There's a flat or business model when it comes to media.

54:25.720 --> 54:27.720
But that essence of adversity needs to be there.

54:27.720 --> 54:33.720
There needs to be someone who has an adverse interest to the government to force the government to maintain his credibility by sharing information.

54:33.720 --> 54:38.720
I mean, I can't an individual decide that. We've had two examples.

54:38.720 --> 54:43.720
One of the WikiLeaks and this last recent one where someone exposed the...

54:43.720 --> 54:44.720
Yes, nothing I'd say.

54:44.720 --> 54:49.720
So can an individual decide, this is immoral, I'm going to expose this.

54:49.720 --> 54:58.720
It's a very interesting question because one may feel that they've done a service, and yet do they have a right to do that?

54:58.720 --> 55:06.720
Suppose they decided that some Democratic principle was entirely wrong and should be exposed.

55:06.720 --> 55:10.720
I mean, there is a whole interesting argument we made about all of this.

55:10.720 --> 55:15.720
Yeah, it's a hard question about who should be making the decision when it comes to government secrecy.

55:15.720 --> 55:26.720
And it's difficult to tell the director of the NSA that one of his employees should be the one making the decision about what should be public and what shouldn't be.

55:26.720 --> 55:34.720
I think an equally intolerable answer is that the executive alone should decide what should be secret and what shouldn't be.

55:34.720 --> 55:40.720
And the practical answer is, you know, our constitution is one that sets up a system of checks and balances.

55:40.720 --> 55:41.720
It pits...

55:41.720 --> 55:43.720
Two or two secrets, wasn't it?

55:43.720 --> 55:44.720
Yeah.

55:44.720 --> 55:48.720
One, that they were doing it. And two, they're doing it to us.

55:48.720 --> 56:05.720
And that's kind of interesting because in a certain sense, he exposed they were doing it, which then allows us to be prepared to act in a certain way to protect our privacy.

56:05.720 --> 56:17.720
So maybe what we need is not that they do it, but that we know that they do it because it would be pretty stupid if you were plotting...

56:17.720 --> 56:26.720
to overthrow the government to do it in an email, you know, to a list of your colleagues who were going to blow up something.

56:26.720 --> 56:36.720
I mean, they know that, okay, the Germans didn't know we... I mean, you know, the Germans didn't know we broke their code.

56:36.720 --> 56:46.720
So the secret was not only getting their secrets where they were going to bomb and where they were going to be, but it was the secret that we could find out this.

56:46.720 --> 56:56.720
So maybe what we need to do is something around finding out what the secrets are.

56:56.720 --> 57:00.720
Aren't we protected in a certain sense now?

57:00.720 --> 57:03.720
There's also a notion of the legitimacy of the relationship, right?

57:03.720 --> 57:13.720
I mean, that any situation where you give somebody authority over you, you're saying, I know something about this person, they've represented themselves fairly, and there's a legitimacy to the authority that I'm giving you.

57:13.720 --> 57:24.720
And I think when people feel that legitimacy has been undermined, that they've been tricked or it's in some way, that that's when they start to react against it and feel that they have the right then to reveal or leak or something like that.

57:24.720 --> 57:39.720
Well, if you wanted to tell someone that you didn't want the government to know, you wouldn't send an email, you wouldn't go on the phone, you'd probably meet them in some public place to exchange.

57:39.720 --> 57:49.720
So we have some protection by no, surprisingly, by knowing that they can invade us.

57:49.720 --> 58:08.720
And so in a certain sense, I think the revelation of that, rather than anything particular secret, but that secret is what so infuriates the government, because now it prevents them from doing the one thing they hoped to do.

58:08.720 --> 58:15.720
At least they say they hoped to do is to catch these bad folks doing the thing.

58:15.720 --> 58:23.720
Now, if you're a smart, bad folk, you're not going to do it in a way that the government would find out.

58:23.720 --> 58:34.720
I'm not sure the revelations changed that, though, for, you know, if I think we all knew the government had the technological capability to do what's been revealed.

58:34.720 --> 58:42.720
And if you were a terrorist, you would certainly expect that there would be no barrier to the government using that capability against you.

58:42.720 --> 58:47.720
Any system that requires cause, you know, suspected terrorists will pass that threshold.

58:47.720 --> 58:49.720
They will be targetable under any system.

58:49.720 --> 58:54.720
The biggest surprise, I think, from our perspective, anyway, was that it was so untargeted.

58:54.720 --> 59:03.720
And so the only people I think who have been, who have learned information that they didn't already assume was happening, you know, who learned that the former surveillance officer was going to be able to do it,

59:03.720 --> 59:13.720
who learned that the former surveillance was happening and didn't already assume was happening, were the ordinary public, you know, innocent Americans who are not plotting terrorist attacks,

59:13.720 --> 59:18.720
and so don't think daily about how to disguise their communications.

59:18.720 --> 59:20.720
And that's our concern.

59:20.720 --> 59:27.720
You know, that it's difficult to quantify the cost of an invasion of privacy.

59:27.720 --> 59:40.720
You know, you might say that for going a particular international call with a controversial colleague or for going visiting a particular website is not much of a harm in isolation.

59:40.720 --> 59:46.720
But in the aggregate, I think it is, I mean, I think it isn't in isolation, but in the aggregate it certainly is, that those hesitations add up.

59:46.720 --> 01:00:00.720
You know, in a sense, it allows the government to break down our ability to construct the private life that you started out this conversation by describing.

01:00:00.720 --> 01:00:10.720
You know, it takes away from the private citizen agency, the ability to manage his private affairs.

01:00:10.720 --> 01:00:15.720
You've written about this as a battleground, right?

01:00:15.720 --> 01:00:20.720
Yeah, lots of battles in the battleground.

01:00:20.720 --> 01:00:22.720
I'm trying to think about the pluck out.

01:00:22.720 --> 01:00:25.720
One thing is about going back to the 1700s, we shouldn't go back there.

01:00:25.720 --> 01:00:37.720
Yes, again, technically speaking, but in terms of technology, the principles of democracy and a nation's foundation were forged there, so it's important to go back for that reason.

01:00:37.720 --> 01:00:44.720
Otherwise, we go back to the 60s in which it was said during the Vietnam War, we had it destroyed in order to save it, right?

01:00:44.720 --> 01:00:56.720
And I think if that logic starts appearing as part of what we exist in now, then we have brought that kind of war to the homeland, right?

01:00:56.720 --> 01:01:03.720
And so that concerns me in terms of the freedom and the spaces of dissent.

01:01:03.720 --> 01:01:15.720
So if everyone, if there's a blanket notion that citizens are potentially connected, not they're not a potentially terrorist, they're just potentially connected to someone who might be connected to a terrorist.

01:01:15.720 --> 01:01:28.720
Then dissenters who've already been determined to be terrorists in different kinds of discourses, the FBI considers lots of different kinds of protests to be actually forms of terrorism, domestic terrorism.

01:01:28.720 --> 01:01:38.720
Then we may have already gutted the foundation under which people can have a democratic life as well as a rich, interior, personal life.

01:01:38.720 --> 01:01:44.720
And so that's the battleground that concerns me, is also where dissent can take place.

01:01:44.720 --> 01:01:49.720
Both through surveillance, the counter surveillance, I was thinking about cop watch, right?

01:01:49.720 --> 01:01:55.720
So instead of these sort of also grand figures like Snowden who do these international things, how about very local, while politics is local,

01:01:55.720 --> 01:02:10.720
very local things like cop watch that are tracking police abuse on the streets, and then the ways those people who are documenting that might be kind of investigative journalists are being preemptively arrested, their equipment confiscated,

01:02:10.720 --> 01:02:21.720
all this sort of NYPD techniques against Occupy Wall Street attempts to visualize what was going on by the police, especially during the clearing out of Zuccotti.

01:02:21.720 --> 01:02:31.720
I mean, these are ways that there's a prevention, a preemptive actually intervention into the forms of transparency that can happen from bottom up from the people on the streets.

01:02:31.720 --> 01:02:35.720
So that to me concerns me, that's why I think it's a battleground.

01:02:35.720 --> 01:02:44.720
And so think about it more in terms of warfare, in which case law is very important to find curbs and to be part of that.

01:02:44.720 --> 01:02:59.720
But when I think of at least the stories I've heard about the NYPD having built into their budgets, the fact that they're going to predict these lawsuits because of their extra legal detention, preemptive detention of protesters on the streets of New York, right?

01:02:59.720 --> 01:03:06.720
So they figure that they're going to do this, it's going to be illegal, they're going to lose in court, and they're going to have to pay out a civil case, right?

01:03:06.720 --> 01:03:20.720
So that's already built into the way that the strategy works to manage dissent, and that to me is where, when you think about who gets to be, who gets to produce a kind of transparency upon whom and under what conditions so.

01:03:20.720 --> 01:03:47.720
Who would it be interesting to, if there was someone among us who was a high tech person, who could tell us what we would have to do to counter now, they're Google and some of the others are saying that in fact,

01:03:47.720 --> 01:03:52.720
they're going to build devices that will prevent them from doing it.

01:03:52.720 --> 01:04:03.720
Now, I mean, clearly one way is to try to prevent them by arguing from principles of law and justice and so on.

01:04:03.720 --> 01:04:16.720
Another way, of course, is as an evolution, you know, or something evolves, and then those that survive have to evolve new things to the people who are going to do it.

01:04:16.720 --> 01:04:27.720
And then there are some things to do those old things, and so that there is this kind of balance, there's this kind of always tension that exists in life.

01:04:27.720 --> 01:04:45.720
So I can't imagine, I mean, I cannot imagine, but I cannot not imagine that there are high tech folks who are figuring out ways that you might be able to scramble phone messages in some way or internet,

01:04:45.720 --> 01:05:02.720
and so on, and maybe what we need to equalize some of this injustice because it's happening to us, but we don't have much lee except through the law to try to counter it.

01:05:02.720 --> 01:05:16.720
Maybe we need to develop a new technology that I attach it to my phone for any phone call that I don't want anyone to be able to decipher.

01:05:16.720 --> 01:05:37.720
It turns out it's relatively simple to disguise the content of your internet communications, your emails. Most people won't take the extra steps necessary, and Gmail has no incentive to facilitate it because their business model is based upon access to your email.

01:05:37.720 --> 01:05:54.720
But there are ways to encrypt those communications. What's much more difficult is to disguise your metadata, and it turns out, and the reason is because you generally need to expose your metadata so that your communication service knows where to send your information.

01:05:54.720 --> 01:06:08.720
If you're sending an email, the two line needs to be exposed so that the next computer knows where to send it. There's a lot of research that's gone into how to disguise that originally funded by the Navy, because the government wanted a way of securing its internal communications,

01:06:08.720 --> 01:06:24.720
and so they invested heavily in a system of what's called onion routing, where you would sequentially encrypt your communications through a series of hops with the idea that no one hop knows the full path, and it's very difficult to reconstruct.

01:06:24.720 --> 01:06:32.720
But these are difficult technologies to use for most people, and I think they're part of the solution, but they're not the full solution.

01:06:32.720 --> 01:06:51.720
But if we have to do something like that, what kind of society are we living in? And what is the implication of having to protect ourselves, and what's the implication of the government having the power to find out information about a private individual

01:06:51.720 --> 01:07:06.720
without regard to the, you might say, the basic rights of that person for privacy? I mean, what's the implication? Have we undermined really the whole sense of democracy and the sense of trusting government?

01:07:06.720 --> 01:07:22.720
It seems like the whole world is beginning to shift in terms of what are our values, what are we dealing with here? Well, some of it's not new. We use envelopes when we send a mail generally.

01:07:22.720 --> 01:07:32.720
Most people don't send truly private pieces of mail on postcards. They don't write something very sensitive on a postcard. They put it in an envelope.

01:07:32.720 --> 01:07:46.720
And it turns out that just the way the phone systems developed, they're all like postcards. When you are talking over the phone, there is nothing to prevent anyone who has access to the line anywhere along it from listening to the conversation. There's no protection. It's a postcard.

01:07:46.720 --> 01:07:54.720
And we have kind of a system of blind trust for the intermediaries, but it's a trust that we're now learning is undressified.

01:07:54.720 --> 01:08:02.720
The same has largely been true of email. Email for most of its history has been communicated entirely unencrypted.

01:08:02.720 --> 01:08:11.720
If you send, you know, give me an example, if you send a Gmail from a Gmail account to another Gmail account, that's generally encrypted internally to Gmail.

01:08:11.720 --> 01:08:23.720
But if you send a Gmail email to someone on Yahoo's account, the connection between Gmail and Yahoo's is not encrypted. So anyone, and not just our government and not just our government, but even a relatively unsophisticated hacker.

01:08:23.720 --> 01:08:32.720
Could intercept that communication. So some of it, I think, is just common sense. It's putting the envelope on your communication.

01:08:32.720 --> 01:08:44.720
But I agree that we shouldn't have to. It's a sad commentary that people in the tech community are now thinking of their products from the No Trust model.

01:08:44.720 --> 01:08:50.720
They're assuming that nothing can be trusted. The server can't be trusted because the NSA has access to it.

01:08:50.720 --> 01:09:00.720
The telecoms can't be trusted because they'll roll over and give up the information to less design a system that is secure, even if you can't trust the servers, which is possible.

01:09:00.720 --> 01:09:03.720
You know, but it's a sad commentary.

01:09:03.720 --> 01:09:17.720
Following up, why would somebody want to have, you can hear it, a private conversation on their phone in a public place?

01:09:17.720 --> 01:09:28.720
I'm sure we all have experience. People having fights on the phone and other kinds of things, which are really private.

01:09:28.720 --> 01:09:39.720
Now, we couldn't have done that before, at best. We could be in an oboe for the street, but usually you were in your office or home where you did those.

01:09:39.720 --> 01:09:47.720
So we now have a device which promotes it.

01:09:47.720 --> 01:09:54.720
And I believe promotes the idea that there is in private.

01:09:54.720 --> 01:09:59.720
That is, I don't only see it as the government.

01:09:59.720 --> 01:10:09.720
But I guess I'm trying to think it through with something not just the government and us, but something is happening.

01:10:09.720 --> 01:10:15.720
Commercial, you were mentioning. I mean, there are some incredible things on online dating.

01:10:15.720 --> 01:10:24.720
Now, you can fill out a form to begin with, and you say you really want, you're interested in dating brunettes.

01:10:24.720 --> 01:10:31.720
And so the pictures and the information they send you are brunettes, but they're not all brunettes.

01:10:31.720 --> 01:10:45.720
Now, the devices now can monitor if you start hitting a not-on brunettes, but on blondes, let's say, or black-haired people.

01:10:45.720 --> 01:10:54.720
And they will now switch. They will take your action rather than what you stated.

01:10:54.720 --> 01:11:08.720
So we now have to end. We know that in terms of buying things, these devices, these algorithms can come up and present you with things that you've done before.

01:11:08.720 --> 01:11:18.720
So even commercially, they're keeping track of your behavior. So it's endemic, I guess, is what I'm saying.

01:11:18.720 --> 01:11:24.720
We've always had to protect ourselves from our government and our constitution.

01:11:24.720 --> 01:11:30.720
Our initial struggle was to try to figure out how to do that for this country.

01:11:30.720 --> 01:11:53.720
But it's not only it's ourselves allowing ourselves less privacy, and it is our commerce in our commercial worlds and our everyday lives in which people are keeping track of what we do, what we're buying, and so on.

01:11:53.720 --> 01:12:08.720
So I guess, I mean, you read some of Scalia, you know, he would like us back to, you can't go into your house.

01:12:08.720 --> 01:12:13.720
Well, that's what it says, you know, fundamental interpretation.

01:12:13.720 --> 01:12:19.720
You can't need a warrant to come into your home. Well, talking on a phone is not your home.

01:12:19.720 --> 01:12:24.720
So they could argue we're not going to take technology into account.

01:12:24.720 --> 01:12:32.720
Then of course, the more progressive arguments are that indeed it's the idea of privacy and protection.

01:12:32.720 --> 01:12:48.720
But it just seems to me that we need a kind of a balance, a kind of protection, one in terms of understanding why we are giving up privacy.

01:12:48.720 --> 01:13:09.720
And two, mechanisms by which those of us who want could reestablish it, learning how to encode or getting the tech folks to give us really very simple algorithms to make an arm of encoding and encrypting the easier to do.

01:13:09.720 --> 01:13:11.720
I'm going to butt in here in the interest of time.

01:13:11.720 --> 01:13:18.720
I'm going to sum up and say that we're very trusting and we want to be close to people and be known and we're very curious and therefore very prying.

01:13:18.720 --> 01:13:20.720
And we'll have to grapple with that in the area of secrecy.

01:13:20.720 --> 01:13:25.720
We're now open for questions for the next 20 minutes. Please come to the microphone if you'd like to ask.

01:13:25.720 --> 01:13:31.720
You didn't really discuss, and I'm interested in this because it's got to do with human nature.

01:13:31.720 --> 01:13:37.720
I think the mechanism by which the NSA obtains the data.

01:13:37.720 --> 01:13:43.720
For instance, I suspect they don't really hack like you were saying.

01:13:43.720 --> 01:13:46.720
I don't think they hacked the lines and servers and stuff.

01:13:46.720 --> 01:13:48.720
I think it works like this.

01:13:48.720 --> 01:13:50.720
I'm guessing.

01:13:50.720 --> 01:13:54.720
They get a court order and you could help me here.

01:13:54.720 --> 01:14:05.720
They get a court order that says, okay, you can go to Google or AOL and present it to the President and say,

01:14:05.720 --> 01:14:15.720
we want your permission to tap into your memory, your servers, et cetera.

01:14:15.720 --> 01:14:26.720
And the President of AOL thinks and says, hey, what if I said no?

01:14:26.720 --> 01:14:36.720
What would the government do if I refused to obey the court order?

01:14:36.720 --> 01:14:46.720
So, I would like to know really the mechanism by which they're doing all this stuff.

01:14:46.720 --> 01:14:49.720
And maybe someone could tell me.

01:14:49.720 --> 01:14:53.720
Yeah, there are a couple ways, a number of ways they do it.

01:14:53.720 --> 01:14:58.720
The vast majority of the information the NSA collects is not through hacking.

01:14:58.720 --> 01:14:59.720
They do do some hacking.

01:14:59.720 --> 01:15:10.720
There are documented cases of the FBI seeking hacking orders in order to remotely turn on the video camera on someone's laptop without that person knowing.

01:15:10.720 --> 01:15:11.720
So, hacking happens.

01:15:11.720 --> 01:15:14.720
But the vast majority of what the NSA does is not through hacking.

01:15:14.720 --> 01:15:18.720
It's either through court orders directing companies to turn over information.

01:15:18.720 --> 01:15:29.720
So, for example, the very first document that Edward Snowden revealed to the world was an order from the Secret Foreign Intelligence Surveillance Court compelling Verizon Business Network services,

01:15:29.720 --> 01:15:42.720
which is a subsidiary of Verizon, to turn over on an ongoing daily basis records of every single call that came across the network that either started in or ended in the United States.

01:15:42.720 --> 01:15:52.720
So, that is an example. There are similar types of orders that allow programs of surveillance directed at Google, Yahoo, Microsoft, etc.

01:15:52.720 --> 01:16:02.720
And then there's a lot of surveillance that takes place outside the United States, either through alliances with other countries, with their intelligence services,

01:16:02.720 --> 01:16:13.720
or through picking up information off the wire, kind of physical hacking or tapping, or picking it up out of the air using satellite and radio wave surveillance, which happens.

01:16:13.720 --> 01:16:16.720
But the vast majority of it is not through hacking.

01:16:16.720 --> 01:16:18.720
And you're absolutely right about that.

01:16:18.720 --> 01:16:21.720
What happens when the companies are talking to you?

01:16:21.720 --> 01:16:23.720
No, they know.

01:16:23.720 --> 01:16:25.720
Well, they're compelled by court order.

01:16:25.720 --> 01:16:27.720
They can challenge those orders.

01:16:27.720 --> 01:16:29.720
They don't have a great incentive to.

01:16:29.720 --> 01:16:41.720
It's interesting, you know, this type of order, the one that was directed to Verizon, there have been similar ones to all the major companies, and they've been going to those companies every 90 days since 2006.

01:16:41.720 --> 01:16:44.720
So, each one of them has received dozens of orders.

01:16:44.720 --> 01:16:47.720
Not a single one of the telecoms has challenged that order.

01:16:47.720 --> 01:16:50.720
Even though on its face it's extraordinary.

01:16:50.720 --> 01:16:57.720
Every single record of every single call that comes across your network, whether it's related to a terrorist or not, hand over.

01:16:57.720 --> 01:17:01.720
And not a single one has challenged them, but they could challenge them.

01:17:01.720 --> 01:17:05.720
The reason they don't have an incentive is because, A, they have a very close working relationship with the government.

01:17:05.720 --> 01:17:09.720
They have a lot of government contracts, so they have a financial incentive not to.

01:17:09.720 --> 01:17:12.720
B, the statute immunizes them, so they're not.

01:17:12.720 --> 01:17:15.720
They don't suffer any legal liability for turning over your call records.

01:17:15.720 --> 01:17:17.720
You can't sue them.

01:17:17.720 --> 01:17:21.720
And C, they're compensated at fair market value by the statute for their cooperation.

01:17:21.720 --> 01:17:22.720
So they're getting paid.

01:17:22.720 --> 01:17:24.720
So they don't have much of an incentive.

01:17:24.720 --> 01:17:34.720
And on the other side, on the side of the service providers, the internet, the tech companies, as opposed to the telecoms, the tech companies have occasionally pushed back.

01:17:34.720 --> 01:17:40.720
The last major one was by Yahoo back in 2007.

01:17:40.720 --> 01:17:47.720
Haven't really been any major challenges from the tech companies since although they're starting to ramp up their efforts now and they're pushing back a little bit.

01:17:47.720 --> 01:17:51.720
But they have the same relationships with the government.

01:17:51.720 --> 01:17:57.720
They have the same immunity provided by the statute and they have the same provision for fair market compensation.

01:17:57.720 --> 01:18:02.720
Please introduce yourself.

01:18:02.720 --> 01:18:11.720
Greg Burke, this usually we've heard that there has to be a tacit kind of balance between individuals and institutions.

01:18:11.720 --> 01:18:20.720
I mean, maybe governments or societies or businesses, things like that over time where there's an understanding that there's a certain amount of

01:18:20.720 --> 01:18:32.720
less than a free discussion, I don't know between each other in terms of what information we've heard about being polite.

01:18:32.720 --> 01:18:41.720
And we all passively never believe anything that we see on television, for instance, in terms of advertisements and stuff like that.

01:18:41.720 --> 01:18:43.720
And it's been acceptable over the years.

01:18:43.720 --> 01:18:45.720
It's been a certain balance.

01:18:45.720 --> 01:19:02.720
Now we have this huge amount of technology that has shifted and shift the balance away from the individual towards institutions with regard to how to manipulate this interaction of the dance of social commerce.

01:19:02.720 --> 01:19:14.720
And particularly I'm concerned now with how is the individual as a responsible in the democratic society supposed to get the information from the government.

01:19:14.720 --> 01:19:19.720
It's supposed to get the information that is necessary to make decisions about voting.

01:19:19.720 --> 01:19:31.720
The issue here is believing what you hear from politicians, from people who are actually in the government.

01:19:31.720 --> 01:19:43.720
It seems to me that we have in our society now created a paranoia about terrorism that requires a lot of people to want to give up certain rights.

01:19:43.720 --> 01:19:48.720
And this is an opportunity to manipulate.

01:19:48.720 --> 01:19:52.720
And I just use your imbalance now because of people.

01:19:52.720 --> 01:19:54.720
I can't figure out what's true.

01:19:54.720 --> 01:20:07.720
I mean, how can you all on the panel here figure out what's true in terms of being able to make a little perform decision as a citizen to vote both from what the government is telling you on what you see on the news.

01:20:07.720 --> 01:20:16.720
I read wiki and that's how I found out about the prison program and how Google collaborated with the government with the week.

01:20:16.720 --> 01:20:19.720
So that's my source of the shh.

01:20:19.720 --> 01:20:24.720
This is not just happening to us.

01:20:24.720 --> 01:20:26.720
We are participating in this.

01:20:26.720 --> 01:20:43.720
And I guess that's been the psychological point I've been trying to understand is to what degree have we psychologically moved away from this idea of the private.

01:20:43.720 --> 01:21:03.720
And I think that one could find many, many examples of a shift during the same period and maybe even a longer to that makes it easier for the government to, in fact, do some of these things.

01:21:03.720 --> 01:21:14.720
The shift to telephone conversations in public.

01:21:14.720 --> 01:21:16.720
Just simply that.

01:21:16.720 --> 01:21:19.720
Now my wife and I were in Paris.

01:21:19.720 --> 01:21:25.720
We've just come back and shockingly, there are not many people on the phone walking the streets.

01:21:25.720 --> 01:21:33.720
We've been walking the difference in the two major cities in the world in this city.

01:21:33.720 --> 01:21:38.720
You can't go a block without someone talking and hearing them.

01:21:38.720 --> 01:21:43.720
And that's not the case in a week of walking in Paris.

01:21:43.720 --> 01:21:50.720
So I think there's something happening psychologically.

01:21:50.720 --> 01:22:16.720
And I think we can even find it in some of our theories and that suggests that privacy in terms of not expressing what you really think or not doing such.

01:22:16.720 --> 01:22:20.720
I'll be brief.

01:22:20.720 --> 01:22:28.720
In fact, changing us and making us more susceptible to it.

01:22:28.720 --> 01:22:32.720
Now it was interesting because you asked what we could do.

01:22:32.720 --> 01:22:40.720
I mean there is some outrage and it's going on for a while, but it's shocking how little there is.

01:22:40.720 --> 01:22:51.720
I'd be very curious if people don't use their phone as much or don't use email as much knowing that potentially someone could be listening in and gathering data.

01:22:51.720 --> 01:22:58.720
So it's happening to us, but I think some other things are happening.

01:22:58.720 --> 01:23:05.720
There's a psychology that is happening at the same time, which is playing into this.

01:23:05.720 --> 01:23:13.720
Can I just suggest one thing because we've had this conversation a little bit today, but is it possible that most of that shift is at the margins?

01:23:13.720 --> 01:23:21.720
Because I suspect that if you ask the person who's on their phone walking down New York having what is usually in a conversation with a mom or dad.

01:23:21.720 --> 01:23:25.720
It's not usually the most private conversation in the world, but suppose even if it is.

01:23:25.720 --> 01:23:30.720
If you ask that person, would you share with me your Gmail password?

01:23:30.720 --> 01:23:35.720
Tell me your social security number, allow me to install video equipment in your home.

01:23:35.720 --> 01:23:37.720
They'll say no to those things.

01:23:37.720 --> 01:23:42.720
So I think there's a core of privacy that persists even if there is a shift in the margins.

01:23:42.720 --> 01:23:44.720
But is it just at the margins?

01:23:44.720 --> 01:23:47.720
Well the question is, is it at the...

01:23:47.720 --> 01:23:50.720
Well do you mean margin in terms of people or not?

01:23:50.720 --> 01:23:59.720
I mean I've been in restaurants where a young woman is talking to her mother and having an argument about something in which I'm privy to.

01:23:59.720 --> 01:24:02.720
And she does not.

01:24:02.720 --> 01:24:04.720
She is not.

01:24:04.720 --> 01:24:11.720
This doesn't seem to bother her that a complete stranger is listening to this going on.

01:24:11.720 --> 01:24:13.720
Now does everyone do it?

01:24:13.720 --> 01:24:15.720
No of course not.

01:24:15.720 --> 01:24:22.720
Lots of people don't talk on their phones unless they really need to or just small exchange of information.

01:24:22.720 --> 01:24:26.720
So in some sense it's not everyone doing it.

01:24:26.720 --> 01:24:38.720
But I do think, for example, etiquette which disappeared in the 60s when the idea was no you let it all hang out.

01:24:38.720 --> 01:24:48.720
There's a struggle etiquette books disappeared there actually have reappeared which is kind of an interesting phenomena.

01:24:48.720 --> 01:24:58.720
But it now is you can't have a private for it. You'll have to make it public if someone asks you a question.

01:24:58.720 --> 01:25:03.720
Good interpersonal life was you gave them the answer.

01:25:03.720 --> 01:25:06.720
So I don't know how marginal it is.

01:25:06.720 --> 01:25:17.720
But I would be concerned in this struggle with this, with government which is what are major concerns here.

01:25:17.720 --> 01:25:20.720
I would be concerned that it's not them just doing it to us.

01:25:20.720 --> 01:25:31.720
And if they are doing it to us, that we are becoming more compliant psychologically to it.

01:25:31.720 --> 01:25:34.720
Time for a couple more questions I hope.

01:25:34.720 --> 01:25:37.720
I think people waiting are.

01:25:37.720 --> 01:25:48.720
I just want to ask what you guys think is the role of the psychology of fear in the way that the policies have been crafted.

01:25:48.720 --> 01:25:57.720
Because it seems to me that the way that the NSA's role has grown sort of comports with what millions of years of evolution have forged in us.

01:25:57.720 --> 01:26:03.720
There's the classical example of you have an animal in Savannah and here's the glass gras rustling behind it.

01:26:03.720 --> 01:26:07.720
And it can make two types of mistakes in that situation.

01:26:07.720 --> 01:26:13.720
We're worried that there's a threat and turn around and there's nothing, which is a mistake.

01:26:13.720 --> 01:26:18.720
Or it could assume that it was just the wind, but it's actually a predator and a dead.

01:26:18.720 --> 01:26:24.720
And so of course evolution pushes us in the direction of leaping at a threat that may not be present.

01:26:24.720 --> 01:26:32.720
And it seems that our reaction to one very significant but relatively isolated terrorist event has had a very profound effect.

01:26:32.720 --> 01:26:40.720
On our government policy and the way that we all sort of accepted changes in our own security.

01:26:40.720 --> 01:26:47.720
And so because this is such a deep-seated, strong, evolutionarily formed predisposition,

01:26:47.720 --> 01:26:53.720
I wonder if there's a real plausible way of fighting against it because it's such a strong urge.

01:26:53.720 --> 01:26:57.720
I'll just add before the human nature component of this,

01:26:57.720 --> 01:27:04.720
we'll just add that there's a whole layer of mediated repetition of the trauma that happens that reactivates that moment too.

01:27:04.720 --> 01:27:18.720
So the annual replaying of the images, the bushes, the security codes and the color codes and the constant reminding of people that we're at war.

01:27:18.720 --> 01:27:27.720
So I think regardless of whether this, what it touches in terms of the basic dimensions of being a human,

01:27:27.720 --> 01:27:30.720
the cultural mediated dimensions are very political in terms of that can be changed.

01:27:30.720 --> 01:27:40.720
There's no reason why we have to say, okay, well, this is a defining moment of our entire senses of self as Americans because we've been attacked.

01:27:40.720 --> 01:27:45.720
Which is something that other countries around the world go through on a daily basis.

01:27:45.720 --> 01:27:52.720
Right, so this sort of American exceptionalism is something also I think that is a cultural dimension of this fear, that it's not just something that-

01:27:52.720 --> 01:28:00.720
We have been at war as a society. We haven't stopped from the Second World War. We have the Korean War.

01:28:00.720 --> 01:28:13.720
We have had an enemy. I mean, we could start looking at paranoia and judge on the stand or-

01:28:13.720 --> 01:28:21.720
An enemy for the last 75 years. There's all we spin in an enemy.

01:28:21.720 --> 01:28:30.720
That's true, but at the same time, the 9-11 acted like an acute trauma. In some sense was unexpected.

01:28:30.720 --> 01:28:37.720
I mean, we should have expected, but people didn't expect it because we've been fighting out there.

01:28:37.720 --> 01:28:50.720
We haven't had something hit us in quite this way. So it acts like a traumatic event to which it's almost like we're acting all of us in a post-traumatic neurosis.

01:28:50.720 --> 01:29:06.720
I mean, in the sense that we're always on guard against the repetition of the trauma, and that gets extended into policy and into the public arena in such a way as to cause a whole shift in our world.

01:29:06.720 --> 01:29:15.720
Since that happened, we've had a major shift in this country towards a long, a long signal reaction.

01:29:15.720 --> 01:29:24.720
And I don't think that's going to be easily reversed.

01:29:24.720 --> 01:29:37.720
I have a slightly different focus. I was struck by your analogy of the supernatural detective who could figure anything out retroactively.

01:29:37.720 --> 01:29:53.720
And the assumption of this broad data collection is essentially, I think, that if we have the data, somehow we can reconstruct the past and do so with great accuracy or with sufficient accuracy.

01:29:53.720 --> 01:30:06.720
And I'm thinking immediately a couple things. One is Google Books, where Google is going around scanning books.

01:30:06.720 --> 01:30:14.720
I don't know if any of you have ever had the experience of actually looking at these books. They're terrible.

01:30:14.720 --> 01:30:25.720
Nope, they scan them, but they don't proofread them. And I know, I mean, I've downloaded some of these books.

01:30:25.720 --> 01:30:39.720
Some of them are unreadable. They're gobbledygook. I notice, for example, even here we have to have technicians coming around constantly adjusting to get.

01:30:39.720 --> 01:30:58.720
I mean, this is open recording. There's no secrecy about it. And yet it takes apparently a great deal of tending to make sure that you get a good recording.

01:30:58.720 --> 01:31:15.720
And it takes a great deal of data who, obviously, if we record everybody's data, technically, if it were all listened to, it would mean that everybody would have to be working to listen to everybody's data.

01:31:15.720 --> 01:31:35.720
And it's a mathematical problem, almost. The existence of the data, I think, often gives people the idea that somehow the data is knowledge, whereas often I think it's not data but interpretation.

01:31:35.720 --> 01:31:49.720
And I'm also responding to the personal experience of having been the subject of a government investigation many years ago for political activity during the Vietnam War.

01:31:49.720 --> 01:32:09.720
And I got a copy of the investigative report. And I wrote a response to it, which began with the sentiment that as a taxpayer, I was greatly disappointed in the low quality of the investigation.

01:32:09.720 --> 01:32:21.720
I mean, I'm not going to bother to go. But it was, it was, I was appalled. This is what they came up with. How much did they spend for this?

01:32:21.720 --> 01:32:38.720
So I think in part, what I'm saying here is, yeah, there's an issue about the collection of data, but there's also an issue, I think, about the perception of almost, you know, supernatural.

01:32:38.720 --> 01:32:51.720
You know, supernatural knowledge and so forth, which I think is very, very questionable. But it, you know, knowledge or the perception of knowledge also is power.

01:32:51.720 --> 01:32:57.720
So I don't know if anybody wants to comment on those comments, but those are some of my.

01:32:57.720 --> 01:33:10.720
I would say, right, I mean, that can be very politically disabling to think that there's nothing that can be done. All this data is out there. The government is perfectly efficient as we're talking about efficiency, like creating the algorithms that can detect all these things.

01:33:10.720 --> 01:33:22.720
So, so the notion of that actually shifts a kind of power dynamic that says we can't do anything about it, but it's also, it's just so perfectly done. I mean, that when I study conspiracy theories, sometimes that's what it is.

01:33:22.720 --> 01:33:33.720
And the classic, the classic, the classic classic classic fantasy at the end of.

01:33:33.720 --> 01:33:43.720
He's Germany. And the efforts to reconstruct and understand what people thought they knew and also for to buy up.

01:33:43.720 --> 01:34:02.720
And the feeling of distrust and the ability to, to, to have a working democracy, basically, in, in a environment of such potential betrayal and distrust.

01:34:02.720 --> 01:34:18.720
The lesson of the, the 9-11 Commission report was not that we didn't have enough information, but, but that we didn't analyze it properly. But the response was to collect more out of a fear that, or, or a suspicion, I suppose, that if we just have more information, we'll solve it.

01:34:18.720 --> 01:34:34.720
You know, data can lie, which is one of the reasons why the government relies more heavily on metadata, because metadata is, doesn't lie as easily, or it's more easy, is more difficult to, to, you know, to obscure. But I think that's a good point.

01:34:34.720 --> 01:34:51.720
Carl Kleben from New York. I think the panel has covered a whole variety of different things and it's hard to be focused.

01:34:51.720 --> 01:35:11.720
Which is rather than the issue of national security and spying and the threat to civil liberties or the restrictions of civil liberties that have always happened when those things have been threatened and how much worse all of this could be down with and is with the explosion of information and the explosion of technology

01:35:11.720 --> 01:35:30.720
and the accessibility of information. What interests me more, in no way to strike the importance of all that, but what interests me more is the information that we give away so, and willingly, and the implications of that.

01:35:30.720 --> 01:35:47.720
And that is, you know, all given the accessibility on the Internet of all the data, including our financial data, our medical data, our legal data, our personal lives, what we do and what we don't do, how we spend our money, et cetera.

01:35:47.720 --> 01:36:06.720
I wonder if the panel could comment more about this psychological, social, and even political ramifications of that, leaving out for the moment the special issue of national security and national safety versus.

01:36:06.720 --> 01:36:20.720
But the whole change in privacy or the way in which, at least in America, and maybe in the rest of the world, we kind of willingly are, that's sort of gone or largely compromised.

01:36:20.720 --> 01:36:25.720
I'd like to start with that. So it's a question about the freely and willingly.

01:36:25.720 --> 01:36:30.720
I think there's Mauricio Lacerado who said, right, in the 60s, self-expression was a sign of freedom.

01:36:30.720 --> 01:36:37.720
Today, it's an obligation and a compulsion, which is not just a psychological one, but an economic one.

01:36:37.720 --> 01:36:41.720
It's an imperative that people create digital profiles.

01:36:41.720 --> 01:36:45.720
Young people do, right, in order to be able to get jobs, right?

01:36:45.720 --> 01:36:46.720
So that's one way.

01:36:46.720 --> 01:36:51.720
It's like this constant need to express oneself, to show oneself digitally,

01:36:51.720 --> 01:37:00.720
communicationally, in order to connect with the world. There's partially that. I think there's also, there is a change in what it means to share.

01:37:00.720 --> 01:37:06.720
I don't think it means people just, you know, produce everything without thinking about it.

01:37:06.720 --> 01:37:10.720
I mean, there are new words, I'd say, in our vocabulary.

01:37:10.720 --> 01:37:11.720
Sorry?

01:37:11.720 --> 01:37:14.720
Only adolescents texting to each other.

01:37:14.720 --> 01:37:18.720
Sorry, adolescents texting to each other?

01:37:18.720 --> 01:37:20.720
I mean, that's a particular form of communication.

01:37:20.720 --> 01:37:21.720
Let me text you.

01:37:21.720 --> 01:37:22.720
Sure.

01:37:22.720 --> 01:37:23.720
I'm also doing that too.

01:37:23.720 --> 01:37:24.720
Yeah.

01:37:24.720 --> 01:37:30.720
So I'm thinking about words that have entered the vocabulary, like oversharing and TMI, which young people also use.

01:37:30.720 --> 01:37:32.720
Too much information, right?

01:37:32.720 --> 01:37:37.720
So it's not as though it's unfiltered.

01:37:37.720 --> 01:37:44.720
I think the questions of etiquette, protocol, and what these filters are haven't been part of a discussion enough,

01:37:44.720 --> 01:37:47.720
but we're not also asking young people enough.

01:37:47.720 --> 01:37:49.720
How are they already managing this privacy?

01:37:49.720 --> 01:37:53.720
They don't want parents looking. They don't want employers looking at everything, right?

01:37:53.720 --> 01:37:58.720
They don't even want their partners, their romantic partners looking at all of their communication either.

01:37:58.720 --> 01:38:05.720
So I would just want to complicate the notion that it's sort of this flood that almost is coming from individuals

01:38:05.720 --> 01:38:11.720
rather than a social compulsion, again, around express yourself, or there's something questionable about you.

01:38:11.720 --> 01:38:18.720
If you don't express yourself, if you're not on call 24-7, says the family, says the job,

01:38:18.720 --> 01:38:21.720
says reality TV, right? You're hiding something.

01:38:21.720 --> 01:38:26.720
So I think that what we've lost is a notion that, yeah, that we might want to say that there's something worth hiding,

01:38:26.720 --> 01:38:32.720
which is a different one than just saying people are just giving freely and willingly, but what is it worth protecting?

01:38:32.720 --> 01:38:36.720
Not just its privacy, but its secrecy, which might be a little different too.

01:38:36.720 --> 01:38:41.720
And I also suggest that it's maybe more a difference in degree and not necessarily a difference in kind.

01:38:41.720 --> 01:38:47.720
You've always had to share extraordinarily personal information in order to obtain certain services.

01:38:47.720 --> 01:38:53.720
It is true now your medical records, for example, are often available online, but those medical records used to reside in your doctor's office.

01:38:53.720 --> 01:39:02.720
The digitization makes them more easily accessible and brings with it complicated questions about informational security and privacy.

01:39:02.720 --> 01:39:04.720
That's another con, though.

01:39:04.720 --> 01:39:15.720
Again, a new audience has more gray hair than the population at large, but clearly,

01:39:15.720 --> 01:39:27.720
I mean, you can go into a restaurant and someone's taking a picture of what they're eating to send to someone as they're eating it,

01:39:27.720 --> 01:39:33.720
or they're describing what they're doing in the here and now.

01:39:33.720 --> 01:39:39.720
And so these are another kind of information.

01:39:39.720 --> 01:39:45.720
But it's hard to compare that to what would have happened 50 years ago when the technology didn't exist.

01:39:45.720 --> 01:40:02.720
But the point is the technology allows for it, and I do believe there are social rules, psychological things that are changing in modern societies,

01:40:02.720 --> 01:40:09.720
which are undoing this, loneliness.

01:40:09.720 --> 01:40:17.720
I mean, silence, not having it light all the time, or being in the dark.

01:40:17.720 --> 01:40:20.720
We evolved with light and dark.

01:40:20.720 --> 01:40:24.720
We don't have to be in the dark anymore.

01:40:24.720 --> 01:40:26.720
We can go on and on.

01:40:26.720 --> 01:40:30.720
You can talk to someone in a continuous fashion.

01:40:30.720 --> 01:40:34.720
We're texting in cars as we're driving.

01:40:34.720 --> 01:40:42.720
I mean, there was a lot of insanity if you look at it from a cultural point of view that are going on.

01:40:42.720 --> 01:40:49.720
I mean, yes, you have a nice dinner and you talk about it.

01:40:49.720 --> 01:40:53.720
You say, gee, we went to this wonderful restaurant and you should go with it.

01:40:53.720 --> 01:40:59.720
We had this dish and you'd describe it if you're a foodie, but now you can take a picture of it.

01:40:59.720 --> 01:41:03.720
And not only show it later, but show it at the time you're eating.

01:41:03.720 --> 01:41:05.720
You're not going to show it later. That's the thing.

01:41:05.720 --> 01:41:07.720
So why not just think of it as temporality?

01:41:07.720 --> 01:41:09.720
I'm doing it now. I don't have to deal with it later.

01:41:09.720 --> 01:41:14.720
So it's a moment where it interrupts the present, but it just becomes a temporality.

01:41:14.720 --> 01:41:17.720
It takes it out of the private.

01:41:17.720 --> 01:41:24.720
It takes it out of eating the meal, at least either by yourself or with the person you're eating with.

01:41:24.720 --> 01:41:32.720
And now you make it a public eating. This dessert is now a public act.

01:41:32.720 --> 01:41:37.720
Now, if you think about it, okay, I mean, maybe that's a good thing.

01:41:37.720 --> 01:41:39.720
I don't know, but it sure as hell is a new thing.

01:41:39.720 --> 01:41:42.720
Well, it's always a public act. You're in a restaurant doing it.

01:41:42.720 --> 01:41:44.720
The question is how big the audience is.

01:41:44.720 --> 01:41:47.720
We're streaming this event, right? Or where it'll be streamed at some point.

01:41:47.720 --> 01:41:51.720
Has the role of privacy changed in child development and families?

01:41:51.720 --> 01:41:53.720
I think it has changed.

01:41:53.720 --> 01:41:56.720
It's evolving things no longer.

01:41:56.720 --> 01:42:00.720
Strict signs of demarcations that used to exist.

01:42:00.720 --> 01:41:53.720
That's a

01:42:00.720 --> 01:42:01.720
a subjective artifact.

01:42:01.720 --> 01:42:04.720
My father was not my friend. He was my father.

01:42:04.720 --> 01:42:07.720
And now fathers have to be friends.

01:42:07.720 --> 01:42:13.720
And what does friendship require?

01:42:13.720 --> 01:42:21.720
Well, friendship requires a reciprocality, which means giving up some of your privacy.

01:42:21.720 --> 01:42:25.720
I actually have been trying to understand that.

01:42:25.720 --> 01:42:27.720
I'm not sure it's a good thing.

01:42:27.720 --> 01:42:31.720
I'm just not sure that it isn't leading.

01:42:31.720 --> 01:42:39.720
Indeed, our parenting is not in fact leading a whole new set of generations.

01:42:39.720 --> 01:42:46.720
Almost two now to in fact not to just to know everything.

01:42:46.720 --> 01:42:51.720
And this is part of it. It's ongoing knowing everything.

01:42:51.720 --> 01:42:57.720
Now, that's a setup when you say there's danger out there and we're going to protect you.

01:42:57.720 --> 01:43:01.720
Because you used to it to begin with.

01:43:01.720 --> 01:43:07.720
And now you've got to they're giving you some kind of what seems like a good reason,

01:43:07.720 --> 01:43:11.720
which of course as you were saying isn't.

01:43:11.720 --> 01:43:17.720
One, you have to analyze this huge amount that you're collecting, which is not easy to do.

01:43:17.720 --> 01:43:22.720
But the fact is I think there is a psychological change.

01:43:22.720 --> 01:43:28.720
And I think we as older people in fact are not as susceptible to it.

01:43:28.720 --> 01:43:34.720
And I know as I the young and look at the public behavior,

01:43:34.720 --> 01:43:42.720
I mean others in the room look at therapeutic sense and a different kind of behavior.

01:43:42.720 --> 01:43:51.720
But in a public behavior, I see things which are just out of my experience.

01:43:51.720 --> 01:43:54.720
I think we have time for one more question.

01:43:54.720 --> 01:43:57.720
Two short ones.

01:43:57.720 --> 01:43:59.720
Okay.

01:43:59.720 --> 01:44:03.720
I'm a Lexi Kalaturak, a Summit Analyst here at New York Signaling.

01:44:03.720 --> 01:44:09.720
So I had I think going through a few of the things I'm here, closer sorry.

01:44:09.720 --> 01:44:16.720
Trust and mistrust, can you believe anything or can you know, certainly the governmental to private citizen level.

01:44:16.720 --> 01:44:20.720
But I think it also comes up in the use of the technology and families.

01:44:20.720 --> 01:44:23.720
I've been talking about child development.

01:44:23.720 --> 01:44:31.720
Sometimes I'll have parents in my office who will say, you know, my kids' new phone has GPS on it.

01:44:31.720 --> 01:44:34.720
I'll attract them.

01:44:34.720 --> 01:44:37.720
Well, maybe.

01:44:37.720 --> 01:44:43.720
And then hopefully we can get into a discussion of what would the purpose of tracking them be?

01:44:43.720 --> 01:44:46.720
What information would they gain from that?

01:44:46.720 --> 01:44:50.720
What would they do with that information?

01:44:50.720 --> 01:44:57.720
And then it doesn't become an easy yes or no answer at that point, which I think is good.

01:44:57.720 --> 01:45:01.720
So I think it can come up in other ways.

01:45:01.720 --> 01:45:13.720
You know, is the government benevolently listening to everything or are they really just looking for terrorists or, you know, one of the, I think Obama's not finest moments was basically telling us, don't worry about what the NSA is doing, right?

01:45:13.720 --> 01:45:16.720
But in a family, that might be okay.

01:45:16.720 --> 01:45:24.720
In a family, a teenager might come home with alcohol in his breath and a parent may think, should I say something?

01:45:24.720 --> 01:45:27.720
Well, that depends.

01:45:27.720 --> 01:45:28.720
Have you talked about this before?

01:45:28.720 --> 01:45:29.720
Is this the first time?

01:45:29.720 --> 01:45:31.720
Is this the tenth time?

01:45:31.720 --> 01:45:46.720
And hopefully what's there is a relationship in which you can maybe trust your teenager to a certain point, but not too much, but that it's established and that you can count on it in some way.

01:45:46.720 --> 01:45:50.720
Obviously, when we're talking about private citizens and the government, we can't do that.

01:45:50.720 --> 01:45:52.720
Some people feel you can't trust anything.

01:45:52.720 --> 01:45:55.720
They say some people feel, well, you know, they probably know what they're doing.

01:45:55.720 --> 01:46:04.720
So that's why we have rules and I'm very thankful we have people like you guarding our, but the balance of those things.

01:46:04.720 --> 01:46:08.720
But I think it comes up in other ways too.

01:46:08.720 --> 01:46:15.720
One other comment just on the issue of sort of groups and dissent.

01:46:15.720 --> 01:46:22.720
One of the times op-ed columnist from many years ago wrote a column saying, never use your credit card, always pay cash.

01:46:22.720 --> 01:46:25.720
It was the libertarian guy, I can't remember his name.

01:46:25.720 --> 01:46:27.720
And I thought, well, why?

01:46:27.720 --> 01:46:29.720
I mean, it's easy to use a credit card.

01:46:29.720 --> 01:46:30.720
It's convenient.

01:46:30.720 --> 01:46:36.720
Well, okay, but I'm not doing anything terribly embarrassing on my credit card or subversive.

01:46:36.720 --> 01:46:44.720
But if I were a little bit, then I would probably want to be able to pay cash and not worry about it and not have myself targeted.

01:46:44.720 --> 01:46:46.720
In some way.

01:46:46.720 --> 01:46:58.720
So I think with texting and with every email being possibly recorded, we may be making a white bread society where it's really dangerous to say anything that's a little too provocative.

01:46:58.720 --> 01:47:11.720
If you're a student who wants to go to college one day, God forbid somebody from the admissions office somewhere should see your Facebook where maybe you were holding a beer and you were underage, etc, etc.

01:47:11.720 --> 01:47:19.720
I would say that in the 1980s, they had an album called Give Me Convenience or Give Me Death.

01:47:19.720 --> 01:47:22.720
40 years ago to today, it still works.

01:47:22.720 --> 01:47:29.720
Quick comment, I don't have a Facebook profile and I have experienced a certain amount of peer pressure to get one.

01:47:29.720 --> 01:47:33.720
I've had friends say to me, come on, it's fun.

01:47:33.720 --> 01:47:42.720
And I feel like an anomaly that I don't.

01:47:42.720 --> 01:47:49.720
But my quick question is, were you recommending that individuals encrypt their email correspondence?

01:47:49.720 --> 01:47:52.720
And if so, how do we get the information?

01:47:52.720 --> 01:47:55.720
I'm happy to talk to the technology effort, if you like.

01:47:55.720 --> 01:48:05.720
It turns out if you encrypt your emails, there are special rules that apply for the NSA's collection and they can collect and keep that information indefinitely under pretty much any one of their programs.

01:48:05.720 --> 01:48:10.720
So the more you try to protect your privacy, the more susceptible you are to NSA surveillance.

01:48:10.720 --> 01:48:17.720
Now they may not be able to decrypt it immediately, but they can keep it so long as they deem fit.

01:48:17.720 --> 01:48:27.720
I think this is really one of the fundamental paradoxes of the situation, the hackers are the people that are involved in protecting our privacy, these kinds of dichotomies.

01:48:27.720 --> 01:48:30.720
No, don't draw attention to yourself.

01:48:30.720 --> 01:48:39.720
And there are interesting questions about the role of attention and direction of attention in terms of constructing the self when you have all of this information equally available.

01:48:39.720 --> 01:48:48.720
The one thing that technology can do is make passive or pervasive or dragnet surveillance costly enough not to be effective.

01:48:48.720 --> 01:48:52.720
It can force the government to engage in targeted rather than dragnet surveillance.

01:48:52.720 --> 01:48:58.720
And the virtue of that is that the government then will use its limited resources where it should.

01:48:58.720 --> 01:49:04.720
And it turns out even if you encrypt your communications, it's very easy to encrypt your communications in transit.

01:49:04.720 --> 01:49:11.720
But it's very difficult to secure your endpoints. It's very difficult to secure your laptop or to secure your desktop.

01:49:11.720 --> 01:49:17.720
And that's because Windows and Mac and all these operating systems are fundamentally insecure because they're too complicated to make secure.

01:49:17.720 --> 01:49:20.720
And so if the NSA wants to get to you in a targeted way, they can.

01:49:20.720 --> 01:49:28.720
And there's nothing to stop them. And that might be a good thing because they're generally when they use their resources in a targeted way or focusing on the right people.

01:49:28.720 --> 01:49:35.720
And so technology can make untargeted surveillance difficult and force the government to engage in the type of targeted surveillance that should be engaging in.

01:49:35.720 --> 01:49:42.720
So if I could say yes to you and 350 million other people I would, but if it's just, yeah, we can talk about it.

01:49:42.720 --> 01:50:01.720
Thank you everybody for coming and for participating so thoroughly and thank our panelists very, very much.

