WEBVTT

00:00.000 --> 00:06.140
So I'm Ed Nurse-Essian, I'm Director of the Center and I'd like to welcome you to this

00:06.140 --> 00:12.080
meeting on what mathematics can tell us about the mind and the brain. The idea for this round

00:12.080 --> 00:22.200
table was generated during a dinner conversation with Sylvan Capel, who's head of the Mathematics

00:22.200 --> 00:31.840
Institute at NYU and Charles Marmour, who's a psychiatrist and chairman of the department

00:31.840 --> 00:39.600
at NYU. So they thought that this would be a very timely subject for us to have a round

00:39.600 --> 00:47.280
table about at the Helix Center and I want to thank them for it. Just briefly, we have

00:47.280 --> 00:54.000
a number of programs set up already for the fall and I'd like to mention them. I think

00:54.000 --> 01:02.720
the first one after this is a program on why economists disagree, which will be on October

01:02.720 --> 01:14.260
13th and we'll have economists from the two sides of the intellectual or scientific areas

01:14.260 --> 01:26.140
discussing it. The following day on Sunday, and is it a two-third day? We will have a

01:26.140 --> 01:34.540
program called Poetry and Jazz where we have a poet and a jazz musician who will play,

01:34.540 --> 01:42.260
recite and discuss the relationship between poetry and jazz. Following that in October,

01:42.260 --> 01:51.220
Friday and Saturday, we'll have two round tables. One of them is going to be on, I wrote the

01:51.220 --> 01:59.180
exact title somewhere, Life and Movement and the other would be on male-male competition,

01:59.180 --> 02:06.020
globalization, war and violence. These two round tables have been organized and proposed

02:06.020 --> 02:13.940
by Maxine Schitz-Johnson, who is an emeritus professor of philosophy of science from Oregon

02:13.940 --> 02:20.220
University and who was here during the Philip Deides days and did a two or three programs

02:20.220 --> 02:32.260
for us. Our website is up and one of the ideas that has always propelled us is that these

02:32.260 --> 02:39.020
round tables should not just end here, but there should be an ongoing conversation taking

02:39.020 --> 02:47.540
place afterwards. We were not set up before for it and I think we are. Maybe Rob can say

02:47.540 --> 02:52.580
what you do for that.

02:52.580 --> 03:03.420
Yes, thank you, Rod. First of all, go to www.thehelixcenter.org or helixcenter.org and that will access

03:03.420 --> 03:12.780
the website. There's a link to sign up after which you can participate in conversations

03:12.780 --> 03:19.100
on the website. You can either join a topic, a question that has already been posed by

03:19.100 --> 03:25.780
someone else related to one of the events here or you can propose a new subject for

03:25.780 --> 03:32.100
discussion. The other thing is that if you want to comment on anything that's going on

03:32.100 --> 03:42.300
here, you can Twitter at the helixcenter.

03:42.300 --> 03:51.180
As I said, today's subject has a very easy title, but it is a rather complicated subject

03:51.180 --> 04:02.740
and we have people who I think can discuss it who are leaders in this field. I will start

04:02.740 --> 04:09.620
with Ned Bloch who's been to us a number of times. He's the silver professor of philosophy,

04:09.620 --> 04:15.700
biology and neural science at NYU. He came to NYU from MIT where he was chair of the

04:15.700 --> 04:21.700
philosophy program there. He works in philosophy of mind and foundations of neuroscience and

04:21.700 --> 04:32.340
cognitive science. Bar, there are many trout who is unfortunately unable to be here today.

04:32.340 --> 04:39.500
What is with us via Skype is distinguished university professor of computational biology

04:39.500 --> 04:45.060
and professor of mathematics at the University of Pittsburgh. He's written more than 200

04:45.060 --> 04:54.700
papers in math, philosophy, physics and math, biology, physics and neuroscience. He has a

04:54.700 --> 05:03.140
software called XPPAUT for the simulation of an analysis of dynamical systems. As written

05:03.140 --> 05:08.140
a number of books and one of them is available here for you if you would like to purchase

05:08.140 --> 05:14.860
it. Ken Miller is professor, department of neuroscience, department of physiology and

05:14.860 --> 05:22.940
center for theoretical neurobiology at Columbia University. He's co-director of the Schwartz

05:22.940 --> 05:32.580
program in theoretical neurobiology and its center of theoretical neuroscience. He's also

05:32.580 --> 05:38.860
co-director of its neurobiology and behavior graduate program. He serves as vice chair

05:38.860 --> 05:43.660
of the department of neuroscience. He's the founding editor of the Journal of Computational

05:43.660 --> 05:52.300
Neuroscience, recipient of the Alfred P. Sloan research fellowship, Sol Scholars Award, Del

05:52.300 --> 06:01.820
Web Biology fellowship, National Science Foundation graduate fellowship and author of many articles.

06:01.820 --> 06:07.860
All of the people have books and you can see them after the meeting. George Reakey Jr.

06:07.860 --> 06:12.580
is associate professor with tenure and head of the laboratory of biological modeling at

06:12.580 --> 06:19.260
the Rockefeller University and the senior fellow of the Neuroscience Institute. He developed

06:19.260 --> 06:25.500
the first microprocessed processor controlled lab instruments, an x-ray camera and his Fourier

06:25.500 --> 06:32.780
synthesis software was used to solve many protein structures worldwide. Beginning in the 70s

06:32.780 --> 06:39.020
his interest has turned to problems of pattern recognition, perceptual categorization and

06:39.020 --> 06:44.460
motor control which he studies primarily through computer simulations of relevant neuronal

06:44.460 --> 06:55.100
systems. Xiao Zhing Wang, am I pronouncing it wrong? Is professor of neurobiology, a joint

06:55.100 --> 07:00.460
professor of physics, applied mathematics and psychology, director of the Schwartz program

07:00.460 --> 07:06.780
in theoretical neuroscience at the Yale University. He's a theoretical neuroscientist studying

07:06.780 --> 07:12.300
executive and cognitive function whose group has pioneered neural circuit models of the

07:12.300 --> 07:18.220
prefrontal cortex discovering a specific neural circuit mechanism for decision making.

07:22.540 --> 07:30.380
He's also studying I believe schizophrenia. Dr. Wang was a recipient of the Alfred

07:30.380 --> 07:36.300
Peace Loan Fellow, National Science Foundation Career Award and John Simon Guggenheim Memorial

07:36.300 --> 07:45.100
Foundation Fellow. Is that it? Okay. So that's it and we can get going.

07:45.100 --> 07:51.100
Thank you.

08:02.140 --> 08:08.220
Probably a very naive scientist point of view which I'm sure the philosophers will correct me but

08:08.220 --> 08:15.180
essentially the mind comes from the brain and the brain is part of the natural world and

08:15.180 --> 08:28.060
mathematics is developed in the study of physics of the trajectories of moving objects and how

08:28.700 --> 08:35.420
collections of objects and new properties emerge at a higher level. And in essence,

08:35.420 --> 08:41.100
studying the mind by studying the brain is no different. We're studying a physical system that

08:42.060 --> 08:48.780
has many, many levels, many interacting parts at each level leading to new phenomena at the

08:48.780 --> 08:53.420
next level and at the next from the molecules to the cells to the circuits and the circuit

08:53.420 --> 09:00.060
behavior to the ultimately to the animals behavior. And what we use math for is to

09:00.060 --> 09:09.180
understand how these interacting pieces produce the phenomena that we see. And in particular,

09:09.180 --> 09:14.060
I think one of the biggest things that we do is we're studying things at one level like we have a

09:14.060 --> 09:19.740
lot of cells connected with some circuitry and they have some functional responses. Say I study

09:19.740 --> 09:26.380
visual cortex and so as a visual image comes in the neurons have certain responses to the visual

09:26.380 --> 09:31.500
world which have been well studied. But how do those responses with all of their details and

09:31.500 --> 09:37.260
complexity emerge out of the circuit? One of the circuit motifs that the interactions between the

09:37.260 --> 09:44.620
cells that lead to this behavior emerging. And then so these multilevel one behavior at one level

09:44.620 --> 09:48.940
emerging from another level from interaction of many things at another level is sort of the essence

09:48.940 --> 09:54.620
of what we try to understand as we try to understand the brain. And ultimately, all the elements of

09:54.620 --> 10:02.940
our minds are things that we would like to identify as emergent properties of what neurons do in

10:02.940 --> 10:11.980
the same sense. And so mathematics is a tool of taking objects that you might say are blindly

10:11.980 --> 10:16.700
interacting. They're interacting according to some rules. The rules might have some intelligence,

10:16.700 --> 10:20.220
but they're interacting according to some rules and understanding what emerges out of them.

10:20.220 --> 10:28.220
And that's to the extent to which the mind is a emanation of the natural physical world.

10:28.220 --> 10:30.780
Mathematics is a way to understand what happens there.

10:30.780 --> 10:41.180
Could I go on from what you said because it's a perfect introduction? I'd like to make a distinction

10:41.180 --> 10:47.660
that I would like the audience to go home with between math as a tool for studying the brain,

10:47.660 --> 10:52.860
which involves both statistics, physics and chemistry, as you've pointed out,

10:52.860 --> 10:58.780
how we use computers to simulate what goes on with neurons, with ions in the brain,

10:58.780 --> 11:05.500
with blood flow and all of these things. And on the other hand, the question of whether

11:06.220 --> 11:12.460
mathematics should have a role in our theories about cognition and things at a higher level like

11:12.460 --> 11:18.140
the question of consciousness and free will and all these things where it's not so obvious that

11:18.140 --> 11:25.020
there's a connection. I think the place where a connection does come in and Ed Block knows

11:25.020 --> 11:31.500
something about this is the theory called functionalism, which says that the material that the brain

11:31.500 --> 11:37.740
is made out of really doesn't matter. It's the functions that the various parts carry out and

11:37.740 --> 11:45.740
how they interact with each other. And if we call that a kind of mathematics because to work out

11:45.740 --> 11:53.100
in detail what it implies does involve some mathematics, then I think one has to be very careful not

11:53.100 --> 12:01.500
to go too far. And what we see today is this metaphor, if you will, that the brain is a kind of computer.

12:01.500 --> 12:07.580
You know, it started out with the first electronic computers after the war, which were called

12:07.580 --> 12:13.980
electronic brains in the papers and magazines of that era. You still hear that phrase once in a while.

12:13.980 --> 12:19.820
And so we have a whole field where every paper you read now says this piece of cortex computes

12:19.820 --> 12:26.220
this and this does that. And I think exposed fact, you can't deny that. As signals come in,

12:26.220 --> 12:31.740
there are electric signals on neurons. They go into some areas, some stuff happens and other

12:31.740 --> 12:37.340
electrical signals come out and exposed fact, oh, that you can describe that as a computation.

12:37.340 --> 12:44.380
And but what that hides is how did it get to work that way? What part did evolution play on,

12:44.380 --> 12:49.740
especially on tajini, which I mean the development of the individual interacting with the world.

12:50.300 --> 12:55.820
And that's why some of us think it's important to work not just with totally abstract mathematical

12:55.820 --> 13:01.500
models, but things like robots actually moving around in the world and receiving visual input

13:01.500 --> 13:07.660
from cameras and trying to do something like an animal or a human would do in the real world.

13:07.660 --> 13:13.340
So I'll shut up now. I've taken enough time, but I just think it's very important to distinguish

13:13.340 --> 13:20.700
between those two kinds of areas where we use math as a theory and as a tool. And the consequences

13:20.700 --> 13:29.500
are different. So in the areas in which I work, the metaphor of the brain as a computer has faded.

13:31.020 --> 13:36.780
I think it's heyday was the 80s and maybe it's still every day in neuroscience journals.

13:36.780 --> 13:43.820
Okay, but here's the problem. One of the hallmarks of a computer is that there can be many ways of

13:43.820 --> 13:52.540
realizing of making the same computational structure. So it's commonly said in introductory books

13:52.540 --> 14:00.380
about computation that you can do a computation with using an electronic computer. You could do

14:00.380 --> 14:07.980
the same computation using something with wheels and pulleys and gears. You could make a hydraulic

14:07.980 --> 14:16.780
setup that uses the same computational principles, the same program at some level of abstraction,

14:16.780 --> 14:24.300
but does it completely differently. But the upshot of a lot of neuroscience is that it's not so easy

14:24.300 --> 14:30.700
to see how you could do the same computation differently. Multiple realizability seems to be

14:30.700 --> 14:37.660
fading away when we see the complexity of the electrochemical processes. So neurons influence

14:37.660 --> 14:46.060
other neurons by sending out chemicals. And those chemicals diffuse. And it's not clear that the

14:46.060 --> 14:53.740
computational pictures are the right way of describing that. I would agree with that to some extent.

14:53.740 --> 14:59.020
But the first, the guy right before that, I don't know who's speaking in anything,

14:59.020 --> 15:09.580
but at any given time. But the robots and external world and internal world, I mean, I don't see how

15:09.580 --> 15:17.500
that is the use of mathematics. Math is all those. And to address some recent point,

15:21.420 --> 15:26.380
he has a good point. The brain is a computer. In fact, if you go back, the brain has been many

15:26.380 --> 15:31.340
things. It was back in Aristotle's time. I think it was pumps and water and things like that.

15:33.500 --> 15:40.700
And more recently, I heard a talk that it was all done by quantum mechanics and things like that.

15:40.700 --> 15:46.380
So whatever the newest theory is, is what the brain is. And it always bugs me because I think

15:46.380 --> 15:55.980
the brain is what it is. And math is just a way, as Ken said, of taking lots of abstract boxes

15:55.980 --> 16:02.380
and arrows that experimentalists put together, at least to me, I'm a hardened reductionist.

16:03.740 --> 16:12.060
And it's just the way of taking boxes and arrows and using it to, it's sort of an existence proof

16:12.060 --> 16:20.540
that this is the right mechanism. So I'm too stupid to ask. But I'm a big fan of how.

16:20.540 --> 16:31.500
Let me just add a few things about what has been said. So, you know, I guess one reason that math

16:31.500 --> 16:38.300
is really important in neuroscience is that neuroscience is one of the fields in biology that

16:38.300 --> 16:44.540
are the most quantitative experimentally. So the neurophysiology, the measurements,

16:44.540 --> 16:51.100
the experiments are really quantitative, has had a very long tradition of very quantitative,

16:51.980 --> 16:57.660
you know, measurements and analysis. And that actually is important to bear in mind.

16:57.660 --> 17:03.580
And that's why we are capable of using mathematical models and theory in this field.

17:03.580 --> 17:16.300
And it's clear already, I guess, from what we heard that we don't really know how to conceptualize

17:16.300 --> 17:24.140
the brain. You know, we have all kinds of analogies. But suddenly, when you really compare brain

17:24.140 --> 17:29.820
with computer, they are just so dramatically different, right? So what computer is really

17:29.820 --> 17:36.940
great at, like making zillions of computations very quickly, we're not very good at it. What

17:36.940 --> 17:43.580
we are really wonderful at, like recognizing objects, recognizing a face in a crowd, in a fuzzy,

17:43.580 --> 17:49.260
you know, foggy kind of environment, computer is incapable of doing today's computer, right? So

17:49.260 --> 17:58.620
this is dramatically different, you know, dramatic differences between brain and computers, as we

17:58.620 --> 18:04.540
know today. But on the other hand, clearly, if not consciousness, we need to think about the

18:04.540 --> 18:10.860
computation. What kind of computations that brain does? So that's, you know, another way of thinking

18:10.860 --> 18:16.780
about the connection within the brain and the mathematics. I'm not sure the computation is going

18:16.780 --> 18:22.380
to turn out to be so important. You know, as a number of people mentioned, there are different

18:22.380 --> 18:27.100
levels of description. And computation would be important at one level, but not at another.

18:27.100 --> 18:37.180
A standard example of this is the explanation of why a rigid square peg doesn't go through a hole

18:37.180 --> 18:43.340
in a rigid board, which can be done on the basis of the rigidity of the materials and the geometry

18:43.340 --> 18:49.660
of the hole in the peg. So at that level, there really isn't anything that would be called

18:49.660 --> 18:54.860
computation. Of course, if you go to the elementary particle level, then you have a, you could get

18:54.860 --> 19:01.900
an explanation, which is computational, but which obscures the simple level of description. So it's

19:01.900 --> 19:07.900
not always clear. So I don't think you can, unless you trivialize the notion of computation by assuming

19:07.900 --> 19:17.340
that anything is a computation. So commonplace that you could regard a river as computing the

19:17.340 --> 19:25.420
rate of erosion of its banks by, as an analog model of itself, it's a computer that computes its own

19:25.420 --> 19:31.420
rate of erosion. So you can trivialize the notion of computation, but I don't think we can just assume

19:31.420 --> 19:37.900
our priori that the right way to think about the mind is going to be a computational level,

19:37.900 --> 19:44.540
a computational way at the most abstract level. That's fair. I guess you could say, so what's the

19:44.540 --> 19:53.020
alternative? I guess one alternative would be, what really matters is behavior and thought, maybe,

19:53.020 --> 20:00.940
mental life and our behavior, right? Can you describe those things without talking about the

20:00.940 --> 20:05.980
computation? Well, as the guy in the screen said, we're always using the latest technology

20:07.740 --> 20:13.580
to describe the mind. And there's a famous paper by neuroscientist John Marshall that goes into the

20:13.580 --> 20:21.820
history of this, and he mentioned a few cases, but at the time of the popularity of the catapult,

20:22.620 --> 20:29.580
people's theory of vision was that there's little catapults on objects that catapult a tiny

20:29.580 --> 20:33.900
simulacrum of the object into your eye. And then, of course, the famous

20:35.660 --> 20:41.740
telephone exchange model of the brain, or in the early days of the telephones. So the computer is a

20:41.740 --> 20:49.180
very notable artifact, and if you trivialize the notion of computation, we can describe everything

20:49.180 --> 20:55.500
as a computer. But that doesn't mean that we know now that computation is going to be important

20:56.700 --> 21:05.180
in describing, for example, consciousness. Well, I think, I mean, computer is a loaded word,

21:05.180 --> 21:11.180
because it means the things that we have on our desk. Clearly, they don't know anything like the

21:11.180 --> 21:19.180
brain does. But computation, I mean, I think the reason to use a word like that, I mean,

21:19.180 --> 21:24.780
maybe it's a matter of semantics and defining what we mean by it. But the hard,

21:26.060 --> 21:33.020
it's biological function, obviously, is to make sure that blood and nutrition gets to every cell

21:33.020 --> 21:39.340
in the body. And so it has to be a very good pump, and has to pump more and less under different

21:39.340 --> 21:46.460
circumstances. The brain is a piece of meat sitting inside my head, whose function is, in some way,

21:46.460 --> 21:53.500
to taking information about the sensory world and guide behavior toward the animals,

21:53.500 --> 21:57.420
you know, to hold the animals' goals and guide behavior toward those goals. And

22:00.460 --> 22:06.300
to me, computation means that you have to process information, and that's the job of the brain.

22:06.300 --> 22:11.980
And that's all that computation means to me. But it's very clearly, you know, it's not what the

22:11.980 --> 22:16.140
heart does, that's not what the liver does, that's what the brain is for, for processing the

22:16.140 --> 22:22.300
information coming in from the sensory world, and processing, you know, having built in sense of

22:22.300 --> 22:27.500
your, of the animals' goals, and working out the behaviors that are going to achieve those goals.

22:27.500 --> 22:31.500
That's a lot of information processing, and that's the reason for me for the word

22:31.500 --> 22:36.700
computation. It doesn't process the information anything like a computer does.

22:36.700 --> 22:45.900
It's a diffusion of a chemical, is that computation? It can be described

22:45.900 --> 22:50.780
computationally, but is that a computation? No, it's a diffusion of a chemical on the brain.

22:51.580 --> 22:56.700
So I don't see, you know, it just seems to me to be trivializing the issue to call that computation.

22:56.700 --> 23:04.860
Well, that's all the question. I mean, people, Stephen Wolfram called his cellular automata

23:05.500 --> 23:13.180
computation. And you know, I think we're getting hung up on semantics here. And I do want to say

23:13.180 --> 23:18.620
that the metaphor of a computer or computation is going to be really careful because when we do

23:18.620 --> 23:25.100
a computation on our computer, if we type the same thing, we get the same response every time.

23:25.100 --> 23:31.420
And the really cool thing about the brain is the fact that you don't. And that turns out to be

23:31.420 --> 23:36.700
really important, right? Because if you get the same thing every time, then you can't learn. You

23:36.700 --> 23:43.820
can't change. You can't adapt. And that's one real difference, I think, of the metaphor of a computer

23:44.380 --> 23:50.620
and a real brain is that it, you know, you don't get the same thing every time you do something.

23:50.620 --> 23:57.020
Yeah. What I want to add to what Ken said, and it fits right with what you said, is I have a slogan,

23:57.020 --> 24:02.540
the function of the brain is not to process information. It is to create information. And

24:02.540 --> 24:09.500
there's a distinction really trying to draw it between a process in the sense of an algorithm or

24:09.500 --> 24:15.420
a pre-planned design where you, you know, perform operations on numerical quantities and get some

24:15.420 --> 24:23.260
result. But it's this renewal, this learning, this initialization, if you will, of the infant who

24:23.260 --> 24:29.260
comes into the world not doing any of these things and somehow figures out not because a programmer

24:29.260 --> 24:34.540
comes in and tweaks some neurons around to make it work right, but just by having experience in

24:34.540 --> 24:41.900
the world. And that's what the industrial, what I say, the desktop computer doesn't have. And as

24:41.900 --> 24:47.340
long as we understand that, then we're fine to say, as Ken does, you know, the visual cortex,

24:48.220 --> 24:52.620
you know, computes edges and that sort of thing. Sure. I don't know what it computes. I think

24:52.620 --> 24:56.940
we're very naive about what it computes, but it's clearly taking in the visual world and ultimately

24:56.940 --> 25:02.540
leading us to open our eyes and see people and chairs and lights and to see objects and their

25:02.540 --> 25:07.660
relationships and to know a lot about them. But exactly what it does, computes to do that,

25:07.660 --> 25:16.300
I don't think we really know. I guess I would just add that, you know, it's true that when you ask

25:17.580 --> 25:23.180
ourselves, so ask people, you know, in daily lives, you think, you know, I don't really always

25:23.180 --> 25:27.740
think in terms of computation, I think, you know, what's my goal? What I need to do today? So in that

25:27.740 --> 25:33.020
sense, you start with a goal, you make decisions in order to achieve your goal and you seek

25:33.020 --> 25:39.820
actively information from the environment. And sometimes you have to process, you know,

25:39.820 --> 25:45.660
information forced on you, but there is active process that the main thing is to try to achieve

25:45.660 --> 25:50.860
your goals, right, the behavior goals. So in that sense, it's not, you know, it's different from

25:50.860 --> 25:56.860
the suddenly, very different from information processing from the computer perspective.

25:56.860 --> 26:04.060
And it's also always trying to predict, I mean, you get partial information and you anticipate,

26:04.060 --> 26:12.700
nobody, you know, you watch somebody to ball and they're automatically, nobody is born with

26:12.700 --> 26:19.420
Newton's in there, but you figure out how to do this because you're trying to predict trajectories

26:20.300 --> 26:24.460
and you're predicting what somebody's going to say. There's all kinds of cool psychophysics

26:24.460 --> 26:29.500
experiments that can exploit this. And that's another thing a computer really doesn't do very well

26:30.780 --> 26:37.820
is sort of extrapolate to the future because we have to do that to interact with the real world.

26:43.100 --> 26:47.500
So one, in terms of the question of the role of mathematics, I'd like to just, you know,

26:47.500 --> 26:56.380
return to the idea of, yeah, but to the idea of emergence because I think, I mean, for me, you

26:56.380 --> 27:03.740
know, where theory plays and theory is basically building models which are mathematical and computer

27:03.740 --> 27:10.060
models to try to put together the pieces to figure out how they explain phenomena. And so it's,

27:10.060 --> 27:18.300
when I say theory, you could substitute math if you like. And what the role of theory, the

27:18.300 --> 27:26.140
biggest role in trying to understand the brain has to do with this idea of properties emerging

27:26.140 --> 27:35.020
at one level out of the complexity at another level. I mean, physics has pioneered some thinking

27:35.020 --> 27:41.580
about that kind of problem in terms of, you know, understanding how you take a lot of molecules

27:41.580 --> 27:46.940
and they end up having properties of being liquid and having a certain volume and a pressure. And

27:47.500 --> 27:53.980
so how the interactions at one level lead to these at a very different level, these qualities,

27:53.980 --> 27:57.980
like being liquid and being viscous that, you know, in terms of molecule, I would have no meaning,

27:57.980 --> 28:04.940
but it emerges out of the interaction of many, many molecules. But the apparatus that physics

28:04.940 --> 28:12.700
developed is pretty specialized in those situations. And the brain is just unbelievably more complex,

28:12.700 --> 28:19.180
of course. But always what we're, you know, where we really, where theory really gives you insight

28:19.180 --> 28:23.980
is when you know a lot of things at one level and you know a lot of things at the next level.

28:23.980 --> 28:28.540
You know, you know how these neurons respond to this situation and you know something about what

28:28.540 --> 28:34.460
the neurons are made of and how they're connected to each other. But you have no idea how you get

28:34.460 --> 28:40.140
from here to there. And you try to put them together in terms of what you know, you know,

28:40.140 --> 28:48.460
you have some ideas and you find suddenly a principle, say, of how a circuit can be organized so that

28:48.460 --> 28:54.140
these properties, these actual responses to the world up here will emerge from these neurons down

28:54.140 --> 29:04.780
here. But again and again at every level, it's that process of new phenomena emerging out of the

29:04.780 --> 29:11.180
interactions of complex interaction to many things at a completely different level. That's,

29:11.980 --> 29:17.340
I think, the most striking point where math is absolutely critical. You can't believe that.

29:17.340 --> 29:22.940
And the best example of that is one of the, I mean one of the best examples is the first example

29:22.940 --> 29:30.380
of that, the Hodgkin-Hosley theory, which basically took a hypothesis about channels and gates and

29:30.380 --> 29:36.220
used that equations down very simply just four differential equations and were able to completely

29:36.220 --> 29:41.100
explain the action potential of the squid. That was the first real example of mathematics

29:41.740 --> 29:46.700
doing something very specific. And you know, I think things have continued on like that.

29:46.700 --> 29:53.020
I think that's exactly what, you know, it's what Ken said to you, how do you take pieces of stuff

29:53.020 --> 29:58.540
and get emergency properties? The only way you can do that is with theory, and the only way you

29:58.540 --> 30:03.100
can do that is, and the only way you can do that kind of theory is with mathematics. And that's a

30:03.100 --> 30:10.220
big difference between neuroscience and, say, physics is every physics experiment is driven by theory.

30:10.220 --> 30:18.620
And neuroscience experiments almost are ever driven by theory. And it's just kind of an immature

30:18.620 --> 30:29.340
science so far, I think. I disagree that neuroscience isn't driven by theory. Certainly in the visual

30:29.340 --> 30:35.180
system, most of our, at least a great deal of what we know was derived from the psychology of the

30:35.180 --> 30:40.620
visual system that was discovered before we knew the neuroscience of it. You know, the three kinds

30:40.620 --> 30:48.220
of cones, the opponent process system, that was all discovered by visual psychologists.

30:48.220 --> 30:53.260
Well, before we understood the neural underpants. And Gestalt psychologists who contributed

30:53.260 --> 30:59.580
at things about what salient in a visual scene and so forth. But it's, but,

30:59.580 --> 31:04.940
well, I just push it experiment. I'm just making a kind of hard case there. I don't complete, I agree

31:04.940 --> 31:12.380
with you guys. It is just not, you know, not completely. But maybe, I guess one way Ken and

31:12.380 --> 31:22.460
Bard articulated is to understand how you explain behavior at some level in terms of the interactions

31:22.460 --> 31:30.140
and dynamics at the level below underneath it. So, in a way, I guess my PhD, otherwise, I used to say

31:30.140 --> 31:36.700
the world is like onion. There are many layers. And really, you can satisfaction the scientist

31:36.700 --> 31:41.020
by be able to explain something in terms of what's more fundamental maybe underneath it.

31:41.980 --> 31:47.100
There's another aspect of it that's really experienced why mathematics is really important

31:47.100 --> 31:54.620
for neuroscience. That is, the nerve system has a lot of feedback loops. And there's positive

31:54.620 --> 32:00.860
feedback loops. So this neuron excites the other neuron that excites back this neuron. Or there's

32:00.860 --> 32:06.780
inhibitory, you know, negative feedback loops. Like any, you know, system with a lot of feedback

32:06.780 --> 32:12.060
loops, it's very hard to predict what's going to have when you do something, right, somewhere.

32:12.060 --> 32:21.180
So, I guess one example I like to give is, you know, this day people talk about connectivity,

32:21.180 --> 32:29.180
right? And so if you know connectivity, the connectome among genes or neurons, it's very

32:29.180 --> 32:34.540
important information. You really learn a lot by knowing the anatomy and connectivity. But the

32:34.540 --> 32:40.140
example I'm going to give you illustrates why that's not enough to predict behavior.

32:40.140 --> 32:46.460
Okay, imagine I give you a circuit with just two neurons that we know inhibit to each other. Okay,

32:46.460 --> 32:52.140
neuron one, if it's neuron two, and neuron two, if it's neuron one, what are going to predict?

32:52.700 --> 32:58.940
What's going to be the behavior to begin? Well, for a very long time, people think the behavior

32:58.940 --> 33:05.500
would be half center oscillator. So neuron one is up, suppress the neuron two, and then for some reason

33:05.500 --> 33:12.220
they go, this one goes up, the one goes down. Okay, that's the motif for generating movements.

33:12.220 --> 33:19.100
So if you walk left, right, left, right. Okay, so that's the circuit to get this kind of pattern,

33:19.100 --> 33:24.220
generation. But it turns out that when you really analyze the dynamics of this kind of circuit,

33:24.220 --> 33:31.260
you can have some other way of behavior. You could have, for example, neuron one being up all the time,

33:31.260 --> 33:36.380
and always surprising neuron two. So you have a switch. Okay, you give a little kick for neural

33:36.380 --> 33:41.340
two, that switch is a neural one up, a neural two up, and suppresses neural one. So that,

33:41.340 --> 33:46.300
you know, gives you a mechanism to build a switch. Does that make sense? And it turns out that

33:46.300 --> 33:52.300
surprisingly, in fact, under some conditions, even if those two neurons inhibit each other,

33:52.300 --> 33:57.660
sometimes they are completely in sync. So they go up together, they go down together,

33:57.660 --> 34:06.140
right? And this is a very complicated, intuitive kind of behavior of perfect synchrony by mutual

34:06.140 --> 34:13.500
inhibition. It turns out to be, you know, actually happening in real life in the brain. And this is

34:13.500 --> 34:20.060
the mechanism now, one of the mechanisms at least, for explaining brain waves, that we all see,

34:20.060 --> 34:24.940
you know, when you do EEG measurements, for example. This is, I think, a very, very interesting

34:24.940 --> 34:32.060
example, we're only by looking at the dynamics with the help of math, we can really figure out

34:32.060 --> 34:36.700
what's possible in this kind of system with feedback loops. And actually, let me just

34:36.700 --> 34:43.100
build on that, because say in that case, you know, the idea of them working together is essentially,

34:43.900 --> 34:47.980
they both fire, they both suppress each other, and then they both recover together, and then

34:47.980 --> 34:51.580
they're active, they both fire, they both suppress each other. So it gives you a new intuition.

34:51.580 --> 34:56.620
You study the math, maybe you hadn't thought of that before, but you've got down the equation,

34:56.620 --> 35:00.380
you study them, and you discover this other regime where things are going together instead

35:00.380 --> 35:04.940
of opposite, which is all you really thought of. And then once the math has shown you this new

35:04.940 --> 35:11.420
regime, now I can explain it to you without any equations. So the math often acts like a scaffolding,

35:12.860 --> 35:18.860
out of which we could, you know, that we use to gain an intuitive understanding that we can

35:18.860 --> 35:22.620
then express without the math. And that's, at least when I really feel like I understand something.

35:23.340 --> 35:30.700
But the math is incredibly rich. I mean, the full details are in there, but as you study it,

35:30.700 --> 35:34.940
and you start to see it behave in ways you didn't expect, and then you start to try to work out

35:34.940 --> 35:39.260
why exactly is it doing that, you ultimately come up with a story you can tell. And when you can

35:39.260 --> 35:44.140
tell yourself a story that explains it, which is a new intuition that you didn't have before,

35:44.140 --> 35:50.380
but you discovered it by working on the math and figuring out why it's doing what it's doing.

35:52.220 --> 35:55.580
That's the scaffolding of math leading to the intuitive understanding.

35:56.300 --> 36:02.060
So are you saying that it's not that you have an intuition, and then the math can explain it?

36:02.060 --> 36:05.900
But you are saying that the math itself creates the intuition.

36:05.900 --> 36:10.860
Elite, by banging on the math and the behaviors that you don't understand and figuring out why

36:10.860 --> 36:14.300
they're doing what they're doing. You're getting new intuitions, yeah.

36:14.300 --> 36:20.700
One thing to be important in this is that the correct math at one level may be quite different

36:20.700 --> 36:25.580
from the correct math at another level. And the example of the computer is a good case.

36:26.140 --> 36:31.740
So the computer operates by these binary elements, but of course at a deeper level,

36:31.740 --> 36:39.580
they're not binary at all. They fluctuate fluctuations of voltage, but at the computational level,

36:39.580 --> 36:43.500
we have to think of them as binary in order to understand the computation.

36:46.620 --> 36:52.220
So if I understand correctly, I mean, math has always had a place in neurophysiology,

36:52.220 --> 36:57.500
because when you talk about electric currents and voltages and so on, so you always had

36:58.220 --> 37:06.460
a kind of high school math or college math when I went to medical school, that was there.

37:06.460 --> 37:15.100
But what you are saying is that what we are doing is not just understanding what happens, let's say,

37:16.540 --> 37:22.140
when a current goes along a nerve, how can we explain it physically and mathematically?

37:22.140 --> 37:28.620
But that mathematical ideas allow us to understand things that without them, we couldn't even imagine

37:28.620 --> 37:33.980
or dare. Absolutely. Yep, yep, yep. Yeah, like, you know,

37:33.980 --> 37:42.220
if you press your hand and press your hand and you'll start to see little flashlight

37:43.340 --> 37:49.260
for a while, you'll start to see geometric patterns like checkerboards flashing and things like that.

37:49.260 --> 37:58.060
So why? What is going on there? And it's not obvious that this is all probably in the visual

37:58.060 --> 38:04.380
cortex, but what's the mechanism? And math kind of gives you this umbrella. And for example, the

38:04.380 --> 38:11.260
example that Aozhing gave of two mutually inhibitory neurons, one guy making one guy a switch,

38:11.260 --> 38:16.940
okay? That's a switch and it's completely symmetric. One guy can be up, the other guy can be up.

38:16.940 --> 38:23.260
Okay, that's an example, the simplest example of what we'll call spontaneous pattern formation.

38:23.260 --> 38:30.380
And what math does is give you this sort of broad brush in which to explain lots and lots of patterns

38:30.380 --> 38:36.060
that you see. For example, Ken has done lots of work on things called ocular dominance patterns

38:36.060 --> 38:44.060
in the visual cortex. And it's all based and I've done stuff on the phosphor. I just told you

38:44.060 --> 38:50.700
about the flicker and pressing your eyeballs. And they all work with the same basic principle of,

38:50.700 --> 38:57.580
I guess we call it, he can hat that there's excitation or also we could call it Reaganomics,

38:57.580 --> 39:03.020
where you help the guy that help your buddies and then you inhibit everybody else.

39:08.540 --> 39:13.340
But it's called lapping ambition. I forgot to say that. You know, that's a,

39:13.340 --> 39:20.140
it's been known from a horseshoe crab and all the way up and it pretty much can do,

39:21.100 --> 39:26.060
you know, it's a very straightforward concept, but it allows you to explain

39:26.060 --> 39:31.820
so many things. And it's all under sort of a, there's a very broad mathematical theory that

39:31.820 --> 39:45.340
delivers all these cases. Well, are you Dunbar? Yeah, yeah, I'm sorry. I'm thinking back

39:45.340 --> 39:50.380
something Ned said way back at the beginning about different multiple solutions to the same problem.

39:50.380 --> 39:55.740
And just looking at the math alone and never mind the neuroscience, we find that

39:55.740 --> 40:02.460
there are different kinds of math we can use to apply to a neural system or a neural network,

40:02.460 --> 40:08.140
if I'll use that word. And so we find in our field that sometimes people get stuck in one or

40:08.140 --> 40:13.180
another of these and maybe a conversation like this can help. What I'm thinking of is,

40:13.900 --> 40:20.300
I edited a book where some authors, with a lot of different subjects, but there were authors in

40:20.300 --> 40:24.620
there who felt that most of them neural modeling that people are doing today is all wrong,

40:24.620 --> 40:31.580
because it divides neurons up into little pieces called compartmental models where you say

40:31.580 --> 40:35.500
everything that's going on in this little bit is the same and then it's hooked to another little

40:35.500 --> 40:41.340
bit by a resistor. And that simplifies the computation. But that's not really right because the

40:41.340 --> 40:47.740
voltage along the membrane changes in a continuous manner. And so you really should use differential

40:47.740 --> 40:54.220
equations. And so what you end up is pages and pages of so-called Green's function solutions and

40:54.220 --> 40:59.580
things in the most complicated system, these guys have been able to work out is two neurons

40:59.580 --> 41:03.820
talking to each other. And you get a lot of insight from that. And you get a lot of insight

41:03.820 --> 41:09.660
from understanding how the diameter of the cable as it changes as you get farther away from the cell

41:09.660 --> 41:15.580
body affects how the voltage is changing. And you can go on like that and spend a whole career

41:15.580 --> 41:20.860
doing that. And meanwhile, you haven't gone to the next level up as Ken and many of us are interested

41:20.860 --> 41:27.420
in. So it behooves all of us who are in this field, I think, to be aware of these different levels

41:27.420 --> 41:33.980
and be willing to move up and down among them as befits the particular problem of interest.

41:34.780 --> 41:40.140
Maybe what I said is super obvious. I'm glad to pick up on that.

41:43.180 --> 41:47.740
One thing that I think maybe is maybe surprising to people, not in the field, is that

41:47.740 --> 41:58.060
it's not the case that you put every detail into your model. If you do, you're all is lost. You don't

41:58.060 --> 42:10.220
have any help at all. Because there's a couple of reasons. One is that there's many, many, many

42:10.220 --> 42:16.540
details. Exactly what kinds of channels do you have in the membrane and what are the physical

42:16.540 --> 42:21.020
properties of each of these channels? How do they respond in which way? What's their density?

42:21.900 --> 42:25.900
And on and on and on? How exactly do your dendrites spread out in space?

42:26.860 --> 42:32.860
Most of those details, we don't really know. We know that there are such things and that they

42:32.860 --> 42:39.660
have some structure and we have maybe some range in which they all live. But so the more of these

42:39.660 --> 42:46.700
details you put in, the more unconstrained by data, unconstrained by data freedom you put into your

42:46.700 --> 42:52.060
model. The more unconstrained by data complexity you put into your model. And if your model then

42:52.060 --> 42:56.140
goes and does something, how are you going to figure out why it does it when there's so many

42:56.140 --> 43:03.100
unconstrained details? And so part of the real art of modeling is the art of simplification.

43:03.100 --> 43:10.380
The art of knowing what are the key relationships that I want to model and then I want to understand

43:10.380 --> 43:17.260
what emergency. And I'm going to throw all the rest away to simplify, to just understand what

43:17.260 --> 43:23.820
do these dynamics of these simple entities that I'm going to model lead to and can I identify that?

43:23.820 --> 43:29.740
Can I then understand what's going on in the brain with this simplification and then in some

43:29.740 --> 43:35.180
way that's testable. This simple structure leads to all this stuff and it also should lead to

43:35.180 --> 43:43.420
this other stuff people haven't looked at. So let's go and measure that. Somebody, I think what

43:43.420 --> 43:47.580
Edan Segev is another theoretical neuroscientist and I think maybe he was quoting Picasso. I've

43:47.580 --> 43:52.940
kind of lost track of the quotes but they talked about modeling as the lie that reveals the truth.

43:53.580 --> 43:58.460
Because you start out with a lie. You start out with a simple question. You have to. And there's

43:58.460 --> 44:05.020
actually a big to do in the field right now. There's something called the Blue Brain Project

44:05.580 --> 44:12.060
of Henry Markham and Switzerland where his claim and belief is that he's going to put every detail

44:12.060 --> 44:16.140
into the computer and now it is going to merge the brain and then we're going to understand the brain.

44:16.780 --> 44:23.340
And I have to say every theoretical neuroscientist, I know thinks that is nuts, including myself.

44:23.340 --> 44:30.460
Because something will happen. God knows why. God knows what it depends on. God knows which

44:30.460 --> 44:36.220
detail was important and which wasn't. Maybe you can maneuver it to do things like the brain.

44:36.220 --> 44:41.660
Maybe you can't. I mean at the moment they have some very basic behavior, things exciting and

44:41.660 --> 44:46.620
inhibit other things. I mean nothing very specific unless they see we replicated the brain. But when

44:46.620 --> 44:53.340
you throw in every detail, I mean the essence of understanding that when we build this scaffold

44:53.340 --> 44:59.820
and then eventually I can tell you a story, that story can't have a billion moving parts in it.

44:59.820 --> 45:05.980
Because our brains can't handle it. And so we don't understand it. Now if we knew what those

45:05.980 --> 45:12.060
billion moving parts were down to the physical details, then like physicists where they do know

45:12.060 --> 45:16.860
those billion moving parts in real detail, they can just put it in the computer and see what it does

45:16.860 --> 45:20.780
because they really have control over all of that complexity from the data. But we don't.

45:21.740 --> 45:25.500
And so we have to simplify and we have to come to

45:28.140 --> 45:32.620
stories of how some interaction at one level leads to an interaction at another level. So that I

45:32.620 --> 45:38.300
do models where very often, sometimes I use more complicated models but very often I use models

45:38.300 --> 45:45.100
where I take a neuron which is a spatially extended object with dendrites that are extending over

45:45.100 --> 45:49.740
hundreds of microns that are communicating with each other in complicated ways, receiving all

45:49.740 --> 45:55.420
kinds of inputs at different places and integrating that input in complicated ways. And I describe it

45:55.420 --> 46:01.100
as a point neuron that just takes a lot of input, sums them, does a certain unlinearity to them.

46:01.100 --> 46:06.780
But then I study how these interactions, who's connected to who, the circuitry among these point

46:06.780 --> 46:13.180
neurons, what behavior that leads to. And lo and behold, you discover things that tell you a lot,

46:13.740 --> 46:19.180
give you new insight into how the brain works. Now we've thrown away a lot of detail of integration

46:19.180 --> 46:23.740
and that worries me. Maybe those details of integration when we put them in are going to

46:23.740 --> 46:29.260
radically change things. But the fact that you come up with an insight that unifies an awful lot

46:29.260 --> 46:34.620
of behavior in a simple way and it's testable and the test bear out, that gives me a lot of confidence,

46:34.620 --> 46:38.860
although not a certainty, that all those details are not going to overturn what I've learned by

46:38.860 --> 46:47.420
studying things at this level. Well, so you learned both by what you can explain and what you can't.

46:47.420 --> 46:51.420
So you can't explain something. It shows that the detail was important. Well, I know, because you

46:51.420 --> 46:55.020
don't know, maybe you just missed it, right? You know, you don't know why you can't, you know,

46:55.020 --> 47:00.540
negative results. When you can, then you've really got your hands on something. It's hard to get

47:00.540 --> 47:06.860
non-existent proof in these things. Yeah. The other thing I think this is building what Ken said is,

47:08.060 --> 47:12.620
you know, you start with something simple and you see what it does, a port neuron or whatever,

47:12.620 --> 47:18.220
and then you use that to build up your model. I think I want to point the other side of the

47:18.220 --> 47:23.420
coin. We've been talking a lot about what mathematics can do for neuroscience, but the other thing is

47:23.420 --> 47:27.660
what can neuroscience do for mathematics? And, you know, there's one of these big questions,

47:27.660 --> 47:34.540
or one question that many of us are very interested in is if you've got many, many detailed models

47:34.540 --> 47:43.580
of neurons hooked together, is there a principled way you like a simplified model out of that? And

47:43.580 --> 47:49.420
people call this trying to derive a mean feeling from some sort of spiking neurons.

47:49.420 --> 47:56.060
Now, Jing has done a lot of this. I've done some of this. I don't know about the other guys Ken might

47:56.060 --> 48:03.580
have, but I get that this requires new mathematics as well and difficult mathematics because there's

48:03.580 --> 48:14.620
noise and stochasticity and things like that. So I think, you know, there's this great positive

48:14.620 --> 48:19.740
feedback that neuroscience math and a lot of nice mathematics has come out of trying to answer some,

48:19.740 --> 48:27.740
even some of the simplest neuroscience questions. We only heard about every other word of

48:29.340 --> 48:36.220
Oh, yeah, it's cutting out a lot. Oh, well, you want to? Yeah, seems to be bad, right?

48:36.860 --> 48:40.060
I don't know what's the matter. Is it my connection?

48:41.420 --> 48:44.300
Who knows? We don't know. Okay.

48:44.300 --> 48:50.940
You will go into power. I mean, I'm hearing enough that I can make sense of it, but maybe it's

48:50.940 --> 48:59.180
because I know I know some of the words are being left out. Maybe it's just we'll recap a little

48:59.180 --> 49:05.420
bit what Bartle is saying. Basically, he's saying that, you know, I guess, rephrasing it, you could

49:05.420 --> 49:12.620
say, you know, in the past or even today, physics is really a major source of mathematics, right?

49:12.620 --> 49:19.820
A lot of physics problems, you know, particle physics, especially, for example, has led to

49:20.380 --> 49:26.460
many new branches in math. And maybe today, biological sciences, especially neuroscience,

49:27.260 --> 49:35.980
in fact, is going to provide a new source for, you know, problems and maybe ideas that will

49:35.980 --> 49:41.100
inspire new math. So one of the specific examples Bartle mentioned is the so-called

49:41.100 --> 49:48.460
the mean field theory. How do you go from most biologically based action potential kind of

49:48.460 --> 49:56.140
neural models and neural network models to population description, okay? Where you say, you know,

49:56.140 --> 50:01.740
for each little group of neurons, you know, they all within this group, all the neurons are more

50:01.740 --> 50:08.380
less doing the same thing. What I really care about is the dynamics of the activity, the overall

50:08.380 --> 50:15.820
population activity of this neural group. So can I find a mathematical way, mathematical way,

50:15.820 --> 50:21.500
to derive, you know, mobile, physically based, spiking neural model to a population description?

50:21.500 --> 50:26.380
That's one example. And that's what I said. Yeah. Really?

50:28.060 --> 50:32.460
Essentially, I guess I just add it's really true. People actually feel like

50:32.460 --> 50:39.580
that today there is going to be really a lot of interesting questions in part from neuroscience

50:39.580 --> 50:44.540
that's going to inspire new math. So for example, not just neuroscience, of course. I guess I

50:44.540 --> 50:50.620
would just mention one example is, you know, the kind of dynamics that really deviate in very,

50:50.620 --> 50:55.580
very high dimensional space. Okay. So if you think about, you know, really the nerve system

50:56.220 --> 51:00.860
described it in certain ways, you basically need the zinnians of variables, zinnians of

51:00.860 --> 51:06.220
activity variables for neurons on neural populations. So you have to describe the dynamics in a very

51:06.220 --> 51:12.140
high dimensional space. And you know, the math of dynamics in very high dimensional space is

51:12.140 --> 51:18.700
true in neuroscience, and maybe true in some other scientific branches, given the data we now have

51:18.700 --> 51:25.580
today. So, and I think that's one of the examples where, you know, the science, including neuroscience,

51:25.580 --> 51:32.220
drives mass. Yeah. I can give another example that I just ran into on a thesis committee of a

51:32.220 --> 51:39.180
physics student at Rockefeller named Bo Tei Fumei, who was interested when he comes down to the

51:39.180 --> 51:44.380
random walk problem, but expressed in terms of a neuron, you have a neuron, some noise sources,

51:44.380 --> 51:49.260
the membrane potential is fluctuating around. And the question you'd like to ask is,

51:49.260 --> 51:54.460
how long do you expect it will be before one of those fluctuations goes over threshold and the

51:54.460 --> 52:01.820
neuron fires? And so if you look at the fluctuations as what was called a random walk in other areas

52:01.820 --> 52:08.060
of biology or chemistry, you know, this is a problem where a lot of work has been done, but he was able

52:08.060 --> 52:13.260
by looking at it from the point of view of a neuroscience problem to produce some new mathematics

52:13.260 --> 52:17.660
that adds to that whole body of work. So there's another, just an example.

52:17.660 --> 52:30.780
I think a very beautiful example of making some new math is some work done by Fred Wolfen,

52:30.780 --> 52:39.020
his group in Germany that was recently published in Science, where without, they're trying to

52:39.020 --> 52:45.420
understand certain patterns that form in the arrangement of the neurons in the visual cortex of what

52:45.420 --> 52:51.980
neurons have been, the primary visual cortex are responsive to light dark edges of a certain

52:51.980 --> 52:57.180
orientation, and they care very much about the orientation. Change the orientation of 20 or 30

52:57.180 --> 53:04.140
degrees, they may stop responding. And the what orientation they prefer is laid out in a way that

53:04.140 --> 53:08.780
sort of rotates periodically as you move across the cortex so that all the orientations are

53:08.780 --> 53:17.820
being represented. But it's laid out in a particular kind of pattern, and Fred, so in physics,

53:17.820 --> 53:23.980
there's quite a lot of literature on pattern formation, on how, you know, interactions among

53:23.980 --> 53:30.620
chemicals may lead to some kind of stripy behavior and so forth, to some pattern emerging. And there's

53:30.620 --> 53:40.380
a very established literature of how you can go about analyzing those processes. Those have always

53:40.380 --> 53:46.460
dealt with real value variables, though, so I don't know if you all know about real numbers and

53:46.460 --> 53:52.700
complex numbers, complex numbers, important part of mathematics, but in the pattern formation

53:52.700 --> 53:56.780
literature, just because these are physical variables, these have all been real value variables that

53:56.780 --> 54:02.300
are organizing into patterns. It turns out that the proper description of these patterns, you need

54:02.300 --> 54:10.700
to use complex value variables, and that required Fred to really revise or extend the existing

54:13.100 --> 54:18.940
methodology on pattern formation into that case, and then, and he also had to bring another extension

54:18.940 --> 54:24.220
to it, which is in physics, all of the interactions are local. Things just talk to their neighbors.

54:24.220 --> 54:28.140
They're not able to talk to somebody way over here directly, because there's no long-range

54:28.140 --> 54:33.180
connections between molecules, say, but in among neurons, there are long-range connections,

54:33.180 --> 54:36.780
and so he had to bring in the role of long-range connections as well into how this influences

54:36.780 --> 54:44.700
pattern formation, and the, the upshot is, I mean, he spent 10 or 15 years developing this theory

54:44.700 --> 54:54.460
layer by layer by layer by layer, and the great triumph was he was able to predict that the structure

54:55.340 --> 55:02.940
of these maps, it should have a certain signature, which is the density of, of points where all

55:02.940 --> 55:08.700
orientations meet, which are called pinwheels, or singularities, and that that density in the

55:08.700 --> 55:17.260
right unit should be the number pi, and they went, and they measured it, and some people had measured,

55:17.260 --> 55:22.140
and to do that, they had to develop new quantitative methods of measuring the density of pinwheels,

55:22.140 --> 55:26.460
because there's always a lot of noise, and it depends on how you filter things, and they had to find

55:26.460 --> 55:31.260
ways of filtering out the noise that didn't filter out the signal, which people, people hadn't had

55:31.260 --> 55:35.260
good ways of measuring pinwheel density before, so they developed new mathematics for that,

55:35.260 --> 55:43.020
and people had studied maybe a few maps at a time, but they studied 100 maps with 10,000

55:43.020 --> 55:47.500
singularities in order to get good enough statistics, and they found that the density was pi to

55:47.500 --> 55:55.020
within plus or minus 2%, meaning that, and what, what that meant for us, in terms of the physics of it,

55:55.020 --> 56:01.260
or in terms of what happened, how do these patterns emerge, is basically this number pi, this organization

56:01.260 --> 56:06.220
that's characterized by this, this number pi, emerges very naturally out of self-organization,

56:06.220 --> 56:12.060
meaning it's not, every cell isn't told by genetics what orientation to develop,

56:12.060 --> 56:17.180
rather they develop by interacting with one another, maybe they excite their neighbors, and they may

56:17.180 --> 56:22.300
have some long range suppression, and so they're developing through interaction, and this self-organization

56:22.300 --> 56:27.580
among all these moving parts leads to this pattern, and the fact that he was able to show that you

56:27.580 --> 56:31.500
get this very robust prediction of pi under that scenario, and then he wouldn't measure it,

56:31.500 --> 56:37.020
and that's what was there, and it was there across three different species that are separated by

56:37.020 --> 56:42.780
hundreds of millions of years in evolution, and in fact, separated so far that the common ancestor

56:42.780 --> 56:47.980
had such a tiny visual cortex that it probably didn't have these patterns at all, meaning that it had

56:47.980 --> 56:54.300
to evolve, that this pi pattern had to evolve twice independently, well that would happen naturally

56:54.300 --> 56:59.100
if it's just, if it happens by the self-organization process, if you think it's genetically specified,

56:59.100 --> 57:03.260
that would be very hard to explain, so I think this was a huge triumph, and it was advanced in the

57:03.260 --> 57:09.660
math and advanced in our understanding of the biology. An argument that the pinwheel structure isn't

57:10.940 --> 57:17.420
genetically determined, at least not in any simple way, is McGonker serves ferrets where he was able

57:17.420 --> 57:24.060
to set up something where they use their auditory cortex to perceive visually, able to rewire

57:24.060 --> 57:29.900
the ferrets at a very early age, they also show that auditory cortex shows that pinwheel structure.

57:29.900 --> 57:35.580
Although actually, it does show pinwheels, but I don't think it's that characteristic structure

57:35.580 --> 57:38.460
that Fred has identified. So I think it's a different pinwheels.

57:38.460 --> 57:44.220
Yeah, I think it's a lot, I think it's different, I'm not actually certain of that, but I think it's

57:44.220 --> 57:55.740
different. Well, we seem to be at a dead moment, so I'll just change the subject slightly and say

57:56.940 --> 58:05.020
there's still plenty of room for new progress in this whole field and the diffusion of molecules,

58:05.020 --> 58:11.980
as I mentioned a couple of times. I just want to say, I suggested in a book chapter some time ago

58:11.980 --> 58:18.540
that in studying the brain we needed to combine not just what neurons are doing, but what molecules

58:18.540 --> 58:25.900
are doing it and propose using a kind of finite element modeling, which is what engineers do who

58:25.900 --> 58:31.580
build skyscrapers and bridges, looking at the physics of how little blocks of matter interact

58:31.580 --> 58:37.340
under pressure. And this was rejected by referees as being ridiculous, although I thought it might

58:37.340 --> 58:41.580
have something to do, for example, with studying tumors in the brain and how a tumor might press

58:41.580 --> 58:47.980
on another part of the brain and cause something not to function because pressure might be changing

58:48.620 --> 58:55.820
the activity of channels or something. But I just saw in a recent document that I'm reading, which

58:56.620 --> 59:03.100
well, it's a PhD thesis, that this is now being applied, this kind of idea in the

59:03.100 --> 59:08.860
eye where people are working on retinal prostheses, you know, and the idea there is to

59:08.860 --> 59:16.380
in a blind person who's lost the visual receptors, it's known that the so-called retinal ganglion

59:16.380 --> 59:21.500
cells, the cells that send the output of the retina back to the brain, those are often still

59:21.500 --> 59:26.220
functional even when the receptors are not. So the person is blind, but that part of the eye is good.

59:26.220 --> 59:32.380
So the proposal and it's been tried now in real life by different groups, you know, is to stick

59:32.380 --> 59:38.140
some sort of array of electrodes into the back of the eye and stimulate these retinal ganglion cells

59:38.140 --> 59:44.780
to provide some sort of prosthetic vision. And so this thesis that I'm reading has done just,

59:45.660 --> 59:48.780
he of course never saw my proposal, it must have come out of his own ideas, but

59:49.580 --> 59:56.700
the idea of making a finite element model of the fluid in the eye and then using the laws of

59:59.660 --> 01:00:03.500
you know, the laws of electricity and magnetism to figure out how when you

01:00:03.500 --> 01:00:09.660
put a little current into an electrode, how does that spread through that fluid and which ganglion

01:00:09.660 --> 01:00:16.460
cells does it affect? So you can figure out what's the best way to compute what, now in a computer,

01:00:16.460 --> 01:00:23.340
you know, what's stimulus to put into that electrode array to get the most natural vision. So there's

01:00:23.340 --> 01:00:29.180
a very new kind of extension of what we've all been doing, looking at just one neuron, talking to

01:00:29.180 --> 01:00:35.900
another and taking into account this ionic environment. And I think, you know, this is a very positive

01:00:36.700 --> 01:00:40.460
thing to be happening right now. You may know more about this than I do.

01:00:40.460 --> 01:00:47.340
I think, you know, you bring up, okay, so it seems we've sort of switched a little bit to pathology,

01:00:47.340 --> 01:00:54.140
I guess, because this is a bad retina. And can you guys hear me every other word or do we speak to

01:00:54.140 --> 01:01:03.580
twice for or, okay? Yeah, right now. Okay, okay, all right. So, you know, let me give you an example

01:01:03.580 --> 01:01:11.740
of where math can be very helpful in in pathologies is one of the classic mechanisms for Parkinson's

01:01:11.740 --> 01:01:17.020
disease is something called deep brain stimulation. And the problem with deep brain stimulation is

01:01:17.020 --> 01:01:22.940
it's really, really stupid. It just does the same thing over and over again. And it doesn't

01:01:22.940 --> 01:01:28.860
depend on any feedback or anything else. But there's a number of groups. There's groups in Germany,

01:01:28.860 --> 01:01:36.540
and there's groups in the US that have developed much smarter, much smarter versions of deep brain

01:01:36.540 --> 01:01:44.700
stimulation, based on writing down some goals for what happens in the basal ganglia, whether you treat

01:01:44.700 --> 01:01:50.380
them as oscillators, or as excitatory inhibitory networks. And by using that, they've been

01:01:50.380 --> 01:01:56.780
in a motor come up with techniques or deep brain stimulation. And this is this could not be

01:01:56.780 --> 01:02:00.620
have done could not have been done without the math predicting this method would work.

01:02:01.260 --> 01:02:07.180
But much more efficient ways of doing deep brain stimulation that won't come on until

01:02:07.180 --> 01:02:12.380
there's a sense that something's wrong. And when it comes on, it does it much more efficiently

01:02:12.380 --> 01:02:18.780
instead of jolting it with, you know, hundreds of millivolts of stuff they can do things in

01:02:18.780 --> 01:02:26.060
in much lower levels and therefore improve things like battery life and also reduce damage a great

01:02:26.060 --> 01:02:32.300
deal to the brain. You know, some of that work is going on at Rockpower 2 in the lab of Donald

01:02:32.300 --> 01:02:37.500
Faf, who I want to mention because he's on the board of this organization that's sponsoring us

01:02:37.500 --> 01:02:44.700
today. He has a student doing deep brain stimulation in a mouse model of traumatic brain injury.

01:02:44.700 --> 01:02:51.820
And they're not, perhaps, unfortunately not doing what you say in terms of the math of what the

01:02:51.820 --> 01:02:58.540
network is doing. But what they have done is to try out different modes of stimulation, you know,

01:02:58.540 --> 01:03:07.260
whether it's a random or a chaotic or a pure oscillator, a regular oscillation. And do these

01:03:07.260 --> 01:03:13.820
different modes of stimulation produce better results in that mouse model. So again, this is

01:03:13.820 --> 01:03:18.140
something kind of new that's going on in just a few places and very positive, I think.

01:03:20.860 --> 01:03:25.980
Especially for this audience, maybe it's also worth mentioning something related. So actually,

01:03:25.980 --> 01:03:34.700
I'm on my way to a kind of short summer school on so-called computational psychiatry. So there

01:03:34.700 --> 01:03:44.860
are several places including Yale and Germany and UCL in London where people feel like if we have

01:03:44.860 --> 01:03:51.500
some, we are starting to have some understanding about the second mechanisms of brain structures,

01:03:52.060 --> 01:03:58.460
especially the prefrontal cortex that are implicated in mental disorders. So if we know something

01:03:58.460 --> 01:04:03.820
about the circuitry in this part of the brain. So it's not, all the brains are really the same.

01:04:03.820 --> 01:04:10.300
Okay, so we know that there are early sensory areas that are, you know, optimized for

01:04:10.300 --> 01:04:15.900
information processing. And then there are some, you know, kind of more cognitive areas that are

01:04:15.900 --> 01:04:22.060
more implicated in decision-making and control of our behavior. So prefrontal cortex is one,

01:04:22.780 --> 01:04:28.620
you know, the best example perhaps of cognitive type circuitry that's implicating in many

01:04:28.620 --> 01:04:37.500
mental illness disorder types. So there's a sense that, you know, and again, this system's

01:04:37.500 --> 01:04:45.260
very complex to just try to understand by intuition along. And the second modeling has helped together

01:04:45.260 --> 01:04:54.140
with experimentation to kind of tease out, you know, what really might go on in normal subjects

01:04:54.140 --> 01:05:02.300
as well as seeing patients, like phoenix patients or autism, for example. I mean, we know a bit

01:05:02.300 --> 01:05:08.700
about schizophrenia, maybe much less, very little still, but there's something about schizophrenia,

01:05:08.700 --> 01:05:16.620
but even less on autism, I think. But still, the idea is that if mathematics really, you know,

01:05:16.620 --> 01:05:23.020
biologically based model of prefrontal cortex, if such a thing can be done, would provide a very

01:05:23.020 --> 01:05:30.540
useful platform to really explore what may go wrong if this goes down, if that goes up, you know,

01:05:30.540 --> 01:05:38.380
if, you know, at the circuitry level. And if that's the case, it really provides a two, first,

01:05:38.380 --> 01:05:45.020
to also try to understand what really underlines cognitive deficits in mental disorders.

01:05:45.020 --> 01:05:57.820
And there's a, this is just hypothesis and speculation, but there are, so the cerebral cortex is,

01:05:57.820 --> 01:06:04.540
you know, the main, the stuff that makes us smart. It's what, it's peculiar to mammals.

01:06:04.540 --> 01:06:08.620
The part of the brain that you ball specifically in mammals, to all the folded up stuff you see

01:06:08.620 --> 01:06:13.020
on the surface. And it's what you see with and hear with and think with. And pretty much,

01:06:13.020 --> 01:06:16.300
I think it's fair to say that your whole conscious life is computed there. I don't want to say

01:06:16.300 --> 01:06:20.300
where, what consciousness is, but let's say whatever does enter consciousness is computed there.

01:06:22.540 --> 01:06:28.860
And it has what has always fascinated anyone who tries to study cortex is that

01:06:29.580 --> 01:06:35.820
it looks so much the same no matter what it's doing. Whether it's doing, you know, here's a piece

01:06:35.820 --> 01:06:39.660
that's, that's analyzing the visual scene. Here's a piece that's analyzing touch. Here's a piece

01:06:39.660 --> 01:06:45.180
that's analyzing audition. Here's a piece that's involved in motor planning and, and thinking and,

01:06:45.900 --> 01:06:51.740
you know, speaking. And there are differences. There definitely are differences. But the first

01:06:51.740 --> 01:06:56.540
thing that strikes you is how much they look alike. How much they seem to be the same architecture,

01:06:56.540 --> 01:07:04.220
the same processing unit. And so it makes all of us dream at least that there is a fundamental

01:07:04.220 --> 01:07:09.660
processing unit that was invented in a million evolution that's very good at doing something,

01:07:09.660 --> 01:07:13.420
which when we really understand it, we'll be able to fill in what that something is. But something

01:07:13.420 --> 01:07:21.260
like being able to take a varying world, find invariant structure in it, represent that invariant

01:07:21.260 --> 01:07:27.980
structure associatively, and then do that again and again and again. So there's also a hypothesis

01:07:27.980 --> 01:07:36.540
that some diseases like schizophrenia or autism might be not specifically cognitive deficit to

01:07:36.540 --> 01:07:41.740
the cortex, specifically deficits in, you know, particular cognitive regions. But they might be

01:07:41.740 --> 01:07:49.900
deficits in that processing unit that therefore would manifest not only in higher order cognitive

01:07:49.900 --> 01:07:55.020
processing, but you would also see it in low level visual processing. And indeed in schizophrenia,

01:07:55.020 --> 01:08:02.780
for example, there's something in much of sensory cortex called surround suppression. It's a

01:08:02.780 --> 01:08:08.140
lateral inhibition that Bard was talking about before, which is that if I have a neuron that

01:08:08.140 --> 01:08:13.580
responds to some visual stimulus here, then what's around it, the context can suppress the

01:08:13.580 --> 01:08:22.220
responses somewhat. And it turns out that the people with schizophrenia have much weaker

01:08:22.220 --> 01:08:27.580
surround suppression in primary visual cortex. And you can imagine that that's some kind of,

01:08:28.220 --> 01:08:34.140
you know, that that could be some kind of global deficit in integrating, you know, local

01:08:34.140 --> 01:08:38.620
information here or local information there, putting it together, that perhaps in some way

01:08:38.620 --> 01:08:42.780
that I couldn't explain to you might add up to the cognitive deficits that we see as schizophrenia

01:08:42.780 --> 01:08:49.100
when that deficit is happening in the right brain region. So we don't know, but it's possible that

01:08:49.100 --> 01:08:54.700
these are diseases of the cortical processing unit and not of very specific cognitive functions.

01:08:54.700 --> 01:09:02.380
Would that kind of problem with the processing unit also be able to explain why schizophrenia

01:09:02.380 --> 01:09:08.620
is sometimes a deteriorating condition? I always wondered, imagine if once that processing is that

01:09:08.620 --> 01:09:14.700
way, then it should stay the same way. Yes, I know it's a good question. You know, I can't say that

01:09:14.700 --> 01:09:19.420
I've thought out all the implications of this really deep into schizophrenia. I've been struck

01:09:19.420 --> 01:09:26.300
by the fact that there are these very low level deficiencies in schizophrenia and certainly,

01:09:26.300 --> 01:09:31.820
in autism, it's been shown that at low level sensory areas, there's much more variability

01:09:31.820 --> 01:09:35.980
in the processing. The mean response to a given stimulus is the same, but there's much more

01:09:35.980 --> 01:09:41.020
variability in the response. So that it gives me the hint that there are maybe more general

01:09:41.020 --> 01:09:46.220
processing problems in the cortex, but I don't know enough at that level of detail.

01:09:46.220 --> 01:09:52.700
There's lots of very specific deficits in, especially in the prefrontal cortex,

01:09:52.700 --> 01:10:03.420
in the inhibitory circuitry, some of the receptors become slower, they become weaker,

01:10:04.540 --> 01:10:10.060
maybe compensation because there's also deficits in the excitatory stuff. So I think it's basically

01:10:10.060 --> 01:10:17.340
what Ken was saying is that it's this basic circuitry, this seven layer or six or seven layer

01:10:17.340 --> 01:10:25.260
structure, and there's something that goes wrong with, and Ken pointed out, if you weaken some of

01:10:25.260 --> 01:10:32.300
these things like Xiaojing, if you weaken these inhibitory things, for example, which inhibitory

01:10:32.300 --> 01:10:39.340
guys, or what kind of keep everything controlled. I mean, the cortex is highly recurrent, highly

01:10:39.340 --> 01:10:45.580
excitatory recurrent, and because of that, any kind of perturbation of this controlling inhibition

01:10:45.580 --> 01:10:52.060
can lead to all kinds of dramatic pathologies, activity where you don't want it not being able to

01:10:52.060 --> 01:11:00.220
hold activity, spread of activity where it shouldn't go. That's, for example, epilepsy,

01:11:00.220 --> 01:11:06.940
and spontaneous activity when it's not there, for example, hallucinations that are some of the

01:11:07.500 --> 01:11:14.620
negative things that happen, positive things that happen with, so yeah, I think, and math can

01:11:14.620 --> 01:11:23.740
really help us tear apart how these deficits in vision or deficit in the circuitry can lead to

01:11:23.740 --> 01:11:30.060
some sort of macroscopic measure. For example, one thing that they found associated with cognitive

01:11:30.060 --> 01:11:36.700
deficits in schizophrenia, people have greatly reduced certain kinds of problems in the brain

01:11:37.660 --> 01:11:45.100
Xiaojing alluded to, these ones that are related to mutual inhibition in generating these 40 to 60

01:11:45.100 --> 01:11:52.780
Hertz rhythms in the brain, and those rhythms are shown to be diminished in schizophrenics also.

01:11:52.780 --> 01:12:02.140
So, math can kind of connect these deficits in circuitry with the macroscopic rhythms and

01:12:02.140 --> 01:12:10.460
hopefully some of the cognitive deficits. So, to relate to what Barton King just said,

01:12:10.460 --> 01:12:18.620
I guess one way to view this is to say, yeah, there's a canonical general layout, there's a general

01:12:18.620 --> 01:12:27.340
in an organization of, say, cerebral cortex, and that's universal, let's say, okay, it's true in

01:12:27.340 --> 01:12:33.500
early sensory areas like primary visual cortex as well as prefrontal cortex. But what's interesting

01:12:33.500 --> 01:12:42.140
is that there could be some quantitative differences, right, and so to use the same analogy as used

01:12:42.140 --> 01:12:48.940
before, you have the same matter, same material, which can be either in the liquid state or solid

01:12:48.940 --> 01:12:53.500
state depending on the temperature, right. So, you could say just by changing something in

01:12:53.500 --> 01:12:58.060
temperature in a great fashion, sometimes by a small amount, if you are near the, you know,

01:13:02.060 --> 01:13:08.220
solidification critical point, just really the small change of certain things will

01:13:08.220 --> 01:13:14.140
give you a very different kind of behavior, right. And that's how I see it, like, you know, comparing

01:13:14.140 --> 01:13:21.340
sensory area versus prefrontal cortex, okay. So, and that really is very important and very

01:13:21.340 --> 01:13:27.820
interesting to realize. And then, you can ask even by the same amount of change of certain things

01:13:27.820 --> 01:13:34.220
due to genetic defect or due to environmental, you know, insult, what's the impact?

01:13:34.220 --> 01:13:41.660
You know, sensory system versus the more cognitive type of system. So, by understanding the

01:13:41.660 --> 01:13:48.860
operational mode, the behavior of each system, we can, you know, indeed address, you know, look

01:13:48.860 --> 01:13:54.380
at, exam, how, you know, abnormalities can occur in each of the areas.

01:13:55.580 --> 01:14:01.660
Let me ask Ken a question, because you emphasize the unity of structure across the cortex, but

01:14:01.660 --> 01:14:06.380
of course, as you well know, and I'll do, there's differences, you know, more than 100 years ago,

01:14:06.380 --> 01:14:11.340
Broadman described all with these numbered areas, and they have slight differences in the

01:14:11.980 --> 01:14:15.900
population of different cell types or the lengths of the dendrites or areas.

01:14:18.060 --> 01:14:25.580
I'm sure you didn't mean to denigrate that, but just, do you feel that those anatomical

01:14:25.580 --> 01:14:31.900
differences that are easily visible can be related, in fact, to the functional differences that

01:14:32.780 --> 01:14:39.420
Shaoxing is talking about? Or, you know, should we be looking at whether we can understand why

01:14:39.420 --> 01:14:44.940
those differences are there, or is it just sort of peripheral and unimportant accidental, I mean,

01:14:44.940 --> 01:14:48.460
to say? No, I mean, I think ultimately we need to understand those variations, but just,

01:14:48.460 --> 01:14:55.660
I very much take XJ's point, sorry, we call it XJ, so that's just a call again.

01:14:56.540 --> 01:15:03.580
Very much like SJ's point, that, you know, there may be some commonality, but it may be

01:15:03.580 --> 01:15:09.900
operating in a different regime, and in particular, one difference that's very well known is that,

01:15:09.900 --> 01:15:20.300
in primary sensory cortex, the excitatory neurons make much fewer synapses onto each other,

01:15:20.300 --> 01:15:27.260
so an individual neuron in primary visual cortex might receive 700 excitatory synapses,

01:15:27.260 --> 01:15:32.380
but in prefrontal cortex it might receive 20,000 excitatory synapses, and that has an obvious,

01:15:33.100 --> 01:15:39.500
theoretically what you expect from that is that the place with 20,000 excitatory synapses is much

01:15:39.500 --> 01:15:44.140
more likely to be able to generate its own activity in the absence of a stimulus, which in fact is

01:15:44.140 --> 01:15:48.460
one of the big differences between frontal cortex and primary sensory cortex, where without a stimulus,

01:15:49.180 --> 01:15:54.220
there's some background activity going on, but it doesn't generate the kinds of activity.

01:15:54.220 --> 01:15:58.620
It's stimulus, but frontal cortex has to generate its own activity, it's got to make motor plans

01:15:58.620 --> 01:16:04.700
and make the animal go, so that's one example of, you know, a numerical change that leads to a

01:16:04.700 --> 01:16:09.020
qualitative change in your operating regime, and you may have a lot of the same structure underneath,

01:16:09.020 --> 01:16:13.340
I'm sure that that's probably, you know, if we got down to every one of broadment areas,

01:16:13.340 --> 01:16:17.900
every one of them would have some specialization that gives us some little, some, I mean, every

01:16:17.900 --> 01:16:21.820
specialization and structure has got to be there for some specialization and function, and we don't

01:16:21.820 --> 01:16:28.300
know what it is, but I prefer, I prefer right now to try to focus on, you know, what is the basic

01:16:28.300 --> 01:16:33.020
operation of this unit rather than before we tackle all of its variations, but I do think between

01:16:33.020 --> 01:16:36.860
sensory and motor, those are really two fundamentally different things that we need to each understand.

01:16:36.860 --> 01:16:44.140
Well, how about something? I want to add something, if I can, is, it's, you know, there's also

01:16:44.140 --> 01:16:49.740
who you're talking to and who talks to you that really matters, so the prefrontal cortex gets

01:16:49.740 --> 01:16:54.540
information from lots of other different things than the visual cortex, so even though the

01:16:54.540 --> 01:17:00.060
the hardware is the same connectivity, and I guess we come back to the old connect story,

01:17:00.060 --> 01:17:06.540
is different, and I think that can also be a big reason why there's a difference in

01:17:06.540 --> 01:17:12.380
functionality. I mean, it's just simply that you're getting, you know, the, the, the CPUs are the

01:17:12.380 --> 01:17:19.500
same, it's just the, the, the memory and who you're talking to is completely different.

01:17:20.700 --> 01:17:24.700
Yeah, that's right. Right on the water finish.

01:17:25.900 --> 01:17:30.940
Oh, yeah, I think, you know, the, the point you were making before about, we don't know what the

01:17:30.940 --> 01:17:36.460
units are yet. Look, I, I, I take the unit story very seriously, for one thing, it seems evolution

01:17:36.460 --> 01:17:42.860
is generally plausible. We know that there's a reason to think that the, you know, increase in

01:17:43.660 --> 01:17:51.260
cortex that we have from earlier stages is just duplication. You know, we have all these areas

01:17:51.260 --> 01:17:58.300
that seem to be basically descended from retinas that, you know, they needed more cortex to make

01:17:58.300 --> 01:18:08.140
another retina. So there does seem to be some reason to think that from an evolutionary point

01:18:08.140 --> 01:18:14.780
of view, it's a matter of just, you know, duplication, but it seems amazing that we don't know what

01:18:14.780 --> 01:18:20.700
these units are. How many neurons in such a unit would you say?

01:18:21.260 --> 01:18:24.380
What's the size of the unit? So what we think of as... What do you mean by it?

01:18:24.380 --> 01:18:28.620
Yeah, I mean, the unit is a totally hypothetical speculative object right now, but,

01:18:30.620 --> 01:18:35.420
what's, what's commonly thought going back to the work of Hubel and Wiesel 40, 50 years ago,

01:18:36.460 --> 01:18:41.660
is that about a square millimeter of cortex is sort of processing a local, a local bit of

01:18:41.660 --> 01:18:47.580
information, and that contains about 100,000 neurons. And then when you consider, though,

01:18:47.580 --> 01:18:51.020
that these different units are talking to each other, because you don't only process local

01:18:51.020 --> 01:18:55.420
information, you're modulated by your context, you know, so how big should there should we take

01:18:55.420 --> 01:18:59.580
the processing unit to be? But that gives you a beginning. I've asked the same question to other

01:18:59.580 --> 01:19:08.140
neuroscientists, and sometimes I get the answer 10,000 neurons. I mean, it just shows how hypothetical

01:19:08.140 --> 01:19:14.300
it is if we don't even... If we don't have methods of estimating that... Well, I mean, we know how many

01:19:14.300 --> 01:19:18.060
neurons there are in a given area, but the question is how big an area should we call a unit? Yeah.

01:19:18.060 --> 01:19:20.300
Yeah. He has to... Well, there is a great... Well, there is a great...

01:19:20.300 --> 01:19:18.560
...

01:19:21.260 --> 01:19:21.260
...

01:19:21.260 --> 01:19:21.260
...

01:19:21.260 --> 01:19:21.260
...

01:19:21.260 --> 01:19:21.760
...

01:19:21.760 --> 01:19:22.260
...

01:19:22.260 --> 01:19:22.260
...

01:19:22.260 --> 01:19:23.260
...

01:19:23.260 --> 01:19:23.260
...

01:19:23.260 --> 01:19:24.260
...

01:19:24.260 --> 01:19:24.260
...

01:19:45.080 --> 01:19:46.080
...

01:19:46.080 --> 01:19:47.860
...

01:19:53.300 --> 01:20:00.400
...

01:20:03.580 --> 01:20:03.920
...

01:20:03.700 --> 01:20:05.060
...

01:20:05.060 --> 01:20:06.360
...

01:20:08.160 --> 01:20:09.700
chats

01:20:09.700 --> 01:20:14.020
I'm every perception that we make, every thought that we have.

01:20:14.020 --> 01:20:16.780
And the whole world of metaphor depends

01:20:16.780 --> 01:20:20.860
on a more sophisticated pattern recognition.

01:20:20.860 --> 01:20:23.860
Now, my simple question is, is it conceivable

01:20:23.860 --> 01:20:29.300
that there is some mathematical expression of whatever

01:20:29.300 --> 01:20:31.460
matches one pattern to another?

01:20:31.460 --> 01:20:33.260
Because we can't work without it.

01:20:33.260 --> 01:20:34.140
That's my question.

01:20:34.140 --> 01:20:36.780
I think that's the holy grail for understanding course.

01:20:36.780 --> 01:20:38.180
I mean, I think we will get there,

01:20:38.180 --> 01:20:40.340
but we're not there yet.

01:20:40.340 --> 01:20:43.420
So just to say something about what we know about pattern

01:20:43.420 --> 01:20:49.780
recognition, what we don't know, it was shown a long time

01:20:49.780 --> 01:20:53.540
ago that pigeons can recognize patterns

01:20:53.540 --> 01:20:57.260
that we have not been able to make a machine that can recognize.

01:20:57.260 --> 01:21:02.860
So for example, it was shown, I think, 30 years ago that you,

01:21:02.860 --> 01:21:07.220
so this was done by a famous, maybe infamous Harvard

01:21:07.220 --> 01:21:08.940
psychologist named Heron Stein.

01:21:08.940 --> 01:21:12.740
He got a bunch of pictures from the National Geographic

01:21:12.740 --> 01:21:17.700
that some of which had people or parts of people in them.

01:21:17.700 --> 01:21:20.580
Sometimes they were like a tree trunk with some fingers

01:21:20.580 --> 01:21:23.780
on one side and others that had no people in them

01:21:23.780 --> 01:21:24.700
or no parts of people.

01:21:24.700 --> 01:21:28.100
And he got pigeons to, he trained pigeons

01:21:28.100 --> 01:21:31.100
so that they could recognize the difference between a picture

01:21:31.100 --> 01:21:33.220
that had a person or a part of a person.

01:21:33.220 --> 01:21:36.220
And they did very well, better than some of the students

01:21:36.220 --> 01:21:40.100
in his lab because that's why they're flying things that

01:21:40.100 --> 01:21:43.020
could do better in aerial photograph.

01:21:43.020 --> 01:21:45.460
They could do better in the aerial analysis.

01:21:45.460 --> 01:21:49.540
We don't have any kind of artificial pattern recognized

01:21:49.540 --> 01:21:50.180
so they can do that.

01:21:50.180 --> 01:21:53.100
We don't know how it's done.

01:21:53.100 --> 01:21:56.260
But I do believe that when we understand it,

01:21:56.260 --> 01:22:00.100
we will understand it mathematically.

01:22:00.100 --> 01:22:03.580
Until you can describe mathematically how you take the image

01:22:03.580 --> 01:22:07.220
and what you do with it in order to recognize the pattern,

01:22:07.220 --> 01:22:08.380
then we won't understand that.

01:22:08.380 --> 01:22:10.460
And I think we will understand it.

01:22:10.460 --> 01:22:12.900
My own feeling is that we're not going to figure it out

01:22:12.900 --> 01:22:15.380
by trying to invent algorithms.

01:22:15.380 --> 01:22:18.460
We're going to figure it out by studying how nature did it,

01:22:18.460 --> 01:22:20.020
which is how our brains do it.

01:22:20.020 --> 01:22:21.140
Because I don't think we're smart enough

01:22:21.140 --> 01:22:22.300
to reinvent that ourselves.

01:22:22.300 --> 01:22:23.220
I think we have to discover it.

01:22:23.220 --> 01:22:26.900
It's an important point that I agree with what you just said.

01:22:26.900 --> 01:22:32.420
But it reveals a real tectonic shift in this field

01:22:32.420 --> 01:22:36.780
where there was a time when people thought they could discover

01:22:36.780 --> 01:22:38.060
these just by thinking about it.

01:22:38.060 --> 01:22:39.500
Just by thinking about it.

01:22:39.500 --> 01:22:40.500
Yeah.

01:22:40.500 --> 01:22:41.500
You know, David.

01:22:41.500 --> 01:22:44.940
The analogy I'd like to make is that quantum mechanics

01:22:44.940 --> 01:22:46.980
is the weirdest theory.

01:22:46.980 --> 01:22:49.700
I mean, you get used to it and it makes sense to you.

01:22:49.700 --> 01:22:55.060
But never in a billion years would anybody have figured it out

01:22:55.060 --> 01:22:56.420
just by thinking about it.

01:22:56.420 --> 01:22:59.180
Physicists had to knock their heads on atoms

01:22:59.180 --> 01:23:01.060
and the weird way that adults behave

01:23:01.060 --> 01:23:03.780
and knock their heads again and again and again

01:23:03.780 --> 01:23:07.860
for decades until they finally somehow knocked their heads

01:23:07.860 --> 01:23:11.180
enough that they managed to get to the point of quantum mechanics.

01:23:11.180 --> 01:23:12.580
And then it started explaining things.

01:23:12.580 --> 01:23:16.380
And I think understanding how the brain does instantly

01:23:16.380 --> 01:23:17.660
recognizes things.

01:23:17.660 --> 01:23:19.740
I think it's in the same category.

01:23:19.740 --> 01:23:21.540
I know there's a line over here, but I really

01:23:21.540 --> 01:23:22.660
want to throw in two things.

01:23:22.660 --> 01:23:25.860
First, famously in that Heronstein experiment,

01:23:25.860 --> 01:23:27.620
people complained just what you said

01:23:27.620 --> 01:23:30.260
that the birds fly around so they would know about trees.

01:23:30.260 --> 01:23:32.860
So he got the pigeons also to recognize scenes that

01:23:32.860 --> 01:23:36.380
had fish or not fish, which the pigeons had never seen.

01:23:36.380 --> 01:23:38.180
But no, my point was going to be, yeah,

01:23:38.180 --> 01:23:39.460
we don't know how this works.

01:23:39.460 --> 01:23:42.340
But I firmly believe that part of the story

01:23:42.340 --> 01:23:46.180
is going to be what I've said earlier this afternoon,

01:23:46.180 --> 01:23:49.460
the interaction of the young individual with the world.

01:23:49.460 --> 01:23:52.140
The way we're going to recognize patterns

01:23:52.140 --> 01:23:56.420
that connect with each other is because they occur together

01:23:56.420 --> 01:23:59.980
in time or space on and off during development.

01:23:59.980 --> 01:24:02.740
And parts of the brain are, I believe,

01:24:02.740 --> 01:24:07.940
wired in such a way as to respond to those connections.

01:24:07.940 --> 01:24:12.340
And that's what you cannot get by describing patterns

01:24:12.340 --> 01:24:15.740
geometrically or with words.

01:24:15.740 --> 01:24:17.860
It's all part of a scene.

01:24:17.860 --> 01:24:20.300
And we know that we recall things in connection

01:24:20.300 --> 01:24:24.060
with stimuli that were part of that scene

01:24:24.060 --> 01:24:28.780
when we first saw that pattern that may be totally unrelated.

01:24:28.780 --> 01:24:31.020
I recognize a certain Beethoven symphony

01:24:31.020 --> 01:24:33.260
because when I played the record years and years ago,

01:24:33.260 --> 01:24:34.780
there was a scratch at one point.

01:24:34.780 --> 01:24:38.540
And that scratch is in my brain at that point in the music.

01:24:38.540 --> 01:24:40.380
And that's how I know that with that.

01:24:40.380 --> 01:24:46.820
So it's the whole surround, not just one thing that

01:24:46.820 --> 01:24:48.260
makes patterns.

01:24:48.260 --> 01:24:50.580
OK, I'll shut up.

01:24:50.580 --> 01:24:51.660
I'm sorry, I'm sorry.

01:24:51.660 --> 01:24:54.100
I'm actually a mathematically oriented psychiatrist,

01:24:54.100 --> 01:24:55.940
which is relatively rare thing.

01:24:55.940 --> 01:24:59.380
In 2003, I organized the first symposium

01:24:59.380 --> 01:25:01.980
at the American Psychiatric on Game Theory in Psychiatry.

01:25:01.980 --> 01:25:03.500
And it was roundly ridiculed.

01:25:03.500 --> 01:25:04.980
I just have to, you know, it and I

01:25:04.980 --> 01:25:06.660
were roundly ridiculed for this notion

01:25:06.660 --> 01:25:11.620
that game theory could be applicable to psychiatry.

01:25:11.620 --> 01:25:13.740
So I've been thinking about these ideas for a long time.

01:25:13.740 --> 01:25:15.620
And I want to thank this panel for bringing this here.

01:25:15.620 --> 01:25:17.900
I think it's absolutely fantastic.

01:25:17.900 --> 01:25:20.980
And cutting edge kind of discussion.

01:25:20.980 --> 01:25:23.860
I'd just like to say that if the hypothesis for today

01:25:23.860 --> 01:25:26.820
is whether or not the mind can be described by mathematics,

01:25:26.820 --> 01:25:28.500
I would consider the negation of that.

01:25:28.500 --> 01:25:30.700
I mean, if the mind cannot be discovered

01:25:30.700 --> 01:25:33.340
explained by mathematics, how could you possibly explain it?

01:25:33.340 --> 01:25:36.340
What other language are you going to propose to do it in?

01:25:36.340 --> 01:25:38.460
First of all, you're irreducibly a dualist.

01:25:38.460 --> 01:25:42.580
If you propose another language, you're irreducibly a dualist.

01:25:42.580 --> 01:25:45.060
Second of all, you're rejecting evolution

01:25:45.060 --> 01:25:47.540
because evolution is about maximization under competition,

01:25:47.540 --> 01:25:51.820
which is a mathematically solvable problem.

01:25:51.820 --> 01:25:55.300
And third of all, you would have to propose

01:25:55.300 --> 01:25:57.340
that there's some brain-dependent language that

01:25:57.340 --> 01:25:59.180
do a better job than mathematics, which I think

01:25:59.180 --> 01:26:03.980
is as close as we get to a brain-independent language.

01:26:03.980 --> 01:26:05.740
I don't think we need any comments on that.

01:26:05.740 --> 01:26:07.740
I don't think anybody will disagree with that here.

01:26:07.740 --> 01:26:08.300
Well, I don't know.

01:26:08.300 --> 01:26:09.380
Maybe that's a law.

01:26:09.380 --> 01:26:09.900
But OK.

01:26:13.020 --> 01:26:14.860
That's just so fun.

01:26:14.860 --> 01:26:16.660
The notion of statistical mechanics

01:26:16.660 --> 01:26:18.900
leads us to conclude that phenomena like pressure

01:26:18.900 --> 01:26:22.380
merge from the interaction of molecules

01:26:22.380 --> 01:26:23.900
is the prediction of the panel then

01:26:23.900 --> 01:26:27.540
that a complete physiological and structural description

01:26:27.540 --> 01:26:30.140
of some neural system is going to then

01:26:30.140 --> 01:26:33.500
just lead to the deduction that we have in front of us

01:26:33.500 --> 01:26:35.340
a cognitive system.

01:26:35.340 --> 01:26:38.780
In other words, once the physical language of a system

01:26:38.780 --> 01:26:40.740
of neurons is described completely,

01:26:40.740 --> 01:26:43.540
do you think, or is it the opinion of the group,

01:26:43.540 --> 01:26:45.420
that we will then come to the conclusion

01:26:45.420 --> 01:26:49.140
that we've in essence described the mechanism of cognition

01:26:49.140 --> 01:26:52.180
without being able to fully describe what cognition is?

01:26:52.180 --> 01:26:54.420
Perhaps it touches on the notion of consciousness

01:26:54.420 --> 01:26:55.340
versus not.

01:26:55.340 --> 01:26:56.980
But just let's say even from an information

01:26:56.980 --> 01:26:59.340
theoretic perspective, what are the thoughts of the panel?

01:26:59.340 --> 01:27:02.260
Well, I said something that's relevant to this earlier.

01:27:02.260 --> 01:27:05.940
The example of the square peg in the round hole.

01:27:05.940 --> 01:27:06.300
OK.

01:27:06.300 --> 01:27:09.740
So you could get an explanation of that, quote,

01:27:09.740 --> 01:27:12.820
explanation in terms of the elementary particle

01:27:12.820 --> 01:27:16.460
clouds, but it would just obscure the explanation

01:27:16.460 --> 01:27:19.140
that you can see in terms of geometry and rigidity.

01:27:19.140 --> 01:27:20.580
You could add to it by explaining

01:27:20.580 --> 01:27:22.900
why those things that are rigid are rigid

01:27:22.900 --> 01:27:25.620
or when they would fail to be rigid.

01:27:25.620 --> 01:27:28.740
But some explanations have an appropriate level

01:27:28.740 --> 01:27:31.620
that isn't illuminated from below.

01:27:31.620 --> 01:27:34.780
And sometimes the what's below is so complicated

01:27:34.780 --> 01:27:39.300
that you have no hope of deducing the molar behavior

01:27:39.300 --> 01:27:40.540
from what's below.

01:27:40.540 --> 01:27:44.020
So I think we have to find the right level

01:27:44.020 --> 01:27:46.860
for any given phenomenon that we're interested in.

01:27:46.860 --> 01:27:48.500
Is this in essence become a sort of short-time question?

01:27:48.500 --> 01:27:51.860
But that doesn't answer his question, which is,

01:27:51.860 --> 01:27:53.540
will this emerge?

01:27:53.540 --> 01:27:55.780
And will consciousness or cognition

01:27:55.780 --> 01:27:58.900
emerge from this low level?

01:27:58.900 --> 01:28:02.220
And I think as reductionists, or at least most of us

01:28:02.220 --> 01:28:04.420
as reductionists, the answer has to be yes.

01:28:04.420 --> 01:28:08.740
I don't know how that levels will have to ignore.

01:28:08.740 --> 01:28:10.700
At what course grading we have to do,

01:28:10.700 --> 01:28:16.340
but I don't see how we can't answer that question is yes.

01:28:16.340 --> 01:28:20.140
Look, if there's a distinction between being a physicalist,

01:28:20.140 --> 01:28:24.100
which I am, I don't believe in any soul

01:28:24.100 --> 01:28:26.980
that somehow interferes with the elementary particles,

01:28:26.980 --> 01:28:28.780
there's a difference between being a physicalist

01:28:28.780 --> 01:28:30.340
and being a reductionist.

01:28:30.340 --> 01:28:33.140
So you're a physicalist, you think, OK, it's all just matter.

01:28:33.140 --> 01:28:35.900
And somehow the consciousness and cognition

01:28:35.900 --> 01:28:37.100
have to come out of matter.

01:28:37.100 --> 01:28:38.940
But that's different from thinking.

01:28:38.940 --> 01:28:42.660
You're going to be able to take any explanation you get

01:28:42.660 --> 01:28:46.780
at the cognitive level and reduce it to an explanation

01:28:46.780 --> 01:28:49.500
in terms of the smallest items.

01:28:49.500 --> 01:28:52.980
That is a very adventurous, controversial claim,

01:28:52.980 --> 01:28:55.300
even for physicalists.

01:28:55.300 --> 01:28:57.020
So that's why I keep saying it's the right,

01:28:57.020 --> 01:28:59.140
you have to find the right level.

01:28:59.140 --> 01:29:02.700
I guess the old is in, I guess I would like to add is.

01:29:02.700 --> 01:29:05.820
Well, I understand they all turn it.

01:29:05.820 --> 01:29:11.060
Well, maybe it's pretty fair to say that for very good reasons

01:29:11.060 --> 01:29:14.180
that neuroscience has been for a very long time,

01:29:14.180 --> 01:29:18.100
focused on early sensory information processing

01:29:18.100 --> 01:29:19.540
and the motor behavior.

01:29:19.540 --> 01:29:23.460
But it's becoming more and more frequent, common now,

01:29:23.460 --> 01:29:25.980
that people feel like you can study

01:29:25.980 --> 01:29:31.900
the neuro-biological mechanism of cognitive processes,

01:29:31.900 --> 01:29:34.580
such as decision-making in a rigorous way.

01:29:34.580 --> 01:29:37.820
So that's a sea change in my mind.

01:29:37.820 --> 01:29:39.780
So many things that people thought

01:29:39.780 --> 01:29:42.180
were in the realm of psychologists

01:29:42.180 --> 01:29:47.140
and now really been studied in a very cross disciplinary fashion

01:29:47.140 --> 01:29:51.700
with cognitive psychologists and physiologists

01:29:51.700 --> 01:29:55.180
and computational theorists.

01:29:55.180 --> 01:29:57.020
They're going together to understand

01:29:57.020 --> 01:30:00.580
really the mechanism of even cognition, I'd say.

01:30:00.580 --> 01:30:02.380
And the answer to your comment, it seems

01:30:02.380 --> 01:30:03.940
that one of the aspirations then is

01:30:03.940 --> 01:30:05.940
to be able to come up with a descriptive mechanism

01:30:05.940 --> 01:30:08.460
to talk about very high-dimensionality systems.

01:30:08.460 --> 01:30:10.460
In a sense, it's very, for any of us,

01:30:10.460 --> 01:30:12.540
it's very hard to do that in any discipline, it seems.

01:30:12.540 --> 01:30:16.460
And so for such an perhaps the most exceptional high-dimensionality

01:30:16.460 --> 01:30:18.180
system, it seems very hard to talk

01:30:18.180 --> 01:30:21.580
with any micro and macro phenomenon other than the physicality.

01:30:21.580 --> 01:30:24.780
From a CS person's point of view, it's hard to talk about.

01:30:24.780 --> 01:30:26.700
We can come up with dumb little models.

01:30:26.700 --> 01:30:28.780
Seems that logic itself has some problems with it.

01:30:28.780 --> 01:30:31.220
But I'm just very curious as to what

01:30:31.220 --> 01:30:34.460
practicing neuroscientists think of this.

01:30:34.460 --> 01:30:37.940
I mean, I think every mental entity has ultimately

01:30:37.940 --> 01:30:42.340
got to be understood as some in neural terms

01:30:42.340 --> 01:30:43.700
and will be understood in neural terms,

01:30:43.700 --> 01:30:46.140
except maybe conscious itself.

01:30:46.140 --> 01:30:49.660
Given all of this is going on, why do you have a sensation?

01:30:49.660 --> 01:30:51.420
I don't know that that ever can be answered.

01:30:51.420 --> 01:30:58.420
But at least every mental structure

01:30:58.420 --> 01:31:01.460
has a neural substrate ultimately, and that's

01:31:01.460 --> 01:31:03.500
an article of faith, I think.

01:31:03.500 --> 01:31:07.500
But I would distinguish between has a neural structure

01:31:07.500 --> 01:31:11.420
is grounded in the neural structure?

01:31:11.420 --> 01:31:12.300
That's on one side.

01:31:12.300 --> 01:31:16.060
The other side is can be understood in terms

01:31:16.060 --> 01:31:17.140
of that neural structure.

01:31:17.140 --> 01:31:20.420
So there's a level of understanding.

01:31:20.420 --> 01:31:22.700
You can't always get more understanding

01:31:22.700 --> 01:31:26.500
by going to the smaller and smaller parts.

01:31:26.500 --> 01:31:28.700
So I think that's a totally different point.

01:31:28.700 --> 01:31:30.260
No, no, you work upwards.

01:31:30.260 --> 01:31:32.900
You get the little, I'd explain the next guy,

01:31:32.900 --> 01:31:35.660
and then you work.

01:31:35.660 --> 01:31:39.020
I don't see why this is such a contradiction.

01:31:39.020 --> 01:31:40.860
You work downwards too.

01:31:40.860 --> 01:31:44.260
And sometimes the downwards is better than the upwards.

01:31:44.260 --> 01:31:45.260
Oh, I agree.

01:31:45.260 --> 01:31:47.260
I agree.

01:31:47.260 --> 01:31:49.740
You have to meet the two ends at some point.

01:31:49.740 --> 01:31:52.180
I mean, I think the point is that you're not

01:31:52.180 --> 01:31:54.300
going to describe the brain in terms of elementary particles.

01:31:54.300 --> 01:31:55.900
But it is ultimately made of them.

01:31:55.900 --> 01:31:57.660
You've got to work at some intermediate level of structure

01:31:57.660 --> 01:31:59.900
to understand the next level of structure.

01:31:59.900 --> 01:32:02.300
But we're going to understand structure

01:32:02.300 --> 01:32:04.140
we've made out of neurons that correspond

01:32:04.140 --> 01:32:05.620
to the structures of our minds.

01:32:05.620 --> 01:32:06.980
That's what I believe.

01:32:06.980 --> 01:32:11.460
Maybe it's time to throw pen rows in here just briefly.

01:32:11.460 --> 01:32:14.980
Because if we're physicalists, and believe that it's all

01:32:14.980 --> 01:32:17.820
done with math, there's extensions

01:32:17.820 --> 01:32:19.340
that we haven't made yet.

01:32:19.340 --> 01:32:22.340
And there are people who try very hard to bring in stuff

01:32:22.340 --> 01:32:25.740
that we can claim as physical.

01:32:25.740 --> 01:32:28.260
But it's so complicated.

01:32:28.260 --> 01:32:33.180
Quantum mechanical fluctuations in microtubules

01:32:33.180 --> 01:32:35.260
in neural neurons.

01:32:35.260 --> 01:32:36.700
In neural stools.

01:32:36.700 --> 01:32:40.980
And so I think all of us believe that's probably wrong.

01:32:40.980 --> 01:32:43.540
And I think we can understand how it might be wrong,

01:32:43.540 --> 01:32:45.940
just because of all the complexity of these levels

01:32:45.940 --> 01:32:48.340
that we've already talked about or enough to explain it.

01:32:48.340 --> 01:32:49.460
But that's an intuition.

01:32:49.460 --> 01:32:50.740
It's not a proof.

01:32:50.740 --> 01:32:53.260
So that remains to be seen.

01:32:53.260 --> 01:32:54.980
But it'll still be physical.

01:32:54.980 --> 01:32:58.660
I think that there's no argument.

01:32:58.660 --> 01:32:59.820
Go ahead.

01:32:59.820 --> 01:33:01.060
Hi, everyone.

01:33:01.060 --> 01:33:06.620
First, I want to feel that I love what you said today.

01:33:06.620 --> 01:33:09.220
And sorry for the language.

01:33:09.220 --> 01:33:13.900
But I'm the kind of people who like to formalize life

01:33:13.900 --> 01:33:15.220
and whatever.

01:33:15.220 --> 01:33:19.540
Even my speech, for example, this is why I was late tonight.

01:33:19.540 --> 01:33:26.860
Because my husband speaks in such a linear way

01:33:26.860 --> 01:33:32.900
where I speak of things in a three dimensional way.

01:33:32.900 --> 01:33:36.540
I mean, I start and I open the parentheses and close.

01:33:36.540 --> 01:33:39.420
And I remember exactly where I opened this.

01:33:39.420 --> 01:33:40.620
And then I open another.

01:33:40.620 --> 01:33:45.980
And so after the third parentheses, he says he's bored.

01:33:45.980 --> 01:33:49.780
But I know that people is not bored.

01:33:49.780 --> 01:33:51.580
It depends on which people are talking with.

01:33:51.580 --> 01:33:58.020
I mean, for example, yesterday, now two days ago.

01:33:58.020 --> 01:33:59.140
That's your parentheses?

01:33:59.140 --> 01:34:00.140
Or is that your question?

01:34:00.140 --> 01:34:01.140
Sorry.

01:34:01.140 --> 01:34:02.140
This is one of the first questions.

01:34:02.140 --> 01:34:03.140
Sorry.

01:34:03.140 --> 01:34:11.180
And two days ago, I was, let's say, bored about some online

01:34:11.180 --> 01:34:13.900
agendas, because I couldn't put inside what

01:34:13.900 --> 01:34:15.500
I was thinking about.

01:34:15.500 --> 01:34:21.900
I mean, also because my email address was hacked twice.

01:34:21.900 --> 01:34:24.140
So I prefer to do something simple.

01:34:24.140 --> 01:34:29.540
And I start putting some sticky notes on the mirror.

01:34:29.540 --> 01:34:30.020
Look, OK.

01:34:30.020 --> 01:34:32.620
Let's say the pink one for projects,

01:34:32.620 --> 01:34:36.980
the blue one for contacts and meetings, like this.

01:34:36.980 --> 01:34:38.780
The yellow one for all the other stuff

01:34:38.780 --> 01:34:42.780
and the internet I have to do right now turns for this.

01:34:42.780 --> 01:34:47.540
And the green one, something, all but the pieces, which means,

01:34:47.540 --> 01:34:49.740
OK, you get up on this.

01:34:49.740 --> 01:34:51.860
Share it, get out.

01:34:51.860 --> 01:34:56.140
And then I start to divide into columns and rows,

01:34:56.140 --> 01:35:00.780
because I work for databases since 15 years.

01:35:00.780 --> 01:35:01.780
15 years.

01:35:01.780 --> 01:35:02.780
15 years.

01:35:02.780 --> 01:35:03.780
Yeah.

01:35:03.780 --> 01:35:04.780
Yeah.

01:35:04.780 --> 01:35:05.780
I don't know.

01:35:05.780 --> 01:35:10.100
And so I just, in the sticky notes,

01:35:10.100 --> 01:35:11.820
I put a kind of bullet points.

01:35:11.820 --> 01:35:16.780
So I mean, sometimes I realize that my mind is like a database.

01:35:16.780 --> 01:35:21.540
And that's why I love math, physics.

01:35:21.540 --> 01:35:26.300
For example, I remember when I started physics, the first physics

01:35:26.300 --> 01:35:27.300
hasn't.

01:35:27.300 --> 01:35:32.260
After a while, I still have all the ground,

01:35:32.260 --> 01:35:34.500
because everything happens.

01:35:34.500 --> 01:35:37.060
It comes from a dynamic load.

01:35:37.060 --> 01:35:40.500
So even a pen falling down.

01:35:40.500 --> 01:35:44.260
Well, I stare at the pen because that pen was connected with this

01:35:44.260 --> 01:35:45.260
and this and this.

01:35:45.260 --> 01:35:50.060
So it was full of math, physics, and whatever.

01:35:50.060 --> 01:35:53.740
And thank you for letting me understand better.

01:35:53.740 --> 01:35:54.740
Thank you.

01:35:54.740 --> 01:35:55.740
Thank you.

01:35:55.740 --> 01:35:56.740
Sorry about that.

01:35:56.740 --> 01:35:57.740
Thank you.

01:35:57.740 --> 01:36:02.540
I want to talk to the guy who is a skype or whatever.

01:36:02.540 --> 01:36:05.900
He told about, I don't know his name.

01:36:05.900 --> 01:36:06.420
Sorry.

01:36:06.420 --> 01:36:09.500
Anyway, for all of you, he told about computer.

01:36:09.500 --> 01:36:10.500
You're still listening.

01:36:10.500 --> 01:36:11.500
He's still listening.

01:36:11.500 --> 01:36:12.500
He just checking his notes.

01:36:12.500 --> 01:36:13.500
He's always the same.

01:36:13.500 --> 01:36:14.500
He's starting from an input.

01:36:14.500 --> 01:36:17.500
You can have all the same output.

01:36:17.500 --> 01:36:25.500
Well, this is about, you can call them deterministic algorithms.

01:36:25.500 --> 01:36:31.500
But in logic, there are also non-deterministic algorithms,

01:36:31.500 --> 01:36:37.500
which are like this, something that can happen in different way.

01:36:37.500 --> 01:36:41.500
Even the starting point, the same.

01:36:41.500 --> 01:36:45.500
But it's hard to develop in a computer.

01:36:45.500 --> 01:36:46.500
Thank you.

01:36:46.500 --> 01:36:47.500
Thank you.

01:36:47.500 --> 01:36:48.500
Thank you.

01:36:48.500 --> 01:36:49.500
Thank you.

01:36:49.500 --> 01:36:50.500
Thank you.

01:36:50.500 --> 01:36:51.500
Thank you.

01:36:51.500 --> 01:37:01.500
So I was really interested by the idea of, sorry, how, you know, whatever type of unit we're

01:37:01.500 --> 01:37:07.500
talking about, there may be similar ones across the cortex.

01:37:07.500 --> 01:37:11.500
I just was doing research in like cross-modal stuff.

01:37:11.500 --> 01:37:14.500
And so I'm really interested in that.

01:37:14.500 --> 01:37:22.500
And I guess my question is just, you know, do you think that even though we're talking

01:37:22.500 --> 01:37:28.500
about reproduction of units in a biological way, it may be just sort of the most efficient

01:37:28.500 --> 01:37:32.500
way of, you know, growing the brain through time.

01:37:32.500 --> 01:37:38.500
But there could also be this byproduct, which, you know, contributes to our sort of unified

01:37:38.500 --> 01:37:44.500
experience of the world in the sense that these units are similar and therefore can maybe

01:37:44.500 --> 01:37:48.500
communicate through, you know, communicate to each other more easily.

01:37:48.500 --> 01:37:52.500
And I just wonder if any of you have anything to say about that?

01:37:52.500 --> 01:37:54.500
I mean, yeah, that's confusing.

01:37:54.500 --> 01:38:01.500
Well, just the idea that like whatever unit you're talking about, they are reproduced

01:38:01.500 --> 01:38:04.500
across the cortex.

01:38:04.500 --> 01:38:11.500
And does that, I mean, do you know if that has any, does that have any effect on how easily

01:38:11.500 --> 01:38:17.500
they communicate to each other and how something happening in the visual cortex can be referred

01:38:17.500 --> 01:38:20.500
to something in the auditory cortex?

01:38:20.500 --> 01:38:27.500
Or is it just really, you know, basically, anyways, I'll stop.

01:38:27.500 --> 01:38:29.500
But I thought it was interesting.

01:38:29.500 --> 01:38:33.500
I mean, I should just say, I mean, there's unity at a lot of levels.

01:38:33.500 --> 01:38:38.500
There's unity at the, you know, when you look at this one millimeter chunk that it, you know,

01:38:38.500 --> 01:38:42.500
it looks to fruit, you know, there's a lot of similarity no matter where you are in cortex.

01:38:42.500 --> 01:38:48.500
But there's also unity in, you know, a lot of sort of higher level themes of how different,

01:38:48.500 --> 01:38:55.500
how the different chunks talk to each other across millimeters, how one area talks to another

01:38:55.500 --> 01:39:02.500
area and talks back, how they get their input from the thalamus and how they send loops

01:39:02.500 --> 01:39:04.500
through the basal ganglia.

01:39:04.500 --> 01:39:09.500
There's a lot of themes that are conserved across, you know, many levels of the hierarchy.

01:39:09.500 --> 01:39:15.500
So, but we're still, it's very early days for really figuring out what the hell that's all about.

01:39:15.500 --> 01:39:21.500
It might be useful to mention that just the basic mechanisms of communication are pretty much the same.

01:39:21.500 --> 01:39:26.500
I mean, there's a large number of neurotransmitters that have been identified, but there's a couple of major ones,

01:39:26.500 --> 01:39:29.500
you know, glutamate and gala.

01:39:29.500 --> 01:39:33.500
And those are used all over the brain.

01:39:33.500 --> 01:39:36.500
So that allows them to communicate with another one.

01:39:36.500 --> 01:39:42.500
The other minor transmitters modulate that activity and they may act differently in different places

01:39:42.500 --> 01:39:48.500
to help produce the different types of, you know, functionality that exists in those different places.

01:39:48.500 --> 01:39:58.500
But the overall scheme is very much, you know, calcium transmission through ion channels is the same everywhere.

01:39:58.500 --> 01:40:03.500
I'm sorry, I mean, there's probably ten kinds of calcium channels, but you know what I mean?

01:40:03.500 --> 01:40:04.500
Right, right, right.

01:40:04.500 --> 01:40:07.500
It's the ion that sends signals.

01:40:07.500 --> 01:40:12.500
So that facilitates what you're asking about.

01:40:12.500 --> 01:40:20.500
Right, I guess just to crystallize, my question is, you know, if you have one unit over here and another unit over here,

01:40:20.500 --> 01:40:30.500
and they're similarly structured, you know, the brain's whole function is to communicate things to two different areas.

01:40:30.500 --> 01:40:36.500
And so, does that, I mean, since you guys know so much about this stuff, does that similarity in structure

01:40:36.500 --> 01:40:43.500
in different areas does it often facilitate the communication, or is that an unrelated thing?

01:40:43.500 --> 01:40:46.500
Is it just, I want to hear the frequency and...

01:40:46.500 --> 01:40:58.500
I mean, you can, I could sort of, I could sort of say, I mean, there are some theories that if one area doing something,

01:40:58.500 --> 01:41:05.500
for example, a famous theory is that one area is oscillating in a particular rhythm,

01:41:05.500 --> 01:41:11.500
and it's much better, it has a better chance of communicating with another area that has a similar type of oscillation.

01:41:11.500 --> 01:41:16.500
So I can say, you know, I don't know if that, I'm paraphrasing what you said there correctly or not,

01:41:16.500 --> 01:41:24.500
but there, you know, that's a, that's so-called binding theory, and there's other things like that.

01:41:24.500 --> 01:41:31.500
So yeah, I mean, you guys that are similarly firing are more likely to hook up together and communicate.

01:41:31.500 --> 01:41:41.500
And there's one other thought I have, it just, I mean, somebody, the big commonality that you see is this six-layer structure of the cells.

01:41:41.500 --> 01:41:49.500
And although we don't know exactly what it means, it's clear that sort of different kinds of input enter in different layers with different functions.

01:41:49.500 --> 01:41:55.500
So it's so-called feed-forward input comes into layer four, top-down input tends to come into layer one.

01:41:55.500 --> 01:42:03.500
So we don't, you know, we don't understand what that's about, but there is a commonality there,

01:42:03.500 --> 01:42:08.500
which probably means that, you know, anybody who sends an input into layer one of somebody else,

01:42:08.500 --> 01:42:12.500
that has a certain meaning as opposed to sending it into layer four of somebody else.

01:42:12.500 --> 01:42:14.500
So that's maybe a lot of the lines I'm thinking about.

01:42:14.500 --> 01:42:16.500
Yeah, that is, yeah, that helps. Thank you.

01:42:16.500 --> 01:42:17.500
Okay.

01:42:17.500 --> 01:42:20.500
I just wanted to comment on it since I'm here at the mic.

01:42:20.500 --> 01:42:30.500
The metaphor is another way that different parts of the brain communicate using this sensory language, like sharp cheese, lavender, you know, so you're getting it into play.

01:42:30.500 --> 01:42:36.500
My comment is about using mathematics to, for physiology and vice versa.

01:42:36.500 --> 01:42:44.500
And the question is when the architecture of the brain starts to tweak a little bit, like in multiple sclerosis, you lose some island.

01:42:44.500 --> 01:42:50.500
In autism, you have shorter connections as opposed to the long connections in the brain.

01:42:50.500 --> 01:42:55.500
You have more white matter as opposed to gray matter.

01:42:55.500 --> 01:43:01.500
In dyslexia, you have sort of a neurological junk drawer of cells that aren't aligned.

01:43:01.500 --> 01:43:05.500
Can you use this in your model to infer what must be going on?

01:43:05.500 --> 01:43:07.500
In other words, this is not working.

01:43:07.500 --> 01:43:11.500
And that helps your model to decide what does work.

01:43:11.500 --> 01:43:15.500
I think ultimately, yes.

01:43:15.500 --> 01:43:17.500
You have to sort of know enough.

01:43:17.500 --> 01:43:26.500
You have to have enough of a model of that particular phenomena that you then can begin to say, well, if I change this variable here, how's that going to change things?

01:43:26.500 --> 01:43:30.500
So, you know, if you're just completely in the dark, you're not going to get there yet.

01:43:30.500 --> 01:43:32.500
But I think in the long run, yes.

01:43:32.500 --> 01:43:37.500
Webbing, you know, because the smaller changes give you small behavioral changes, especially with demyel.

01:43:37.500 --> 01:43:41.500
So that's not necessarily true. Small changes don't always.

01:43:41.500 --> 01:43:46.500
Small changes don't always give you small changes in behavior.

01:43:46.500 --> 01:43:57.500
I mean, the cortex is very, parts of it are very tightly balanced and just small perturbations are enough to kick you into wildly different area.

01:43:57.500 --> 01:43:59.500
And that's why it's so hard to control it.

01:43:59.500 --> 01:44:07.500
So, but, yeah, I think I agree with Ken, and I think ultimately we're going to be able to use, you know, theory and things to say.

01:44:07.500 --> 01:44:16.500
Like, if what we do, we say, you know, if this happens, then why does this lead to this sort of broader, you know, phenomena?

01:44:16.500 --> 01:44:31.500
If we wreck this neuron, why do we get this kind of behavior? And that's where theory is very helpful.

01:44:31.500 --> 01:44:37.500
Directed initially at NED, of course, anyone else subsequent to that.

01:44:37.500 --> 01:44:46.500
My question is focused on the importance of the known differences between the predictive,

01:44:46.500 --> 01:44:54.500
respectively, the predictive and conformational values of a mathematical description of an observed system.

01:44:54.500 --> 01:44:57.500
Case in point would be Ptolemaic Cosmology.

01:44:57.500 --> 01:45:04.500
It was predictive in terms of the observed motions of stars and planets, but had nothing to do with the physical reality of what was being observed.

01:45:04.500 --> 01:45:09.500
You know, fixed shells with planetoids and so on embedded as points of light.

01:45:09.500 --> 01:45:17.500
More to the context at hand would be the Blue Vraine Project, where the columnar stack has been modeled mathematically,

01:45:17.500 --> 01:45:24.500
so that there is some allegiance to the input output signaling, but it says nothing about the physical structure,

01:45:24.500 --> 01:45:27.500
inherently about the physical structure of the columnar stack.

01:45:27.500 --> 01:45:35.500
So I wanted to ask that and others, is that important to a physicalist, such as myself it is,

01:45:35.500 --> 01:45:42.500
but how important to the value of a robust mathematical theory of the neocortex?

01:45:42.500 --> 01:45:49.500
Well, you know, there's a kind of platitude in this answer, which is, you know, this is a text,

01:45:49.500 --> 01:45:58.500
the Ptolemaic astronomy system is a textbook case of how prediction by curve fitting isn't much use.

01:45:58.500 --> 01:46:03.500
Prediction is impressive if you do it with a general theory.

01:46:03.500 --> 01:46:09.500
So, you know, the Copernican theory had a much better qualitative explanation,

01:46:09.500 --> 01:46:16.500
even though without adding in all that same extra stuff, it didn't do as well in prediction.

01:46:16.500 --> 01:46:24.500
So, yeah, prediction is really important, it gives you reason to believe that the theory that did the prediction is true,

01:46:24.500 --> 01:46:33.500
but it's no good if the way you got that whole system was just by sticking in all the data to begin with.

01:46:33.500 --> 01:46:41.500
So then where are we at with regards to a mathematical description of neurophysiology in the same capacity?

01:46:41.500 --> 01:46:45.500
Is it necessary for, and this has been touched on earlier and earlier questions and so on,

01:46:45.500 --> 01:46:48.500
but how critical is it that at some point, for example, with string theory,

01:46:48.500 --> 01:46:52.500
we don't know because we don't have the technology to investigate that level of scale just yet.

01:46:52.500 --> 01:46:54.500
Maybe a 14 giga-litre of the spectrum.

01:46:54.500 --> 01:46:59.500
I think everybody would agree that we're at a very early days in neuroscience,

01:46:59.500 --> 01:47:05.500
and we don't have a lot of the theoretical structure that will allow us to do the kind of explanation we want.

01:47:05.500 --> 01:47:08.500
We don't even really know what the units are.

01:47:08.500 --> 01:47:12.500
We don't have explanations of things like pattern recognition.

01:47:12.500 --> 01:47:19.500
We can do a lot, at certain levels we have a lot of predictive power,

01:47:19.500 --> 01:47:23.500
but I think we're nowhere near having a satisfactory account.

01:47:23.500 --> 01:47:32.500
I think there's always sort of a tension between the details of your predictions

01:47:32.500 --> 01:47:37.500
and sort of the extent to which you're getting the structure of things right.

01:47:37.500 --> 01:47:42.500
I mean, ultimately what you're looking for is you want to really generalize.

01:47:42.500 --> 01:47:47.500
You want to predict something that wasn't what you put in to begin with.

01:47:47.500 --> 01:47:52.500
You want to be capturing a structure that gives you new insight into stuff that wasn't what led you to start thinking about it.

01:47:52.500 --> 01:47:55.500
You're never in neurobiology right now.

01:47:55.500 --> 01:48:01.500
You're never going to get things quantitatively very precise because there's just too much stuff going on

01:48:01.500 --> 01:48:05.500
that you're not incorporating while you're trying to capture some basic relationships.

01:48:05.500 --> 01:48:10.500
And yet you can make a lot of qualitative, and to some extent quantitative predictions,

01:48:10.500 --> 01:48:18.500
that you can test and verify, but what you really want is the insight that gives you the guess the structure right

01:48:18.500 --> 01:48:22.500
so that you can generalize to new domains with it.

01:48:22.500 --> 01:48:25.500
Go ahead.

01:48:25.500 --> 01:48:34.500
From a different standpoint, I wonder if a more humanistic aspect of

01:48:34.500 --> 01:48:40.500
people can be explained with the models that have been discussed and explained here.

01:48:40.500 --> 01:48:53.500
For example, affect or emotion, why somebody will react to a particular event with joy, somebody else with sorrow,

01:48:53.500 --> 01:48:55.500
another person with anger.

01:48:55.500 --> 01:49:06.500
Can any of this be explained or predicted on the basis either a statistical mathematical model or a physicalistic model?

01:49:06.500 --> 01:49:09.500
Not today, but Sunday.

01:49:09.500 --> 01:49:13.500
Thank you.

01:49:13.500 --> 01:49:14.500
Let's stop.

01:49:14.500 --> 01:49:16.500
Let's take those.

01:49:16.500 --> 01:49:18.500
Oh, man.

01:49:18.500 --> 01:49:21.500
Certainly.

01:49:21.500 --> 01:49:22.500
Okay.

01:49:22.500 --> 01:49:23.500
Thank you.

01:49:23.500 --> 01:49:26.500
Thank you.

