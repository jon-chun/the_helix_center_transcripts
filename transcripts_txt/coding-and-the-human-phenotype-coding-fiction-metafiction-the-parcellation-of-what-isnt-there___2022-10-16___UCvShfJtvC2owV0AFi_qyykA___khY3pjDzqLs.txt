 Good afternoon, everyone. Welcome again to the Heilich Center. I'm Gerald Her with the Associate Director at Heilich. I want to invite everyone, rather, to our third roundtable of the day entitled, Coding Fiction, Metafiction, the Parcelation of What Isn't There. I'm going to take a moment just to describe the brief bios of our wonderful cast of participants. So first, Unina Hoffman is an Assistant Professor of English at the U.S. Murchin Marine Academy. Unita's research applies systems theory and phenomenology to 20th century literature and the global systems novel. Unina's first book, The Voices of David Foster Wallace, used concepts from narrative theory, rhetoric, and phenomenology to examine the experiences of reading through novelistic progression and narrative voices. Unina's new book project, Ending the Endless, examines the way that contemporary system novels understand the globe. Next is Peter A. Glor, who is a research scientist at the Center for the Collective Intelligence at MIT's Sloan School of Management, where he leads a 20-year project exploring collaborative innovation networks. He is also founder and chief creative officer of software company Galaxy Advisors and honorary professor at University of Cologne and at Gillian University in Chan-Chun, China. He also taught at Universidad Catarica in Santiago de Chile, Alta University Helsinki, and a few other universities I have a difficult time pronouncing. University of Applied Sciences, Northwestern Switzerland, and the University of Applied Sciences in Luzern. Earlier, he was a partner with Deloitte and PwC and a manager at UBS. He got his PhD in computer science from the University of Zurich and was a post-doc at the MIT lab for computer science. Mark Hanson is the David and Heli Gurley Brown professor of journalism and the director of the Brown Institute for Media Innovation at Columbia University. He's had over 20 years of collaborations with designers, architects, and artists, helping make work that has been exhibited in the Museum of Modern Art in New York, the Whitney Museum, the Centro Deart Rhinosophia, the London Science Museum, the Cartaget Foundation in Paris, and the lobbies of the New York Times building and the public theater in Manhattan. Hanson holds a BS in Applied Math in the University of California, Davis, and PhD in MA in Statistics from the University of California, Berkeley. Jonathan Kramnik is a Maynard Mack professor of English at Yale University. His research and teaching is in 18th century literature and philosophy, philosophical approaches to literature, and cognitive science and the arts. He's the author of three books, his new book Paper Minds, Literature and the Ecology of Consciousness, asks what distinctive knowledge that literary disciplines and literary form can contribute to discussions of perceptual consciousness, created and natural environments, and skilled engagement with the world. Questions have appeared in critical inquiry, representations, and elsewhere. Before that, actions and objects from Hobbes to Richardson's Stanford 2010 considered representations of mind and material objects along with theories of action during the long 18th century. Dr. Nikos A. Saligaros is professor of mathematics and architecture at the University of Texas at San Antonio, and internationally recognized architectural theorist and urbanist. His publications include the books, Algorithmic Sustainable Design, Anti-Architecture and Deconstruction, A Theory of Architecture, Principles of Urban Structure and Unified Architectural Theory, plus numerous scientific articles. He co-authored the Michael, with Michael Mahafie, the books designed for a living planet and a new patterned language for growing regions. Saligaros collaborated with the visionary architect Christopher Alexander over more than 20 years in editing Alexander's monumental, four volume book, The Nature of Order. I think I'll stop there. There's more to say about every one of these wonderful participants, and we'll get started with our talk. Okay, so this is a fairly broad topic I think, and I am amazed by the wide range of expertise we've assembled here today. So who wants to begin the narrative of this talk this evening? Why are we here? This is a conference on coding. Is there someone who can make sense of that relative to it? Oh, I have no idea what the topic is about, but it's fascinating, and the participants are fascinating people with fascinating expertise, so I was sort of waiting for a combustion effect of different ideas coming together. I was attracted to attend because of the link between coding and memes and literature, since I find many of the explanations I'm looking for in architectural design in literature, especially the topic literature, 1984 in a brave new world. I'll stop there. I'll add one more point. I guess my thinking about the subject heading was that there's the idea in coding and writing programs about narratives that it's fungible, that you can take it from here to there. It's all based on this code, and you can insert it wherever you want to create whatever effect you want, and it could be a literary effect, it could be from misinformation, which was the subject to our last roundtable. I could talk about coding because I was a coder at MIT 20 years ago, and I used to dream in hyper-talk, which was a programming language, and I still think today when I look at AI, that this is sort of the only field where people have their own language to communicate namely type v-steps for AI, and so I'm not sure whether there is other fields. I mean, in a sense, you have always liked the language of mathematics and so on, but for me, in software and in AI, I'm at the center for collective intelligence, and other level of collective intelligence, which is, you have this language that people use to communicate, which is called Python or some other programming language, and from my own experience, if you are totally immersed, now I'm useless as a coder, about 20 years ago, that's what I was hired, and you start reading and thinking in that programming language. But you can't do it, we're doing now in that programming language, I assume, this kind of communication. The gigs are, I mean, they are very introvert, and we have a hard time looking at each other into the AI. That's one of the problems when you are a coder. But I'm curious about the use of the word language here in the, you know, in the relationship to narrative, is what we're doing, we're a highly specialized human activity of communicating thoughts and meaning versus in spoken form, which then can take a kind of narrative shape. And I'm just wondering, I'm always wondered, like, you know, how much one can extend the meaning of the word language across those two different uses? Well, in my small startup, we are actually, you don't really need to have to talk too much anymore. But this other level of looking at each other and sharing the code seems to be enough sometimes. So in that sense, the collective intelligence seems to get to a higher level, that's my perception. I think it could be possible to have a conversation in code. It would just be a different kind of conversation because you would presumably have, it's not like you have language as this sort of flow, but rather you have the production of something that is encoded, it's a little bit more entrenched, the coded object, and then you put the code object out there and then someone else looks at it and then they write their own, which actually sounds a little bit to me like a historical model of what literature is like as well, that there is an encoded object that gets placed out there and then it does take a while, it's not this. But it seems similar. I was thinking that the idea of a metaphiction where you will cite one work of literature within the body of a second of work of literature is you're sort of lifting it, appropriating it, commodifying it in some way, and I think that coding is just rich for that reason, whether or not it's rich in a good way or not is a different question, but that sort of, I'm calling you the fungibility of those codes and the sort of narratives that can be taken out here and put over there reminds me of a metaphiction. I'm a little worried with the transition from coding to language because coding is a language spoken only by people who know how to code, whereas language should be understandable by other people, otherwise you cannot communicate. If you write something in a computer language and you give it to the ordinary person, it's meaningless. So I say two entirely different concepts here and I don't see how they can get mixed. For something to be useful to society in literature, I think it has to have a language that's universally available and a language that is even translatable, say from English, to finish. But if you write something in Python, it cannot be translated into a minutes for a spoken language. That was my point. I have some of the similar reservations as you do in the codes around some of these questions about how applicable it is across communities and then also about how helpful it is for our understanding of human cultures, written and spoken and aesthetic artifacts to think of them in terms of the language of the sticking from computer science, which has a ton of money and cultural power behind it, but you might not have as much explanatory force behind it. I think part of what Unina was suggesting is maybe thinking about it the other way around, which is that there's something literary about the computer world, but that would make it that notion of language and narrative more parasitic on what we're doing here and also the way in which many other people live their lives and practice their communicative acts and also spend time with works of art, aesthetic practices and acts as well. You might have heard of TPT-3, which is the biggest AI system available, which basically allows you to describe in English what software is supposed to do. That means you can have your English story and then convert that into executable code, but what I have been thinking more recently about the singularity, which basically means AI taking over, that basically means that we would have to somehow communicate and the question then is who is in the driver sitting in the end? Is it intelligence? Yes, the person who can pull the plug is in the driver's seat. That's the only way we'll save us from catastrophe. There's something common between code. I think the idea that coding itself may be a form of literature is not something that reminds me that musical notation is also something that many people don't know how to read. Oh, sorry. Yeah. Sorry about that. Musical notation is something that most people don't know how to read, but it does create a sort of, some people refer to as a sort of universal language, its production, its execution creates a kind of language. I think that's the sort of level at which maybe coding might apply. And again, I guess I would contribute to this. One is that in reading code, right, in picking up a piece of code and having a look at it, and I know this is, well, anyway, there can be moments of beauty in it in the same way that there are moments of beauty in reading a mathematical proof or something like that, right, that there is an aesthetic sense that someone can look at it and go, wow, what you did here? Oh, look, that little trip, that's amazing, right? So there is an aesthetic sense that comes along with it. I think the second thing is that in my mind, the previous discussion was a little bit upside down. I think that coded systems are creating, organizing into systems of power in our world, and part of the reason why they've gotten away with, and that they are as powerful as they are, is that there is this gap between the language that we are using to communicate and code, right, the fact that people don't understand how computer works is a problem, right, the fact that they don't understand the basics of meaning a lot of reverb, and that makes me nervous, like I'm saying, something awful. But the fact that people don't understand, you know, the suggest then that it's difficult to be, let's say, a responsible citizen, right, in our contemporary political or cultural setting, because we need to understand the basics of how a computer works, I think, and something of how code works, right, so I think that not having that access to that language is leaving us open to a lot of difficulties that we've seen. That's an interesting proposition, Mark. I mean, one year's all the time that we need basic scientific literacy, and I agree with that just as an article of fate, but it's a problem, and we've seen all too clearly in the last couple years, that it's a huge problem that when citizens lack kind of fundamental scientific literacy about the nature of things like what's the interesting climate and whether, you know, how do the dens work, that sort of stuff. It seems, however, that like, how it is that code works and the computer works seems to be a different kind of thing in a way that, I don't know how a plane works, I get in the plane to fly, just flew, you know, across the country last week. I have my iPhone and my computer, I feel, are sort of analogous to that in a way. I'm curious in how the argument is that there is something sort of threatening to democracy or wrong about not having a citizen, not having a capacity for coding, because it doesn't seem to me to be intuitive in the same way that say there's a real problem when people don't have access to science or don't understand the way that science works. I mean, I feel, first of all, there's an increase in which science itself is computational and it is inheriting, this is driving me crazy, and it's inheriting, yeah, that's a problem. I think what I'm suggesting, and I don't think it's either earth shattering or new, the founder of Python or the gentleman who created it has a very long essay talking, I guess it was a darker proposal or something about creating a programming language and the title of it was programming for everyone. And the idea is simply that we teach everyone to read and write, even though we don't expect them to become poets and writers, and by the same token we should teach everyone to code to understand programming or the act of it, because otherwise we are significantly removed from the technological systems that we rely on. And I would say that saying that this is a shiny box that we interact with and I don't really have to know how it works means that now I'm cut off from all the little things that it could do in terms of surveillance and other things. I don't have the capacity to ask questions about what this is doing. And my capacity, the fact that I don't have capacity to ask questions means that there are significant systems of power in our world that are just happily going along doing their thing. And with my position in journalism school, I feel like the one thing that I can offer them is access to the way these systems start to work, the way power builds up in a technological system and some of that can start with something as modest as learning how to code. It says my opinion. I totally agree with what you say in the sense that if computers or the phone were perfect and there would be no bad people on the world, we wouldn't need to know how to code because it would trust in everything would work but unfortunately there is peace and so on. And... Right, no, I get that. I feel like I have the same suspicion about what my phone is doing and tracking and the threats to democracy there and also just the general modification of everything that happens there. And yet I don't know the infrastructure of how it's encoded. And I guess I'm wondering about the connection from the state is a bit far away from questions of narrative perhaps but still seems important to pursue. How we move from the one level of implementation to another and would in fact knowing something about coding give me an additional capacity for resisting the ways in which my phone may or may not be tracking what I'm doing and so forth. I think you could bring that pretty easily back to literature. Great. Because I mean really what are we doing here? We're asking in any object or in any phenomenon of human life what is encoded and why. And in the phone there are some things that are encoded that allow us to use the phone for our purposes but there are some things that are encoded in the phone that allow counter purposes or silent surveillance type purposes but the same is true for a novel. I mean there are certain things that are encoded that are for the purposes of enjoyment and there are other things that are encoded ideologies for the purposes of something perhaps behind the scenes. And so I mean yes we teach people to read and to write but do we teach at them very well to see the sort of broader context of power within what they are reading and writing. Maybe that is something that they also need to know. Oh for sure and thank you for putting it that way and you know that's really perfect because like it extends Mark's initial point about questions of pedagogy. And the importance of sustaining not just kind of basic level computational pedagogy as well as teaching and sort of fundamentals of science but also humanistic pedagogy. And what it means to understand our culture from a more traditional humanistic perspective for these kinds of reasons. May I disagree with all that has been said up until now I don't think the solution to saving our civilization is for people to learn how to code and to actually be able to code the cell phone. Because I believe that that actually pushes them in the direction of being embraced by technology while technology is subjugating the free spirit and taking people away from reading literature so that literature has decreasing value because people are not reading. People are looking at their cell phone all the time. So pushing them to learn the code of the cell phone is not going to steer society away from a total dependence and a total domination by the big tech companies that are taking over their lives. Taking them away from looking at art, listening to music and reading literature. Today's literature or the classical literature. It's all going, going, going, going. So Nick was I then saying we should take away the self-part of everybody and not keep on anymore and put some well-class literature on their own. Well there's been an effort to, and I'm not so sure I think it will work. So I don't want to say I'm advocating this, but there's a movement toward all right well we're going to take coding and have it write for stories. I'm not still in the future a little bit but one of our talks tomorrow on the general GPT-4. GPT-4 is the next GPT-4. Yeah, GPT-4 is the next GPT-4. Yeah, GPT-4 is the next GPT-4. Yeah, we'll talk about that and the ability of a computer program to write a story, let's say. Now again I'm not advocating for it, but it's happening or it's being developed. There's an interesting I think trope about that which is, and this I think speaks to your criticism although it doesn't invalidate it at all. Namely we find that a little creepy. Like I'm reading a story but there's really like a text beneath that that's the real story right? And that's a, look that's in a lot of horror stories about the how 9,000 computer right? But that's a great point. Why do you find it's creepy because you don't know what's going on? If you knew and that's the same as with why I don't want to get the vaccine because I don't trust the vaccine that it's not messing up my body because I don't know what's going on. But then you are back to the argument. If you know how to code perhaps you know what's going on and then you don't think it's creepy if you get the phone. So you can blame literature for what fostering this trope about the weakness of computer projects. We have to be ever heard of the, you know, in the world that you need an iron in without, you know, agreeing with Nico's point, you know, just quite quickly which is, you know, people should be reading works of literature and encountering works of art. I think, I mean, I think that's so compatible entirely with more people knowing more about how to code. I mean, it's, which is just to say that people should know as much as they can about the world. And I think from the perspective of the humanities, we often feel like our sector of the world, which is as real and as important as anything else, is just not drawing as much attention and it doesn't have the same kind of purchase within the university or among the young or getting, have as much support from higher educational establishment as it used to. So it's, again, it's hard not to feel like these conversations are sometimes weighted against a more sort of aesthetically oriented view of the world and the kind of capacities for flourishing and democracy that they can bring. And this speaks to the point that you just raised about, you know, the future of computers writing works of literature, which, you know, is an interesting thing to contemplate. I've read some of the earliest stuff there, just like I've seen some of the computer art that's been generated in the visual domain and it's all interesting and provocative. There's nothing wrong with it as such. What can be sometimes troubling about it is when it's bundled together into a kind of reform picture or, say, higher education in a democratic society in which it is, you know, deemed to be like the future. And then it just becomes, you know, to me at least, and I think, you know, for reasons that are real and just kind of ugly. Not ugly as such. There's nothing wrong with computers writing stories. That's, again, interesting. Ugly in some of the directions that that's pushed and some of the kind of like wide-eyed, sort of like belated, alvin, pufflerism that it's sort of, you know, made to serve. Like the future is here. It looks like computers writing stories. We need to put all of our money there and we need to basically just, you know, starve the people who want to just sit around a table like this and talk about a book. And that way lies, I think, you know, kind of disaster. So obviously the sort of the idea that we teach people to code is not just, all right, and we'll teach them basic and we'll hear as a variable and we'll assign it the number five and we can add two to it and then we can do it. Like, that's when I describe or when I think about or when in my classes we talk about how computation works. You know, there's a well-defined notion of what we're looking at or at least what I've tried to put across in terms of computational literacy, right? The step one is that coding step, like the functional literacy, how does it work? Then there's a critical literacy, right? The idea that you have enough capacity to say why does this look the way it does, right? I mean, technology relentlessly tries to make itself look invisible, right? So it's not there and so we want to have the capacity to say there's something here and why does it look that way? Could it look some other way? So there's functional literacy, there is critical literacy and then a rhetorical literacy, right? Which is that all of these things are, there is no, you know, optimal iPhone, right? It's a thing and it comes from human deliberation and it's a settling in some way. And it itself gives off and kind of has a rhetorical function, right? Again, it makes us feel modern, it makes us feel connected or something like that. So you can deepen all of these concepts and they depend in many ways on sort of humanity-style interpretation, right? I bring in to my class people like Joanna Drucker or something who, you know, makes the point about data versus capta, what is given versus what is taken, right? Like, like, that these things make the teaching of code, right? A richer, fuller experience so that people do come away or presumably students do come away better understanding the systems of power that circulate around technologies in one form or other. And for someone in a journalism school, that's important because journalists are the experts and explainers of last resort in our society and if they can't call shenanigans on something that's happening, then I don't know who's going to do it. Yeah, I'm afraid journalists have been singularly unsuccessful in alerting the world to all the bad things and the manipulations that are occurring by- I would say it's extremely- The next extreme- The next extreme- The harsh, harsh comment. And extreme, yeah, sure. Yeah, okay, I said. I want to answer to the challenge that Peter threw at me as in response to my early comment, Peter, you said that therefore we should make people appreciate literature and art better, but nobody can make anybody do anything. The only way you can make someone do something is by tricking them into thinking that they're getting an advantage by doing something. So all the technologies that we have has tricked us by offering some utility for our lives. That's why we have adopted it. So becoming slaves to the technology was a step-by-step process because it gave us the power, increased power, and we felt that. So the only way to get someone to study literature today is to make it advantageous in an evolutionary sense. If you do this, then you get an advantage, a evolutionary advantage. And not by the academic. You have to take this course because it's required. Yes, but I mean, thank you very much for throwing the ball back to me. But I think you are neglecting one point and that's beauty because what you raise is a very cynical utilitarian view and that's unfortunately the main motivation, particularly in capitalist societies. Then there's this other aspect that I think it has been raised and if you look at pieces of world art, and I'm not sure whether a computer will actually ever get there because TPT-3, it can write something that sounds like a reporter or a lot of string and so on. But it will never be, or even if you go to some higher level literature on the same level. On to now. Perhaps it will come at one point, but I'm not sure. Well, is there something that you could say or can we itemize a number of things that we believe really distinguishes literature from anything that might be available through coding? Yes. Is there a way to itemize that? I mean, I was about to pick up on that. I wanted to respond to Peter's comment about we don't understand how it works and therefore we're afraid because I actually think that frequently I don't know how a piece of literature works, but that is the cause for wonder and delight rather than fear. And that is because I think the distinguishing fact of a piece of literature from something that might be encoded for utilitarian purposes is that it's okay for something like literature to give us something we understand, something that exceeds us and something that is so saturated with meaning that it can't be reduced to a single, perposive goal. And that this kind of brings us back to a point that was coming up in earlier conversations, the question of trust because the unique compact, I think rhetorically between reader and author is ideally one of trust whereby the question of trust is a very different issue when we look at code because we know that the person who is encoding something has perhaps more defined purposes than the literary author. But just to disagree about one thing for myself, Finnegan's Wake scares the daylights out of him. That's because it shows you something about yourself you don't want to admit. It's a great thing. This is a rather pedestrian response, but for many people that I know, especially younger people, and people who have leading disorders for instance, the phone is their lifeline to literature because they're listening to books on tape, they're listening to audio books. And for someone who's been dyslexic all their lives, it's like a whole world opens up to them. And for many people who are very busy, I'm in the world of literature all the time. If I'm walking in Central Park, I'm listening to a novel. It's the only time I have to go into fiction rather than professional books. And that's through this little device. And among the young who spend most of their time on social media, there's a lot of feedback between online activity and staring at your phone and then also reading, which is a lot of active book talk on TikTok, for example, which is all about the analog object. It's not about the small shiny thing. And in fact features usually have the aesthetics of books, what they look like, how they feel in your hands. And they'll show it, I've been reading this, etc. So in fact, it's not just a dichotomous phenomena. It's the digital world and the handheld world and the social media world has created a renewed interest in literary artifacts and objects as it has and painted and sculpted ones as well. Things that exist, however, off your phone, not that you're listening to as you're walking through Central Park, but as you're also just sitting and holding your hand as reading. And I think that's, first of all, terrific. I think it's an interesting cultural phenomenon in its own right. But I also think it shows the viability and the prudence of the aesthetic domain as something that has both a purchase on an appeal to humanity across the board, but also is worth cultivating and spending time with and supporting ultimately. You've got to listen to something and then I will go by the book. And what I mostly was converted by was Finnegan's Wake. Listening to Finnegan's Wake is a true adventure. Well, I should definitely see all of that. I want to return to you in his response because even though I made fun of the Finnegan's Wake and fear, I like the idea that you mentioned trust. I think that it's interesting that when I ask the question, all right, well, can we start itemized differences between coding generated? Art, not even just literature and literature. You said something about trust, which I think is a wonderful sort of, it's an emotion. It's an emotion. You're expressing an emotional thought. So far everyone else has made instrumental arguments about it. As a psychiatrist, I like hearing, okay, so what about how are you feeling about this and where does the feeling that is evoked by art, is that matchable? Can we match that? Because I think you're right. You might be honest, something trust, it would be hard to earn it out of a machine. So perhaps how does it bother an art drive? Because if you look at Lord of the Ring, the original one, it was huge success. And that sequel that Disney has been producing, the reception was horrible, because they were just applying all the formalized things, so that means they didn't get the trust. Is that what you would say? Do you mean the movie adaptation? Yes, exactly. Oh, I see. So the movie adaptations to the sequels failed to earn trust because they were too formalized according to the cinematic industry. Yes, they were too robotic. They were too robotic. But they were just applying some formulas. And so that seems to me an example of what you said, but I'm not an expert in answer you. I would say that probably sounds right, because viewers of media are pretty savvy to tropes. And yeah, I remember seeing the Lord of the Rings the second movie, and it's just trope after trope kind of piled on each other, which feels like it falls short of the kind of meaning saturation that I want from a single other human being. I don't know if that answers your question. The good question also was initially, like, would, can we imagine a novel written entirely by a computer as appealing as a novel written by a human being? I think if you assume time and exponentially increasing computer power, I have no difficulty really imagining that. And no strong feelings either way. Well, okay, well then, why would it be difficult for, let's say, it would be a challenge. What are they surmounting to meet that challenge, right? There's something, anything that requires human intelligence to create. And what's difficult about that, I think it's probably Peter's domain, or maybe Mark more than mine. But I think it's, you know, it would be an analogous problem to anything that requires, again, human intelligence to do, whether or not that's write a novel or drive a car or make scrambled eggs for you in the morning. All of which have been really hard things to do. I mean, it seems to me the most powerful advances in artificial intelligence, as far as I know, and that's very little, have been in, you know, kind of narrow but deep domains. A chance. A chance, for example, sort of power, but radically so, I suppose. Anything that involves, like, as many factors as, you know, would go into writing an novel or again, you know, making you scrambled eggs in the morning, is going to be much harder to do but not inconceivable. So, Magnus Nielsen, the reigning Carlson. Carlson, thank you. He walked out on this match because I think something about the first several moves and because of some previous report that his opponent made cheap. Something about his body, this is opening with, that's it. A human wouldn't do this, I know you're cheap, right? So here you have, no, but that actually wasn't that intuitive that a human wouldn't do it. That human would be cheap. No, no, I think. He was using a computer. Oh, I see that. He recognized that the movement was cheap in chess. He recognized the judges being generated by a robot. And so, it's interesting, so here you have something that's gotten right to the pinnacle of computer programming and beating humans and it does beat humans. But it's missing something from the perspective of human observers. It's missing something, right? Carlson was able to pick that up, it seems. But when they'll go to chess for that, that was solved in the game of Go several years ago. Because Go became, the deep mind became the Go champion. Right, but I'm saying there's still things that humans perceive about the difference between their opponent when it's a human versus a, it's a human versus a computer. And I'm wondering if that perception has something to do with what we would find deficient in a computer generated work of the literature. That's what I'm getting at. Yeah, for sure. And I'm out of the screen with you, maybe even in the very far-efficient future, even that difference would be taken away. In the visual arts where I have more experience being a painter in my youth, in the visual arts, AI can produce paintings today that are better than the professional visual artists. I think we have reached that. I cannot speak about AI generated literature. But the AI generated paintings, depending on what text to image AI programs can generate very beautiful paintings because they sum the opinions of individuals, say, 10 to the 10th number of individuals, which is an extraordinary number. So they can generate a very beautiful painting and you go to a contemporary art gallery, it's mostly garbage. So there's a huge disconnect between what the computers are generating or what are the so-called artists are generating. The Detroit Museum of Art has a new exhibition of Van Gogh and they did it because they were the first American Museum to embrace Van Gogh. And the reviewers in America, the armory show said this guy's dance is terrible, of course he's about that. He's about the most popular artists, visual arts now. That's a trajectory that some human artists have pursued and we would say, well that's a form of imagination, innovation. That's incorrect. That's incorrect. That is propaganda in order for a certain click to make enormous amounts of money by selling garbage and by promoting talentless charlatans. But somebody... What you are saying is totally out of date because it happened 100 years ago. I don't agree with your extrapolation that what happened to Van Gogh, the same thing happened to the Impressionist in Paris that totally extrapolated to the garbage we see produced today and put in art galleries and displacing beautiful works of art from our museums. The Museum's decommissioned wonderful pieces of art and sculpture and fill it with contemporary art that's supposed to be art but it's really garbage. And there's a definition. And here's an AI conjugge where there's garbage for where the bits are because AI has this attempt to the tense, a piece of data of human reactions. Does this create a positive emotional reaction in the body? And we have the sensors and the medical data to see if it creates distress then it's a piece of garbage. If it creates a positive healing reaction according to the movie, medical sensors that can be worn today, is that what we're having to go to the laboratory, wearable sensors if it's positive then it's a valid piece of art because it helps you to cope with the stress. This is... This is... Sorry. Another example I suppose of we're not knowing how a computer functions and not knowing how something works leads you to a kind of crazy conclusion. And I'm assuming the way you were saying this meant ironically because the AI... First of all, Dolly doesn't work by hooking up responses or anything like that. But suppose it did the idea that a set of measurements, what are we going to measure to capture our aesthetic reaction? What are we going to choose? How are we going to choose to measure that? How are we going to choose to measure that? I'm going to put some... Hold on a second. So first of all, there are choices in what to choose to represent lived experience and to even... To stop and to think that there are choices. There are different ways of expressing it. Do you talk to someone before seeing something and then interview them afterwards? It's a little more qualitative but is that something? Like why do we reduce it to a kind of physiological response first of all? And secondly, what Dolly does is it's based on sort of collections of data where captions are matched with images. And the obvious question around almost all AI processes now are like what are the data that they were trained on? Who are the people who even if they were hooked up in some way? Who are they? What cultural references do they have? What are you showing them that's consistent or not? And I think that some of this discussion is what we're missing here is it's sort of not AI versus the artist. It's sort of AI and the artist, right? If you've tried Dolly, you can type something out and put some text in and get an image and go, well, that's not really what I'd like. And so you alter a little bit and you alter a little bit and you alter a little bit and you sort of start to work with it, right? I think to go back to the literacy and then I'll shut up, but to go to the literacy question one more time, that idea that you're typing something into Dolly to get an image and then typing something else and to get an image, slowly Dolly is training you to do what it expects so that you get the answer that you want in the exact same way that when you Google something, right, and if you don't get back the set of results that you want, you don't say bad Google, you say, oh, I did something wrong. And in that moment, Google is training you how to interact with it. And if you don't recognize those training moments, little by little, right, that's how the systems of power work. That's how things start to take to exercise control in a way. Sorry. What are you saying Mark? We are already going there. Exactly. There's no question. Our students don't have that connection, right? They don't have Google more than my own. Also the, yeah, then in return to Nikos' point, I mean, here I think I disagree entirely. I mean, in the sense, but with you. I think that first of all, I mean, I don't believe that you could actually hook people up and get a picture of what their responses to works of art are. But you could get a set of correlations. What they would tell you is actually an entirely debatable phenomenon or question. But, yes, of course you can record what's happening at various levels of your somatic reaction when you were presented with an art object or anything else. Whether that tells you anything meaningful is another question. So that's one thing, even if you could, I mean the assumption that for work of art to be beautiful, what it does is make you feel calm and happier, whatever your phrase was. That also seems to me to be like just, you know, wrong. And that, you know, what you call bad art would produce a somatic response of like irritation or something else. And that that somehow indicates the poor quality of the work also just seems to be wrong. But there's a set of nested assumptions here about what kind of response art works ought to have, whether they're producing you that I think are debatable about whether or not actually like, you know, whether the criterion of judgment ought to lie, whether it should be in, you know, in just an immediate response by someone who has no relationship or education in how to encounter and understand works of art or should be among those who have actually spent time with and are educated in art and art history. All those things are actually to be discussed and debated. So I mean, and again, provide an argument for, it seems to me actually, to return to our earlier discussion, you know, fundamental artistic and aesthetic literacy. Because it's not the case that you can just simply like take someone, you know, and put them in a museum and they will understand what it means to actually look at, you know, a van Gogh, for example, to use a painter that was mentioned earlier or the works of the French impressionist or let alone a more difficult and challenging working contemporary art. And all those things actually require, you know, discussion, education, learning, you know, experience which, you know, ought to be available to as many people as possible. Well, actually, Charlie, we have exactly done that experiment. In Cologne, in the Kedekolis Museum, this year is one of the tools we developed at MIT. It's the happy meter. It measures my mood based on the habits. Sorry, there's something so dystopian and frightening about the expression. There's a lot of people in the papers about that. It has been used. It measures my happiness based on heart rate, acceleration, voice emotion. And in the Kedekolis Museum in Cologne, we have given that to participants, to people. And then we have measured which rooms, which paintings and which sort of watching style actually trigger the strongest emotional reaction. And what is the result? The result is that it very much matters on the tool guide. On the tool guide? Yeah, which is to say, which actually, which is part of what I was saying earlier, which actually depends partly on how the work is presented. Exactly. So, like, you know, how each piece of art is present. And, well, and also, you know, how, even in a very quick way, how the person viewing the work of art, you know, is led into it. It's led to understand it. And, you know, how that person has been taught. So, it's entirely, it seems to me, like, obvious and arguably so, that if someone is actually shown through a museum, thereby an educated, you know, articulate personable tour guide, they will have, they'll be happier on your happy meter because they will actually just be able to understand what they're seeing a bit more. That makes another point about context. The context is always, because if you look at the Mona Lisa, the context is, I have this expectation and I see that sort of vaguely interesting face, but because in East Mona Lisa, I must feel this is the biggest piece of art on the world. So, the context has already been said, and I'm sure I have never done that with happy meter, but I would expect that I would get such a reaction. I would like to clarify tremendous confusions here that have been thrown at the table. I was referring to unconscious reaction of the human body based on the happy meter, exactly those wearable sensors, but unconscious responses of the body without priming and they occur within the first one second or even few milliseconds. Whereas, if you explain the art, you are conditioning the individual to like something. The second point is that when you are looking at the context of 100 people from the Mona Lisa, of course you have to like it. So, control and spur, and it has to be carried out with the individual measuring only the first, the second or less of unconscious reaction. But this, again, I just think that's a wrong understanding or a misguided understanding about what's the issue, but that's an opinion. Wait, but there's a different point I think. Of course, and we have a different opinion. I just wanted to explore that difference because I think it's an interesting one, which is that there is on the one hand a model, which actually has some real history, historical significance to it, that what aesthetic experience is all about is just like this raw, unschooled, immediate thing where you just bring someone in and you show them something. I don't think that's really the way that art tends to work. We're talking about something very, very recent, these measurements. Yes, I know we're talking about technology that's recent, but we're also talking about an understanding about what art is that goes way back. And actually, we have one of many of them, a millennial understanding what art is, and we have contradictory opinions during millennia. So that doesn't settle anything. But what I'm proposing is that these recent technology actually settles the issue because it matters positive body responses. And here's what I disagree with you because you want to validate equally a work of art that creates negative and stressful body responses. I disagree with that. I think that the purpose of art is to help in healing the human body because the human body experiences daily stress, just from the act of living. So what about where the phrase, which is that art should disturb the comfortable and comfort that is disturbed? Why can't we have both? I'd like to be disturbed. Yes. Well, it should be interesting in a lot of words that are interesting. But I think what's been lost here, and I was surprised, Niko, that you took the direction you did, given that the first point you seemed to make was coding and computers are negative, and we should be immersing ourselves in literature and art. And I actually was trying to point out that maybe there are things that coding cannot possibly provide, like for example, whether or not they produce really beautiful paintings, there may yet be something that's missing. I think it's wrong to conclude that when people say they don't mind being disturbed by art, that the whole point of art and the end point of art is to be disturbed, I mentioned Van Gogh because there was a point in the history when he disturbed some people, and now most people I'm sure have happy meters going wild when they see him, right? And that trajectory, that development is a wonderful thing about humanism, right? And I don't see that in computers, that's the thing. The computers can take a huge sampling of people's reactions and look at different works of art that are considered wonderful by experts or not, and it could generate another monoliths, perhaps. But when it comes to being equal to an artist who can create innovation, that may put us off kilter a little bit, but then later we learned a lot of that's something I think I believe computers are not going to be able to do for a long, long time, if at all. Why? I don't know, I was asking all of you, you're the expert. What would I mean, you said you believed, but why? Well, I got thrown into this loop because he started telling me why they could do that. Okay, great. First you were, yeah. You're hung up on Frank Hock, who according to the 17th, 18th century sensibility of realism, disturbs some people, but the colors are very beautiful and it's slightly disturbing, but not as disturbing as the garbage we have seen later, that really creates anxiety, measurable by the happy meter, okay? Without an explanation, but our art schools have been teaching students that the goal of contemporary art for the last several decades is to disturb and create anxiety, which I think is so neuro. And here is where, here is where I think I would like to put two things together. I mentioned earlier that healing comes to the body, not by looking at code, but by looking at beauty. But if we go according to accepted contemporary standards of beauty, we can disturb because it creates anxiety, it's not beautiful, it has switched the function of beauty. And now only computers can tell you what's beautiful. See, I would prefer not to debate that particular point further because it's a great topic. And I'm not arguing, I don't want to argue about it. I don't think we should be debating that any longer because the real issue is the one I'm trying to direct us to, which is, let's imagine that there's this wonderful facsimile and it may be superior to what the garbage that they're putting out of art schools now. That's okay, I'll accept that. What is it that, is it still the case that there is some, is there some spirit in human creativity that the computers will or will not be able to produce? And you think, Jonathan, that they will be able to eventually produce that? I don't think I have any idea. I mean, I wouldn't rule it out, I guess what I would say. I mean, like, doesn't seem to be any, it seems to be par for the course for any complicated human creative activity. And therefore, it's a problem for, again, like, Peter's world to solve. But it doesn't seem to me to be, like, intractable. I think that's the, I think part of the thing, I myself feel a little bit confused with parts of this discussion. Because we are talking about, on the one hand, what is today, then we are talking about what AI is going to do in the future. And whether it's going to do that or not, is AI going to be able to produce a work of literature or art that in any way is going to contain all of the emotions that are presently in the work of literature or in the work of art? And all the personal experiences of the person who wrote it or who painted it is AI. One day going to be able to do that, you may be have the answer to that, but as far as I know, we don't know yet. So there are people who write about all the things that AI is going to do in the next 25, 50 years, such as Max Tegmark and others. But we'll have to wait and see. But so I don't see how that directly connects with the bigger or more general subject, which is coding. Coding is not only about creating literature or art, it's also about all the positives that we have from being able to use the computer, the iPhone and so on. Yes, there are of course plenty of negatives. One of our people who was here in the audience, a neuroscientist from Italy, was telling me how his son doesn't want to read anything because he's looking at his computer. He said, my grandson isn't the same one. He said, my grandson doesn't want to read his constitution. Yes, there are negatives, but there are also plenty of positives in terms of people being in contact with each other, being in touch with each other. So I'm a little bit confused if you will about the direction that we are taking. And as far as art goes, I think the example you gave of the, was it in cold experiment with the heart rate and so on? In the cold experiment in the Kedakolis Museum. Yes, so I think that already gives you an indication that wherever that research is nowhere near reality, if you are going to a museum and there are five paintings, one next to each other, and you have somebody explaining it to you, what you are reacting to is not really that much the painting as what the person is telling you. Now, and that's why I feel when I go to a museum, a big part of it is a waste of time because I'm seeing so many things one after the other by the time I come out, I don't know what I've really seen. If I see in front of one art and I spent ten minutes in front of it, I begin to appreciate and feel something that I can never feel walking through a museum. So to test me just because I think that this is a very exciting color, he put it here especially because he does this and that doesn't tell me anything about the art or the ability of that particular feeling machine to assess anything. It's too early for it. Actually, it's not too early and it's just that I didn't get the idea and I have to thank me because for giving me the idea of having people doing exactly exactly experiment you described by exposing them to different pieces of art to compare which one is the best. But let me just say this because I want to say this clearly. If you're criteria for what is the best is a measurable response of happiness, you're going to get a lot of shit. Just a lot of fucking bad art and bad literature especially. So again, I would just disagree with the basic premise. We will support this premise that you disagree with if they are unconscious responses. Unconscious or not? It's just a bit of a ton of shit. If it's unconscious, it's the body using its evolved mechanism that helped in its survival and if it identifies positively with the art, then it's a positive response that's good for the health. If it has to be explained and then you are conditioning. No, I'm not talking about it. In fact, I think probably most art that I would find interesting you have to have training to appreciate and understand and I think most art that produces that kind of evolved health response you're talking about is going to be crap. We have a opposite opinion and we disagree violently. I think Mark's happy meter is going to get too low for all of us. It feels too close to a mood ring. There is a moment that we can pop this up and talk about narrative for a second. Think about the ways in which we are taking physiological data, whether we should be doing that or not or instantaneous or not, the idea that the AI optimizes something. The narrative that comes along with it, there is an efficiency there in applying the AI. There is an efficiency that comes along with it that we can make better things that are soothing to us or pointed to the progression. That's a very common AI rationale, a very common narrative that goes along with applying an AI system. It makes it hard to unpack and say, well, what are the problems here? Where are the disparities? To say that it's more efficient to whom and to, you know, are the physiological observations sort of steady across different race and gender characterizations and so on. You have to kind of resist that narrative that says that AI is optimizing something. The other thing I would say to the gentleman with his grandson, we say that, pardon? Hold your son. It's quite satisfying. I would say that we say that they kiss her on their phones all the time, right? We say that means that they're really good at computers because they're not good at computers. They're good at learning other people's interfaces. They're good at learning the choices that other people have made. Because they don't recognize anything of that surface as being a choice, right, that this means zoom in and this means zoom out. Somebody made that choice and it wasn't the student working at it. And we have to be able to question those choices, right, and I feel like a citizenry that doesn't have access to the basic ways in which computer design works and computers work can't do that. Yeah, and I agree entirely. The conversation that we were just having about, you know, measuring somatic responses and this connection to artificial intelligence reminds me of just like the FAD 10 years ago, the Vittorio remember very well of just using fMRI to settle all questions. This lights up, that lights up, you know, therefore, you know, this can explain for us ex or wife phenomena in politics or the world or whatever. And that had all the problems that you just identified, Mark and that Vittorio knows very well. FMRI experiments were a good pioneering step in the right direction because they did settle some questions of beauty. The problem is that FMRI is hugely inconvenient, but we're talking about a new generation, but it's a wearable sensor. Yeah, because you can have thousands. The N, FMRI is very small because it's so expensive and here you can, I mean, I have been measuring emotions for the last three years. The phase emotion, voice emotion. The last thing is that we have plans which are highly sensitive movement sensors and we take the electrostatic discharge and then we measure emotions of humans from the plant response. That's totally privacy respecting. Well, but, okay, so Nikas, you use this idea that the goal of art should be to be soothing or to help. I didn't say soothing, I say. Inducive to human health. Okay. Physiological condition. Perfectly good. Perfectly good. Okay. Now, so I feel happier in front of a beautiful painting and I'm sure I do. Now, however, feeling happy on what time scale. You know, one of the whole points about mental health, for example, people who are troubled by their own mental health is that they need to oftentimes go into some form of treatment. They get psychotherapy and they talk about their problems and they may sit with their therapist and say, oh, I love this therapist. What a great therapist they're going to make. I feel so happy when I'm with them and then a month later they think this person doesn't like me. I don't understand. And they keep going, hopefully, and keep going and talking. And they work through that and it involves trust to go back to your comment, you know, there's a trust between two human beings and over time the feeling of happiness or contentment really evolves. So I believe that can happen with works of art as well. That's the only reason I mentioned Van Gogh. Are there other examples? I don't think I would probably disagree with you about whether I like the same one you like or don't like. I'm not so sure I would disagree in most cases. But what I'm saying is that there's an evolution of feelings that you may not pick up in just a moment when you're looking at a work of art, even if it's based on unconscious experience because there's a trajectory that has some bearing on what we think about the art and literature in the long term. You work our way through it. There is a difference. You are making an unsupported conjecture which may or may not be true. It could be true possibly in your field. But in our there are no measurements so far. Measurements have to be done by apparatus exactly like me. The meters those experiments have not yet been done. I would like to bring it back to the question of coding and point out that when we talk about code, we are talking about mediation. We are talking about something that is created and that the form of creation is not transparent. And I think the problem here with this question is partly that we are only talking about visual art and visual art allows us to persist in this very strange assumption that visual art is unmediated. That visual art is not encoded. And your assumptions about our responses to visual art rely on an assumption about visual art that it is not encoded and that it lacks historicity. But if we, so what would you say for instance if we had someone from I don't know 200 years ago or from a different country or from a different social position and they had the happy meter and they looked at a piece of visual art which is entirely encoded and they had the opposite reaction. So I mean what you are basically assuming here is that the visual art lacks any artistry as such and that our response to it is a purely one to one relationship between this sort of non-mediated thing that it does to our body. And let me just add to you in this point the assumption also is that as you were saying earlier it is unconscious but not just unconscious somatically unconscious which leaves out the, you know anything that might be cognitive or intellectual. The, you know that art actually might teach us things or change the way that we think or that might be actually conscious responses to or processes or you know or dynamics involved in encountering not only visual works of art but especially literary ones. And I mean again like that's one account of maybe what an artwork does but it's an is an ought to do but it's a, but it seems to me a kind of you know a pretty small one. I have an answer to this statement. Based on unconfirmed data there seems to be a majority of invariant response from all people all races all cultures roughly estimated 80% and the other 20% is cultural locally variant. But those of us who were in the topic we claim based upon unconfirmed data that about 80% is invariant across all people. And this is the type of responses instantaneous. I ask you a question in neuroscience they're finding out more and more that the placebo effect is partly based on placebo readiness and receptivity in the individual. Is there any placebo effect in relationship to how people respond to these different codes. And the expression of the codes and the effect on the body in what you're describing. Well the honest answer is I have not thought about this deeply about I think the answer is yes that's my suspicion because you are conditioned and this goes back to that we believe Google more than ourselves and so if the happy meters and happy then I think I have to be happy and if I look at painting like one of these are which has been given the reputation of being the most beautiful painting in the world and I have to feel that. And so the happy me to show me that that sort of seems to me to confirm your. Yes the expectation that this is rewarding and stuff that like yes. Okay I would like to go ahead. It's just another put another pay in for computation and narrative. Before you said like one of the positives of trying to apply an AI system right is comes from the or a set of them come from the work you have to do to get there. Right so so that these questions we're asking about is an instantaneous response or not is it something that you can measure from a watch is it might is it a mood ring right taking a little camera of my mood ring right that we that to to go along the path of we're going to optimize or we're going to make efficient the creation of a work of art or something like that means that we need to step back and break that down into pieces. So first of all how are we going to decide that something is great or not is it is it our our physiological response is it a survey that we give someone six months later you're still thinking about this has this changed your opinion like like we can now sit and talk about what are the variables that might that might give rise to this and by talking about those set variables we are doing a lot of actual real work to kind of understand and think about it theorize about the ways in which we appreciate art and that's coming from what's fundamentally a computational question the first place. Yeah. You remind me I was I'm glad you mentioned that because I was about to again challenge Jonathan about his idea that eventually this will be something that will happen I'll tell you what I mean I want to apply what Mark just said. I know I was thinking in a way I you may be again likely contradicting yourself so lightly here in this sense but if you say okay well the solution that Niko's has suggested you absolutely reject that couldn't possibly produce art of you know equal to a human or it's the wrong way to go about performing so the question would be and I maybe Mark is beginning to provide an answer so what do you think other than time what else might get us there. I was saying it's the wrong way of judging work. Yeah. No I would be a way that would allow to allow me machine learning to generate the sort of thing that we think would be equal to a human so-called genius. I mean first of all I don't know because that's not what I do but the but I go from my gatherer and again what I didn't say I wasn't predicting anything because I would have no grounds to make any predictions. I just said I have no problem with the idea that that very that you know very powerful artificial intelligence might be able to write a novel that someone might actually read and not understand that it was written by a machine and not a person but that's because actually that program has been fed you know a gajillion novels written by humans so it actually seems to me that the achievement there is not as huge and kind of world creating as might be as others might claim. Which is just a you know it's just a computing step in computing power and the way that computers work with work with linguistic objects that have been you know around and created by humans with whose computational systems are you know web you still seem to be unsure about what criteria you could apply to train the computer. I mean the ones you would say I guess you'd say the zonicos is suggestion at least in the middle arts would be too simplistic and it wouldn't. No you said the my suggestion is moderately wrong. Okay well it may be. This is a suggestion of judgment right now. Yeah you know so I think that the I think the question of like you know judgment is going to be this or the criteria judgment will be the same whether or not we are reading a book that's written by a computer or whether or not you're reading a book by a human being. I think maybe you know there's a kind of like touring test level in which it might be interesting to see if something could be you know picked up and read and mistaken. I think that that tells you more again about the powers of the computer than it tells you about the nature of you know of literary fiction or literary art simply because what the computer is doing is trying to actually figure out a way of like you know it's reengineering something by amassing massive examples and trying to create something that's like them. That would be the same whether you know the author is machine or person. Especially with nonfiction writing when computers can actually like write papers for example so like there's you know this plagiarism software which can detect whether or not a student has a copy to paper. You can track down sometimes you know whether or not another human being has written it for money but whether there will soon be programs available that will can have a machine write a paper for you if you simply input what the topic is and what the sources are. The answer is it has this has been done. It can. So that presents a real question of judgment I think actually like where again like it's where the question is like you know has the human written that has a machine written that has a real you know kind of important practical dimension to it. And we are actually doing what you just described not for literature but for marketing for simpler and tasks and we are having humans there in our hardware and our tools and then checking whether they respond differently to human designed and we are I'm at business school so we use marketing concept or from cheap developed from cheap history and we don't know the answer yet but in half a year I can tell you. No one's raised the possibility that because humans have free will yet I'm just going to throw that out there. And computers don't wait let me finish that they do the humans are free will and we may have access to let's say an infinite realm including fictional world that don't exist yet and I'm going to have that you create a fictional world that hasn't been in literature so far. The computer might be able to come close maybe but maybe not but don't know when it seems to have taken that possible slam. I knew you were going to say that. Of course there's no free will because free will means that from the stuff in the trash. I think the problem is free will seems to me maybe the to be leading us down the wrong path I mean because I think I'm not sure it solves the question for us in the way that you might want to but maybe just thinking about this is something about the imagination. It seems like what you're trying to get at like that humans have a kind of imagined the capacity to create something that has never existed before an entire world or just simply a community of other humans and problems specific to them. And then is that something that if you give enough examples like feed a computer like you know hundreds and thousands of novels whether the computer could figure out what it means to create a world that has never existed before based on a kind of you know imitation of what it is read. Without lacking the without having the human imaginative capacity to do it on its own without having done all that reading. I think that's you know I mean that I guess is a kind of interesting question about like what gets added to these kind of just acts of basic like imitation and slight adjustment and whether or not there's something special that goes into something that's special that's very detectable by a reader in an artifact that's created by human versus an artifact that's created by computer. That's why I'm writing in the subtitle the Procellation of what's not there. Yeah because there are things that are not there yet and computers can. Right the question is can they get so advanced they can imagine something that humans can imagine. It's impossible to me but it's an interesting question. I think we keep talking about computers as if they aren't human. They come from us like we made them we made we're the ones who are programming them. We are the ones who put the metaphors forward through which certain things are easy to express or hard to express. We're the ones who are collecting the data. We're the ones who setting up the individual criteria upon which it's running and which it's trying to evaluate it. We're the ones putting putting all that together. It's us. So it is a human thing I think to say that we invented hammers too and to do a hammer everything is in hell. Isn't that what they say? Yes. They say that. What they mean by that is that someone using a hammer everything appears in hell which I think is part of Mars coin. There's a more sophisticated hammer. I think that my students I mean I teach computational journalism and we spend some time with natural language processing which is sort of computers applied to creation of language to the Alice's language. We play with GPT three off and on and ask them what are the tasks that are what kinds of things could you as a journalist imagine using the score. There are certain data chain things you can do. Like when New York State started publishing statistics about monkeypox it was putting it out on the health department website as a sentence. Last week there were five cases in New York City. There were three cases in something county that were NGB three would do. You could ask it to do to fleet take that number and put it into a tape those data put it into a table and it would happily do that for you. You could also ask it write me something about a story about what's happening at the border. Well problem is GPT three is not is trained up to like 2014 something like that. So if you mentioned something about Ukraine it's not a contemporary situation it's a past situation. But I think that what I wanted to say is that the way you interact with GPT three it's looking to complete an idea. It's trained on a bank of literature as you suggest. But what the underlying prediction problem is trying to do is to say given them this far in the sentence or this far into the paragraph or whatever it is what comes next. It's always just like guessing what comes next to generate. So you can start and you can do what's called prompt programming and start it you know often in a direction so easiest kind of prompt. You could say English colon hi French colon Bonjour English colon skyscraper French colon and it'll give you what the French translation of skyscraper. Thank you. And then you could ask it to you could start to ask it to you know here's here's an example of five yellow reviews of a particular thing identified to that have sort of racially biased whatever right so you can start to sort of weave it in and there are various ways in which you might interact with a GPT three through through divine defining these prompts and you can chain them together and almost start to build programming ideas that I believe you could sort of teach the fundamentals of computational thinking through a GPT three style interface because it's all just language at that point you're not you know do you know for I and one does something or they do this right I think you are you are pulling apart computational computational questions by by giving instructions to a machine and seeing what comes back. And there's always this moment of oh I didn't expect that. Oh look what happened there right and there's a little bit of delight and whatever that comes from interacting with these systems and I think I think again it comes down to to to to to be open enough and having the exposure to to what these computational systems are all about to be able to ground that conversation and to say all right this is where it might be useful this is where it might be dangerous and we can start to make choices. I think thank you I think we should open the floor up to questions and please I'm going to put the microphone up there. Come on up here. So thank you so much for this lively discussion I'm here since then and in the heating meter I think you score the highest figures so far so thanks. I have a comment and a question the comment is being having involved in some empirical research on aesthetics. I think one is to distinguish the tools from the questions so with the same tools you can ask different questions you can be interested in spotting the place in the brain where beauty sits which is a few millimeters away from where the sublime sits and legitimate question to be to be asked but it's not my cup of tea or you can be more interested in the experience in front of some cultural artifacts and then starts the difficulty because our experience is always situated. So you can do it in easy experiment think about your favorite piece of music and listening to it while you're contemplating your favorite landscape with respect to when you're filling your tax form. So the physiology up to a certain point is clearly the same you you activate the same or theatory pathway blah blah blah but then in the end the experience is completely different. So one of the greatest difficulties is to contextualize the experience within the individual in different time of this life so it's incredibly difficult. The question relates to the parallel between narrative and coding. So if we can draw such a parallel and entertain the idea that narrative is a particular form of coding. Can we also push it to say to the point to entertain the idea that they are more similar than they might look at first sight because narrative in itself is the outcome of a specific cognitive technology. There are people who have been suggesting that the first form of narrative stems from the syntax of movement, the Shenoupe Ratua, Le Raguaran for example, was one of the earliest proposals of such theory. So can this be this idea how does it sound to you? Do you think it is legitimate or? I don't think that I quite understand the claim that narrative is based on a syntax of movement. I think at its fundamentals narrative is based on an expression of causation. And the root can be traced in a time of human evolution when the main activity was utility. The main object whose main purpose is not to serve a specific need but the only purpose is to say something to someone else. Can we trace is there a red line, a continuum between the motor syntax that enables the production of tools for example, with the motor syntax, the narrative syntax that enable you to produce an average, a feature of narrative. Does it sound crazy? I'll close it. Yeah, I mean, it's an interesting way of thinking. I'm not really sure how you would explore the phenomena, to be honest. I mean, like, or it seems like a good prompt for thinking. Yeah, it's kind of a judgement story. A little bit. I think that I share a Nina's intuition that there's a kind of deeply causal structure to most narratives if you want to get them to their simplest structure. And establishing connections between one event and another. The on the side of response, like, why is it that we seem to have a kind of appetite again? It's just so sort of phrased but for want to have a better term. Like, why we have an appetite for stories and narratives presents, you know, is to come at it from the other side, sort of more, you know, on this sort of level of like, you know, consumption rather than the production of stories or what stories are. And I could be there that some of the kind of, some of the deep history you're talking about actually plays an important role. Maybe I'll stop there. I think it's a very, it's a complicated question. I think we're all having a little difficult time wrapping our minds around. Not because it's crazy because you asked, I wouldn't have used that adjective. But you asked, but no, no, no, no, I really mean that. I don't know. I think it's interesting to think, you know, the one criticism of some books is that some literature is like, you know, nothing happens in this story, right? And that doesn't mean that's a valid, that's only one way you can look at it. But more advanced forms of literature, there were, there are more stories where it's more internal that goes on in the story. And some people don't go for that because obviously Homer, in Homer, a lot of action is happening. Closation and movement are closely related. So for sure, we know was based on the idea of one billion ball, ball, that's another, that's sort of a paradigm for causation. So, yeah. There's a connection to between your initial comment and your question, which is that, and I agree entirely with your formulation that you gave of the situatedness of any aesthetic response, which I think raises some real problems for the idea that you could just kind of connect it to something like a happiness meter, which is intrinsically decontextualized, it's just like attached to you. And I think that that raises questions around how you would, I mean, most of the way that we think and talk about artificial intelligence in the way that it can pose the stories is unsituated, that is the program has no situation. It's lifted out from the world. And it's only access to the world is through what we feed it, through other stories, and through a writing of code. That seems to me, I mean, the picture that you were giving, which I know is one that you hold closely, is that of a kind of much of a more embodied interaction with the world, not embodied in the sense of, you know, the kind of unmoving physiology of someone who is just reading or looking at something and then attached to a meter, but actually acting in the world, moving around in it. And there, I think, you know, our agree the entirely. Anyone else? Good to see you. I have a couple of colleagues here. I'm one of Jonathan's friends at Yale. I was struck by the conversation about code from the beginning in that it didn't seem that we could ever, like there was ever really a consensus about what a code is, that there's a lot of sort of implicit understanding about who, like, the difference between, you know, code switching and language and computer code. And like, so I, you know, while I was sitting there at Google, a little bit of etymological, I was just thinking about where these words come from and code comes from codecs. It comes from the book of laws that were established that everyone kind of referenced as a kind of index of cultural authority, right? That was the sort of where we get the word code. The idea of code as a cipher or system of signals and the rules which govern their use isn't until 1808. And then, you know, in subsequent decades, you get Morse code and things like that. But the idea of it as a system of expressing information and instructions in the form, usable by a computer, is not until 1946 and 47 when it becomes a verb. So what I want to ask is, do you understand code as being something that a computer is the sort of repository or archive of, or is it something that the computer does or that we do to a computer? And I ask because it strikes me as an interesting question about decoding. Does the computer decode what we give it? And my assumption is no, the computer doesn't understand what's encoded, it just processes information. But because it's described as code, there's almost a way in which the machine is sort of like from the origin of the term takes on this sort of humanistic aura that it's this thing that can do what we do, which is decode. But in fact, machines don't decode, they just churn. I mean, I guess you could program something to decode something else, but that's different than saying in the way that we would decipher a cipher. So tell me about code, why is it, why is, why are we using this term to describe what computers do? Well, I would actually just say the other way around, and I would say computer is capable of repeatably exactly in the same way as many times as I wanted, executing my code, whereas if you have a codecs and you have humans interpreting it, then we have all these contexts, and so it's not repeatable. And you don't know because you have the mood of the day and many other influences. And so I think in that sense, the computer is from a consistent. I think all of the senses, the animal article senses that you gave, I think they're fairly consistent, and they do all come back to the sense of a set of rules. And whether that's a set of rules for behavior, in the case of when you give a computer certain lines of code, those are then rules that determine what it will do, what it will produce, or if it's a code, say in narrative, the fundamental set of rules that govern what a narrative is, that all of those different senses of code seem to me like compatible with this idea of a set of rules. So, I mean, I guess if I were to say what is a code, I'm comfortable with it's a set of fundamental principles or rules that govern the generation of something further. Anything else? Okay. Which is, yes, what you said is true, but the asymmetric conditions of the creation of code is inseparable from the cryptographic history, right? So, understanding that, because that's one thing that I'm a magician, and I track asymmetric information conditions, and I interact with a lot of academics. And one thing I find fascinating is that in these discussions, the asymmetric information condition associated with codes and information systems in general is not so well tracked or brought up in these conversations. So, to his point, I think there's something much more deep under what he's saying that's actually quite relevant these days to track how this information, what's the nature of information, we know unique and interoperable data is incredibly valuable. But it really takes a kind of cryptographer, my father-in-law was a naval commander in Holland who worked at NATO Command, and then I have a lot of friends in mathematics at places like the Institute for Defense Analysis, and I think they'd have a lot to say about this conversation. So, and I think those things are especially relevant today, so I'm just backing up your point, really. Well, thank you. Thank you for another wonderful panel. I want to make a question that's going to connect us with the previous panel. Is the publishing of, let's say, computer-generated novel misinformation if I don't disclose that it's being generated by a computer? Well, sure, I mean, in some level, if you define it as information, the question is whether or not... Well, I'm sure, because the computer has been generated by humans. There you go. It's a good answer. I think in journalistic applications, when a story has been written has been automated, even if it's human-edited, the bylines you just, it's been done by an AI. But we do attribute middle marks to George Eliot, right? Even though she wasn't a man, that's my point. Yeah, what does it matter? Yeah, so, question, I think the, from what I understand about the previous panel, was about misinformation, which has a real kind of social effect, or a political effect. And in this case, I mean, it might, that would depend upon the context in which the information mattered. As such, it would be either in some literal sense misleading or withholding, but it wouldn't necessarily. Whether or not it counts as misinformation in the social meaning of that term today, which is really quite important, would depend entirely on the context that day. I think it would be misinformation if you claimed that it was a work of nonfiction, but it would not be misinformation if you gave it the label of fiction. That's all right. Well, everyone, I want to thank you again for an amazing roundtable. I want everyone to know that we're returning here tomorrow morning at 11 for the first roundtable is entitled, Our Natural Language Generators for Real, which is about GPT-3 that we spoke of tonight. And then we'll end the conference with, is the universe a metaverse, and that begins at 2pm. So thank you again, everyone. It was wonderful. Thank you. Thank you.